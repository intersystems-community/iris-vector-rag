"""
Results Display Component

Renders query results, retrieved documents, and performance metrics.
"""

import json
import time
from typing import Any, Dict, List

import streamlit as st
from utils.pipeline_integration import QueryResult


def render_query_result(result: QueryResult, show_details: bool = True):
    """
    Render a complete query result.

    Args:
        result: QueryResult object containing all result data
        show_details: Whether to show detailed information
    """
    if not result.success:
        render_error_result(result)
        return

    # Main answer section
    render_answer_section(result)

    if show_details:
        # Retrieved documents section
        render_retrieved_documents(result.retrieved_documents, result.pipeline)

        # Performance metrics
        render_performance_metrics(result)

        # Metadata and debugging info
        if st.session_state.get("debug_mode", False):
            render_debug_info(result)


def render_answer_section(result: QueryResult):
    """Render the main answer section."""
    st.markdown("### üí¨ Generated Answer")

    # Pipeline indicator
    pipeline_info = get_pipeline_display_info(result.pipeline)

    col1, col2, col3 = st.columns([1, 2, 1])

    with col1:
        st.markdown(f"**{pipeline_info['icon']} {result.pipeline}**")

    with col2:
        st.markdown(f"*Execution Time: {result.execution_time:.2f}s*")

    with col3:
        # Quality indicator (mock for now)
        quality_score = estimate_answer_quality(result.answer)
        quality_color = (
            "green"
            if quality_score > 0.8
            else "orange" if quality_score > 0.6 else "red"
        )
        st.markdown(
            f"<div style='text-align: right; color: {quality_color};'>Quality: {quality_score:.1%}</div>",
            unsafe_allow_html=True,
        )

    # Answer content
    st.markdown("---")

    if result.answer:
        # Display answer with nice formatting
        st.markdown(
            f"""
        <div style="
            background-color: #f8f9fa;
            border-left: 4px solid #1f77b4;
            padding: 1rem;
            border-radius: 0 0.375rem 0.375rem 0;
            margin: 1rem 0;
        ">
            {result.answer}
        </div>
        """,
            unsafe_allow_html=True,
        )

        # Answer actions
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            if st.button("üëç Helpful", key=f"helpful_{result.pipeline}"):
                st.success("Thank you for your feedback!")

        with col2:
            if st.button("üëé Not Helpful", key=f"not_helpful_{result.pipeline}"):
                st.info(
                    "Feedback noted. Try a different pipeline or refine your query."
                )

        with col3:
            if st.button("üìã Copy Answer", key=f"copy_{result.pipeline}"):
                st.session_state[f"copied_answer_{result.pipeline}"] = result.answer
                st.success("Answer copied to clipboard!")

        with col4:
            if st.button("üì§ Share", key=f"share_{result.pipeline}"):
                share_url = generate_share_url(result)
                st.info(f"Share URL: {share_url}")
    else:
        st.warning(
            "No answer was generated. Try rephrasing your query or checking pipeline configuration."
        )


def render_retrieved_documents(documents: List[Dict[str, Any]], pipeline: str):
    """Render retrieved documents section."""
    if not documents:
        st.warning("No documents were retrieved.")
        return

    st.markdown("### üìÑ Retrieved Documents")
    st.markdown(f"*Found {len(documents)} relevant documents*")

    # Document display options
    col1, col2, col3 = st.columns(3)

    with col1:
        show_full_content = st.checkbox(
            "Show Full Content", key=f"full_content_{pipeline}"
        )

    with col2:
        show_metadata = st.checkbox(
            "Show Metadata", value=True, key=f"metadata_{pipeline}"
        )

    with col3:
        sort_by = st.selectbox(
            "Sort by:", ["Relevance", "Title", "Source"], key=f"sort_{pipeline}"
        )

    # Sort documents
    sorted_docs = sort_documents(documents, sort_by)

    # Display documents
    for i, doc in enumerate(sorted_docs):
        render_single_document(doc, i, show_full_content, show_metadata, pipeline)


def render_single_document(
    doc: Dict[str, Any], index: int, show_full: bool, show_metadata: bool, pipeline: str
):
    """Render a single document."""
    with st.expander(
        f"üìÑ Document {index + 1}: {doc.get('title', 'Untitled')}", expanded=index < 2
    ):

        # Document header
        col1, col2 = st.columns([3, 1])

        with col1:
            st.markdown(f"**Title:** {doc.get('title', 'Untitled')}")
            if doc.get("metadata", {}).get("source"):
                st.markdown(f"**Source:** {doc['metadata']['source']}")

        with col2:
            # Relevance score
            score = doc.get("metadata", {}).get("score", 0.0)
            if score > 0:
                score_color = (
                    "green" if score > 0.8 else "orange" if score > 0.6 else "red"
                )
                st.markdown(
                    f"<div style='text-align: right; color: {score_color};'>Score: {score:.3f}</div>",
                    unsafe_allow_html=True,
                )

        # Document content
        content = doc.get("content", "")

        if content:
            if show_full:
                st.markdown("**Content:**")
                st.markdown(content)
            else:
                # Show truncated content
                preview = content[:300] + "..." if len(content) > 300 else content
                st.markdown("**Preview:**")
                st.markdown(preview)

                if len(content) > 300:
                    if st.button(
                        f"Show Full Content", key=f"expand_{pipeline}_{index}"
                    ):
                        st.markdown("**Full Content:**")
                        st.markdown(content)

        # Metadata
        if show_metadata and doc.get("metadata"):
            st.markdown("**Metadata:**")
            metadata = doc["metadata"]

            # Format metadata nicely
            metadata_display = {}
            for key, value in metadata.items():
                if key not in ["score"]:  # Skip score as it's shown above
                    metadata_display[key] = value

            if metadata_display:
                st.json(metadata_display)

        # Document actions
        col1, col2, col3 = st.columns(3)

        with col1:
            if st.button("üìã Copy", key=f"copy_doc_{pipeline}_{index}"):
                st.session_state[f"copied_doc_{pipeline}_{index}"] = content
                st.success("Document copied!")

        with col2:
            if st.button("üîç Analyze", key=f"analyze_{pipeline}_{index}"):
                render_document_analysis(doc)

        with col3:
            if st.button("üì§ Export", key=f"export_doc_{pipeline}_{index}"):
                export_document(doc, f"document_{index + 1}")


def render_performance_metrics(result: QueryResult):
    """Render performance metrics section."""
    st.markdown("### üìä Performance Metrics")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            "Execution Time",
            f"{result.execution_time:.2f}s",
            help="Total time to process the query",
        )

    with col2:
        st.metric(
            "Documents Retrieved",
            len(result.retrieved_documents),
            help="Number of relevant documents found",
        )

    with col3:
        # Token usage estimate
        token_estimate = estimate_token_usage(result)
        st.metric(
            "Est. Tokens",
            f"{token_estimate:,}",
            help="Estimated token usage for this query",
        )

    with col4:
        # Confidence score
        confidence = result.metadata.get("confidence", 0.85)
        st.metric(
            "Confidence", f"{confidence:.1%}", help="Pipeline confidence in the result"
        )

    # Additional metrics in expander
    with st.expander("üìà Detailed Metrics"):

        # Create metrics chart data
        metrics_data = {
            "Retrieval Time": result.metadata.get(
                "retrieval_time", result.execution_time * 0.3
            ),
            "Generation Time": result.metadata.get(
                "generation_time", result.execution_time * 0.7
            ),
            "Processing Time": result.metadata.get(
                "processing_time", result.execution_time * 0.1
            ),
        }

        # Simple bar chart using HTML/CSS
        for metric, value in metrics_data.items():
            percentage = (value / result.execution_time) * 100
            st.markdown(
                f"""
            <div style="margin-bottom: 1rem;">
                <div style="display: flex; justify-content: space-between; margin-bottom: 0.25rem;">
                    <span>{metric}</span>
                    <span>{value:.3f}s ({percentage:.1f}%)</span>
                </div>
                <div style="background-color: #e9ecef; border-radius: 0.375rem; overflow: hidden; height: 1rem;">
                    <div style="background-color: #1f77b4; height: 100%; width: {percentage}%; transition: width 0.3s ease;"></div>
                </div>
            </div>
            """,
                unsafe_allow_html=True,
            )


def render_error_result(result: QueryResult):
    """Render error result."""
    st.error(f"‚ùå Query failed for {result.pipeline}")

    if result.error:
        st.markdown(f"**Error:** {result.error}")

    st.markdown(f"**Execution Time:** {result.execution_time:.2f}s")

    # Troubleshooting suggestions
    with st.expander("üîß Troubleshooting"):
        st.markdown(
            """
        **Common solutions:**
        - Check if the pipeline is properly initialized
        - Verify database connectivity
        - Try a simpler query
        - Reduce the number of top_k results
        - Check pipeline-specific configuration
        """
        )

        if st.button("üîÑ Retry Query", key=f"retry_{result.pipeline}"):
            st.session_state.retry_query = True
            st.rerun()


def render_debug_info(result: QueryResult):
    """Render debugging information."""
    with st.expander("üêõ Debug Information"):
        st.markdown("**Query Details:**")
        st.code(
            f"Pipeline: {result.pipeline}\nQuery: {result.query}\nExecution Time: {result.execution_time:.2f}s"
        )

        st.markdown("**Metadata:**")
        st.json(result.metadata)

        st.markdown("**Raw Result:**")
        debug_data = {
            "success": result.success,
            "pipeline": result.pipeline,
            "query": result.query,
            "answer": result.answer,
            "num_documents": len(result.retrieved_documents),
            "contexts": len(result.contexts),
            "execution_time": result.execution_time,
            "metadata": result.metadata,
            "error": result.error,
        }
        st.json(debug_data)


# Helper functions
def get_pipeline_display_info(pipeline: str) -> Dict[str, str]:
    """Get display information for a pipeline."""
    info = {
        "BasicRAG": {"icon": "üìù", "color": "#1f77b4"},
        "BasicRerank": {"icon": "üéØ", "color": "#ff7f0e"},
        "CRAG": {"icon": "üîÑ", "color": "#2ca02c"},
        "GraphRAG": {"icon": "üï∏Ô∏è", "color": "#d62728"},
    }
    return info.get(pipeline, {"icon": "‚ùì", "color": "#666666"})


def estimate_answer_quality(answer: str) -> float:
    """Estimate answer quality based on simple heuristics."""
    if not answer:
        return 0.0

    # Simple quality scoring
    score = 0.5  # Base score

    # Length scoring
    if 50 <= len(answer) <= 1000:
        score += 0.2

    # Structure scoring
    if "." in answer:
        score += 0.1
    if answer.count(".") >= 2:
        score += 0.1

    # Content scoring
    quality_indicators = ["research", "study", "evidence", "data", "analysis"]
    for indicator in quality_indicators:
        if indicator.lower() in answer.lower():
            score += 0.02

    return min(1.0, score)


def estimate_token_usage(result: QueryResult) -> int:
    """Estimate token usage for the query."""
    # Simple estimation: ~4 characters per token
    query_tokens = len(result.query) // 4
    answer_tokens = len(result.answer) // 4
    context_tokens = sum(len(ctx) // 4 for ctx in result.contexts)

    return query_tokens + answer_tokens + context_tokens


def sort_documents(
    documents: List[Dict[str, Any]], sort_by: str
) -> List[Dict[str, Any]]:
    """Sort documents based on the specified criteria."""
    if sort_by == "Relevance":
        return sorted(
            documents, key=lambda x: x.get("metadata", {}).get("score", 0), reverse=True
        )
    elif sort_by == "Title":
        return sorted(documents, key=lambda x: x.get("title", "").lower())
    elif sort_by == "Source":
        return sorted(
            documents, key=lambda x: x.get("metadata", {}).get("source", "").lower()
        )
    else:
        return documents


def render_document_analysis(doc: Dict[str, Any]):
    """Render document analysis."""
    st.markdown("**Document Analysis:**")

    content = doc.get("content", "")

    # Simple analysis
    analysis = {
        "Word Count": len(content.split()),
        "Character Count": len(content),
        "Estimated Reading Time": f"{len(content.split()) // 200 + 1} min",
        "Key Topics": extract_key_topics(content),
    }

    for key, value in analysis.items():
        st.markdown(f"**{key}:** {value}")


def extract_key_topics(content: str) -> str:
    """Extract key topics from content (simplified)."""
    # Simple keyword extraction
    common_words = set(
        [
            "the",
            "a",
            "an",
            "and",
            "or",
            "but",
            "in",
            "on",
            "at",
            "to",
            "for",
            "of",
            "with",
            "by",
        ]
    )
    words = [word.lower().strip(".,!?;:") for word in content.split()]
    word_freq = {}

    for word in words:
        if len(word) > 3 and word not in common_words:
            word_freq[word] = word_freq.get(word, 0) + 1

    # Get top 5 most frequent words
    top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:5]
    return ", ".join([word for word, freq in top_words])


def export_document(doc: Dict[str, Any], filename: str):
    """Export document to file."""
    # This would normally trigger a download
    st.success(f"Document exported as {filename}.json")


def generate_share_url(result: QueryResult) -> str:
    """Generate a shareable URL for the result."""
    # This would normally generate a proper shareable URL
    return f"https://rag-demo.example.com/shared/{result.pipeline}?q={result.query[:50]}..."
