#!/usr/bin/env python
"""
RAG with Real Data Demo

This script demonstrates how to use the RAG techniques with real IRIS data.
It runs both Basic RAG and ColBERT RAG using the same query, allowing you 
to compare the results.
"""

import argparse
import logging
import sys
import time
import numpy as np
from typing import List, Dict, Any, Callable

from common.iris_connector import get_iris_connection
from common.utils import Document
from basic_rag.pipeline import BasicRAGPipeline
from colbert.pipeline import ColBERTPipeline

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

def get_mock_embedding_function(embedding_dim: int = 384) -> Callable:
    """
    Get a mock embedding function for testing without dependencies.
    
    Args:
        embedding_dim: Dimension of the embeddings to generate
        
    Returns:
        A function that generates mock embeddings
    """
    def mock_embed_func(text):
        """Generate a mock embedding for text."""
        if isinstance(text, str):
            text = [text]
            
        embeddings = []
        for t in text:
            # Create a deterministic but unique embedding based on text
            np.random.seed(hash(t) % 10000)
            embedding = np.random.randn(embedding_dim)
            # Normalize
            embedding = embedding / np.linalg.norm(embedding)
            embeddings.append(embedding)
            
        return embeddings
    
    return mock_embed_func

def get_mock_token_embedding_function(embedding_dim: int = 128) -> Callable:
    """
    Get a mock token-level embedding function for ColBERT.
    
    Args:
        embedding_dim: Dimension of the token embeddings to generate
        
    Returns:
        A function that generates mock token-level embeddings
    """
    def mock_token_embed_func(text):
        """Generate mock token-level embeddings."""
        import re
        
        # Simple tokenization for testing
        tokens = re.findall(r'\w+|[^\w\s]', text.lower())
        tokens = tokens[:50]  # Limit to 50 tokens
        
        token_embeddings = []
        for i, token in enumerate(tokens):
            # Create deterministic but "unique" embedding based on token and position
            np.random.seed((hash(token) + i) % 10000)
            embedding = np.random.randn(embedding_dim)
            # Normalize
            embedding = embedding / np.linalg.norm(embedding)
            token_embeddings.append(embedding)
            
        return token_embeddings
    
    return mock_token_embed_func

def get_mock_llm_function() -> Callable:
    """
    Get a mock LLM function for testing.
    
    Returns:
        A function that generates mock LLM responses
    """
    def mock_llm_func(prompt):
        """Generate a mock LLM response."""
        # Extract the question from the prompt
        import re
        question_match = re.search(r'Question:\s*(.*?)(?:\n|$)', prompt)
        question = question_match.group(1) if question_match else "Unknown question"
        
        # Create a deterministic response based on the question
        response = f"This is a mock answer to the question: '{question}'. "
        response += "In a real implementation, this would be generated by an LLM based on the retrieved documents."
        
        return response
    
    return mock_llm_func

def run_basic_rag(connection, query: str, top_k: int = 5) -> Dict[str, Any]:
    """
    Run Basic RAG retrieval and answer generation.
    
    Args:
        connection: IRIS connection (real or mock)
        query: Query text
        top_k: Number of documents to retrieve
        
    Returns:
        Dictionary with results
    """
    logger.info(f"Running Basic RAG for query: '{query}'")
    
    # Create embedding and LLM functions
    embedding_func = get_mock_embedding_function()
    llm_func = get_mock_llm_function()
    
    # Create and run the pipeline
    start_time = time.time()
    pipeline = BasicRAGPipeline(
        iris_connector=connection,
        embedding_func=embedding_func,
        llm_func=llm_func
    )
    
    results = pipeline.run(query, top_k=top_k)
    end_time = time.time()
    
    # Add timing information
    results["execution_time"] = end_time - start_time
    
    return results

def run_colbert_rag(connection, query: str, top_k: int = 5) -> Dict[str, Any]:
    """
    Run ColBERT RAG retrieval and answer generation.
    
    Args:
        connection: IRIS connection (real or mock)
        query: Query text
        top_k: Number of documents to retrieve
        
    Returns:
        Dictionary with results
    """
    logger.info(f"Running ColBERT RAG for query: '{query}'")
    
    # Create token embedding and LLM functions
    token_embedding_func = get_mock_token_embedding_function()
    llm_func = get_mock_llm_function()
    
    # Create and run the pipeline
    start_time = time.time()
    pipeline = ColBERTPipeline(
        iris_connector=connection,
        colbert_query_encoder=token_embedding_func,
        llm_func=llm_func,
        client_side_maxsim=True  # Use client-side calculation
    )
    
    results = pipeline.run(query, top_k=top_k)
    end_time = time.time()
    
    # Add timing information
    results["execution_time"] = end_time - start_time
    
    return results

def format_results(title: str, results: Dict[str, Any]) -> str:
    """
    Format results for display.
    
    Args:
        title: Title for the results
        results: Results dictionary
        
    Returns:
        Formatted string
    """
    output = [f"\n===== {title} ====="]
    output.append(f"Query: {results['query']}")
    output.append(f"Answer: {results['answer']}")
    output.append(f"Execution Time: {results['execution_time']:.2f} seconds")
    output.append(f"Retrieved {len(results['retrieved_documents'])} documents:")
    
    for i, doc in enumerate(results['retrieved_documents']):
        # Truncate content for display
        content_preview = doc.content[:100] + "..." if len(doc.content) > 100 else doc.content
        output.append(f"  {i+1}. Document '{doc.id}' (score: {doc.score:.4f})")
        output.append(f"     {content_preview}")
        
    return "\n".join(output)

def parse_args() -> argparse.Namespace:
    """Parse command-line arguments"""
    parser = argparse.ArgumentParser(
        description="Demonstrate RAG techniques with real data"
    )
    
    parser.add_argument(
        "--query", 
        type=str, 
        default="What is the role of inflammation in disease?",
        help="Query text to use for retrieval"
    )
    
    parser.add_argument(
        "--top-k", 
        type=int, 
        default=5, 
        help="Number of documents to retrieve"
    )
    
    parser.add_argument(
        "--mock", 
        action="store_true", 
        help="Use mock IRIS connection"
    )
    
    parser.add_argument(
        "--technique", 
        type=str, 
        choices=["basic", "colbert", "both"],
        default="both", 
        help="Which RAG technique to demonstrate"
    )
    
    parser.add_argument(
        "--verbose", 
        action="store_true", 
        help="Show verbose output"
    )
    
    return parser.parse_args()

def main() -> int:
    """Main function"""
    args = parse_args()
    
    # Configure logging
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Connect to IRIS
    logger.info(f"Connecting to IRIS (using {'mock' if args.mock else 'real'} connection)")
    connection = get_iris_connection(use_mock=args.mock)
    if not connection:
        logger.error("Failed to establish IRIS connection")
        return 1
    
    try:
        if args.technique in ["basic", "both"]:
            basic_results = run_basic_rag(connection, args.query, args.top_k)
            print(format_results("Basic RAG Results", basic_results))
            
        if args.technique in ["colbert", "both"]:
            colbert_results = run_colbert_rag(connection, args.query, args.top_k)
            print(format_results("ColBERT RAG Results", colbert_results))
            
        return 0
    
    except Exception as e:
        logger.error(f"Error running demonstration: {e}")
        return 1
        
    finally:
        # Close connection
        try:
            connection.close()
            logger.info("IRIS connection closed")
        except Exception as e:
            logger.warning(f"Error closing IRIS connection: {e}")

if __name__ == "__main__":
    sys.exit(main())
