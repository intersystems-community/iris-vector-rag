import uuid
from dataclasses import dataclass, field
from typing import Any, Dict


def default_id_factory():
    """Generates a default UUID for document ID."""
    return str(uuid.uuid4())


@dataclass(
    frozen=True
)  # frozen=True makes instances hashable if all fields are hashable
class Document:
    """
    Represents a single document or a piece of text content.

    Attributes:
        page_content: The main textual content of the document.
        metadata: A dictionary of additional information about the document
                  (e.g., source, page number, author). Defaults to an empty dict.
        id: A unique identifier for the document. Defaults to a generated UUID string.
            Can be provided if a specific ID is required.
    """

    page_content: str
    # metadata will be stored as a tuple of sorted (key, value) tuples to ensure hashability
    # The __init__ generated by dataclass will still accept a dict for metadata.
    # We will handle the conversion in __post_init__, but this requires frozen=False temporarily,
    # or a custom __init__.
    # For frozen=True, we must ensure the input type is already hashable or convert it
    # before the object is frozen.
    # A common pattern is to use a property or a factory, or to accept an immutable type.

    # Let's adjust so metadata is stored as a tuple of (key, value) items, sorted for consistency.
    # We'll need a custom __init__ if we want to accept a dict and convert it while frozen=True.
    # Or, we can require the user to pass an immutable representation.

    # Simpler: For frozen dataclasses, if a field is mutable (like dict) and part of hashing/equality,
    # it causes issues. If metadata is truly part of the Document's identity for hashing,
    # it should be immutable.
    # Let's make it so that the Document is hashable by its ID primarily, and eq checks all.
    # This means we might need to implement __hash__ manually if metadata dict is kept.
    # Or, if frozen=True, all fields contributing to eq must be hashable.

    # The simplest fix for the test, given frozen=True, is to ensure metadata is stored as an immutable, hashable type.
    # We can convert it in __post_init__ by temporarily unfreezing, or by using a more complex setup.
    # OR, we can define __hash__ manually.
    # Let's try defining __hash__ manually based on all fields, converting metadata on the fly.
    metadata: Dict[str, Any] = field(default_factory=dict)
    id: str = field(default_factory=default_id_factory)

    # __eq__ is auto-generated and compares all fields.
    # For __hash__ to work with a dict field when frozen=True, it's tricky.
    # Python's default for frozen=True is: if __eq__ is True (default) and __hash__ is None (default),
    # it tries to generate __hash__. If it finds an unhashable field like dict, it fails.

    # Let's remove frozen=True for a moment to implement custom __hash__ and __eq__
    # to handle the dict correctly. Or, better, keep frozen=True and make metadata
    # a field that doesn't participate in hashing if it's a dict, or convert it.

    # The test expects doc1 == doc2, where metadata is part of comparison.
    # And it expects doc1 to be hashable.
    # The issue is that dict itself is unhashable.

    # If we keep frozen=True, we must ensure all fields are hashable.
    # We can change metadata to store an immutable representation.
    # For example, a frozenset of items.

    # Let's try this: metadata will be converted to a frozenset of its items.
    # This requires a custom __init__ or a factory, as __post_init__ can't modify fields in a frozen dataclass.

    # Alternative: Keep frozen=True, and for metadata, use a type that is hashable.
    # The test passes `metadata={"a": 1}`.
    # The simplest way to pass the test is to ensure that the `metadata` field,
    # as part of the dataclass, is treated as hashable.
    # This means the `dict` must be converted to a hashable form for the hash calculation.
    # Dataclasses with `frozen=True` will generate `__hash__` if all fields are hashable.
    # Since `dict` is not, it fails.
    # The fix is to ensure `metadata` is stored as a hashable type, e.g., `frozenset(self.metadata.items())`
    # or a tuple of sorted items.

    # Let's modify the field itself to be a tuple of tuples, and handle dict input in __init__
    # This is not possible with frozen=True and default __init__.

    # Easiest for now: make Document not frozen, and implement __eq__ and __hash__.
    # Or, for the test to pass with frozen=True, the test itself needs to ensure it passes
    # hashable metadata, or the Document needs to transform it.

    # The problem is `metadata: Dict[str, Any]`. If this is part of the hash, it fails.
    # If we make it `eq=False, hash=False` for this field, then it would work but not meet test criteria for equality.

    # Let's make metadata a field that is converted to a hashable type.
    # We can use a property, but that's for access.
    # The actual stored type needs to be hashable.

    # Simplest change to pass the test:
    # The test uses `metadata={"a": 1}`.
    # The dataclass tries to hash this dict.
    # If we change the Document to not be frozen, then __hash__ is None by default.
    # But the test `d = {doc1: "test"}` requires hashability.

    # The core issue: a frozen dataclass with a dict field used in eq comparison
    # will not auto-generate a hash function.
    # We need to provide one, or change the field type.
    # Let's provide a custom __hash__.

    def __hash__(self):
        # Convert dict to a hashable form (tuple of sorted items) for hashing
        meta_tuple = tuple(sorted(self.metadata.items()))
        return hash((self.page_content, meta_tuple, self.id))

    # Note: If __hash__ is defined, __eq__ should also be defined if not using dataclass's default.
    # Since frozen=True implies eq=True by default, the auto-generated __eq__ should be fine
    # as it compares dictionaries correctly. The issue was only hashing.

    def __post_init__(self):
        """Post-initialization checks."""
        if not isinstance(self.page_content, str):
            raise TypeError("page_content must be a string.")
        if not isinstance(self.metadata, dict):
            raise TypeError("metadata must be a dictionary.")
        if not isinstance(self.id, str):
            raise TypeError("id must be a string.")
        if not self.id:
            raise ValueError("id cannot be empty.")


@dataclass(frozen=True)
class Entity:
    """
    Represents an extracted entity from text processing.

    Attributes:
        text: The actual text span of the entity as it appears in the source
        entity_type: The type/category of the entity (e.g., PERSON, DISEASE, DRUG, etc.)
        confidence: Confidence score of the extraction (0.0 to 1.0)
        start_offset: Character offset where entity starts in source text
        end_offset: Character offset where entity ends in source text
        source_document_id: ID of the document this entity was extracted from
        metadata: Additional information about the entity (embeddings, context, etc.)
        id: Unique identifier for the entity
    """

    text: str
    entity_type: str
    confidence: float
    start_offset: int
    end_offset: int
    source_document_id: str
    metadata: Dict[str, Any] = field(default_factory=dict)
    id: str = field(default_factory=default_id_factory)

    def __hash__(self):
        """Convert dict metadata to hashable form for hashing."""
        meta_tuple = tuple(sorted(self.metadata.items()))
        return hash(
            (
                self.text,
                self.entity_type,
                self.confidence,
                self.start_offset,
                self.end_offset,
                self.source_document_id,
                meta_tuple,
                self.id,
            )
        )

    def __post_init__(self):
        """Post-initialization validation."""
        if not isinstance(self.text, str) or not self.text.strip():
            raise ValueError("Entity text must be a non-empty string.")
        if not isinstance(self.entity_type, str) or not self.entity_type.strip():
            raise ValueError("Entity type must be a non-empty string.")
        if not (0.0 <= self.confidence <= 1.0):
            raise ValueError("Confidence must be between 0.0 and 1.0.")
        if not isinstance(self.start_offset, int) or self.start_offset < 0:
            raise ValueError("Start offset must be a non-negative integer.")
        if not isinstance(self.end_offset, int) or self.end_offset < self.start_offset:
            raise ValueError("End offset must be >= start offset.")
        if (
            not isinstance(self.source_document_id, str)
            or not self.source_document_id.strip()
        ):
            raise ValueError("Source document ID must be a non-empty string.")
        if not isinstance(self.metadata, dict):
            raise TypeError("Metadata must be a dictionary.")
        if not isinstance(self.id, str) or not self.id.strip():
            raise ValueError("Entity ID must be a non-empty string.")


@dataclass(frozen=True)
class Relationship:
    """
    Represents a relationship between two entities.

    Attributes:
        source_entity_id: ID of the source entity in the relationship
        target_entity_id: ID of the target entity in the relationship
        relationship_type: Type of relationship (e.g., "causes", "treats", "interacts_with")
        confidence: Confidence score of the relationship extraction (0.0 to 1.0)
        source_document_id: ID of the document where this relationship was found
        metadata: Additional information about the relationship (context, evidence, etc.)
        id: Unique identifier for the relationship
    """

    source_entity_id: str
    target_entity_id: str
    relationship_type: str
    confidence: float
    source_document_id: str
    metadata: Dict[str, Any] = field(default_factory=dict)
    id: str = field(default_factory=default_id_factory)

    def __hash__(self):
        """Convert dict metadata to hashable form for hashing."""
        meta_tuple = tuple(sorted(self.metadata.items()))
        return hash(
            (
                self.source_entity_id,
                self.target_entity_id,
                self.relationship_type,
                self.confidence,
                self.source_document_id,
                meta_tuple,
                self.id,
            )
        )

    def __post_init__(self):
        """Post-initialization validation."""
        if (
            not isinstance(self.source_entity_id, str)
            or not self.source_entity_id.strip()
        ):
            raise ValueError("Source entity ID must be a non-empty string.")
        if (
            not isinstance(self.target_entity_id, str)
            or not self.target_entity_id.strip()
        ):
            raise ValueError("Target entity ID must be a non-empty string.")
        if self.source_entity_id == self.target_entity_id:
            raise ValueError("Source and target entity IDs cannot be the same.")
        if (
            not isinstance(self.relationship_type, str)
            or not self.relationship_type.strip()
        ):
            raise ValueError("Relationship type must be a non-empty string.")
        if not (0.0 <= self.confidence <= 1.0):
            raise ValueError("Confidence must be between 0.0 and 1.0.")
        if (
            not isinstance(self.source_document_id, str)
            or not self.source_document_id.strip()
        ):
            raise ValueError("Source document ID must be a non-empty string.")
        if not isinstance(self.metadata, dict):
            raise TypeError("Metadata must be a dictionary.")
        if not isinstance(self.id, str) or not self.id.strip():
            raise ValueError("Relationship ID must be a non-empty string.")


# Common entity types for biomedical domain (based on SOTA research)
class EntityTypes:
    """Standard entity types for biomedical and general domain extraction."""

    # Biomedical entities (from OpenMed and medical NER research)
    PERSON = "PERSON"
    DISEASE = "DISEASE"
    DRUG = "DRUG"
    TREATMENT = "TREATMENT"
    SYMPTOM = "SYMPTOM"
    GENE = "GENE"
    PROTEIN = "PROTEIN"
    ANATOMY = "ANATOMY"
    PROCEDURE = "PROCEDURE"
    DEVICE = "DEVICE"

    # Additional medical entity types for comprehensive coverage
    VIRUS = "VIRUS"
    BACTERIA = "BACTERIA"
    VACCINE = "VACCINE"
    BIOMARKER = "BIOMARKER"

    # General entities
    ORGANIZATION = "ORGANIZATION"
    LOCATION = "LOCATION"
    DATE = "DATE"
    MONEY = "MONEY"
    PERCENT = "PERCENT"
    PRODUCT = "PRODUCT"
    EVENT = "EVENT"

    @classmethod
    def all_types(cls) -> set:
        """Return all available entity types."""
        return {
            cls.PERSON,
            cls.DISEASE,
            cls.DRUG,
            cls.TREATMENT,
            cls.SYMPTOM,
            cls.GENE,
            cls.PROTEIN,
            cls.ANATOMY,
            cls.PROCEDURE,
            cls.DEVICE,
            cls.ORGANIZATION,
            cls.LOCATION,
            cls.DATE,
            cls.MONEY,
            cls.PERCENT,
            cls.PRODUCT,
            cls.EVENT,
        }

    @classmethod
    def biomedical_types(cls) -> set:
        """Return biomedical-specific entity types."""
        return {
            cls.PERSON,
            cls.DISEASE,
            cls.DRUG,
            cls.TREATMENT,
            cls.SYMPTOM,
            cls.GENE,
            cls.PROTEIN,
            cls.ANATOMY,
            cls.PROCEDURE,
            cls.DEVICE,
        }


# Common relationship types
class RelationshipTypes:
    """Standard relationship types for entity connections."""

    # Medical/biomedical relationships
    TREATS = "treats"
    CAUSES = "causes"
    PREVENTS = "prevents"
    INTERACTS_WITH = "interacts_with"
    LOCATED_IN = "located_in"
    PART_OF = "part_of"
    ASSOCIATED_WITH = "associated_with"

    # General relationships
    RELATED_TO = "related_to"
    MENTIONS = "mentions"
    REFERS_TO = "refers_to"
    WORKS_FOR = "works_for"
    BASED_IN = "based_in"
    HAPPENS_ON = "happens_on"

    @classmethod
    def all_types(cls) -> set:
        """Return all available relationship types."""
        return {
            cls.TREATS,
            cls.CAUSES,
            cls.PREVENTS,
            cls.INTERACTS_WITH,
            cls.LOCATED_IN,
            cls.PART_OF,
            cls.ASSOCIATED_WITH,
            cls.RELATED_TO,
            cls.MENTIONS,
            cls.REFERS_TO,
            cls.WORKS_FOR,
            cls.BASED_IN,
            cls.HAPPENS_ON,
        }


# Coverage Analysis Models

from datetime import datetime
from typing import List
import re


# Critical modules requiring 80% coverage per constitutional requirements
CRITICAL_MODULES = {
    "iris_rag.config",
    "iris_rag.validation",
    "iris_rag.pipelines",
    "iris_rag.services",
    "iris_rag.storage"
}


@dataclass
class CoverageReport:
    """Data model for coverage analysis reports.

    Represents a complete coverage analysis with overall metrics,
    module-level breakdowns, and metadata for tracking and comparison.
    """

    # Required fields
    report_id: str
    timestamp: datetime
    overall_coverage_percentage: float
    total_lines: int
    covered_lines: int
    analysis_duration_seconds: float

    # Optional metadata fields
    git_commit_hash: str = None
    ci_build_id: str = None
    branch_coverage_percentage: float = None

    # Module coverage breakdown
    module_coverage: List[Dict[str, Any]] = field(default_factory=list)

    def __post_init__(self):
        """Validate report data after initialization."""
        self._validate_percentages()
        self._validate_line_counts()
        self._validate_report_id()

    def _validate_percentages(self):
        """Validate coverage percentages are within valid range."""
        if not 0 <= self.overall_coverage_percentage <= 100:
            raise ValueError("Coverage percentage must be between 0 and 100")

        if self.branch_coverage_percentage is not None:
            if not 0 <= self.branch_coverage_percentage <= 100:
                raise ValueError("Branch coverage percentage must be between 0 and 100")

    def _validate_line_counts(self):
        """Validate line count consistency."""
        if self.covered_lines > self.total_lines:
            raise ValueError("Covered lines cannot exceed total lines")

        if self.total_lines < 0 or self.covered_lines < 0:
            raise ValueError("Line counts must be non-negative")

    def _validate_report_id(self):
        """Validate report ID format."""
        if not self.report_id or len(self.report_id.strip()) == 0:
            raise ValueError("Invalid report ID format")

        if len(self.report_id) > 100:
            raise ValueError("Invalid report ID format")

        # Check for invalid characters
        if not re.match(r'^[a-zA-Z0-9\-_]+$', self.report_id):
            raise ValueError("Invalid report ID format")

    @classmethod
    def from_line_counts(
        cls,
        report_id: str,
        timestamp: datetime,
        total_lines: int,
        covered_lines: int,
        analysis_duration_seconds: float,
        **kwargs
    ) -> 'CoverageReport':
        """Create report with automatic percentage calculation."""
        if total_lines == 0:
            overall_coverage_percentage = 0.0
        else:
            overall_coverage_percentage = (covered_lines / total_lines) * 100.0

        return cls(
            report_id=report_id,
            timestamp=timestamp,
            overall_coverage_percentage=overall_coverage_percentage,
            total_lines=total_lines,
            covered_lines=covered_lines,
            analysis_duration_seconds=analysis_duration_seconds,
            **kwargs
        )

    def to_dict(self) -> Dict[str, Any]:
        """Serialize report to dictionary for API responses."""
        data = {
            'report_id': self.report_id,
            'timestamp': self.timestamp.isoformat(),
            'overall_coverage_percentage': self.overall_coverage_percentage,
            'total_lines': self.total_lines,
            'covered_lines': self.covered_lines,
            'analysis_duration_seconds': self.analysis_duration_seconds,
            'module_coverage': self.module_coverage
        }

        # Add optional fields if present
        if self.git_commit_hash:
            data['git_commit_hash'] = self.git_commit_hash
        if self.ci_build_id:
            data['ci_build_id'] = self.ci_build_id
        if self.branch_coverage_percentage is not None:
            data['branch_coverage_percentage'] = self.branch_coverage_percentage

        return data

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'CoverageReport':
        """Deserialize report from dictionary data."""
        # Parse timestamp
        if isinstance(data['timestamp'], str):
            timestamp = datetime.fromisoformat(data['timestamp'].replace('Z', '+00:00'))
        else:
            timestamp = data['timestamp']

        # Extract required fields
        required_fields = {
            'report_id': data['report_id'],
            'timestamp': timestamp,
            'overall_coverage_percentage': data['overall_coverage_percentage'],
            'total_lines': data['total_lines'],
            'covered_lines': data['covered_lines'],
            'analysis_duration_seconds': data['analysis_duration_seconds']
        }

        # Extract optional fields
        optional_fields = {}
        for field_name in ['git_commit_hash', 'ci_build_id', 'branch_coverage_percentage', 'module_coverage']:
            if field_name in data:
                optional_fields[field_name] = data[field_name]

        return cls(**required_fields, **optional_fields)

    def __lt__(self, other: 'CoverageReport') -> bool:
        """Compare reports by coverage percentage."""
        if not isinstance(other, CoverageReport):
            return NotImplemented
        return self.overall_coverage_percentage < other.overall_coverage_percentage

    def __gt__(self, other: 'CoverageReport') -> bool:
        """Compare reports by coverage percentage."""
        if not isinstance(other, CoverageReport):
            return NotImplemented
        return self.overall_coverage_percentage > other.overall_coverage_percentage

    def __eq__(self, other: 'CoverageReport') -> bool:
        """Compare reports by ID and timestamp."""
        if not isinstance(other, CoverageReport):
            return NotImplemented
        return (self.report_id == other.report_id and
                self.timestamp == other.timestamp)

    def __ne__(self, other: 'CoverageReport') -> bool:
        """Compare reports by ID and timestamp."""
        return not self.__eq__(other)

    def generate_summary(self) -> str:
        """Generate human-readable summary text."""
        # Format numbers with commas
        total_lines_formatted = f"{self.total_lines:,}"
        covered_lines_formatted = f"{self.covered_lines:,}"

        # Calculate analysis time in human-readable format
        duration_minutes = int(self.analysis_duration_seconds // 60)
        duration_seconds = int(self.analysis_duration_seconds % 60)

        if duration_minutes > 0:
            duration_str = f"{duration_minutes}m {duration_seconds}s"
        else:
            duration_str = f"{duration_seconds}s"

        # Generate summary
        summary = (
            f"Coverage Report {self.report_id}: "
            f"{self.overall_coverage_percentage:.1f}% coverage "
            f"({covered_lines_formatted} of {total_lines_formatted} lines covered). "
            f"Analysis completed in {duration_str} on {self.timestamp.strftime('%Y-%m-%d %H:%M:%S')}."
        )

        # Add module count if available
        if self.module_coverage:
            summary += f" Analyzed {len(self.module_coverage)} modules."

        # Add branch coverage if available
        if self.branch_coverage_percentage is not None:
            summary += f" Branch coverage: {self.branch_coverage_percentage:.1f}%."

        return summary


@dataclass
class ModuleCoverage:
    """Data model for module-level coverage analysis.

    Represents coverage metrics for a specific module including
    critical module status, target validation, and detailed breakdowns.
    """

    # Required fields
    module_name: str
    file_path: str
    coverage_percentage: float
    total_lines: int
    covered_lines: int
    is_critical_module: bool
    target_coverage_percentage: float

    # Optional detailed fields
    uncovered_lines: List[int] = field(default_factory=list)
    priority_level: str = None
    is_legacy_module: bool = False
    exemption_justification: str = None
    analysis_time_ms: float = None
    vector_operation_coverage: float = None

    def __post_init__(self):
        """Validate module data after initialization."""
        self._validate_percentages()
        self._validate_line_counts()
        self._validate_module_name()
        self._calculate_derived_fields()

    def _validate_percentages(self):
        """Validate coverage percentages are within valid range."""
        if not 0 <= self.coverage_percentage <= 100:
            raise ValueError("Coverage percentage must be between 0 and 100")

        if not 0 <= self.target_coverage_percentage <= 100:
            raise ValueError("Target coverage percentage must be between 0 and 100")

        if self.vector_operation_coverage is not None:
            if not 0 <= self.vector_operation_coverage <= 100:
                raise ValueError("Vector operation coverage must be between 0 and 100")

    def _validate_line_counts(self):
        """Validate line count consistency."""
        if self.covered_lines > self.total_lines:
            raise ValueError("Covered lines cannot exceed total lines")

        if self.total_lines < 0 or self.covered_lines < 0:
            raise ValueError("Line counts must be non-negative")

    def _validate_module_name(self):
        """Validate module name format."""
        if not self.module_name or len(self.module_name.strip()) == 0:
            raise ValueError("Invalid module name format")

        # Check for unreasonably deep nesting
        if self.module_name.count('.') > 10:
            raise ValueError("Invalid module name format")

        # Basic format validation for Python module names
        if not re.match(r'^[a-zA-Z_][a-zA-Z0-9_]*(\.[a-zA-Z_][a-zA-Z0-9_]*)*$', self.module_name):
            # Allow some special characters for test modules
            if not re.match(r'^[a-zA-Z_][a-zA-Z0-9_.-]*$', self.module_name):
                raise ValueError("Invalid module name format")

    def _calculate_derived_fields(self):
        """Calculate derived fields based on module data."""
        # Set priority level if not explicitly provided
        if self.priority_level is None:
            self.priority_level = self._calculate_priority_level()

    def _calculate_priority_level(self) -> str:
        """Calculate priority level based on module characteristics."""
        # High priority: config and validation (foundational)
        if self.module_name in ["iris_rag.config", "iris_rag.validation"]:
            return "HIGH"

        # Medium/High priority: other critical modules
        if self.is_critical_module:
            return "MEDIUM"

        # Lower priority for non-critical modules
        return "LOW"

    @property
    def target_met(self) -> bool:
        """Check if module meets its coverage target."""
        return self.coverage_percentage >= self.target_coverage_percentage

    @classmethod
    def create_for_module(
        cls,
        module_name: str,
        file_path: str,
        coverage_percentage: float,
        total_lines: int,
        covered_lines: int,
        **kwargs
    ) -> 'ModuleCoverage':
        """Create ModuleCoverage with automatic critical module detection."""
        # Determine if module is critical
        is_critical = module_name in CRITICAL_MODULES

        # Set target coverage based on critical status
        if is_critical:
            target_coverage = 80.0
        else:
            target_coverage = 60.0

        # Override target if explicitly provided
        if 'target_coverage_percentage' in kwargs:
            target_coverage = kwargs.pop('target_coverage_percentage')

        return cls(
            module_name=module_name,
            file_path=file_path,
            coverage_percentage=coverage_percentage,
            total_lines=total_lines,
            covered_lines=covered_lines,
            is_critical_module=is_critical,
            target_coverage_percentage=target_coverage,
            **kwargs
        )

    def to_dict(self) -> Dict[str, Any]:
        """Serialize module coverage to dictionary for API responses."""
        data = {
            'module_name': self.module_name,
            'file_path': self.file_path,
            'coverage_percentage': self.coverage_percentage,
            'total_lines': self.total_lines,
            'covered_lines': self.covered_lines,
            'is_critical_module': self.is_critical_module,
            'target_coverage_percentage': self.target_coverage_percentage,
            'target_met': self.target_met,
            'uncovered_lines': self.uncovered_lines,
            'is_legacy_module': self.is_legacy_module
        }

        # Add optional fields if present
        if self.priority_level:
            data['priority_level'] = self.priority_level
        if self.exemption_justification:
            data['exemption_justification'] = self.exemption_justification
        if self.analysis_time_ms is not None:
            data['analysis_time_ms'] = self.analysis_time_ms
        if self.vector_operation_coverage is not None:
            data['vector_operation_coverage'] = self.vector_operation_coverage

        return data


# Example of how other models might be added later:
# @dataclass(frozen=True)
# class Chunk(Document):
#     """Represents a chunk of a larger document."""
#     parent_document_id: str
#     chunk_index: int
#     # Could have its own metadata or inherit/extend parent's

# @dataclass(frozen=True)
# class RetrievedDocument:
#     """Represents a document retrieved by the RAG pipeline, possibly with a score."""
#     document: Document
#     score: float = field(default=0.0)
#     # Any other retrieval-specific info
