# Test configuration files for CLI wizard testing
# These configurations are used to test various scenarios and edge cases

# Valid minimal profile configuration
minimal_profile_valid:
  metadata:
    profile: "quick_start_minimal"
    version: "2024.1"
    schema_version: "2024.1"
    description: "Valid minimal profile for testing"
    created_by: "cli_wizard_test"
  
  sample_data:
    source: "pmc"
    document_count: 10
    categories: ["biomedical"]
    storage_path: "./test_data"
  
  database:
    iris:
      host: "localhost"
      port: 1972
      namespace: "USER"
      username: "demo"
      password: "demo"
      connection_timeout: 30
  
  embeddings:
    provider: "openai"
    model: "text-embedding-ada-002"
    dimensions: 1536
    batch_size: 100
  
  llm:
    provider: "openai"
    model: "gpt-3.5-turbo"
    temperature: 0.7
    max_tokens: 1000
  
  mcp_server:
    enabled: true
    port: 3000
    tools: ["basic", "health_check"]
    timeout: 30
  
  vector_index:
    dimension: 1536
    metric: "cosine"
    index_type: "hnsw"

# Valid standard profile configuration
standard_profile_valid:
  metadata:
    profile: "quick_start_standard"
    version: "2024.1"
    schema_version: "2024.1"
    description: "Valid standard profile for testing"
    created_by: "cli_wizard_test"
  
  sample_data:
    source: "pmc"
    document_count: 100
    categories: ["biomedical", "clinical"]
    storage_path: "./test_data"
  
  database:
    iris:
      host: "localhost"
      port: 1972
      namespace: "USER"
      username: "demo"
      password: "demo"
      connection_timeout: 30
  
  embeddings:
    provider: "openai"
    model: "text-embedding-ada-002"
    dimensions: 1536
    batch_size: 200
  
  llm:
    provider: "openai"
    model: "gpt-4"
    temperature: 0.5
    max_tokens: 2000
  
  mcp_server:
    enabled: true
    port: 3000
    tools: ["basic", "health_check", "search", "analytics"]
    timeout: 60
  
  vector_index:
    dimension: 1536
    metric: "cosine"
    index_type: "hnsw"
  
  performance:
    batch_size: 16
    max_workers: 2
    cache_size: 1000

# Valid extended profile configuration
extended_profile_valid:
  metadata:
    profile: "quick_start_extended"
    version: "2024.1"
    schema_version: "2024.1"
    description: "Valid extended profile for testing"
    created_by: "cli_wizard_test"
  
  sample_data:
    source: "pmc"
    document_count: 1000
    categories: ["biomedical", "clinical", "research"]
    storage_path: "./test_data"
  
  database:
    iris:
      host: "localhost"
      port: 1972
      namespace: "USER"
      username: "demo"
      password: "demo"
      connection_timeout: 60
  
  embeddings:
    provider: "openai"
    model: "text-embedding-ada-002"
    dimensions: 1536
    batch_size: 500
  
  llm:
    provider: "anthropic"
    model: "claude-3-sonnet"
    temperature: 0.3
    max_tokens: 4000
  
  mcp_server:
    enabled: true
    port: 3000
    tools: ["basic", "health_check", "search", "analytics", "advanced", "monitoring"]
    timeout: 120
  
  vector_index:
    dimension: 1536
    metric: "cosine"
    index_type: "hnsw"
  
  performance:
    batch_size: 32
    max_workers: 4
    cache_size: 5000

# Invalid configuration - missing required fields
invalid_missing_metadata:
  # Missing metadata section
  sample_data:
    source: "pmc"
    document_count: 10
  
  database:
    iris:
      host: "localhost"
      port: 1972

# Invalid configuration - wrong profile constraints
invalid_minimal_too_many_docs:
  metadata:
    profile: "quick_start_minimal"
    version: "2024.1"
    schema_version: "2024.1"
  
  sample_data:
    source: "pmc"
    document_count: 100  # Too many for minimal profile (max 50)
    categories: ["biomedical"]
  
  database:
    iris:
      host: "localhost"
      port: 1972
  
  mcp_server:
    tools: ["basic", "health_check", "advanced"]  # Too many tools for minimal

# Invalid configuration - wrong data types
invalid_data_types:
  metadata:
    profile: "quick_start_standard"
    version: 2024.1  # Should be string
    schema_version: "2024.1"
  
  sample_data:
    source: "pmc"
    document_count: "100"  # Should be integer
    categories: "biomedical"  # Should be array
  
  database:
    iris:
      host: "localhost"
      port: "1972"  # Should be integer

# Configuration with environment variables
config_with_env_vars:
  metadata:
    profile: "quick_start_standard"
    version: "2024.1"
    schema_version: "2024.1"
    description: "Configuration with environment variables"
  
  sample_data:
    source: "pmc"
    document_count: "${DOCUMENT_COUNT:-100}"
    categories: ["biomedical"]
  
  database:
    iris:
      host: "${IRIS_HOST:-localhost}"
      port: "${IRIS_PORT:-1972}"
      namespace: "${IRIS_NAMESPACE:-USER}"
      username: "${IRIS_USERNAME:-demo}"
      password: "${IRIS_PASSWORD:-demo}"
  
  embeddings:
    provider: "openai"
    model: "${EMBEDDING_MODEL:-text-embedding-ada-002}"
    api_key: "${OPENAI_API_KEY}"
  
  llm:
    provider: "openai"
    model: "${LLM_MODEL:-gpt-3.5-turbo}"
    api_key: "${OPENAI_API_KEY}"
    temperature: "${LLM_TEMPERATURE:-0.7}"

# Production-like configuration
production_config:
  metadata:
    profile: "quick_start_extended"
    version: "2024.1"
    schema_version: "2024.1"
    description: "Production-like configuration for testing"
    environment: "production"
  
  sample_data:
    source: "pmc"
    document_count: 5000
    categories: ["biomedical", "clinical", "research", "pharmaceutical"]
    storage_path: "/data/rag_samples"
  
  database:
    iris:
      host: "prod-iris.company.com"
      port: 1972
      namespace: "PROD"
      username: "rag_user"
      password: "${IRIS_PROD_PASSWORD}"
      ssl_enabled: true
      connection_pool_size: 10
  
  embeddings:
    provider: "openai"
    model: "text-embedding-ada-002"
    api_key: "${OPENAI_PROD_API_KEY}"
    dimensions: 1536
    batch_size: 1000
    rate_limit: 1000
  
  llm:
    provider: "anthropic"
    model: "claude-3-sonnet"
    api_key: "${ANTHROPIC_PROD_API_KEY}"
    temperature: 0.1
    max_tokens: 8000
    rate_limit: 100
  
  mcp_server:
    enabled: true
    port: 3000
    tools: ["basic", "health_check", "search", "analytics", "advanced", "monitoring"]
    ssl_enabled: true
    auth_required: true
  
  vector_index:
    dimension: 1536
    metric: "cosine"
    index_type: "hnsw"
    ef_construction: 200
    m: 16
  
  performance:
    batch_size: 64
    max_workers: 8
    cache_size: 10000
    memory_limit: "8GB"
  
  monitoring:
    enabled: true
    metrics_port: 9090
    log_level: "INFO"
    health_check_interval: 30

# Multi-tenant configuration
multi_tenant_config:
  metadata:
    profile: "quick_start_extended"
    version: "2024.1"
    schema_version: "2024.1"
    description: "Multi-tenant configuration for testing"
    deployment_type: "multi_tenant"
  
  tenants:
    - name: "tenant_a"
      database:
        iris:
          namespace: "TENANT_A"
          username: "tenant_a_user"
      sample_data:
        document_count: 500
        categories: ["biomedical"]
    
    - name: "tenant_b"
      database:
        iris:
          namespace: "TENANT_B"
          username: "tenant_b_user"
      sample_data:
        document_count: 1000
        categories: ["clinical", "research"]
    
    - name: "tenant_c"
      database:
        iris:
          namespace: "TENANT_C"
          username: "tenant_c_user"
      sample_data:
        document_count: 200
        categories: ["pharmaceutical"]
  
  shared_config:
    database:
      iris:
        host: "multi-tenant-iris.company.com"
        port: 1972
        ssl_enabled: true
    
    embeddings:
      provider: "openai"
      model: "text-embedding-ada-002"
      api_key: "${OPENAI_API_KEY}"
    
    llm:
      provider: "openai"
      model: "gpt-4"
      api_key: "${OPENAI_API_KEY}"

# Development configuration
development_config:
  metadata:
    profile: "quick_start_minimal"
    version: "2024.1"
    schema_version: "2024.1"
    description: "Development configuration for testing"
    environment: "development"
  
  sample_data:
    source: "pmc_sample"  # Use local sample data
    document_count: 10
    categories: ["biomedical"]
    storage_path: "./dev_data"
  
  database:
    iris:
      host: "localhost"
      port: 1972
      namespace: "DEV"
      username: "dev_user"
      password: "dev_password"
      connection_timeout: 10
  
  embeddings:
    provider: "openai"
    model: "text-embedding-ada-002"
    api_key: "${OPENAI_DEV_API_KEY}"
    dimensions: 1536
  
  llm:
    provider: "openai"
    model: "gpt-3.5-turbo"
    api_key: "${OPENAI_DEV_API_KEY}"
    temperature: 0.9  # Higher temperature for experimentation
  
  mcp_server:
    enabled: true
    port: 3001  # Different port for dev
    tools: ["basic", "health_check"]
    debug_mode: true
  
  performance:
    batch_size: 4
    max_workers: 1
    cache_size: 100
  
  monitoring:
    enabled: true
    log_level: "DEBUG"
    metrics_enabled: false

# Migration test configuration
migration_test_config:
  metadata:
    profile: "quick_start_standard"
    version: "2024.1"
    schema_version: "2024.1"
    description: "Configuration for testing migration scenarios"
    migration_source: "legacy_rag_system"
  
  legacy_config:
    # Simulate old configuration format
    database_host: "old-iris.company.com"
    database_port: 1972
    embedding_model: "old-embedding-model"
    llm_model: "old-llm-model"
    document_store: "/old/data/path"
  
  migration_mapping:
    database_host: "database.iris.host"
    database_port: "database.iris.port"
    embedding_model: "embeddings.model"
    llm_model: "llm.model"
    document_store: "sample_data.storage_path"
  
  target_config:
    database:
      iris:
        host: "new-iris.company.com"
        port: 1972
        namespace: "MIGRATED"
    
    embeddings:
      provider: "openai"
      model: "text-embedding-ada-002"
    
    llm:
      provider: "openai"
      model: "gpt-4"
    
    sample_data:
      storage_path: "/new/data/path"