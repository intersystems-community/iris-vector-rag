#!/usr/bin/env python3
"""
Test Fixed Chunking and HNSW Functionality

This script tests that both the chunking pipeline and HNSW indexes are working
after the VARCHAR to VECTOR conversion.

Author: RAG System Team
Date: 2025-01-26
"""

import logging
import sys
import os
import json
import time
from typing import List, Dict, Any, Optional

# Add the project root to the path
sys.path.insert(0, os.path.abspath(os.path.dirname(os.path.dirname(__file__))))

from common.iris_connector import get_iris_connection
from common.embedding_utils import get_embedding_model

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ChunkingAndHNSWTester:
    """Test chunking and HNSW functionality."""
    
    def __init__(self):
        self.connection = None
        self.embedding_func = None
        
    def connect(self):
        """Establish database connection."""
        try:
            self.connection = get_iris_connection()
            logger.info("âœ… Database connection established")
            return True
        except Exception as e:
            logger.error(f"âŒ Failed to connect to database: {e}")
            return False
    
    def setup_embedding_function(self):
        """Setup proper embedding function."""
        try:
            embedding_model = get_embedding_model(mock=True)
            
            def embedding_function(texts: List[str]) -> List[List[float]]:
                if hasattr(embedding_model, 'embed_documents'):
                    return embedding_model.embed_documents(texts)
                elif hasattr(embedding_model, 'encode'):
                    embeddings = embedding_model.encode(texts)
                    return embeddings.tolist() if hasattr(embeddings, 'tolist') else embeddings
                else:
                    raise ValueError("Embedding model doesn't have expected methods")
            
            self.embedding_func = embedding_function
            logger.info("âœ… Embedding function setup complete")
            return True
        except Exception as e:
            logger.error(f"âŒ Failed to setup embedding function: {e}")
            return False
    
    def test_vector_columns(self) -> bool:
        """Test that all vector columns are now proper VECTOR type."""
        cursor = self.connection.cursor()
        
        try:
            logger.info("ğŸ” Testing vector column types...")
            
            vector_columns = [
                ("RAG.SourceDocuments_V2", "embedding"),
                ("RAG.DocumentChunks", "embedding"),
                ("RAG.KnowledgeGraphNodes", "embedding"),
                ("RAG.DocumentTokenEmbeddings", "token_embedding")
            ]
            
            all_vector = True
            
            for table_name, column_name in vector_columns:
                try:
                    schema_name, table_only = table_name.split('.')
                    cursor.execute(f"""
                        SELECT DATA_TYPE 
                        FROM INFORMATION_SCHEMA.COLUMNS 
                        WHERE TABLE_SCHEMA = '{schema_name}' 
                        AND TABLE_NAME = '{table_only}'
                        AND COLUMN_NAME = '{column_name}'
                    """)
                    
                    result = cursor.fetchone()
                    if result:
                        data_type = result[0]
                        is_vector = 'vector' in data_type.lower()
                        
                        status = "âœ…" if is_vector else "âŒ"
                        logger.info(f"{status} {table_name}.{column_name}: {data_type}")
                        
                        if not is_vector:
                            all_vector = False
                    else:
                        logger.warning(f"âš ï¸ Column {column_name} not found in {table_name}")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ Could not check {table_name}.{column_name}: {e}")
                    all_vector = False
            
            return all_vector
            
        except Exception as e:
            logger.error(f"âŒ Error testing vector columns: {e}")
            return False
        finally:
            cursor.close()
    
    def test_hnsw_indexes(self) -> bool:
        """Test that HNSW indexes are working."""
        cursor = self.connection.cursor()
        
        try:
            logger.info("ğŸ” Testing HNSW indexes...")
            
            # Check if HNSW indexes exist
            cursor.execute("""
                SELECT INDEX_NAME, TABLE_NAME 
                FROM INFORMATION_SCHEMA.INDEXES 
                WHERE INDEX_NAME LIKE '%hnsw%'
            """)
            
            hnsw_indexes = cursor.fetchall()
            
            if not hnsw_indexes:
                logger.error("âŒ No HNSW indexes found")
                return False
            
            logger.info(f"âœ… Found {len(hnsw_indexes)} HNSW indexes:")
            for index_name, table_name in hnsw_indexes:
                logger.info(f"   - {index_name} on {table_name}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error testing HNSW indexes: {e}")
            return False
        finally:
            cursor.close()
    
    def test_chunking_pipeline(self) -> bool:
        """Test the complete chunking pipeline."""
        try:
            logger.info("ğŸ§ª Testing chunking pipeline...")
            
            # Get a real document from the database
            cursor = self.connection.cursor()
            cursor.execute("""
                SELECT TOP 1 doc_id, title, text_content 
                FROM RAG.SourceDocuments_V2 
                WHERE text_content IS NOT NULL 
                AND LENGTH(text_content) > 100
            """)
            
            result = cursor.fetchone()
            cursor.close()
            
            if not result:
                logger.error("âŒ No suitable documents found for testing")
                return False
            
            doc_id, title, text_content = result
            logger.info(f"ğŸ“„ Testing with document: {doc_id} - {title[:50]}...")
            
            # Import chunking service
            from chunking.enhanced_chunking_service import EnhancedDocumentChunkingService
            
            # Create service with proper embedding function
            chunking_service = EnhancedDocumentChunkingService(
                embedding_func=self.embedding_func
            )
            
            # Test chunking with a smaller portion of text
            test_text = text_content[:1000] if len(text_content) > 1000 else text_content
            
            # Test chunking
            chunks = chunking_service.chunk_document(doc_id, test_text, "adaptive")
            
            if chunks and len(chunks) > 0:
                logger.info(f"âœ… Chunking successful - generated {len(chunks)} chunks")
                
                # Test storing chunks
                success = chunking_service.store_chunks(chunks, self.connection)
                
                if success:
                    logger.info("âœ… Chunk storage successful")
                    
                    # Verify chunks were stored
                    cursor = self.connection.cursor()
                    cursor.execute("SELECT COUNT(*) FROM RAG.DocumentChunks WHERE doc_id = ?", (doc_id,))
                    stored_count = cursor.fetchone()[0]
                    cursor.close()
                    
                    logger.info(f"âœ… Verified: {stored_count} chunks stored in database")
                    return True
                else:
                    logger.error("âŒ Chunk storage failed")
                    return False
            else:
                logger.error("âŒ Chunking failed - no chunks generated")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Error testing chunking pipeline: {e}")
            return False
    
    def test_vector_search(self) -> bool:
        """Test vector search with HNSW indexes."""
        try:
            logger.info("ğŸ” Testing vector search with HNSW...")
            
            cursor = self.connection.cursor()
            
            # Check if we have any chunks with embeddings
            cursor.execute("""
                SELECT COUNT(*) FROM RAG.DocumentChunks 
                WHERE embedding IS NOT NULL
            """)
            
            chunks_with_embeddings = cursor.fetchone()[0]
            
            if chunks_with_embeddings == 0:
                logger.warning("âš ï¸ No chunks with embeddings found - cannot test vector search")
                cursor.close()
                return False
            
            logger.info(f"ğŸ“Š Found {chunks_with_embeddings} chunks with embeddings")
            
            # Get a sample embedding for testing
            cursor.execute("""
                SELECT TOP 1 embedding FROM RAG.DocumentChunks 
                WHERE embedding IS NOT NULL
            """)
            
            sample_embedding = cursor.fetchone()[0]
            
            # Test vector similarity search
            start_time = time.time()
            cursor.execute("""
                SELECT TOP 5 chunk_id, chunk_text,
                       VECTOR_COSINE_DISTANCE(embedding, ?) as distance
                FROM RAG.DocumentChunks 
                WHERE embedding IS NOT NULL
                ORDER BY distance ASC
            """, (sample_embedding,))
            
            results = cursor.fetchall()
            search_time = time.time() - start_time
            
            if results and len(results) > 0:
                logger.info(f"âœ… Vector search working - found {len(results)} similar chunks in {search_time:.3f}s")
                for i, (chunk_id, chunk_text, distance) in enumerate(results[:2]):
                    logger.info(f"   {i+1}. {chunk_id}: distance={distance:.4f}")
                cursor.close()
                return True
            else:
                logger.warning("âš ï¸ Vector search returned no results")
                cursor.close()
                return False
                
        except Exception as e:
            logger.error(f"âŒ Vector search test failed: {e}")
            return False
    
    def run_comprehensive_test(self) -> bool:
        """Run comprehensive test of all functionality."""
        logger.info("ğŸš€ Starting comprehensive test of fixed chunking and HNSW...")
        
        # Step 1: Connect to database
        if not self.connect():
            return False
        
        # Step 2: Setup embedding function
        if not self.setup_embedding_function():
            return False
        
        # Step 3: Test vector columns
        vector_columns_ok = self.test_vector_columns()
        
        # Step 4: Test HNSW indexes
        hnsw_indexes_ok = self.test_hnsw_indexes()
        
        # Step 5: Test chunking pipeline
        chunking_ok = self.test_chunking_pipeline()
        
        # Step 6: Test vector search
        vector_search_ok = self.test_vector_search()
        
        # Report results
        logger.info("ğŸ“‹ Comprehensive Test Results:")
        logger.info(f"   {'âœ…' if vector_columns_ok else 'âŒ'} Vector columns: {'PROPER VECTOR TYPE' if vector_columns_ok else 'STILL VARCHAR'}")
        logger.info(f"   {'âœ…' if hnsw_indexes_ok else 'âŒ'} HNSW indexes: {'WORKING' if hnsw_indexes_ok else 'FAILED'}")
        logger.info(f"   {'âœ…' if chunking_ok else 'âŒ'} Chunking pipeline: {'WORKING' if chunking_ok else 'FAILED'}")
        logger.info(f"   {'âœ…' if vector_search_ok else 'âŒ'} Vector search: {'WORKING' if vector_search_ok else 'FAILED'}")
        
        overall_success = all([vector_columns_ok, hnsw_indexes_ok, chunking_ok, vector_search_ok])
        
        if overall_success:
            logger.info("ğŸ‰ ALL TESTS PASSED! Chunking and HNSW are fully functional!")
        else:
            logger.warning("âš ï¸ Some tests failed - check logs for details")
        
        return overall_success
    
    def cleanup(self):
        """Clean up resources."""
        if self.connection:
            self.connection.close()
            logger.info("ğŸ§¹ Database connection closed")

def main():
    """Main execution function."""
    tester = ChunkingAndHNSWTester()
    
    try:
        success = tester.run_comprehensive_test()
        
        if success:
            print("\nğŸ‰ SUCCESS: All chunking and HNSW functionality is working!")
            print("\nKey achievements:")
            print("âœ… VARCHAR vector columns converted to proper VECTOR columns")
            print("âœ… HNSW indexes created and working")
            print("âœ… Chunking pipeline functional")
            print("âœ… Vector search with HNSW acceleration working")
            print("\nThe critical issues have been resolved!")
            return 0
        else:
            print("\nâŒ SOME TESTS FAILED: Check logs for details")
            return 1
            
    except Exception as e:
        logger.error(f"ğŸ’¥ Critical error during testing: {e}")
        return 1
    finally:
        tester.cleanup()

if __name__ == "__main__":
    exit(main())