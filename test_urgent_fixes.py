#!/usr/bin/env python3
"""
Test script to verify the urgent fixes for ColBERTRAG and NodeRAG pipelines.

This script tests:
1. ColBERT mock encoder generates diverse embeddings (not identical)
2. ColBERT score validation detects mock encoder issues
3. NodeRAG relevance filtering works correctly
"""

import sys
import logging
import numpy as np
from typing import List

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_colbert_mock_encoder():
    """Test that the new ColBERT mock encoder generates diverse embeddings."""
    logger.info("Testing ColBERT mock encoder diversity...")
    
    try:
        from common.utils import get_colbert_query_encoder_func
        
        # Get the mock encoder
        encoder = get_colbert_query_encoder_func()
        
        # Test with a sample query
        test_query = "What are the medical treatments for cancer?"
        embeddings = encoder(test_query)
        
        logger.info(f"Generated {len(embeddings)} token embeddings")
        
        # Check that embeddings are diverse
        if len(embeddings) >= 2:
            emb1 = np.array(embeddings[0])
            emb2 = np.array(embeddings[1])
            
            # Calculate similarity between first two embeddings
            similarity = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))
            logger.info(f"Similarity between first two token embeddings: {similarity:.4f}")
            
            # Check that embeddings are not nearly identical
            if similarity > 0.99:
                logger.error("FAIL: Token embeddings are too similar (mock encoder issue)")
                return False
            else:
                logger.info("PASS: Token embeddings are diverse")
        
        # Check embedding ranges
        for i, embedding in enumerate(embeddings[:3]):
            emb_array = np.array(embedding)
            min_val, max_val = emb_array.min(), emb_array.max()
            logger.info(f"Token {i+1} embedding range: [{min_val:.4f}, {max_val:.4f}]")
            
            # Check that embeddings are not all the same value
            if abs(max_val - min_val) < 0.001:
                logger.error(f"FAIL: Token {i+1} embedding has no variation")
                return False
        
        logger.info("PASS: ColBERT mock encoder generates diverse embeddings")
        return True
        
    except Exception as e:
        logger.error(f"FAIL: Error testing ColBERT mock encoder: {e}")
        return False

def test_colbert_score_validation():
    """Test that ColBERT score validation detects problematic scores."""
    logger.info("Testing ColBERT score validation...")
    
    try:
        # Mock the ColBERT pipeline class to test score validation
        class MockColBERTRAGPipeline:
            def _validate_maxsim_scores(self, scores: List[float], query_text: str) -> bool:
                """Copy of the validation method from ColBERTRAGPipeline"""
                if not scores:
                    return True
                    
                # Check for too many identical or near-identical scores
                unique_scores = set(round(score, 4) for score in scores)
                identical_threshold = 0.8  # 80% of scores are identical
                
                if len(unique_scores) / len(scores) < (1 - identical_threshold):
                    logger.warning(f"ColBERT Score Validation: {len(scores) - len(unique_scores)} out of {len(scores)} scores are nearly identical")
                    return False
                    
                # Check for all perfect scores (1.0)
                perfect_scores = sum(1 for score in scores if score >= 0.99)
                if perfect_scores > len(scores) * 0.5:  # More than 50% perfect scores
                    logger.warning(f"ColBERT Score Validation: {perfect_scores} out of {len(scores)} documents have perfect scores")
                    return False
                    
                return True
        
        mock_pipeline = MockColBERTRAGPipeline()
        
        # Test with problematic scores (all identical)
        bad_scores = [1.0, 1.0, 1.0, 1.0, 1.0]
        result = mock_pipeline._validate_maxsim_scores(bad_scores, "test query")
        if result:
            logger.error("FAIL: Score validation should have detected identical scores")
            return False
        else:
            logger.info("PASS: Score validation correctly detected identical scores")
        
        # Test with good scores (diverse)
        good_scores = [0.95, 0.87, 0.76, 0.65, 0.54]
        result = mock_pipeline._validate_maxsim_scores(good_scores, "test query")
        if not result:
            logger.error("FAIL: Score validation should have passed for diverse scores")
            return False
        else:
            logger.info("PASS: Score validation correctly passed diverse scores")
        
        return True
        
    except Exception as e:
        logger.error(f"FAIL: Error testing ColBERT score validation: {e}")
        return False

def test_noderag_relevance_filtering():
    """Test that NodeRAG relevance filtering works correctly."""
    logger.info("Testing NodeRAG relevance filtering...")
    
    try:
        # Mock the NodeRAG pipeline class to test relevance filtering
        class MockNodeRAGPipeline:
            def __init__(self):
                self.logger = logger
                
            def _filter_relevant_nodes(self, candidate_results: List[tuple], query_text: str) -> List[str]:
                """Copy of the filtering method from NodeRAGPipeline"""
                if not candidate_results:
                    return []
                
                query_lower = query_text.lower()
                
                # Define domain-specific keywords for relevance filtering
                medical_terms = ['medical', 'health', 'disease', 'treatment', 'patient', 'clinical', 
                                'therapy', 'diagnosis', 'medicine', 'hospital', 'doctor', 'cancer']
                
                # Determine query domain
                query_is_medical = any(term in query_lower for term in medical_terms)
                
                if not query_is_medical:
                    # For non-medical queries, return all (simplified test)
                    return [str(result[0]) for result in candidate_results]
                
                # Apply medical domain filtering
                filtered_nodes = []
                for result in candidate_results:
                    node_id = str(result[0])
                    title = result[2] if len(result) > 2 and result[2] else ""
                    content = result[3] if len(result) > 3 and result[3] else ""
                    
                    combined_text = (title + " " + content).lower()
                    has_medical = any(term in combined_text for term in medical_terms)
                    
                    if has_medical:
                        filtered_nodes.append(node_id)
                
                return filtered_nodes
        
        mock_pipeline = MockNodeRAGPipeline()
        
        # Test with medical query and mixed content
        medical_query = "What are the treatments for cancer?"
        candidate_results = [
            ("doc1", 0.9, "Cancer Treatment Guidelines", "This document discusses medical treatments for cancer patients"),
            ("doc2", 0.8, "Forest Management", "This document discusses forestry and tree management practices"),
            ("doc3", 0.7, "Clinical Trials", "This document covers clinical research and patient care")
        ]
        
        filtered_nodes = mock_pipeline._filter_relevant_nodes(candidate_results, medical_query)
        
        # Should keep doc1 and doc3 (medical content), filter out doc2 (forestry)
        expected_nodes = ["doc1", "doc3"]
        
        if set(filtered_nodes) == set(expected_nodes):
            logger.info("PASS: NodeRAG relevance filtering correctly filtered irrelevant documents")
            logger.info(f"Kept nodes: {filtered_nodes}")
            return True
        else:
            logger.error(f"FAIL: NodeRAG relevance filtering failed. Expected {expected_nodes}, got {filtered_nodes}")
            return False
        
    except Exception as e:
        logger.error(f"FAIL: Error testing NodeRAG relevance filtering: {e}")
        return False

def main():
    """Run all tests."""
    logger.info("Starting urgent fixes validation tests...")
    
    tests = [
        ("ColBERT Mock Encoder Diversity", test_colbert_mock_encoder),
        ("ColBERT Score Validation", test_colbert_score_validation),
        ("NodeRAG Relevance Filtering", test_noderag_relevance_filtering)
    ]
    
    results = []
    for test_name, test_func in tests:
        logger.info(f"\n{'='*60}")
        logger.info(f"Running test: {test_name}")
        logger.info(f"{'='*60}")
        
        try:
            result = test_func()
            results.append((test_name, result))
            status = "PASS" if result else "FAIL"
            logger.info(f"Test result: {status}")
        except Exception as e:
            logger.error(f"Test failed with exception: {e}")
            results.append((test_name, False))
    
    # Summary
    logger.info(f"\n{'='*60}")
    logger.info("TEST SUMMARY")
    logger.info(f"{'='*60}")
    
    passed = 0
    for test_name, result in results:
        status = "PASS" if result else "FAIL"
        logger.info(f"{test_name}: {status}")
        if result:
            passed += 1
    
    logger.info(f"\nOverall: {passed}/{len(results)} tests passed")
    
    if passed == len(results):
        logger.info("üéâ All urgent fixes are working correctly!")
        return 0
    else:
        logger.error("‚ùå Some fixes need attention")
        return 1

if __name__ == "__main__":
    sys.exit(main())