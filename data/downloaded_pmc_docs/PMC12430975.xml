<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xml:lang="en" article-type="research-article" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="pmc-domain-id">1660</journal-id><journal-id journal-id-type="pmc-domain">sensors</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>Multidisciplinary Digital Publishing Institute  (MDPI)</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12430975</article-id><article-id pub-id-type="pmcid-ver">PMC12430975.1</article-id><article-id pub-id-type="pmcaid">12430975</article-id><article-id pub-id-type="pmcaiid">12430975</article-id><article-id pub-id-type="doi">10.3390/s25175402</article-id><article-id pub-id-type="publisher-id">sensors-25-05402</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Speckle Noise Reduction in Digital Holography by 3D Adaptive Filtering</article-title></title-group><contrib-group><contrib contrib-type="author"><name name-style="western"><surname>Kerov</surname><given-names initials="AA">Andrey A.</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#8211; original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role></contrib><contrib contrib-type="author"><name name-style="western"><surname>Kozlov</surname><given-names initials="AV">Alexander V.</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-3556-2663</contrib-id><name name-style="western"><surname>Cheremkhin</surname><given-names initials="PA">Pavel A.</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#8211; original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><xref rid="c1-sensors-25-05402" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-7816-5989</contrib-id><name name-style="western"><surname>Shifrina</surname><given-names initials="AV">Anna V.</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project administration</role></contrib><contrib contrib-type="author"><name name-style="western"><surname>Starikov</surname><given-names initials="RS">Rostislav S.</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project administration</role></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-1340-7734</contrib-id><name name-style="western"><surname>Zlokazov</surname><given-names initials="EY">Evgenii Y.</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role></contrib><contrib contrib-type="author"><name name-style="western"><surname>Petrova</surname><given-names initials="EK">Elizaveta K.</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project administration</role></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-3937-3982</contrib-id><name name-style="western"><surname>Nebavskiy</surname><given-names initials="VA">Vsevolod A.</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-3515-5822</contrib-id><name name-style="western"><surname>Evtikhiev</surname><given-names initials="NN">Nikolay N.</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Resources" vocab-term-identifier="https://credit.niso.org/contributor-roles/resources/">Resources</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name name-style="western"><surname>Mercaldo</surname><given-names initials="F">Francesco</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-05402">Laser Physics Department, Institute for Laser and Plasma Technologies, National Research Nuclear University MEPhI (Moscow Engineering Physics Institute), Kashirskoe Shosse 31, 115409 Moscow, Russia<email>avshifrina@gmail.com</email> (A.V.S.); <email>ezlokazov@gmail.com</email> (E.Y.Z.); </aff><author-notes><corresp id="c1-sensors-25-05402"><label>*</label>Correspondence: <email>cheremhinpavel@mail.ru</email></corresp></author-notes><pub-date pub-type="epub"><day>01</day><month>9</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>9</month><year>2025</year></pub-date><volume>25</volume><issue>17</issue><issue-id pub-id-type="pmc-issue-id">496815</issue-id><elocation-id>5402</elocation-id><history><date date-type="received"><day>29</day><month>7</month><year>2025</year></date><date date-type="rev-recd"><day>24</day><month>8</month><year>2025</year></date><date date-type="accepted"><day>30</day><month>8</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>01</day><month>09</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>13</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-13 17:25:36.317"><day>13</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="sensors-25-05402.pdf"/><abstract><p>Digital holography enables the reconstruction of both 2D and 3D object information from interference patterns captured by digital cameras. A major challenge in this field is speckle noise, which significantly degrades the quality of the reconstructed images. We propose a novel speckle noise reduction method based on 3D adaptive filtering. Our technique processes a stack of holograms, each with an uncorrelated speckle pattern, using an adapted 3D Frost filter. Unlike conventional filtering techniques, our approach exploits statistical adaptivity to enhance noise suppression while preserving fine image details in the reconstructed holograms. Both numerical simulations and optical experiments confirm that our 3D filtering technique significantly enhances reconstruction quality. Specifically, it reduces the normalized standard deviation by up to 40% and improves the structural similarity index by up to 60% compared to classical 2D, 3D median, BM3D, and BM4D filters. Optical experiments validate the method&#8217;s effectiveness in practical digital holography scenarios by local and global image quality estimation metrics. These results highlight adaptive 3D filtering as a promising approach for mitigating speckle noise while maintaining structural integrity in digital holography reconstructions.</p></abstract><kwd-group><kwd>digital holography</kwd><kwd>denoising</kwd><kwd>speckle noise</kwd><kwd>sensor</kwd><kwd>3D filtering</kwd><kwd>image enhancement</kwd><kwd>multi-look technique</kwd><kwd>optical-digital technique</kwd><kwd>adaptive filtering</kwd><kwd>noise reduction</kwd></kwd-group><funding-group><award-group><funding-source>Russian Science Foundation (RSF)</funding-source><award-id>24-19-00899</award-id></award-group><funding-statement>This work was supported by grant 24-19-00899 from the Russian Science Foundation (RSF).</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-05402"><title>1. Introduction</title><p>Holography is a technique of recording both the amplitude and phase information of an object [<xref rid="B1-sensors-25-05402" ref-type="bibr">1</xref>], distinguishing it from classical imaging methods, which capture only amplitude distribution. Initially, holograms were recorded on photosensitive plates using weakly coherent light sources. The advent of coherent laser sources enabled the production of high-quality holograms, leading to the widespread adoption of holography [<xref rid="B2-sensors-25-05402" ref-type="bibr">2</xref>]. The development of digital recording and image processing techniques further advanced this field, giving rise to digital holography, where digital cameras replace photosensitive plates for image capture, and computer-generated holography. This digital approach has found applications in diverse areas such as information security and encryption [<xref rid="B3-sensors-25-05402" ref-type="bibr">3</xref>], optical data archiving [<xref rid="B4-sensors-25-05402" ref-type="bibr">4</xref>], holographic displays [<xref rid="B5-sensors-25-05402" ref-type="bibr">5</xref>], beam profiling [<xref rid="B6-sensors-25-05402" ref-type="bibr">6</xref>] and shaping [<xref rid="B7-sensors-25-05402" ref-type="bibr">7</xref>], microscopy [<xref rid="B8-sensors-25-05402" ref-type="bibr">8</xref>], material characterization [<xref rid="B9-sensors-25-05402" ref-type="bibr">9</xref>], visible light [<xref rid="B10-sensors-25-05402" ref-type="bibr">10</xref>] and terahertz imaging [<xref rid="B11-sensors-25-05402" ref-type="bibr">11</xref>], object detection [<xref rid="B12-sensors-25-05402" ref-type="bibr">12</xref>], and many others.</p><p>Despite these advances, holographic image recording methods face certain challenges. Besides the inherent noise of digital cameras [<xref rid="B13-sensors-25-05402" ref-type="bibr">13</xref>], speckle noise [<xref rid="B14-sensors-25-05402" ref-type="bibr">14</xref>]&#8212;a granular interference pattern arising from the coherent nature of holographic imaging&#8212;remains a significant factor in degrading image quality. Techniques for speckle noise reduction broadly fall into two categories: digital [<xref rid="B15-sensors-25-05402" ref-type="bibr">15</xref>,<xref rid="B16-sensors-25-05402" ref-type="bibr">16</xref>,<xref rid="B17-sensors-25-05402" ref-type="bibr">17</xref>,<xref rid="B18-sensors-25-05402" ref-type="bibr">18</xref>,<xref rid="B19-sensors-25-05402" ref-type="bibr">19</xref>,<xref rid="B20-sensors-25-05402" ref-type="bibr">20</xref>,<xref rid="B21-sensors-25-05402" ref-type="bibr">21</xref>,<xref rid="B22-sensors-25-05402" ref-type="bibr">22</xref>,<xref rid="B23-sensors-25-05402" ref-type="bibr">23</xref>,<xref rid="B24-sensors-25-05402" ref-type="bibr">24</xref>,<xref rid="B25-sensors-25-05402" ref-type="bibr">25</xref>,<xref rid="B26-sensors-25-05402" ref-type="bibr">26</xref>,<xref rid="B27-sensors-25-05402" ref-type="bibr">27</xref>,<xref rid="B28-sensors-25-05402" ref-type="bibr">28</xref>,<xref rid="B29-sensors-25-05402" ref-type="bibr">29</xref>] and optical-digital [<xref rid="B30-sensors-25-05402" ref-type="bibr">30</xref>,<xref rid="B31-sensors-25-05402" ref-type="bibr">31</xref>,<xref rid="B32-sensors-25-05402" ref-type="bibr">32</xref>,<xref rid="B33-sensors-25-05402" ref-type="bibr">33</xref>,<xref rid="B34-sensors-25-05402" ref-type="bibr">34</xref>,<xref rid="B35-sensors-25-05402" ref-type="bibr">35</xref>,<xref rid="B36-sensors-25-05402" ref-type="bibr">36</xref>,<xref rid="B37-sensors-25-05402" ref-type="bibr">37</xref>,<xref rid="B38-sensors-25-05402" ref-type="bibr">38</xref>] methods. Digital methods focus on the postprocessing of a single recorded hologram to mitigate noise, but often at the cost of reduced image contrast and limited effectiveness in handling 3D scene depth. In contrast, optical-digital approaches improve noise suppression by modifying the optical setup to capture multiple holograms with varying speckle patterns. Such modifications include camera [<xref rid="B30-sensors-25-05402" ref-type="bibr">30</xref>] or object shifting [<xref rid="B31-sensors-25-05402" ref-type="bibr">31</xref>], the use of diffusers [<xref rid="B32-sensors-25-05402" ref-type="bibr">32</xref>], angular detuning [<xref rid="B33-sensors-25-05402" ref-type="bibr">33</xref>], and other optical adjustments, though these can pose practical limitations.</p><p>While recent deep learning approaches [<xref rid="B39-sensors-25-05402" ref-type="bibr">39</xref>,<xref rid="B40-sensors-25-05402" ref-type="bibr">40</xref>,<xref rid="B41-sensors-25-05402" ref-type="bibr">41</xref>] show promise, their requirement for large annotated datasets and substantial computational resources limits their practicality in many scenarios.</p><p>In this article, we introduce a novel optical-digital method that utilizes advanced 3D adaptive filtering techniques. Unlike conventional methods such as median or averaging filters, our approach applies a modified adaptive Frost filter to a 3D array of reconstructed holographic images formed from multiple uncorrelated holograms. This hybrid approach combines the multi-look principle with sophisticated 3D adaptive filtering, yielding superior noise reduction compared to traditional and state-of-the-art methods.</p><p>The structure of the paper is as follows. <xref rid="sec2-sensors-25-05402" ref-type="sec">Section 2</xref> discusses the theoretical background of the methods employed. <xref rid="sec3-sensors-25-05402" ref-type="sec">Section 3</xref> details the proposed 3D adaptive filtering algorithm for holographic data. <xref rid="sec4-sensors-25-05402" ref-type="sec">Section 4</xref> presents numerical experiments and their outcomes, followed by <xref rid="sec5-sensors-25-05402" ref-type="sec">Section 5</xref>, which describes the optical experiments. Finally, the Conclusions summarize the key results.</p></sec><sec id="sec2-sensors-25-05402"><title>2. Theory</title><sec id="sec2dot1-sensors-25-05402"><title>2.1. Holography</title><p>A hologram is a recorded interference pattern of two beams [<xref rid="B9-sensors-25-05402" ref-type="bibr">9</xref>], which are called the object beam <italic toggle="yes">E<sub>o</sub></italic>, the wavefront of which has interacted with the object, and the reference beam <italic toggle="yes">E<sub>r</sub></italic>, the wavefront of which stays unchanged. The intensity distribution in that case is given by<disp-formula id="FD1-sensors-25-05402"><label>(1)</label><mml:math id="mm1" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Then, the image of the object can be obtained by multiplying the intensity distribution <inline-formula><mml:math id="mm2" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> by the complex conjugate of the reference beam <inline-formula><mml:math id="mm3" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="FD2-sensors-25-05402"><label>(2)</label><mml:math id="mm4" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:msubsup><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msubsup><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msubsup><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msubsup><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo></mml:mrow><mml:mspace linebreak="newline"/><mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:msup><mml:mrow><mml:msubsup><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msubsup><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>During image reconstruction from a hologram, three diffraction orders typically arise. The zero-order diffraction, corresponding to the first two terms in Equation (2), represents undiffracted radiation and manifests as uniform illumination. The other two orders correspond to the informative object image and the undesired twin image [<xref rid="B42-sensors-25-05402" ref-type="bibr">42</xref>]. The presence of zero-order and twin images is a significant limitation in many recording methods, as the intensity of the original radiation contributes to unwanted diffraction orders alongside the informative object image [<xref rid="B43-sensors-25-05402" ref-type="bibr">43</xref>]. To address this, spatial separation of diffraction orders is commonly employed, enabling isolation and reconstruction of the informative wavefront [<xref rid="B43-sensors-25-05402" ref-type="bibr">43</xref>].</p><p>With advances in computer technologies, a new branch of holography&#8212;discrete holography&#8212;has emerged, encompassing both digital and computer holography. Computer holography [<xref rid="B44-sensors-25-05402" ref-type="bibr">44</xref>,<xref rid="B45-sensors-25-05402" ref-type="bibr">45</xref>] involves synthesizing holograms of modeled objects that may not physically exist, followed by their optical reconstruction. In contrast, digital holography captures holograms using digital imaging methods, with subsequent reconstruction performed either computationally or optically [<xref rid="B46-sensors-25-05402" ref-type="bibr">46</xref>]. The development of digital hologram recording and reconstruction techniques has opened new opportunities to improve image quality through purely digital processing.</p><p>The main factors degrading image quality in digital holography include digital camera noise [<xref rid="B13-sensors-25-05402" ref-type="bibr">13</xref>], zero-order and twin images [<xref rid="B47-sensors-25-05402" ref-type="bibr">47</xref>], and speckle noise [<xref rid="B14-sensors-25-05402" ref-type="bibr">14</xref>]. Among these, speckle noise is typically the most significant contributor to degradation. It arises from the variability of the medium through which the laser radiation propagates during hologram formation, producing a random interference pattern of diffusely scattered light beams that is recorded by the camera alongside the useful signal. Speckle noise [<xref rid="B48-sensors-25-05402" ref-type="bibr">48</xref>] is commonly quantified using the root mean square deviation [<xref rid="B49-sensors-25-05402" ref-type="bibr">49</xref>]:<disp-formula id="FD4-sensors-25-05402"><label>(3)</label><mml:math id="mm5" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mi>I</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">C</italic> is the speckle coefficient, which is a constant and can be experimentally estimated; <italic toggle="yes">I</italic> is the average intensity of the reconstructed image.</p></sec><sec id="sec2dot2-sensors-25-05402"><title>2.2. Speckle Suppression Methods</title><p>Speckle noise reduction methods can be broadly divided into two categories: digital and optical-digital approaches. Digital methods aim to filter a single recorded hologram using computational algorithms that suppress noise while preserving image details. Basic techniques include median filtering [<xref rid="B23-sensors-25-05402" ref-type="bibr">23</xref>] and averaging [<xref rid="B24-sensors-25-05402" ref-type="bibr">24</xref>], while more advanced methods utilize local statistical characteristics of the image. These include the Wiener filter [<xref rid="B25-sensors-25-05402" ref-type="bibr">25</xref>], Lee filter [<xref rid="B26-sensors-25-05402" ref-type="bibr">26</xref>], and Frost filter [<xref rid="B27-sensors-25-05402" ref-type="bibr">27</xref>]. Further improvements have been achieved using more sophisticated approaches, such as the iterative techniques [<xref rid="B15-sensors-25-05402" ref-type="bibr">15</xref>], mean-median filter [<xref rid="B16-sensors-25-05402" ref-type="bibr">16</xref>], BM3D [<xref rid="B28-sensors-25-05402" ref-type="bibr">28</xref>] and its modifications [<xref rid="B17-sensors-25-05402" ref-type="bibr">17</xref>], BM4D [<xref rid="B18-sensors-25-05402" ref-type="bibr">18</xref>], total variation [<xref rid="B19-sensors-25-05402" ref-type="bibr">19</xref>], wavelet-based filtering [<xref rid="B20-sensors-25-05402" ref-type="bibr">20</xref>], non-local means filtering [<xref rid="B21-sensors-25-05402" ref-type="bibr">21</xref>], interpolation-filtering techniques [<xref rid="B22-sensors-25-05402" ref-type="bibr">22</xref>], compressed sensing [<xref rid="B29-sensors-25-05402" ref-type="bibr">29</xref>], and neighborhood filtering [<xref rid="B50-sensors-25-05402" ref-type="bibr">50</xref>]. These advanced algorithms leverage spatial redundancy and correlations in holographic data to enhance noise suppression while maintaining structural integrity.</p><p>Optical-digital methods, in contrast, modify the hologram recording setup to vary the speckle pattern before computational processing. This hybrid approach often outperforms purely digital methods, particularly when multiple holograms with different speckle realizations are available for processing. Optical-digital approaches typically involve two main steps:<list list-type="bullet"><list-item><p>Recording multiple holograms with varying speckle distributions. This is achieved through modifications to the optical setup, such as using diffuser filters [<xref rid="B32-sensors-25-05402" ref-type="bibr">32</xref>], angular detuning [<xref rid="B33-sensors-25-05402" ref-type="bibr">33</xref>], polarization detuning [<xref rid="B34-sensors-25-05402" ref-type="bibr">34</xref>], or wavelength detuning [<xref rid="B35-sensors-25-05402" ref-type="bibr">35</xref>];</p></list-item><list-item><p>Computational postprocessing of the acquired hologram set to suppress noise and improve image quality.</p></list-item></list></p><p>The simplest form of this method is to average a stack of reconstructed images [<xref rid="B33-sensors-25-05402" ref-type="bibr">33</xref>,<xref rid="B34-sensors-25-05402" ref-type="bibr">34</xref>,<xref rid="B35-sensors-25-05402" ref-type="bibr">35</xref>]. Some techniques also apply additional filtering to the averaged image [<xref rid="B32-sensors-25-05402" ref-type="bibr">32</xref>,<xref rid="B36-sensors-25-05402" ref-type="bibr">36</xref>]. A more advanced strategy, proposed in [<xref rid="B37-sensors-25-05402" ref-type="bibr">37</xref>], involves filtering the entire 3D array of reconstructed images. The algorithm operates as follows:<list list-type="bullet"><list-item><p>A 3D stack is formed from multiple reconstructed images with different speckle realizations;</p></list-item><list-item><p>A filtration window of size <inline-formula><mml:math id="mm97" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mi>N</mml:mi><mml:mo>,</mml:mo><mml:mo>&#160;</mml:mo><mml:mi>N</mml:mi><mml:mo>,</mml:mo><mml:mo>&#160;</mml:mo><mml:mi>M</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is defined, where <inline-formula><mml:math id="mm70" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> (odd) denotes the spatial dimensions within each image, and <inline-formula><mml:math id="mm80" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is the number of images in the stack;</p></list-item><list-item><p>For each voxel in the array, the median value within the window is computed and assigned to the corresponding pixel in the output image;</p></list-item><list-item><p>This process is repeated until the entire image is filtered;</p></list-item><list-item><p>This 3D filtering approach has shown a notable improvement in hologram quality compared to classical methods, as it effectively leverages both spatial and cross-frame information to suppress speckle noise.</p></list-item></list></p></sec><sec id="sec2dot3-sensors-25-05402"><title>2.3. Frost Filter</title><p>The Frost filter is a well-established adaptive filter for speckle noise reduction [<xref rid="B51-sensors-25-05402" ref-type="bibr">51</xref>]. The filter&#8217;s adaptivity is dictated by the following algorithm:<list list-type="order"><list-item><p>A filtration window <italic toggle="yes">I</italic> of the image of size <inline-formula><mml:math id="mm90" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mi>N</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>N</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> pixels is selected, where the window size must be odd to ensure the central position of the filtered pixel <inline-formula><mml:math id="mm99" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#958;</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>;</p></list-item><list-item><p>For the window <italic toggle="yes">I</italic>, the distances from the central pixel <inline-formula><mml:math id="mm6" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#958;</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to neighboring pixels are calculated and placed in the matrix <italic toggle="yes">S</italic>. This approach allows for greater consideration of pixels closer to <inline-formula><mml:math id="mm7" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#958;</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> than those farther away;</p></list-item><list-item><p>The average value <inline-formula><mml:math id="mm8" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mo>&#175;</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula> and variation <inline-formula><mml:math id="mm9" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> are calculated for the pixels in the window;</p></list-item><list-item><p>The weighting parameter is then calculated, taking into account the statistical deviations of pixel values in the filtration window:</p></list-item></list>
<disp-formula id="FD5-sensors-25-05402"><label>(4)</label><mml:math id="mm10" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:mo>&#8901;</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mo>&#175;</mml:mo></mml:mover></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm11" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is the damping coefficient value, responsible for the smoothness of filtration. Increasing <inline-formula><mml:math id="mm12" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> increases the sharpness of high-frequency areas of the image but reduces the quality of noise filtration.</p><list list-type="order"><list-item><p>The pixel weight matrix <inline-formula><mml:math id="mm13" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>W</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mi>B</mml:mi><mml:mo>&#8901;</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is calculated based on the obtained parameters;</p></list-item><list-item><p>The filtered pixel value is calculated: <inline-formula><mml:math id="mm14" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mo>&#8721;</mml:mo><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>&#8901;</mml:mo><mml:mi>W</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#8721;</mml:mo><mml:mi>W</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></list-item></list><p>This filter is adaptive, preserving the sharpness of image edges during filtration.</p></sec></sec><sec id="sec3-sensors-25-05402"><title>3. The Proposed Method</title><p>In the context of digital hologram enhancement, locally weighted filters&#8212;such as the Frost filter [<xref rid="B27-sensors-25-05402" ref-type="bibr">27</xref>]&#8212;demonstrate superior performance compared to simpler algorithms like median filtering or averaging. Traditional 3D median or average filtering offers a straightforward approach to processing volumetric data by computing the median or mean value of pixels within a fixed window. While effective at suppressing outliers caused by speckle noise, these methods do not account for local statistical variations, often leading to detail loss in areas with high-intensity gradients.</p><p>We propose a 3D speckle reduction algorithm by extending the classic Frost filter into the volumetric domain. Our modified filter operates on a 3D volume, capturing spatial correlations within each image and temporal correlations across the stack of reconstructions. This is accomplished by incorporating adaptive behavior based on local statistical properties, allowing the filter to adjust dynamically to different image regions.</p><p>In the proposed 3D algorithm, the Frost filter is modified as follows. For each spatial location <inline-formula><mml:math id="mm15" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, a 3D processing window of size <inline-formula><mml:math id="mm16" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>W</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>W</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is defined, where <inline-formula><mml:math id="mm17" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>W</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is the side length of the square window, and <inline-formula><mml:math id="mm18" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is the number of reconstructed holograms.</p><p>The local mean and variance are computed across the full 3D window:<disp-formula id="FD6-sensors-25-05402"><label>(5)</label><mml:math id="mm19" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#956;</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mstyle><mml:mrow><mml:msub><mml:mo stretchy="false">&#8721;</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>&#8712;</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mi>A</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="FD7-sensors-25-05402"><label>(6)</label><mml:math id="mm20" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mstyle><mml:mrow><mml:munder><mml:mo mathsize="130%">&#8721;</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>&#8712;</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>A</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mfenced><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mi>&#956;</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm21" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> is the intensity at position <inline-formula><mml:math id="mm22" overflow="scroll"><mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> at slice <inline-formula><mml:math id="mm23" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. The damping coefficient is then calculated as<disp-formula id="FD8-sensors-25-05402"><label>(7)</label><mml:math id="mm24" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>&#945;</mml:mi><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>&#956;</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>&#949;</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
with <inline-formula><mml:math id="mm25" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> being the damping factor and <inline-formula><mml:math id="mm26" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#949;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> a small constant to prevent division by zero.</p><p>The distance term is retained only in the spatial domain:<disp-formula id="FD9-sensors-25-05402"><label>(8)</label><mml:math id="mm27" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msqrt><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>u</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>v</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
since inter-slice geometric distances are not physically meaningful for the reconstruction of the same scene under different speckle realizations. Treating all slices equally ensures that speckle diversity is fully exploited, while spatial fidelity is preserved.</p><p>Accordingly, the weight is assigned to each voxel:<disp-formula id="FD10-sensors-25-05402"><label>(9)</label><mml:math id="mm28" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
which is normalized as<disp-formula id="FD11-sensors-25-05402"><label>(10)</label><mml:math id="mm29" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover><mml:mfenced separators="|"><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>w</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mo stretchy="false">&#8721;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup><mml:mo>&#8712;</mml:mo><mml:mi>W</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mrow><mml:mi>w</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8242;</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Finally, the filtered pixel value is computed as the weighted average:<disp-formula id="FD12-sensors-25-05402"><label>(11)</label><mml:math id="mm30" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo mathsize="140%">&#8721;</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>&#8712;</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover><mml:mfenced separators="|"><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mfenced><mml:mi>A</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Boundary regions are handled by zero-padding the input stack.</p><p>The algorithm consists of the following key steps:<list list-type="bullet"><list-item><p>Recording a series of holograms with varying speckle distributions, enabled by modifying the optical setup;</p></list-item><list-item><p>Reconstructing the holograms to form a 3D stack of images;</p></list-item><list-item><p>Applying the modified adaptive Frost filter to the entire 3D dataset, leveraging cross-layer statistics for enhanced speckle reduction;</p></list-item><list-item><p>A schematic overview of the proposed method is provided in <xref rid="sensors-25-05402-f001" ref-type="fig">Figure 1</xref>.</p></list-item></list></p><p>In summary, the proposed 3D Frost filtering approach enhances digital hologram reconstruction by incorporating both intra-layer and inter-layer statistical dependencies into a unified adaptive framework. Unlike conventional 2D methods, the 3D approach takes full advantage of volumetric multi-speckle data, enabling it to distinguish noise from true structural variations&#8212;even in regions with steep gradients&#8212;while preserving fine image details.</p></sec><sec id="sec4-sensors-25-05402"><title>4. Numerical Experiments</title><p>Initially, the proposed method, along with the standard and state-of-the-art algorithms, was evaluated through numerical experiments for speckle noise reduction. Test images &#8220;Peppers&#8221; and &#8220;Baboon&#8221;, each with a resolution of 256 &#215; 256 pixels, are shown in <xref rid="sensors-25-05402-f002" ref-type="fig">Figure 2</xref>a,b, respectively. Holograms were synthesized using direct Fresnel diffraction calculations via the single-fast Fourier transform method [<xref rid="B52-sensors-25-05402" ref-type="bibr">52</xref>]. To simulate a 3D stack, speckle noise was modeled according to the statistics of fully developed speckle, where the intensity <inline-formula><mml:math id="mm31" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> follows a negative exponential distribution [<xref rid="B48-sensors-25-05402" ref-type="bibr">48</xref>]:<disp-formula id="FD13-sensors-25-05402"><label>(12)</label><mml:math id="mm32" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mo>&#175;</mml:mo></mml:mover></mml:mrow></mml:mfrac></mml:mstyle><mml:mrow><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mo>&#175;</mml:mo></mml:mover></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>&#8805;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm33" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mo>&#175;</mml:mo></mml:mover><mml:mo>&#160;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the average value. Independent realizations of speckle were generated for each image, and the noise was applied in a multiplicative manner by scaling every pixel intensity of the hologram with the corresponding speckle factor.</p><p>For image reconstruction, inverse direct calculation of Fresnel diffraction was used. Examples of noisy images are shown in <xref rid="sensors-25-05402-f002" ref-type="fig">Figure 2</xref>c,d.</p><sec id="sec4dot1-sensors-25-05402"><title>4.1. Reconstructed Image Quality Metrics</title><p>In addition to speckle contrast (see Equation (4)), the normalized standard deviation (NSTD) [<xref rid="B53-sensors-25-05402" ref-type="bibr">53</xref>], the structural similarity index (SSIM) [<xref rid="B54-sensors-25-05402" ref-type="bibr">54</xref>], blind/referenceless image spatial quality evaluator (BRISQUE) [<xref rid="B55-sensors-25-05402" ref-type="bibr">55</xref>], and perception-based image quality evaluator (PIQE) [<xref rid="B56-sensors-25-05402" ref-type="bibr">56</xref>] were used.</p><p>The NSTD is a pixel-by-pixel comparison method, while SSIM performs a comparison in a certain neighborhood of each pixel. Thus, a more accurate assessment of filtration quality can be obtained not only globally&#8212;since the statistical features of the image are spatially non-uniform&#8212;but also locally.</p><p>Each local SSIM assessment is calculated in a certain neighborhood of the investigated pixel [<xref rid="B54-sensors-25-05402" ref-type="bibr">54</xref>]. The output values will range from &#8722;1 to +1. A value of +1 will be obtained in the case of the complete identity of the compared images. Mathematically, SSIM is expressed as follows:<disp-formula id="FD14-sensors-25-05402"><label>(13)</label><mml:math id="mm34" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">I</mml:mi><mml:mi mathvariant="normal">M</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>&#956;</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>&#956;</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mfenced separators="|"><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>&#956;</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>&#956;</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm35" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#956;</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm36" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#956;</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>&#160;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are the average signal intensities, <inline-formula><mml:math id="mm37" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm38" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> are standard deviations, <inline-formula><mml:math id="mm39" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is covariance, <inline-formula><mml:math id="mm40" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm41" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> are constants.</p><p>NSTD is a common measure for assessing image quality and intensity distribution, in particular [<xref rid="B53-sensors-25-05402" ref-type="bibr">53</xref>]<disp-formula id="FD15-sensors-25-05402"><label>(14)</label><mml:math id="mm42" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">D</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">&#8721;</mml:mo><mml:mrow><mml:mi>&#958;</mml:mi><mml:mo>,</mml:mo><mml:mi>&#951;</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi>E</mml:mi><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mi>&#958;</mml:mi><mml:mo>,</mml:mo><mml:mi>&#951;</mml:mi></mml:mrow></mml:mfenced><mml:mi>F</mml:mi><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mi>&#958;</mml:mi><mml:mo>,</mml:mo><mml:mi>&#951;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">&#8721;</mml:mo><mml:mrow><mml:mi>&#958;</mml:mi><mml:mo>,</mml:mo><mml:mi>&#951;</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mi>&#958;</mml:mi><mml:mo>,</mml:mo><mml:mi>&#951;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mfenced><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">&#8721;</mml:mo><mml:mrow><mml:mi>&#958;</mml:mi><mml:mo>,</mml:mo><mml:mi>&#951;</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mi>&#958;</mml:mi><mml:mo>,</mml:mo><mml:mi>&#951;</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm43" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm44" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> are the original and reconstructed images, respectively; <inline-formula><mml:math id="mm45" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mo>&#160;</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> are image dimensions; <inline-formula><mml:math id="mm46" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#958;</mml:mi><mml:mo>,</mml:mo><mml:mi>&#951;</mml:mi><mml:mo>&#160;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are the pixel numbers.</p><p>The NSTD value allows us to determine the degree of difference between images. The similarity assessment is based on the assumption that if the NSTD value is 0, the images are completely identical. If the NSTD value is close to 1, this indicates a significant difference between the images.</p><p>In addition to reference-based metrics (NSTD and SSIM), we also employed no-reference quality assessment methods, which allow evaluating images without the need for a ground truth. One such metric is the BRISQUE [<xref rid="B55-sensors-25-05402" ref-type="bibr">55</xref>]. It is based on natural scene statistics in the spatial domain and quantifies deviations from the regular statistical properties typically observed in natural images. This makes the metric particularly useful for coherent imaging scenarios, where reference images are often unavailable, and subjective visual quality is of primary importance:<disp-formula id="FD16-sensors-25-05402"><label>(15)</label><mml:math id="mm47" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi><mml:mi mathvariant="normal">R</mml:mi><mml:mi mathvariant="normal">I</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">Q</mml:mi><mml:mi mathvariant="normal">U</mml:mi><mml:mi mathvariant="normal">E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>v</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm48" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the natural scene statistics-based feature vector of the image <inline-formula><mml:math id="mm49" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="mm50" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is a regression model trained on subjective quality scores. A lower value of BRISQUE indicates higher perceptual quality.</p><p>The PIQE [<xref rid="B56-sensors-25-05402" ref-type="bibr">56</xref>] is another no-reference quality metric that extracts perceptually relevant features from different orientations and scales and classifies them into quality-aware categories. The final score is computed as a weighted aggregation of these feature-based distortions:<disp-formula id="FD17-sensors-25-05402"><label>(16)</label><mml:math id="mm51" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">I</mml:mi><mml:mi mathvariant="normal">Q</mml:mi><mml:mi mathvariant="normal">E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo mathsize="140%">&#8721;</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm52" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the distortion feature in the category <inline-formula><mml:math id="mm53" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="mm54" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the corresponding perceptual weight. Similar to BRISQUE, lower PIQE values indicate better perceptual quality.</p><p>Together, BRISQUE and PIQE provide complementary perspectives on image fidelity, enabling robust evaluation of speckle suppression methods in both simulated and experimental holographic data.</p></sec><sec id="sec4dot2-sensors-25-05402"><title>4.2. Filtration Using the Proposed Method</title><p>To expand the analysis, various denoising methods were used:<list list-type="bullet"><list-item><p>The classical Frost filter;</p></list-item><list-item><p>The proposed 3D Frost method applied to multiple reconstructed images;</p></list-item><list-item><p>The classical Lee filter;</p></list-item><list-item><p>The newly developed 3D Lee method, applied to multiple reconstructed images;</p></list-item><list-item><p>The 3D median method, applied to multiple reconstructed images;</p></list-item><list-item><p>The BM3D filter;</p></list-item><list-item><p>The BM4D filter, applied to multiple reconstructed images.</p></list-item></list></p><p>For the classical Frost filter [<xref rid="B27-sensors-25-05402" ref-type="bibr">27</xref>], a 3 &#215; 3 pixel window was used, as it provided optimal filtering performance while maintaining image sharpness. A damping factor of 3 was chosen to balance noise suppression and the preservation of high-frequency image details. The proposed 3D Frost filter used the same parameters to ensure fair comparability of the results. The Lee filter, a well-established adaptive filtering method based on local statistical analysis [<xref rid="B26-sensors-25-05402" ref-type="bibr">26</xref>], was also considered. Both the classical Lee filter and the novel 3D Lee filter were implemented with a 3 &#215; 3 window size. The 3D median filter, which has already demonstrated promising results in prior studies [<xref rid="B37-sensors-25-05402" ref-type="bibr">37</xref>], was also included for comparison. For benchmarking purposes, the proposed method was further compared to state-of-the-art algorithms: conventional BM3D [<xref rid="B28-sensors-25-05402" ref-type="bibr">28</xref>], which is applied to a single image, and BM4D [<xref rid="B14-sensors-25-05402" ref-type="bibr">14</xref>], which is applied to a set of images.</p><p>Filtered images obtained using each method are shown in <xref rid="sensors-25-05402-f003" ref-type="fig">Figure 3</xref>. For the 3D Frost, 3D Lee, 3D median, and BM4D filters, 90 reconstructed images were used. Quantitative metric values (NSTD and SSIM) for the filtered images are presented in <xref rid="sensors-25-05402-t001" ref-type="table">Table 1</xref>, with the best results highlighted in bold. The dependencies of NSTD and SSIM on the number of images used in the 3D filtering window are illustrated in <xref rid="sensors-25-05402-f004" ref-type="fig">Figure 4</xref>. Additionally, images that were denoised by the proposed method using different numbers of holograms are given in the attached video files (<xref rid="app1-sensors-25-05402" ref-type="app">Supplementary Materials</xref>).</p><p>Our method shows a significant improvement over the standard 2D Frost filter, reducing NSTD by over 60% and improving SSIM by over 160%. In contrast, reconstructed images using the standard Frost filter exhibit a high level of noise, highlighting the substantial advantage of the proposed 3D filtering approach over classical 2D methods.</p><p>Among the 3D filtering methods tested, the proposed 3D Frost method consistently delivered the best results. Compared to the 3D Lee and 3D median filters, it achieves roughly 20&#8211;30% improvements in NSTD and 10&#8211;35% improvements in SSIM, confirming that the 3D Frost filter is particularly effective for applications requiring strong noise suppression while preserving structural image details.</p><p>The dependency of SSIM and NSTD on the number of images in the 3D filtering window further illustrates the method&#8217;s efficiency. Remarkably, using only 10 images yields a 30% increase in SSIM and a 20% decrease in NSTD, reaching within 10% of the optimal values obtained using 90 images. Even with just five images, the proposed method often outperforms other filters applied to 90-image datasets. This efficiency demonstrates the algorithm&#8217;s ability to deliver near-optimal noise suppression and structural fidelity with minimal data and computational load. Unlike multi-look approaches that typically require hundreds of holograms, the proposed method achieves high-quality results with a significantly reduced number of inputs, making it particularly well-suited for time-sensitive applications.</p><p>In addition to outperforming classical and other 3D filters, the proposed method also surpasses state-of-the-art techniques such as BM3D and BM4D. As shown in <xref rid="sensors-25-05402-t001" ref-type="table">Table 1</xref>, it achieves significantly lower NSTD and higher SSIM values across standard test images (e.g., Baboon and Peppers). The proposed method reduces NSTD by roughly 40% and 30% relative to BM3D and BM4D, respectively, while improving structural similarity by more than 50% and 65%.</p><p>To show the proposed method&#8217;s advantages over state-of-the-art techniques more clearly, <xref rid="sensors-25-05402-t002" ref-type="table">Table 2</xref> is added. The SSIM and NSTD values for several other test images are given for the proposed method and the BM4D filter. Processing times are also shown. Ninety holograms were used for both denoising methods. Numerical simulations were performed on a desktop computer equipped with an AMD Ryzen 5 5600X processor (6 cores and 12 threads), 16 GB DDR4 RAM operating at 4000 MHz, and an NVIDIA GeForce GTX 1660 Ti GPU with 6 GB of VRAM.</p><p>It can be seen that the proposed method consistently maintains superior noise suppression and structural preservation. Moreover, it delivers this performance with exceptional computational efficiency&#8212;being approximately 200 times faster than BM4D.</p><p>Thus, the proposed method outperforms various existing standard and state-of-the-art techniques. It provides significantly better quality of the reconstructed images. Additionally, compared to the multi-look approaches, high-quality results can be achieved with a significantly reduced number of holograms. Moreover, the method is significantly faster than the block matching with 3D and 4D filtering.</p></sec></sec><sec id="sec5-sensors-25-05402"><title>5. Optical Experiments</title><p>To demonstrate the practical applicability of the developed methods, a series of holograms with varying speckle distributions was recorded. An 80 mW, 561 nm laser (CNI Co., Changchun, China, model SSP-SLM-561-FN) was used as the radiation source. To ensure uniform beam distribution, a spatial low-pass filter&#8212;consisting of a micro-lens and a 50 &#956;m aperture&#8212;was employed. Beam splitter 1 was used to divide the beam into reference and object beams.</p><p>To introduce variation in speckle distribution across the holograms, a rotating diffuser (&#8709;24 mm, 2.3 mm thickness, 80&#8211;50 scratch-dig surface quality on the smooth side, and &lt;3 arcmin parallelism) was placed in the object beam. After passing through the diffuser, the object beam was reflected off the sample. The beam splitter 2 was then used to recombine the object and reference beams. The resulting interference patterns were recorded using a Retiga R6 digital camera (QImaging, Surrey, BC, Canada) (5.9 MP, low noise [<xref rid="B57-sensors-25-05402" ref-type="bibr">57</xref>]).</p><p>While our rotating diffuser arrangement induces temporal variation in the speckle field, it does not achieve full decorrelation between consecutive hologram frames. The Retiga R6 camera operates at only ~6.9 fps. This frame rate is far below the kilohertz-level rates typically needed to resolve fully independent speckle realizations; for instance, setups employing rotating diffusers have demonstrated effective speckle suppression at 2 kHz to 10 kHz [<xref rid="B58-sensors-25-05402" ref-type="bibr">58</xref>]. Consequently, our imaging captures partial speckle averaging, which is beneficial but not sufficient for complete decorrelation. Nonetheless, even partial decorrelation contributes positively to speckle suppression. By tuning the diffuser&#8217;s rotational speed and the camera&#8217;s exposure time, it remains possible to integrate multiple quasi-independent speckle patterns per frame, resulting in reduced speckle contrast (<inline-formula><mml:math id="mm55" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msqrt><mml:mi>M</mml:mi></mml:msqrt></mml:mrow></mml:mrow></mml:math></inline-formula> averaging law [<xref rid="B59-sensors-25-05402" ref-type="bibr">59</xref>]).</p><p>To push speckle decorrelation further, alternative approaches such as ultra-high-speed cameras capable of kilohertz&#8211;megahertz frame rates or high-rate phase modulation methods (e.g., micro-electromechanical systems or digital micromirror devices [<xref rid="B60-sensors-25-05402" ref-type="bibr">60</xref>]) can be used.</p><p>A pair of closely placed coins was chosen as a reflective amplitude object for holograms recording. The experimental setup is illustrated in <xref rid="sensors-25-05402-f005" ref-type="fig">Figure 5</xref>, while an example of a digital hologram and the corresponding reconstructed image is shown in <xref rid="sensors-25-05402-f006" ref-type="fig">Figure 6</xref>. To evaluate speckle contrast values in the reconstructed images, uniform regions were selected for analysis. Several corresponding regions are shown with red rectangles in <xref rid="sensors-25-05402-f006" ref-type="fig">Figure 6</xref>b.</p><p>The speckle contrast was evaluated for images processed using BM4D, a widely adopted denoising method, and the proposed 3D Frost filter. The results for several zones and several numbers of images are presented in <xref rid="sensors-25-05402-t003" ref-type="table">Table 3</xref>. For comparison, the values for unfiltered images were obtained by averaging over all frames within the designated regions of interest. Initial values for the speckle contrast are 0.52 &#177; 0.02 (zone 1), 0.53 &#177; 0.02 (zone 2), and 0.52 &#177; 0.01 (zone 3).</p><p>The performance of the two filters exhibits a clear and divergent trend as the number of input images increases. The BM4D filter demonstrates stable performance, with speckle contrast values showing minimal improvement beyond 20 images. In contrast, the proposed 3D Frost filter shows a strong, consistent improvement in speckle reduction. While values for the proposed method start with a higher speckle contrast at lower image counts (e.g., 10&#8211;20 images), its performance surpasses that of BM4D as more data are incorporated. For instance, with 60 images, the proposed method achieves a speckle contrast up to 58% lower than BM4D in certain zones. The average speckle contrast value for the proposed method was decreased by eight times to 0.064 &#177; 0.009, while for the BM3D filter, it was decreased to 0.108 &#177; 0.021.</p><p>This performance is further validated by the no-reference image quality metrics BRISQUE and PIQE, summarized in <xref rid="sensors-25-05402-t004" ref-type="table">Table 4</xref>. The BRISQUE value for initial images is 40.3 &#177; 0.2. The initial PIQE value is 47.8 &#177; 0.7. Lower scores for these metrics indicate higher perceptual quality. The BM4D filter again shows consistent, stagnant scores across all image counts. For the proposed method, increasing the number of images ultimately leads to significantly better scores. This indicates that the proposed method not only reduces speckle noise more effectively but also does so while preserving significantly better image quality and structural integrity, especially with larger datasets.</p><p>Further insights into algorithm performance are provided in <xref rid="sensors-25-05402-f007" ref-type="fig">Figure 7</xref>, which illustrates examples of the dependences of speckle contrast on the number of input images, and in <xref rid="sensors-25-05402-f008" ref-type="fig">Figure 8</xref>, which shows the variation of BRISQUE and PIQE under the same conditions.</p><p>A visual comparison of the filtered outputs confirms the structural preservation advantages of the proposed method, as initially indicated by its lower BRISQUE and PIQE scores. As shown in the enlarged areas of <xref rid="sensors-25-05402-f009" ref-type="fig">Figure 9</xref>, the BM4D filter tends to generate artifacts in regions with strong edges, degrading image clarity. The proposed filter avoids these artifacts, resulting in a more natural and structurally coherent image that is critical for accurate interpretation.</p><p>The robustness of BM4D and the proposed 3D Frost method was also compared using relative error. BM4D exhibited very low variability, with relative errors below 0.5% for global metrics and ranging from 0.6% to 15.8% for speckle contrast across regions of interest. The proposed method showed similar robustness in global metrics (BRISQUE: 0.2%; PIQE: 1.3%) and slightly higher variability for speckle contrast, with relative errors spanning approximately 1.4% to 16.1% depending on the zone. Overall, both methods demonstrate high stability.</p><p>In addition to quality improvements, the proposed filter significantly outperforms BM4D in terms of computational efficiency. <xref rid="sensors-25-05402-t005" ref-type="table">Table 5</xref> presents the processing times for both filters applied to 10, 20, 40, and 60 images. As the number of images increases, the performance gap becomes even more pronounced. The proposed method is up to 100 times faster than the BM4D filter. These processing times were calculated for the case when holograms were pre-restored before both methods were applied. This allows maximization of computational speed where memory is abundant. Under memory constraints, the time for the proposed method nearly doubles during the processing of dozens of images.</p><p>The images after filtration with BM4D and the proposed 3D Frost methods are shown in <xref rid="sensors-25-05402-f010" ref-type="fig">Figure 10</xref>. It can be seen that visually, speckle noise suppression was superior with the proposed filter, especially in the lower right corner of the image.</p><p>The optimal number of input holograms represents a trade-off between processing speed and reconstruction quality. A minimum of 10&#8211;15 holograms is sufficient for a perceptible improvement when speed is the priority. However, for applications demanding high quality, performance continues to improve with larger datasets, indicating that the highest quality is achieved by maximizing the number of holograms.</p><p>Thus, the proposed 3D Frost method demonstrates significantly better performance compared to existing techniques, including classical algorithmic variants. This makes the method highly effective for applications where acquiring multiple holograms is feasible. As more holograms are recorded, image quality continues to improve with additional holograms.</p><p>The primary limitation of the method lies in its requirement to register a sequence of holograms. Therefore, a balance must be found between the degree of image enhancement and the time required for hologram acquisition, as the scene should stay unchanged while recording. However, as shown in <xref rid="sensors-25-05402-f007" ref-type="fig">Figure 7</xref> and <xref rid="sensors-25-05402-f008" ref-type="fig">Figure 8</xref> and <xref rid="sensors-25-05402-t003" ref-type="table">Table 3</xref> and <xref rid="sensors-25-05402-t004" ref-type="table">Table 4</xref>, only a small number of images are sufficient to achieve high-quality reconstruction.</p><p>Unlike traditional approaches, the proposed method incorporates a larger amount of signal information for calculating each pixel value, which contributes to a reduction in the required number of holograms. This, in turn, leads to an increase in the signal-to-noise ratio, further confirming the method&#8217;s suitability for practical applications.</p><p>Future improvements may include the integration of a dynamic weight function, adaptively adjusted based on inter-image variations or correlations within the 3D structure. This enhancement will be the subject of our further research in the field of digital hologram filtering.</p></sec><sec sec-type="conclusions" id="sec6-sensors-25-05402"><title>6. Conclusions</title><p>In this work, we proposed and validated a 3D adaptive Frost filtering method for speckle noise reduction in digital holography. Numerical and optical experiments consistently confirm its advantages over both classical and state-of-the-art approaches. Compared to the conventional Frost filter, the proposed method reduces noise variation by more than a factor of two and more than doubles the structural similarity, highlighting the benefit of extending adaptive filtering into the volumetric domain. Relative to other 3D filters such as the median and Lee variants, our approach achieves roughly 20&#8211;30% stronger speckle suppression while providing up to one-third higher structural similarity, demonstrating a better balance between noise reduction and detail preservation.</p><p>Against BM3D and BM4D, the proposed filter yields about 30&#8211;40% lower noise measures and over 50% higher similarity indices while being nearly two orders of magnitude faster computationally. Optical experiments further show that as the number of holograms increases, the method continues to improve steadily: with 60 input frames, it achieves more than 50% lower speckle contrast compared to BM4D. No-reference perceptual metrics confirm this trend, with improvements of up to twofold in perceived image quality at higher frame counts.</p><p>A notable advantage of the proposed method is that it reaches near-optimal performance even with a modest number of holograms, as 10&#8211;15 images are already sufficient to achieve most of the possible quality gains, making it well-suited for practical, time-sensitive holographic imaging. These results demonstrate that 3D adaptive filtering not only surpasses traditional and advanced methods in speckle suppression and structural fidelity but also does so with exceptional efficiency. This makes the approach promising for applications in biomedical imaging, nondestructive testing, and optical metrology, where both image clarity and acquisition speed are critical.</p></sec></body><back><fn-group><fn><p><bold>Disclaimer/Publisher&#8217;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><app-group><app id="app1-sensors-25-05402"><title>Supplementary Materials</title><p>The following supporting information can be downloaded at: <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.mdpi.com/article/10.3390/s25175402/s1">https://www.mdpi.com/article/10.3390/s25175402/s1</uri>, See Videos S1 and S2 for supporting content.</p><supplementary-material id="sensors-25-05402-s001" position="float" content-type="local-data" orientation="portrait"><media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="sensors-25-05402-s001.zip" position="float" orientation="portrait"/></supplementary-material></app></app-group><notes><title>Author Contributions</title><p>Conceptualization, P.A.C., N.N.E., R.S.S., and E.Y.Z.; methodology, P.A.C., A.V.S., and R.S.S.; software, A.A.K. and A.V.K.; validation, A.A.K.; formal analysis, R.S.S., E.Y.Z., and V.A.N.; investigation, P.A.C., A.A.K., and A.V.K.; resources, N.N.E.; data curation, A.V.S., E.K.P., and V.A.N.; writing&#8212;original draft preparation, A.A.K. and P.A.C.; writing&#8212;review and editing, A.A.K. and P.A.C.; visualization, A.A.K. and A.V.K.; supervision, N.N.E.; project administration, R.S.S., A.V.S., and E.K.P.; funding acquisition, N.N.E. All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Institutional Review Board Statement</title><p>Not applicable.</p></notes><notes><title>Informed Consent Statement</title><p>Not applicable.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>Data are contained within the article or <xref rid="app1-sensors-25-05402" ref-type="app">Supplementary Material</xref>.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflicts of interest.</p></notes><glossary><title>Abbreviations</title><p>The following abbreviations are used in this manuscript:
<array orientation="portrait"><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">BM3D</td><td align="left" valign="middle" rowspan="1" colspan="1">block-matching and 3D filtering</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">BM4D</td><td align="left" valign="middle" rowspan="1" colspan="1">block matching with 4D filtering</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">BRISQUE</td><td align="left" valign="middle" rowspan="1" colspan="1">blind/referenceless image spatial quality evaluator</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">NSTD</td><td align="left" valign="middle" rowspan="1" colspan="1">normalized standard deviation</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">PIQE</td><td align="left" valign="middle" rowspan="1" colspan="1">perception-based image quality evaluator</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">SSIM</td><td align="left" valign="middle" rowspan="1" colspan="1">structural similarity index measure</td></tr></tbody></array></p></glossary><ref-list><title>References</title><ref id="B1-sensors-25-05402"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sheridan</surname><given-names>J.T.</given-names></name><name name-style="western"><surname>Kostuk</surname><given-names>R.K.</given-names></name><name name-style="western"><surname>Gil</surname><given-names>A.F.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Lu</surname><given-names>W.</given-names></name><name name-style="western"><surname>Zhong</surname><given-names>H.</given-names></name><name name-style="western"><surname>Tomita</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Neipp</surname><given-names>C.</given-names></name><name name-style="western"><surname>Franc&#233;s</surname><given-names>J.</given-names></name><name name-style="western"><surname>Gallego</surname><given-names>S.</given-names></name><etal/></person-group><article-title>Roadmap on Holography</article-title><source>J. Opt.</source><year>2020</year><volume>22</volume><fpage>123002</fpage><pub-id pub-id-type="doi">10.1088/2040-8986/abb3a4</pub-id></element-citation></ref><ref id="B2-sensors-25-05402"><label>2.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Collier</surname><given-names>R.J.</given-names></name><name name-style="western"><surname>Burckhardt</surname><given-names>C.B.</given-names></name><name name-style="western"><surname>Lin</surname><given-names>L.H.</given-names></name></person-group><source>Optical Holography</source><publisher-name>Elsevier BV</publisher-name><publisher-loc>Amsterdam, The Netherlands</publisher-loc><year>1971</year></element-citation></ref><ref id="B3-sensors-25-05402"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ahmed</surname><given-names>Z.E.</given-names></name><name name-style="western"><surname>Abdelazeem</surname><given-names>R.M.</given-names></name><name name-style="western"><surname>Attia</surname><given-names>Y.A.</given-names></name><name name-style="western"><surname>Khattab</surname><given-names>T.A.</given-names></name><name name-style="western"><surname>Falldorf</surname><given-names>C.</given-names></name><name name-style="western"><surname>Bergmann</surname><given-names>R.B.</given-names></name><name name-style="western"><surname>Agour</surname><given-names>M.</given-names></name></person-group><article-title>A Complementary Approach for Securing and Anti-Counterfeiting of Valuable Documents Based on Encryption of Computer-Generated Hologram</article-title><source>Sensors</source><year>2025</year><volume>25</volume><elocation-id>2410</elocation-id><pub-id pub-id-type="doi">10.3390/s25082410</pub-id><pub-id pub-id-type="pmid">40285100</pub-id><pub-id pub-id-type="pmcid">PMC12031057</pub-id></element-citation></ref><ref id="B4-sensors-25-05402"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Khodadad</surname><given-names>D.</given-names></name></person-group><article-title>Digital Holography and Its Application</article-title><source>Appl. Sci.</source><year>2024</year><volume>14</volume><elocation-id>11254</elocation-id><pub-id pub-id-type="doi">10.3390/app142311254</pub-id></element-citation></ref><ref id="B5-sensors-25-05402"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lin</surname><given-names>J.-H.</given-names></name><name name-style="western"><surname>Liang</surname><given-names>J.-Q.</given-names></name><name name-style="western"><surname>Lin</surname><given-names>F.-C.</given-names></name><name name-style="western"><surname>Huang</surname><given-names>Q.</given-names></name><name name-style="western"><surname>Li</surname><given-names>N.-N.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>D.</given-names></name></person-group><article-title>Color Holographic 3D Display Method with Low Speckle Noise Based on Improved Iterative GS Algorithm</article-title><source>Opt. Laser Technol.</source><year>2025</year><volume>184</volume><fpage>112584</fpage><pub-id pub-id-type="doi">10.1016/j.optlastec.2025.112584</pub-id></element-citation></ref><ref id="B6-sensors-25-05402"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zuo</surname><given-names>S.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>S.</given-names></name><name name-style="western"><surname>Pulham</surname><given-names>C.</given-names></name><name name-style="western"><surname>Tang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Perrie</surname><given-names>W.</given-names></name><name name-style="western"><surname>Allegre</surname><given-names>O.J.</given-names></name><name name-style="western"><surname>Tang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Sharp</surname><given-names>M.</given-names></name><name name-style="western"><surname>Leach</surname><given-names>J.</given-names></name><name name-style="western"><surname>Whitehead</surname><given-names>D.J.</given-names></name><etal/></person-group><article-title>High-Performance NIR Laser-Beam Shaping and Materials Processing at 350 W with a Spatial Light Modulator</article-title><source>Photonics</source><year>2025</year><volume>12</volume><elocation-id>544</elocation-id><pub-id pub-id-type="doi">10.3390/photonics12060544</pub-id></element-citation></ref><ref id="B7-sensors-25-05402"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Reztsov</surname><given-names>T.V.</given-names></name><name name-style="western"><surname>Chernykh</surname><given-names>A.V.</given-names></name><name name-style="western"><surname>Orlova</surname><given-names>T.</given-names></name><name name-style="western"><surname>Petrov</surname><given-names>N.V.</given-names></name></person-group><article-title>A Dynamic Analysis of Toron Formation in Chiral Nematic Liquid Crystals Using a Polarization Holographic Microscope</article-title><source>Polymers</source><year>2025</year><volume>17</volume><elocation-id>1849</elocation-id><pub-id pub-id-type="doi">10.3390/polym17131849</pub-id><pub-id pub-id-type="pmid">40647859</pub-id><pub-id pub-id-type="pmcid">PMC12251636</pub-id></element-citation></ref><ref id="B8-sensors-25-05402"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kim</surname><given-names>H.-W.</given-names></name><name name-style="western"><surname>Cho</surname><given-names>M.</given-names></name><name name-style="western"><surname>Lee</surname><given-names>M.-C.</given-names></name></person-group><article-title>Image Processing Techniques for Improving Quality of 3D Profile in Digital Holographic Microscopy Using Deep Learning Algorithm</article-title><source>Sensors</source><year>2024</year><volume>24</volume><elocation-id>1950</elocation-id><pub-id pub-id-type="doi">10.3390/s24061950</pub-id><pub-id pub-id-type="pmid">38544214</pub-id><pub-id pub-id-type="pmcid">PMC10974359</pub-id></element-citation></ref><ref id="B9-sensors-25-05402"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Huang</surname><given-names>C.-H.</given-names></name><name name-style="western"><surname>He</surname><given-names>S.-C.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>T.-Y.</given-names></name><name name-style="western"><surname>Cheng</surname><given-names>C.-J.</given-names></name><name name-style="western"><surname>Tu</surname><given-names>H.-Y.</given-names></name></person-group><article-title>Three-Dimensional Surface Reconstruction for Specular/Diffuse Composite Surfaces</article-title><source>Sensors</source><year>2024</year><volume>24</volume><elocation-id>7942</elocation-id><pub-id pub-id-type="doi">10.3390/s24247942</pub-id><pub-id pub-id-type="pmid">39771679</pub-id><pub-id pub-id-type="pmcid">PMC11679573</pub-id></element-citation></ref><ref id="B10-sensors-25-05402"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yang</surname><given-names>T.</given-names></name><name name-style="western"><surname>Lu</surname><given-names>Z.</given-names></name></person-group><article-title>Holo-U2net for High-Fidelity 3D Hologram Generation</article-title><source>Sensors</source><year>2024</year><volume>24</volume><elocation-id>5505</elocation-id><pub-id pub-id-type="doi">10.3390/s24175505</pub-id><pub-id pub-id-type="pmid">39275416</pub-id><pub-id pub-id-type="pmcid">PMC11398203</pub-id></element-citation></ref><ref id="B11-sensors-25-05402"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Fan</surname><given-names>F.</given-names></name><name name-style="western"><surname>Li</surname><given-names>J.</given-names></name><name name-style="western"><surname>Ji</surname><given-names>B.</given-names></name><name name-style="western"><surname>Rong</surname><given-names>L.</given-names></name><name name-style="western"><surname>Ge</surname><given-names>L.</given-names></name><name name-style="western"><surname>Zhao</surname><given-names>H.</given-names></name><name name-style="western"><surname>Shi</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>D.</given-names></name><name name-style="western"><surname>Wan</surname><given-names>M.</given-names></name></person-group><article-title>Total Variation Extrapolation Algorithm for High-Fidelity Terahertz In-Line Digital Holography</article-title><source>Opt. Lasers Eng.</source><year>2025</year><volume>193</volume><fpage>109048</fpage><pub-id pub-id-type="doi">10.1016/j.optlaseng.2025.109048</pub-id></element-citation></ref><ref id="B12-sensors-25-05402"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Xu</surname><given-names>X.</given-names></name><name name-style="western"><surname>Luo</surname><given-names>W.</given-names></name><name name-style="western"><surname>Ren</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Song</surname><given-names>X.</given-names></name></person-group><article-title>Intelligent Detection and Recognition of Marine Plankton by Digital Holography and Deep Learning</article-title><source>Sensors</source><year>2025</year><volume>25</volume><elocation-id>2325</elocation-id><pub-id pub-id-type="doi">10.3390/s25072325</pub-id><pub-id pub-id-type="pmid">40218838</pub-id><pub-id pub-id-type="pmcid">PMC11991423</pub-id></element-citation></ref><ref id="B13-sensors-25-05402"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cheremkhin</surname><given-names>P.A.</given-names></name><name name-style="western"><surname>Evtikhiev</surname><given-names>N.N.</given-names></name><name name-style="western"><surname>Krasnov</surname><given-names>V.V.</given-names></name><name name-style="western"><surname>Rodin</surname><given-names>V.G.</given-names></name><name name-style="western"><surname>Starikov</surname><given-names>R.S.</given-names></name></person-group><article-title>Shot Noise and Fixed-Pattern Noise Effects on Digital Hologram Reconstruction</article-title><source>Opt. Lasers Eng.</source><year>2021</year><volume>139</volume><fpage>106461</fpage><pub-id pub-id-type="doi">10.1016/j.optlaseng.2020.106461</pub-id></element-citation></ref><ref id="B14-sensors-25-05402"><label>14.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Picart</surname><given-names>P.</given-names></name></person-group><article-title>Speckle Noise in Digital Holographic Images: Genesis and Reduction Methods</article-title><source>Digital Holography and Three-Dimensional Imaging</source><comment>Th1A.1</comment><publisher-name>Optica Publishing Group</publisher-name><publisher-loc>Washington, DC, USA</publisher-loc><year>2017</year><pub-id pub-id-type="doi">10.1364/DH.2017.Th1A.1</pub-id></element-citation></ref><ref id="B15-sensors-25-05402"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Buitrago-Duque</surname><given-names>C.</given-names></name><name name-style="western"><surname>Castaneda</surname><given-names>R.</given-names></name><name name-style="western"><surname>Garcia-Sucerquia</surname><given-names>J.</given-names></name></person-group><article-title>Pointwise Phasor Tuning for Single-Shot Speckle Noise Reduction in Phase Wave Fields</article-title><source>Opt. Lasers Eng.</source><year>2021</year><volume>137</volume><fpage>106365</fpage><pub-id pub-id-type="doi">10.1016/j.optlaseng.2020.106365</pub-id></element-citation></ref><ref id="B16-sensors-25-05402"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Guerrero-Casta&#241;eda</surname><given-names>R.F.</given-names></name><name name-style="western"><surname>Garcia-Sucerquia</surname><given-names>J.</given-names></name><name name-style="western"><surname>Doblas</surname><given-names>A.</given-names></name></person-group><article-title>Speckle Noise Reduction in Coherent Imaging Systems via Hybrid Median&#8211;Mean Filter</article-title><source>Opt. Eng.</source><year>2021</year><volume>60</volume><fpage>123107</fpage><pub-id pub-id-type="doi">10.1117/1.oe.60.12.123107</pub-id></element-citation></ref><ref id="B17-sensors-25-05402"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>D.</given-names></name><name name-style="western"><surname>Liang</surname><given-names>S.</given-names></name><name name-style="western"><surname>Ma</surname><given-names>H.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Dong</surname><given-names>M.</given-names></name><name name-style="western"><surname>Wan</surname><given-names>X.</given-names></name></person-group><article-title>Noise Suppression in the Reconstructed Image of Digital Holography Based on the BEMDV Method Using Improved Particle Swarm Optimization</article-title><source>Appl. Opt.</source><year>2023</year><volume>62</volume><fpage>5159</fpage><lpage>5169</lpage><pub-id pub-id-type="doi">10.1364/AO.492220</pub-id><pub-id pub-id-type="pmid">37707219</pub-id></element-citation></ref><ref id="B18-sensors-25-05402"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Maggioni</surname><given-names>M.</given-names></name><name name-style="western"><surname>Katkovnik</surname><given-names>V.</given-names></name><name name-style="western"><surname>Egiazarian</surname><given-names>K.</given-names></name><name name-style="western"><surname>Foi</surname><given-names>A.</given-names></name></person-group><article-title>Nonlocal Transform-Domain Filter for Volumetric Data Denoising and Reconstruction</article-title><source>IEEE Trans. Image Process.</source><year>2013</year><volume>22</volume><fpage>119</fpage><lpage>133</lpage><pub-id pub-id-type="doi">10.1109/TIP.2012.2210725</pub-id><pub-id pub-id-type="pmid">22868570</pub-id></element-citation></ref><ref id="B19-sensors-25-05402"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yu</surname><given-names>H.</given-names></name><name name-style="western"><surname>Jia</surname><given-names>S.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Dong</surname><given-names>J.</given-names></name></person-group><article-title>Phase Coherent Noise Reduction in Digital Holographic Microscopy Based on Adaptive Total Variation</article-title><source>Opt. Lasers Eng.</source><year>2020</year><volume>134</volume><fpage>106204</fpage><pub-id pub-id-type="doi">10.1016/j.optlaseng.2020.106204</pub-id></element-citation></ref><ref id="B20-sensors-25-05402"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sharma</surname><given-names>A.</given-names></name><name name-style="western"><surname>Sheoran</surname><given-names>G.</given-names></name><name name-style="western"><surname>Jaffery</surname><given-names>Z.A.</given-names></name><name name-style="western"><surname>Moinuddin</surname></name></person-group><article-title>Improvement of Signal-To-Noise Ratio in Digital Holography Using Wavelet Transform</article-title><source>Opt. Lasers Eng.</source><year>2008</year><volume>46</volume><fpage>42</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1016/j.optlaseng.2007.07.004</pub-id></element-citation></ref><ref id="B21-sensors-25-05402"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fu</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Leng</surname><given-names>J.</given-names></name><name name-style="western"><surname>Xu</surname><given-names>Z.</given-names></name></person-group><article-title>Speckle Reduction in Digital Holography by Fast Logistic Adaptive Non-Local Means Filtering</article-title><source>Photonics</source><year>2024</year><volume>11</volume><elocation-id>147</elocation-id><pub-id pub-id-type="doi">10.3390/photonics11020147</pub-id></element-citation></ref><ref id="B22-sensors-25-05402"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kozlov</surname><given-names>A.V.</given-names></name><name name-style="western"><surname>Cheremkhin</surname><given-names>P.A.</given-names></name><name name-style="western"><surname>Svistunov</surname><given-names>A.S.</given-names></name><name name-style="western"><surname>Rodin</surname><given-names>V.G.</given-names></name><name name-style="western"><surname>Starikov</surname><given-names>R.S.</given-names></name><name name-style="western"><surname>Evtikhiev</surname><given-names>N.N.</given-names></name></person-group><article-title>Interpolation-Filtering Method for Image Improvement in Digital Holography</article-title><source>Appl. Sci.</source><year>2024</year><volume>14</volume><elocation-id>8790</elocation-id><pub-id pub-id-type="doi">10.3390/app14198790</pub-id></element-citation></ref><ref id="B23-sensors-25-05402"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Garcia-Sucerquia</surname><given-names>J.</given-names></name><name name-style="western"><surname>Ram&#237;rez</surname><given-names>J.A.</given-names></name><name name-style="western"><surname>Prieto</surname><given-names>D.V.</given-names></name></person-group><article-title>Reduction of Speckle Noise in Digital Holography by Using Digital Image Processing</article-title><source>Optik</source><year>2005</year><volume>116</volume><fpage>44</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.1016/j.ijleo.2004.12.004</pub-id></element-citation></ref><ref id="B24-sensors-25-05402"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kreis</surname><given-names>T.</given-names></name><name name-style="western"><surname>Werner</surname><given-names>W.</given-names></name></person-group><article-title>Suppression of the Dc Term in Digital Holography</article-title><source>Opt. Eng.</source><year>1997</year><volume>36</volume><fpage>2357</fpage><pub-id pub-id-type="doi">10.1117/1.601426</pub-id></element-citation></ref><ref id="B25-sensors-25-05402"><label>25.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Montresor</surname><given-names>S.</given-names></name><name name-style="western"><surname>Quehe</surname><given-names>P.Y.</given-names></name><name name-style="western"><surname>Verhaeghe</surname><given-names>S.</given-names></name><name name-style="western"><surname>Picard</surname><given-names>P.</given-names></name></person-group><article-title>Evaluation of Denoising Algorithms Applied to the Reduction of Speckle in Digital Holography</article-title><source>Proceedings of the 2015 23rd European Signal Processing Conference (EUSIPCO)</source><conf-loc>Nice, France</conf-loc><conf-date>31 August&#8211;4 September 2015</conf-date><fpage>2316</fpage><lpage>2320</lpage></element-citation></ref><ref id="B26-sensors-25-05402"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lee</surname><given-names>J.-S.</given-names></name></person-group><article-title>Digital Image Enhancement and Noise Filtering by Use of Local Statistics</article-title><source>IEEE Trans. Pattern Anal. Mach. Intell.</source><year>1980</year><volume>PAMI-2</volume><fpage>165</fpage><lpage>168</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.1980.4766994</pub-id><pub-id pub-id-type="pmid">21868887</pub-id></element-citation></ref><ref id="B27-sensors-25-05402"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Frost</surname><given-names>V.S.</given-names></name><name name-style="western"><surname>Stiles</surname><given-names>J.A.</given-names></name><name name-style="western"><surname>Shanmugan</surname><given-names>K.S.</given-names></name><name name-style="western"><surname>Holtzman</surname><given-names>J.C.</given-names></name></person-group><article-title>A Model for Radar Images and Its Application to Adaptive Digital Filtering of Multiplicative Noise</article-title><source>IEEE Trans. Pattern Anal. Mach. Intell.</source><year>1982</year><volume>PAMI-4</volume><fpage>157</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.1982.4767223</pub-id><pub-id pub-id-type="pmid">21869022</pub-id></element-citation></ref><ref id="B28-sensors-25-05402"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Katkovnik</surname><given-names>V.</given-names></name><name name-style="western"><surname>Shevkunov</surname><given-names>I.A.</given-names></name><name name-style="western"><surname>Petrov</surname><given-names>N.V.</given-names></name><name name-style="western"><surname>Egiazarian</surname><given-names>K.</given-names></name></person-group><article-title>Wavefront Reconstruction in Digital Off-Axis Holography via Sparse Coding of Amplitude and Absolute Phase</article-title><source>Opt. Lett.</source><year>2015</year><volume>40</volume><fpage>2417</fpage><lpage>2420</lpage><pub-id pub-id-type="doi">10.1364/OL.40.002417</pub-id><pub-id pub-id-type="pmid">26393754</pub-id></element-citation></ref><ref id="B29-sensors-25-05402"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lin</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Jia</surname><given-names>S.</given-names></name><name name-style="western"><surname>Zhou</surname><given-names>X.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>H.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>L.</given-names></name><name name-style="western"><surname>Li</surname><given-names>G.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>Z.</given-names></name></person-group><article-title>Digital Holographic Microscopy Phase Noise Reduction Based on an Over-Complete Chunked Discrete Cosine Transform Sparse Dictionary</article-title><source>Opt. Lasers Eng.</source><year>2023</year><volume>166</volume><fpage>107571</fpage><pub-id pub-id-type="doi">10.1016/j.optlaseng.2023.107571</pub-id></element-citation></ref><ref id="B30-sensors-25-05402"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pan</surname><given-names>F.</given-names></name><name name-style="western"><surname>Xiao</surname><given-names>W.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>S.</given-names></name><name name-style="western"><surname>Rong</surname><given-names>L.</given-names></name></person-group><article-title>Application of Three-Dimensional Spatial Correlation Properties of Coherent Noise in Phase Noise Suppression for Digital Holographic Microscopy</article-title><source>Opt. Laser Technol.</source><year>2013</year><volume>51</volume><fpage>67</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1016/j.optlastec.2013.03.022</pub-id></element-citation></ref><ref id="B31-sensors-25-05402"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Panezai</surname><given-names>S.</given-names></name><name name-style="western"><surname>Zhao</surname><given-names>J.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>D.</given-names></name><name name-style="western"><surname>Rong</surname><given-names>L.</given-names></name></person-group><article-title>Speckle Suppression in Off-Axis Lensless Fourier Transform Digital Holography</article-title><source>Opt. Commun.</source><year>2017</year><volume>397</volume><fpage>100</fpage><lpage>104</lpage><pub-id pub-id-type="doi">10.1016/j.optcom.2017.04.012</pub-id></element-citation></ref><ref id="B32-sensors-25-05402"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kubota</surname><given-names>S.</given-names></name><name name-style="western"><surname>Goodman</surname><given-names>J.W.</given-names></name></person-group><article-title>Very Efficient Speckle Contrast Reduction Realized by Moving Diffuser Device</article-title><source>Appl. Opt.</source><year>2010</year><volume>49</volume><fpage>4385</fpage><lpage>4391</lpage><pub-id pub-id-type="doi">10.1364/AO.49.004385</pub-id><pub-id pub-id-type="pmid">20697441</pub-id></element-citation></ref><ref id="B33-sensors-25-05402"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dong</surname><given-names>J.</given-names></name><name name-style="western"><surname>Jia</surname><given-names>S.</given-names></name><name name-style="western"><surname>Yu</surname><given-names>H.</given-names></name></person-group><article-title>Hybrid Method for Speckle Noise Reduction in Digital Holography</article-title><source>J. Opt. Soc. Am. A</source><year>2019</year><volume>36</volume><fpage>D14</fpage><lpage>D22</lpage><pub-id pub-id-type="doi">10.1364/JOSAA.36.000D14</pub-id><pub-id pub-id-type="pmid">31873362</pub-id></element-citation></ref><ref id="B34-sensors-25-05402"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rong</surname><given-names>L.</given-names></name><name name-style="western"><surname>Xiao</surname><given-names>W.</given-names></name><name name-style="western"><surname>Pan</surname><given-names>F.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>S.</given-names></name><name name-style="western"><surname>Li</surname><given-names>R.</given-names></name></person-group><article-title>Speckle Noise Reduction in Digital Holography by Use of Multiple Polarization Holograms</article-title><source>Chin. Opt. Lett.</source><year>2010</year><volume>8</volume><fpage>653</fpage><lpage>655</lpage><pub-id pub-id-type="doi">10.3788/COL20100807.0653</pub-id></element-citation></ref><ref id="B35-sensors-25-05402"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Leng</surname><given-names>J.</given-names></name><name name-style="western"><surname>Sang</surname><given-names>X.</given-names></name><name name-style="western"><surname>Yan</surname><given-names>B.</given-names></name></person-group><article-title>Speckle Suppression in Digital Holographic Imaging with Random Phases and Different Wavelengths</article-title><source>Opt. Eng.</source><year>2014</year><volume>53</volume><fpage>033105</fpage><pub-id pub-id-type="doi">10.1117/1.OE.53.3.033105</pub-id></element-citation></ref><ref id="B36-sensors-25-05402"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Che</surname><given-names>L.</given-names></name><name name-style="western"><surname>Xiao</surname><given-names>W.</given-names></name><name name-style="western"><surname>Pan</surname><given-names>F.</given-names></name><name name-style="western"><surname>Dong</surname><given-names>B.</given-names></name><name name-style="western"><surname>Zhong</surname><given-names>Z.</given-names></name></person-group><article-title>Reduction of Speckle Noise in Digital Holography by Combination of Averaging Several Reconstructed Images and Modified Nonlocal Means Filtering</article-title><source>Opt. Commun.</source><year>2018</year><volume>426</volume><fpage>9</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1016/j.optcom.2018.05.004</pub-id></element-citation></ref><ref id="B37-sensors-25-05402"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cheremkhin</surname><given-names>P.A.</given-names></name><name name-style="western"><surname>Evtikhiev</surname><given-names>N.N.</given-names></name><name name-style="western"><surname>Kozlov</surname><given-names>A.V.</given-names></name><name name-style="western"><surname>Krasnov</surname><given-names>V.V.</given-names></name><name name-style="western"><surname>Rodin</surname><given-names>V.G.</given-names></name><name name-style="western"><surname>Starikov</surname><given-names>R.S.</given-names></name></person-group><article-title>An Optical-Digital Method of Noise Suppression in Digital Holography</article-title><source>J. Opt.</source><year>2022</year><volume>24</volume><fpage>115702</fpage><pub-id pub-id-type="doi">10.1088/2040-8986/ac90d3</pub-id></element-citation></ref><ref id="B38-sensors-25-05402"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kumar</surname><given-names>V.</given-names></name><name name-style="western"><surname>Dubey</surname><given-names>A.K.</given-names></name><name name-style="western"><surname>Gupta</surname><given-names>M.</given-names></name><name name-style="western"><surname>Singh</surname><given-names>V.</given-names></name><name name-style="western"><surname>Butola</surname><given-names>A.</given-names></name><name name-style="western"><surname>Mehta</surname><given-names>D.S.</given-names></name></person-group><article-title>Speckle Noise Reduction Strategies in Laser-Based Projection Imaging, Fluorescence Microscopy, and Digital Holography with Uniform Illumination, Improved Image Sharpness, and Resolution</article-title><source>Opt. Laser Technol.</source><year>2021</year><volume>141</volume><fpage>107079</fpage><pub-id pub-id-type="doi">10.1016/j.optlastec.2021.107079</pub-id></element-citation></ref><ref id="B39-sensors-25-05402"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Guo</surname><given-names>X.</given-names></name><name name-style="western"><surname>Xie</surname><given-names>F.</given-names></name><name name-style="western"><surname>Yang</surname><given-names>T.</given-names></name><name name-style="western"><surname>Ming</surname><given-names>M.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>T.</given-names></name></person-group><article-title>Physics-Informed Generative Adversarial Networks for Laser Speckle Noise Suppression</article-title><source>Sensors</source><year>2025</year><volume>25</volume><elocation-id>3842</elocation-id><pub-id pub-id-type="doi">10.3390/s25133842</pub-id><pub-id pub-id-type="pmid">40648100</pub-id><pub-id pub-id-type="pmcid">PMC12252416</pub-id></element-citation></ref><ref id="B40-sensors-25-05402"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Xie</surname><given-names>Z.Q.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>L.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>H.H.</given-names></name><name name-style="western"><surname>Wen</surname><given-names>K.H.</given-names></name><name name-style="western"><surname>Guo</surname><given-names>J.W.</given-names></name></person-group><article-title>Speckle Noise Reduction for Digital Holographic Images Using Swin Transformer</article-title><source>Opt. Lasers Eng.</source><year>2025</year><volume>184</volume><fpage>108605</fpage><pub-id pub-id-type="doi">10.1016/j.optlaseng.2024.108605</pub-id></element-citation></ref><ref id="B41-sensors-25-05402"><label>41.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Khorin</surname><given-names>P.A.</given-names></name><name name-style="western"><surname>Dzyuba</surname><given-names>A.P.</given-names></name><name name-style="western"><surname>Chernykh</surname><given-names>A.V.</given-names></name><name name-style="western"><surname>Georgieva</surname><given-names>A.O.</given-names></name><name name-style="western"><surname>Petrov</surname><given-names>N.V.</given-names></name><name name-style="western"><surname>Khonina</surname><given-names>S.N.</given-names></name></person-group><article-title>Neural Network-Assisted Interferogram Analysis Using Cylindrical and Flat Reference Beams</article-title><source>Appl. Sci.</source><year>2023</year><volume>13</volume><elocation-id>4831</elocation-id><pub-id pub-id-type="doi">10.3390/app13084831</pub-id></element-citation></ref><ref id="B42-sensors-25-05402"><label>42.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pavillon</surname><given-names>N.</given-names></name><name name-style="western"><surname>Seelamantula</surname><given-names>C.S.</given-names></name><name name-style="western"><surname>K&#252;hn</surname><given-names>J.</given-names></name><name name-style="western"><surname>Unser</surname><given-names>M.</given-names></name><name name-style="western"><surname>Depeursinge</surname><given-names>C.</given-names></name></person-group><article-title>Suppression of the Zero-Order Term in Off-Axis Digital Holography through Nonlinear Filtering</article-title><source>Appl. Opt.</source><year>2009</year><volume>48</volume><fpage>H186</fpage><lpage>H195</lpage><pub-id pub-id-type="doi">10.1364/AO.48.00H186</pub-id><pub-id pub-id-type="pmid">19956290</pub-id></element-citation></ref><ref id="B43-sensors-25-05402"><label>43.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stoykova</surname><given-names>E.S.</given-names></name><name name-style="western"><surname>Kang</surname><given-names>H.</given-names></name><name name-style="western"><surname>Park</surname><given-names>J.P.</given-names></name></person-group><article-title>Twin-Image Problem in Digital Holography&#8212;A Survey (Invited Paper)</article-title><source>Chin. Opt. Lett.</source><year>2014</year><volume>12</volume><fpage>060013</fpage><lpage>60024</lpage><pub-id pub-id-type="doi">10.3788/COL201412.060013</pub-id></element-citation></ref><ref id="B44-sensors-25-05402"><label>44.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Fan</surname><given-names>H.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>F.</given-names></name><name name-style="western"><surname>Gu</surname><given-names>X.</given-names></name><name name-style="western"><surname>Qian</surname><given-names>X.</given-names></name><name name-style="western"><surname>Poon</surname><given-names>T.-C.</given-names></name></person-group><article-title>Polygon-Based Computer-Generated Holography: A Review of Fundamentals and Recent Progress (Invited)</article-title><source>Appl. Opt.</source><year>2022</year><volume>61</volume><fpage>B363</fpage><lpage>B374</lpage><pub-id pub-id-type="doi">10.1364/AO.444973</pub-id><pub-id pub-id-type="pmid">35201160</pub-id></element-citation></ref><ref id="B45-sensors-25-05402"><label>45.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pi</surname><given-names>D.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>J.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>Y.</given-names></name></person-group><article-title>Review of Computer-Generated Hologram Algorithms for Color Dynamic Holographic Three-Dimensional Display</article-title><source>Light Sci. Appl.</source><year>2022</year><volume>11</volume><fpage>231</fpage><pub-id pub-id-type="doi">10.1038/s41377-022-00916-3</pub-id><pub-id pub-id-type="pmid">35879287</pub-id><pub-id pub-id-type="pmcid">PMC9314381</pub-id></element-citation></ref><ref id="B46-sensors-25-05402"><label>46.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Schnars</surname><given-names>U.</given-names></name><name name-style="western"><surname>Falldorf</surname><given-names>C.</given-names></name><name name-style="western"><surname>Watson</surname><given-names>J.</given-names></name><name name-style="western"><surname>J&#252;ptner</surname><given-names>W.</given-names></name></person-group><source>Digital Holography and Wavefront Sensing: Principles, Techniques and Applications</source><publisher-name>Springer</publisher-name><publisher-loc>Berlin/Heidelberg, Germany</publisher-loc><year>2015</year><fpage>1</fpage><lpage>226</lpage></element-citation></ref><ref id="B47-sensors-25-05402"><label>47.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cuche</surname><given-names>E.</given-names></name><name name-style="western"><surname>Marquet</surname><given-names>P.</given-names></name><name name-style="western"><surname>Depeursinge</surname><given-names>C.</given-names></name></person-group><article-title>Spatial Filtering for Zero-Order and Twin-Image Elimination in Digital Off-Axis Holography</article-title><source>Appl. Opt.</source><year>2000</year><volume>39</volume><fpage>4070</fpage><lpage>4075</lpage><pub-id pub-id-type="doi">10.1364/AO.39.004070</pub-id><pub-id pub-id-type="pmid">18349988</pub-id></element-citation></ref><ref id="B48-sensors-25-05402"><label>48.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Goodman</surname><given-names>J.W.</given-names></name></person-group><source>Speckle Phenomena in Optics: Theory and Applications</source><publisher-name>SPIE Press</publisher-name><publisher-loc>Bellingham, WA, USA</publisher-loc><year>2020</year><pub-id pub-id-type="doi">10.1117/3.2548484</pub-id></element-citation></ref><ref id="B49-sensors-25-05402"><label>49.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Skipetrov</surname><given-names>S.E.</given-names></name><name name-style="western"><surname>Peuser</surname><given-names>J.</given-names></name><name name-style="western"><surname>Cerbino</surname><given-names>R.</given-names></name><name name-style="western"><surname>Zakharov</surname><given-names>P.</given-names></name><name name-style="western"><surname>Scheffold</surname><given-names>F.</given-names></name></person-group><article-title>Noise in Laser Speckle Correlation and Imaging Techniques</article-title><source>Opt. Express</source><year>2010</year><volume>18</volume><fpage>14519</fpage><lpage>14534</lpage><pub-id pub-id-type="doi">10.1364/OE.18.014519</pub-id><pub-id pub-id-type="pmid">20639937</pub-id></element-citation></ref><ref id="B50-sensors-25-05402"><label>50.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>K.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>L.</given-names></name><name name-style="western"><surname>Xiao</surname><given-names>J.</given-names></name><name name-style="western"><surname>Li</surname><given-names>J.</given-names></name><name name-style="western"><surname>Wen</surname><given-names>K.</given-names></name></person-group><article-title>Reduction of Speckle Noise in Digital Holography Using a Neighborhood Filter Based on Multiple Sub-Reconstructed Images</article-title><source>Opt. Express</source><year>2022</year><volume>30</volume><fpage>9222</fpage><lpage>9232</lpage><pub-id pub-id-type="doi">10.1364/OE.454032</pub-id><pub-id pub-id-type="pmid">35299356</pub-id></element-citation></ref><ref id="B51-sensors-25-05402"><label>51.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ren</surname><given-names>R.</given-names></name><name name-style="western"><surname>Jia</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Yang</surname><given-names>J.</given-names></name><name name-style="western"><surname>Kasabov</surname><given-names>N.K.</given-names></name><name name-style="western"><surname>Huang</surname><given-names>X.</given-names></name></person-group><article-title>Quasi-Noise-Free and Detail-Preserved Digital Holographic Reconstruction</article-title><source>IEEE Access</source><year>2019</year><volume>7</volume><fpage>52155</fpage><lpage>52167</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2019.2910187</pub-id></element-citation></ref><ref id="B52-sensors-25-05402"><label>52.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Verrier</surname><given-names>N.</given-names></name><name name-style="western"><surname>Atlan</surname><given-names>M.</given-names></name></person-group><article-title>Off-Axis Digital Hologram Reconstruction: Some Practical Considerations</article-title><source>Appl. Opt.</source><year>2011</year><volume>50</volume><fpage>H136</fpage><lpage>H146</lpage><pub-id pub-id-type="doi">10.1364/AO.50.00H136</pub-id><pub-id pub-id-type="pmid">22192998</pub-id></element-citation></ref><ref id="B53-sensors-25-05402"><label>53.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fienup</surname><given-names>J.R.</given-names></name></person-group><article-title>Invariant Error Metrics for Image Reconstruction</article-title><source>Appl. Opt.</source><year>1997</year><volume>36</volume><fpage>8352</fpage><lpage>8357</lpage><pub-id pub-id-type="doi">10.1364/AO.36.008352</pub-id><pub-id pub-id-type="pmid">18264376</pub-id></element-citation></ref><ref id="B54-sensors-25-05402"><label>54.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Bovik</surname><given-names>A.C.</given-names></name><name name-style="western"><surname>Sheikh</surname><given-names>H.R.</given-names></name><name name-style="western"><surname>Simoncelli</surname><given-names>E.P.</given-names></name></person-group><article-title>Image Quality Assessment: From Error Visibility to Structural Similarity</article-title><source>IEEE Trans. Image Process.</source><year>2004</year><volume>13</volume><fpage>600</fpage><lpage>612</lpage><pub-id pub-id-type="doi">10.1109/TIP.2003.819861</pub-id><pub-id pub-id-type="pmid">15376593</pub-id></element-citation></ref><ref id="B55-sensors-25-05402"><label>55.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mittal</surname><given-names>A.</given-names></name><name name-style="western"><surname>Moorthy</surname><given-names>A.K.</given-names></name><name name-style="western"><surname>Bovik</surname><given-names>B.A.</given-names></name></person-group><article-title>No-Reference Image Quality Assessment in the Spatial Domain</article-title><source>IEEE Trans. Image Process.</source><year>2012</year><volume>21</volume><fpage>4695</fpage><lpage>4708</lpage><pub-id pub-id-type="doi">10.1109/TIP.2012.2214050</pub-id><pub-id pub-id-type="pmid">22910118</pub-id></element-citation></ref><ref id="B56-sensors-25-05402"><label>56.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Venkatanath</surname><given-names>N.</given-names></name><name name-style="western"><surname>Praneeth</surname><given-names>D.</given-names></name><name name-style="western"><surname>Chandrasekhar Bh</surname><given-names>M.</given-names></name><name name-style="western"><surname>Channappayya</surname><given-names>S.S.</given-names></name><name name-style="western"><surname>Medasani</surname><given-names>S.</given-names></name></person-group><article-title>Blind Image Quality Evaluation Using Perception Based Features</article-title><source>Proceedings of the 2015 Twenty First National Conference on Communications (NCC)</source><conf-loc>Mumbai, India</conf-loc><conf-date>27 February&#8211;1 March 2015</conf-date></element-citation></ref><ref id="B57-sensors-25-05402"><label>57.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kozlov</surname><given-names>A.V.</given-names></name><name name-style="western"><surname>Rodin</surname><given-names>V.G.</given-names></name><name name-style="western"><surname>Starikov</surname><given-names>R.S.</given-names></name><name name-style="western"><surname>Evtikhiev</surname><given-names>N.N.</given-names></name><name name-style="western"><surname>Cheremkhin</surname><given-names>P.A.</given-names></name></person-group><article-title>Estimation of Camera&#8217;s Noise by Uniform Target Segmentation</article-title><source>IEEE Sens. J.</source><year>2023</year><volume>23</volume><fpage>4883</fpage><lpage>4891</lpage><pub-id pub-id-type="doi">10.1109/JSEN.2023.3238673</pub-id></element-citation></ref><ref id="B58-sensors-25-05402"><label>58.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stangner</surname><given-names>T.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>H.</given-names></name><name name-style="western"><surname>Dahlberg</surname><given-names>T.</given-names></name><name name-style="western"><surname>Wiklund</surname><given-names>K.</given-names></name><name name-style="western"><surname>Andersson</surname><given-names>M.</given-names></name></person-group><article-title>Step-By-Step Guide to Reduce Spatial Coherence of Laser Light Using a Rotating Ground Glass Diffuser</article-title><source>Appl. Opt.</source><year>2017</year><volume>56</volume><fpage>5427</fpage><lpage>5435</lpage><pub-id pub-id-type="doi">10.1364/AO.56.005427</pub-id><pub-id pub-id-type="pmid">29047500</pub-id></element-citation></ref><ref id="B59-sensors-25-05402"><label>59.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Goodman</surname><given-names>J.W.</given-names></name></person-group><article-title>Some Fundamental Properties of Speckle</article-title><source>J. Opt. Soc. Am.</source><year>1976</year><volume>66</volume><fpage>1145</fpage><lpage>1150</lpage><pub-id pub-id-type="doi">10.1364/JOSA.66.001145</pub-id></element-citation></ref><ref id="B60-sensors-25-05402"><label>60.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Restrepo</surname><given-names>J.</given-names></name><name name-style="western"><surname>Correa-Rojas</surname><given-names>N.</given-names></name><name name-style="western"><surname>Herrera-Ramirez</surname><given-names>J.</given-names></name></person-group><article-title>Speckle Noise Reduction in Digital Holography Using a DMD and Multi-Hologram Resampling</article-title><source>Appl. Sci.</source><year>2020</year><volume>10</volume><elocation-id>8277</elocation-id><pub-id pub-id-type="doi">10.3390/app10228277</pub-id></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-05402-f001" orientation="portrait"><label>Figure 1</label><caption><p>Schematic representation of the proposed 3D adaptive filtering method.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05402-g001.jpg"/></fig><fig position="float" id="sensors-25-05402-f002" orientation="portrait"><label>Figure 2</label><caption><p>The test images (<bold>a</bold>,<bold>b</bold>) and reconstructed ones from the noisy holograms (<bold>c</bold>,<bold>d</bold>).</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05402-g002.jpg"/></fig><fig position="float" id="sensors-25-05402-f003" orientation="portrait"><label>Figure 3</label><caption><p>Results of filtering noisy images using the proposed (<bold>a</bold>,<bold>b</bold>), classical Frost (<bold>c</bold>,<bold>d</bold>), classical Lee (<bold>e</bold>,<bold>f</bold>), 3D Lee (<bold>g</bold>,<bold>h</bold>), 3D median (<bold>i</bold>,<bold>j</bold>), BM3D (<bold>k</bold>,<bold>l</bold>), and BM4D (<bold>m</bold>,<bold>n</bold>) methods.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05402-g003a.jpg"/><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05402-g003b.jpg"/><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05402-g003c.jpg"/></fig><fig position="float" id="sensors-25-05402-f004" orientation="portrait"><label>Figure 4</label><caption><p>Dependencies of NSTD and SSIM vs. the number of reconstructed images (Baboon (<bold>a</bold>,<bold>b</bold>) and Peppers (<bold>c</bold>,<bold>d</bold>)) for the proposed, 3D Lee, and 3D median methods.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05402-g004.jpg"/></fig><fig position="float" id="sensors-25-05402-f005" orientation="portrait"><label>Figure 5</label><caption><p>Experimental scheme for registering digital holograms with different speckle distributions.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05402-g005.jpg"/></fig><fig position="float" id="sensors-25-05402-f006" orientation="portrait"><label>Figure 6</label><caption><p>Example of a hologram (<bold>a</bold>) and a reconstructed image with several regions (1st, 2nd, and 3rd) for speckle contrast calculation (<bold>b</bold>).</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05402-g006.jpg"/></fig><fig position="float" id="sensors-25-05402-f007" orientation="portrait"><label>Figure 7</label><caption><p>Dependences of speckle contrast in 1st (<bold>a</bold>), 2nd (<bold>b</bold>), and 3rd (<bold>c</bold>) zones vs. the number of images.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05402-g007.jpg"/></fig><fig position="float" id="sensors-25-05402-f008" orientation="portrait"><label>Figure 8</label><caption><p>BRISQUE (<bold>a</bold>) and PIQE (<bold>b</bold>) scores dependences vs. the number of images.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05402-g008.jpg"/></fig><fig position="float" id="sensors-25-05402-f009" orientation="portrait"><label>Figure 9</label><caption><p>Enlarged areas of the images containing edges filtered by the BM4D (<bold>a</bold>) and the proposed filter (<bold>b</bold>).</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05402-g009.jpg"/></fig><fig position="float" id="sensors-25-05402-f010" orientation="portrait"><label>Figure 10</label><caption><p>Images after filtration with BM4D (<bold>a</bold>) and the proposed (<bold>b</bold>) methods.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05402-g010.jpg"/></fig><table-wrap position="float" id="sensors-25-05402-t001" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05402-t001_Table 1</object-id><label>Table 1</label><caption><p>Reconstructed image quality after filtering. The best results are highlighted in bold.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Filter</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">NSTD (Baboon)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">SSIM (Baboon)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">NSTD (Peppers)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">SSIM (Peppers)</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Frost</td><td align="center" valign="middle" rowspan="1" colspan="1">0.244</td><td align="center" valign="middle" rowspan="1" colspan="1">0.290</td><td align="center" valign="middle" rowspan="1" colspan="1">0.210</td><td align="center" valign="middle" rowspan="1" colspan="1">0.349</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">The Proposed Method</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.092</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.762</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.061</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.915</bold>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Lee</td><td align="center" valign="middle" rowspan="1" colspan="1">0.154</td><td align="center" valign="middle" rowspan="1" colspan="1">0.471</td><td align="center" valign="middle" rowspan="1" colspan="1">0.183</td><td align="center" valign="middle" rowspan="1" colspan="1">0.348</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">3D Lee</td><td align="center" valign="middle" rowspan="1" colspan="1">0.112</td><td align="center" valign="middle" rowspan="1" colspan="1">0.656</td><td align="center" valign="middle" rowspan="1" colspan="1">0.078</td><td align="center" valign="middle" rowspan="1" colspan="1">0.886</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">3D Median</td><td align="center" valign="middle" rowspan="1" colspan="1">0.122</td><td align="center" valign="middle" rowspan="1" colspan="1">0.580</td><td align="center" valign="middle" rowspan="1" colspan="1">0.105</td><td align="center" valign="middle" rowspan="1" colspan="1">0.669</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">BM3D</td><td align="center" valign="middle" rowspan="1" colspan="1">0.151</td><td align="center" valign="middle" rowspan="1" colspan="1">0.346</td><td align="center" valign="middle" rowspan="1" colspan="1">0.111</td><td align="center" valign="middle" rowspan="1" colspan="1">0.746</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">BM4D </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.118</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.392</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.109</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.618</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05402-t002" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05402-t002_Table 2</object-id><label>Table 2</label><caption><p>Metrics values for BM4D and the proposed method after filtration. The best results are highlighted in bold.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">
</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">BM4D</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">The Proposed Method</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Image </th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Processing Time, s</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">NSTD </th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSIM </th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Processing Time, s</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">NSTD </th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SSIM </th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Cameraman</td><td align="center" valign="middle" rowspan="1" colspan="1">220</td><td align="center" valign="middle" rowspan="1" colspan="1">0.096</td><td align="center" valign="middle" rowspan="1" colspan="1">0.681</td><td align="center" valign="middle" rowspan="1" colspan="1">0.94</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.067</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.867</bold>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Lake</td><td align="center" valign="middle" rowspan="1" colspan="1">224</td><td align="center" valign="middle" rowspan="1" colspan="1">0.135</td><td align="center" valign="middle" rowspan="1" colspan="1">0.538</td><td align="center" valign="middle" rowspan="1" colspan="1">0.86</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.079</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.890</bold>
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Walbridge</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">227</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.135</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.447</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.96</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.095</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.833</bold>
</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05402-t003" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05402-t003_Table 3</object-id><label>Table 3</label><caption><p>Speckle contrast values for the reconstructed image. The best results are highlighted in bold.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Number of Images</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Zone</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">BM4D</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">The Proposed Method</th></tr></thead><tbody><tr><td rowspan="3" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">10</td><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.101</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0.186</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.117</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0.178</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.131</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.177</td></tr><tr><td rowspan="3" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">20</td><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">0.091</td><td align="center" valign="middle" rowspan="1" colspan="1">0.130</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">0.111</td><td align="center" valign="middle" rowspan="1" colspan="1">0.119</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.127</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.134</td></tr><tr><td rowspan="3" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">40</td><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.086</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0.092</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">0.115</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.085</bold>
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.121</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.102</bold>
</td></tr><tr><td rowspan="3" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">60</td><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">0.087</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.060</bold>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">0.108</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.061</bold>
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.123</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.078</bold>
</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05402-t004" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05402-t004_Table 4</object-id><label>Table 4</label><caption><p>BRISQUE and PIQE values for the reconstructed image. The best results are highlighted in bold.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Number of Images</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">BRISQUE</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">PIQE</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">BM4D</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The Proposed Method</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">BM4D</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The Proposed Method</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">10</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>29.5</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">31.9</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>26.0</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">39.7</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">20</td><td align="center" valign="middle" rowspan="1" colspan="1">29.2</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>28.6</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>25.5</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">33.5</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">40</td><td align="center" valign="middle" rowspan="1" colspan="1">29.2</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>21.3</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>25.0</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">28.3</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">60</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">29.1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>4.8</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">24.8</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>16.0</bold>
</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05402-t005" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05402-t005_Table 5</object-id><label>Table 5</label><caption><p>Processing times for BM4D and the proposed method.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Number of Images</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Processing Time, s</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">BM4D</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The Proposed Method</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">10</td><td align="center" valign="middle" rowspan="1" colspan="1">216</td><td align="center" valign="middle" rowspan="1" colspan="1">17.7</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">20</td><td align="center" valign="middle" rowspan="1" colspan="1">522</td><td align="center" valign="middle" rowspan="1" colspan="1">18.16</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">40</td><td align="center" valign="middle" rowspan="1" colspan="1">1172</td><td align="center" valign="middle" rowspan="1" colspan="1">18.23</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">60</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1781</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">18.24</td></tr></tbody></table></table-wrap></floats-group></article></pmc-articleset>