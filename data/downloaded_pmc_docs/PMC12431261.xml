<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xml:lang="en" article-type="research-article" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="pmc-domain-id">1660</journal-id><journal-id journal-id-type="pmc-domain">sensors</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>Multidisciplinary Digital Publishing Institute  (MDPI)</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12431261</article-id><article-id pub-id-type="pmcid-ver">PMC12431261.1</article-id><article-id pub-id-type="pmcaid">12431261</article-id><article-id pub-id-type="pmcaiid">12431261</article-id><article-id pub-id-type="doi">10.3390/s25175482</article-id><article-id pub-id-type="publisher-id">sensors-25-05482</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>QAMT: An LLM-Based Framework for Quality-Assured Medical Time-Series Data Generation</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-0518-1608</contrib-id><name name-style="western"><surname>Luo</surname><given-names initials="Y">Yi</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#8211; original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><xref rid="af1-sensors-25-05482" ref-type="aff">1</xref><xref rid="af2-sensors-25-05482" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-8803-2055</contrib-id><name name-style="western"><surname>Zhang</surname><given-names initials="Y">Yong</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><xref rid="af2-sensors-25-05482" ref-type="aff">2</xref><xref rid="c1-sensors-25-05482" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Xing</surname><given-names initials="C">Chunxiao</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><xref rid="af2-sensors-25-05482" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Ren</surname><given-names initials="P">Peng</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><xref rid="af2-sensors-25-05482" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0005-5988-2356</contrib-id><name name-style="western"><surname>Liu</surname><given-names initials="X">Xinhao</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#8211; original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><xref rid="af1-sensors-25-05482" ref-type="aff">1</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name name-style="western"><surname>Lee</surname><given-names initials="BG">Boon Giin</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-05482"><label>1</label>School of Computer Science and Technology, Beijing Institute of Technology, Beijing 100081, China; <email>luoyi@bit.edu.cn</email> (Y.L.); <email>liuxinhao@bit.edu.cn</email> (X.L.)</aff><aff id="af2-sensors-25-05482"><label>2</label>BNRist, DCST, RIIT, Tsinghua University, Beijing 100084, China; <email>xingcx@tsinghua.edu.cn</email> (C.X.); <email>renpeng@tsinghua.edu.cn</email> (P.R.)</aff><author-notes><corresp id="c1-sensors-25-05482"><label>*</label>Correspondence: <email>zhangyong05@tsinghua.edu.cn</email></corresp></author-notes><pub-date pub-type="epub"><day>03</day><month>9</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>9</month><year>2025</year></pub-date><volume>25</volume><issue>17</issue><issue-id pub-id-type="pmc-issue-id">496815</issue-id><elocation-id>5482</elocation-id><history><date date-type="received"><day>03</day><month>8</month><year>2025</year></date><date date-type="rev-recd"><day>28</day><month>8</month><year>2025</year></date><date date-type="accepted"><day>31</day><month>8</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>03</day><month>09</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>13</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-13 17:25:36.317"><day>13</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="sensors-25-05482.pdf"/><abstract><p>The extensive deployment of diverse sensors in hospitals has resulted in the collection of various medical time-series data. However, these real-world medical time-series data suffer from limited volume, poor data quality, and privacy concerns, resulting in performance degradation in downstream tasks, such as medical research and clinical decision-making. Existing studies provide generated medical data as a supplement or alternative to real-world data. However, medical time-series data are inherently complex, including temporal data such as laboratory measurements and static event data such as demographics and clinical outcomes, with each patient&#8217;s temporal data being influenced by their static event data. This intrinsic complexity makes the generation of high-quality medical time-series data particularly challenging. Traditional methods typically employ Generative Adversarial Networks (GANs) or Variational Autoencoders (VAEs), but these methods struggle to generate high-quality static event data of medical time-series data and often lack interpretability. Currently, large language models (LLMs) introduce new opportunities for medical data generation, but they face difficulties in generating temporal data and have challenges in specific domain generation tasks. In this study, we are the first to propose an LLM-based framework for modularly generating medical time-series data, QAMT, which generates quality-assured data and ensures the interpretability of the generation process. QAMT constructs a reliable health knowledge graph to provide medical expertise to the LLMs and designs dual modules to simultaneously generate static event data and temporal data, constituting high-quality medical time-series data. Moreover, QAMT introduces a quality assurance module to evaluate the generated data. Unlike existing methods, QAMT preserves the interpretability of the data generation process. Experimental results show that QAMT can generate higher-quality time-series medical data compared with existing methods.</p></abstract><kwd-group><kwd>medical time-series data generation</kwd><kwd>large language models</kwd><kwd>health knowledge graph</kwd><kwd>data quality assurance</kwd></kwd-group><funding-group><award-group><funding-source>National Natural Science Foundation of China</funding-source><award-id>42371480</award-id></award-group><funding-statement>This research was funded by the National Natural Science Foundation of China under Grant 42371480.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-05482"><title>1. Introduction</title><p>With the development of Internet-of-Things (IoT) technologies, hospitals are increasingly equipped with a wide array of sensors that monitor and capture various medical data. Since these sensors record data continuously (e.g., vital signs), most of the medical data exist in the form of time-series data. These data support medical research through effective exploration and mining [<xref rid="B1-sensors-25-05482" ref-type="bibr">1</xref>] and offer valuable assistance in tasks such as health monitoring [<xref rid="B2-sensors-25-05482" ref-type="bibr">2</xref>], clinical decision-making [<xref rid="B3-sensors-25-05482" ref-type="bibr">3</xref>], disease diagnosis [<xref rid="B4-sensors-25-05482" ref-type="bibr">4</xref>,<xref rid="B5-sensors-25-05482" ref-type="bibr">5</xref>], and treatment recommendation [<xref rid="B6-sensors-25-05482" ref-type="bibr">6</xref>].</p><p>Although medical time-series data have demonstrated substantial value in various downstream tasks, their acquisition remains a significant bottleneck. On one hand, although sensors collect data in real time, issues such as sensor malfunctions and the inherent complexity of medical time-series data often lead to challenges in data quality. As a result, medical time-series datasets commonly used, such as eICU [<xref rid="B7-sensors-25-05482" ref-type="bibr">7</xref>] and MIMIC-III [<xref rid="B8-sensors-25-05482" ref-type="bibr">8</xref>], suffer from missing values, inaccuracies, incompleteness, etc., ultimately resulting in poor data quality [<xref rid="B9-sensors-25-05482" ref-type="bibr">9</xref>]. On the other hand, because medical time-series data contain highly sensitive information (e.g., patients&#8217; age, gender), their access is typically subject to strict privacy regulations and governance controls [<xref rid="B10-sensors-25-05482" ref-type="bibr">10</xref>], resulting in limited data volume and privacy concerns. Some studies attempt to mitigate privacy risks by removing personal information from medical data. However, even de-identified data remain vulnerable to re-identification [<xref rid="B11-sensors-25-05482" ref-type="bibr">11</xref>,<xref rid="B12-sensors-25-05482" ref-type="bibr">12</xref>]. Other studies also explore the use of federated learning to address this issue. However, these works still face challenges related to system deployment and security attacks [<xref rid="B13-sensors-25-05482" ref-type="bibr">13</xref>]. Motivated by these limitations, generated medical time-series data offer a supplement and alternative to real-world data.</p><p>However, due to the complexity of medical time-series data, which encompass a wide variety of variables that interact in complex and nonlinear ways, generating such data is challenging. A critical aspect of medical time-series data is the presence of static event data (e.g., demographics, clinical outcomes), which can significantly influence temporal data (e.g., vital signs, laboratory measurements). For instance, an in-hospital patient&#8217;s temporal data, which would include hundreds of variables, such as heart rate and blood pressure, can be influenced by several static event variables, including age, comorbidities, etc. We define an effective medical time-series generation model as one that jointly models both static event data and temporal data. Consequently, generating medical time-series data presents several significant challenges:<list list-type="bullet"><list-item><p><bold>Challenge 1: Joint Generation of Temporal Data and Static Event Data.</bold> Medical time-series data consist of diverse data types, each with unique characteristics. Among them, static event data are generally high-dimensional and discrete (e.g., demographics, clinical outcomes), whereas temporal data tend to be lower-dimensional and continuous (e.g., vital signs, laboratory measurements). Therefore, jointly generating medical time-series data that include both static and temporal components is essential for producing comprehensive and realistic datasets.</p></list-item><list-item><p><bold>Challenge 2: Clinical Constraints and Variable Dependencies.</bold> Many variables in medical time-series data are governed by clinical constraints, and their values often exhibit strong interdependencies. For example, a patient&#8217;s systolic blood pressure value of zero is clinically impossible. Additionally, if a patient consistently exhibits systolic blood pressure readings above 150 mmHg, a final diagnosis would not be hypotension. Accurately modeling these constraints and dependencies is essential to ensure the clinical plausibility of generated data.</p></list-item><list-item><p><bold>Challenge 3: Need for Interpretability.</bold> The generation process of medical time-series data should be interpretable. In clinical research and practice, it is crucial for stakeholders to understand how the data are produced in order to evaluate their quality, support downstream applications, and maintain trust in data-driven healthcare systems.</p></list-item></list></p><p><xref rid="sensors-25-05482-t001" ref-type="table">Table 1</xref> shows that traditional medical time-series data generation methods based on deep learning techniques primarily rely on generative models, such as Variational Autoencoders (VAEs) [<xref rid="B14-sensors-25-05482" ref-type="bibr">14</xref>] and Generative Adversarial Networks (GANs) [<xref rid="B15-sensors-25-05482" ref-type="bibr">15</xref>]. However, although GANs and VAEs have demonstrated strong performance in generating long-sequence temporal data, they face significant challenges in simultaneously producing high-quality static event data. A few studies have attempted to address this by incorporating statistical summaries of the generated temporal data as inputs to guide the generation of static event data [<xref rid="B16-sensors-25-05482" ref-type="bibr">16</xref>]. Nevertheless, GANs and VAEs still struggle to generate sparse one-hot encoded representations [<xref rid="B17-sensors-25-05482" ref-type="bibr">17</xref>] with satisfactory fidelity. In addition, it is challenging to incorporate clinical constraints and variable dependencies into these models, and the black-box nature of deep learning models further limits the interpretability of the generation process. The emergence of large language models (LLMs) presents a promising new direction for medical time-series data generation [<xref rid="B9-sensors-25-05482" ref-type="bibr">9</xref>,<xref rid="B10-sensors-25-05482" ref-type="bibr">10</xref>]. LLMs have demonstrated strong capabilities in modeling complex distributions over discrete data [<xref rid="B18-sensors-25-05482" ref-type="bibr">18</xref>]. However, since LLMs are primarily designed for text-based tasks, they struggle to jointly generate high-quality continuous temporal data [<xref rid="B10-sensors-25-05482" ref-type="bibr">10</xref>]. Moreover, due to their limited exposure to domain-specific medical knowledge, generating clinically meaningful and high-quality medical time-series data remains a challenge for LLMs [<xref rid="B19-sensors-25-05482" ref-type="bibr">19</xref>]. A recent study [<xref rid="B20-sensors-25-05482" ref-type="bibr">20</xref>] proposes a pipeline framework for medical time-series data generation. However, this framework lacks clinical constraints and variable dependencies, as well as interpretability in the data generation process. Therefore, jointly generating high-quality medical time-series data that include temporal data and static event data with an interpretable generation process remains a significant challenge in current research.</p><p>In this study, we propose a modularized LLM-based framework for <bold>Q</bold>ality-<bold>A</bold>ssured <bold>M</bold>edical <bold>T</bold>ime-series data generation, QAMT. To incorporate domain-specific medical knowledge into LLMs and guide both the generation and quality assurance of medical time-series data, we leverage a reliable Health Knowledge Graph Builder, HKGB [<xref rid="B30-sensors-25-05482" ref-type="bibr">30</xref>], to build a health knowledge graph (HKG). During the medical time-series generating process, QAMT adopts dual modules, combining GANs for generating temporal data and health knowledge graph-based retrieval augmented generation for generating static event data. This design leverages the advantages of existing methods and jointly generates medical time-series data. To assess the quality of the generated medical time-series data, QAMT integrates a quality assurance module that evaluates the data through clinical constraints and inter-variable dependencies, using the capabilities of the HKGB, LLMs, and a chain-of-thought prompting over HKG. In contrast to existing methods, QAMT maintains interpretability throughout the medical time-series data generation process. The main contributions of this work are as follows:<list list-type="bullet"><list-item><p>QAMT jointly generates medical time-series data, which include both continuous temporal data and discrete static event data.</p></list-item><list-item><p>QAMT ensures the quality assurance of the generated data by accounting for real-world clinical constraints and variable dependencies.</p></list-item><list-item><p>QAMT enables interpretability in the medical time-series data generation process.</p></list-item><list-item><p>QAMT is evaluated on the eICU and MIMIC-III datasets, and demonstrates superior performance compared to state-of-the-art models in terms of fidelity, utility, and privacy.</p></list-item></list></p><p>In this paper, we outline the problem definition and review related work in <xref rid="sec2-sensors-25-05482" ref-type="sec">Section 2</xref>. <xref rid="sec3-sensors-25-05482" ref-type="sec">Section 3</xref> introduces the overall architecture and workflow of the proposed QAMT framework. In <xref rid="sec4-sensors-25-05482" ref-type="sec">Section 4</xref>, we delve into the design of the health knowledge graph (HKG) module and explain the motivation for incorporating HKG. <xref rid="sec5-sensors-25-05482" ref-type="sec">Section 5</xref> details the dual modules responsible for jointly generating medical time-series data, including the static event data generation module and temporal data generation module. We present our data quality assurance module, including how clinical constraints and variable dependencies are enforced in <xref rid="sec6-sensors-25-05482" ref-type="sec">Section 6</xref>. In <xref rid="sec7-sensors-25-05482" ref-type="sec">Section 7</xref>, we provide an explanation of the interpretability of QAMT. In <xref rid="sec8-sensors-25-05482" ref-type="sec">Section 8</xref>, we provide experimental results to evaluate our proposed QAMT. Finally, <xref rid="sec9-sensors-25-05482" ref-type="sec">Section 9</xref> summarizes the key contributions of this work and discusses potential directions for future research.</p></sec><sec id="sec2-sensors-25-05482"><title>2. Preliminaries and Related&#160;Work</title><p>In this chapter, <xref rid="sec2dot1-sensors-25-05482" ref-type="sec">Section 2.1</xref> provides the definition of our medical time-series data generation task. <xref rid="sec2dot2-sensors-25-05482" ref-type="sec">Section 2.2</xref>, <xref rid="sec2dot3-sensors-25-05482" ref-type="sec">Section 2.3</xref>, <xref rid="sec2dot4-sensors-25-05482" ref-type="sec">Section 2.4</xref> discuss the limitations of existing work in jointly generating high-quality and interpretable medical time-series data.</p><sec id="sec2dot1-sensors-25-05482"><title>2.1. Definition</title><p>A medical time-series dataset is denoted as <inline-formula><mml:math id="mm1" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic toggle="yes">N</italic> represents the number of patients, and <inline-formula><mml:math id="mm2" overflow="scroll"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> denotes the medical time-series data of the <italic toggle="yes">i</italic>th patient. Each patient record <inline-formula><mml:math id="mm3" overflow="scroll"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> consists of a sequence of clinical visits, denoted as <inline-formula><mml:math id="mm4" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, and each visit <inline-formula><mml:math id="mm5" overflow="scroll"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> at time <inline-formula><mml:math id="mm6" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is defined as a tuple <inline-formula><mml:math id="mm7" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where: <inline-formula><mml:math id="mm8" overflow="scroll"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is a set of covariates (e.g., demographics) of this patient, <inline-formula><mml:math id="mm9" overflow="scroll"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is a set of clinical outcomes (e.g., expire), <inline-formula><mml:math id="mm10" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> is a sequence of clinical events (e.g., ICD diagnosis codes), and <inline-formula><mml:math id="mm11" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is a collection of temporal data recorded in in-patient settings, including vital signs and laboratory measurements [<xref rid="B10-sensors-25-05482" ref-type="bibr">10</xref>]. We refer to <inline-formula><mml:math id="mm12" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced separators="" open="{" close="}"><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> collectively as <bold>static event data</bold> (high-dimensional and discrete data), and <inline-formula><mml:math id="mm13" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> as <bold>temporal data</bold> (low-dimensional and continuous data). Each temporal data element <inline-formula><mml:math id="mm14" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is further represented as <inline-formula><mml:math id="mm15" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mfenced separators="" open="{" close="}"><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mfenced separators="" open="{" close="}"><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mfenced><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mfenced><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="mm16" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the total number of measurement time points, <inline-formula><mml:math id="mm17" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the number of variables measured at time point <inline-formula><mml:math id="mm18" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm19" overflow="scroll"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the name of the <italic toggle="yes">p</italic>th variable measured at time <inline-formula><mml:math id="mm20" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="mm21" overflow="scroll"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the corresponding observed value. In this paper, our task is to jointly generate high-quality and interpretable medical time-series data, including both static event data and temporal data.</p></sec><sec id="sec2dot2-sensors-25-05482"><title>2.2. Medical Time-Series Data&#160;Generation</title><p>Due to the complexity of medical time-series data, as shown in <xref rid="sensors-25-05482-t001" ref-type="table">Table 1</xref>, few studies have addressed the joint generation of medical time-series data.</p><p>A considerable amount of research has focused on the generation of a sequence of static event data. Traditional methods, such as GAN-based methods [<xref rid="B20-sensors-25-05482" ref-type="bibr">20</xref>,<xref rid="B21-sensors-25-05482" ref-type="bibr">21</xref>] and VAE-based methods [<xref rid="B23-sensors-25-05482" ref-type="bibr">23</xref>], have been widely used. However, the discrete and high-dimensional nature of static event data makes it challenging for them to guarantee the quality of the generated data. Recently, LLMs have been explored for static event data generation [<xref rid="B19-sensors-25-05482" ref-type="bibr">19</xref>,<xref rid="B24-sensors-25-05482" ref-type="bibr">24</xref>]. Empirical studies have demonstrated that LLMs outperform GAN- and VAE-based methods in static event data generation [<xref rid="B31-sensors-25-05482" ref-type="bibr">31</xref>,<xref rid="B32-sensors-25-05482" ref-type="bibr">32</xref>], largely due to their superior capabilities in semantic reasoning and contextual understanding.</p><p>Other research on temporal data generation has primarily focused on producing data with meaningful patterns and trends. Traditional generative techniques, such as GANs [<xref rid="B25-sensors-25-05482" ref-type="bibr">25</xref>,<xref rid="B26-sensors-25-05482" ref-type="bibr">26</xref>,<xref rid="B27-sensors-25-05482" ref-type="bibr">27</xref>] and VAEs [<xref rid="B28-sensors-25-05482" ref-type="bibr">28</xref>], have demonstrated strong potential for generating temporal data. Existing studies have shown that GAN-based methods generally outperform VAE-based methods in generating temporal data [<xref rid="B33-sensors-25-05482" ref-type="bibr">33</xref>]. The application of LLMs to temporal data generation remains relatively underexplored [<xref rid="B10-sensors-25-05482" ref-type="bibr">10</xref>]. This limitation is due to LLMs being inherently designed for text-based tasks, and they must treat numerical temporal data as sequences of tokens.</p><p>Few studies can jointly generate both static event data and temporal data. Traditional GAN-based methods [<xref rid="B16-sensors-25-05482" ref-type="bibr">16</xref>] generate medical time-series data by a hybrid multi-generator framework. LLM-based methods, such as HALO [<xref rid="B9-sensors-25-05482" ref-type="bibr">9</xref>] and SynEHRgy [<xref rid="B10-sensors-25-05482" ref-type="bibr">10</xref>], employ novel tokenization strategies. Although these methods achieve joint generation of medical time-series data, they face notable limitations: GAN-based methods often produce unreliable static event data, while LLM-based methods struggle to generate high-quality temporal data and face high computational cost. Therefore, modularizing the medical time-series data generation task using two modules to generate static event and temporal data may yield better performance than relying on a single model.</p></sec><sec id="sec2dot3-sensors-25-05482"><title>2.3. Medical Time-Series Data Quality&#160;Assurance</title><p>Data quality assurance plays a crucial role in guaranteeing the quality of generated medical time-series data. This assurance must consider not only clinical constraints (value range limits on temporal variables and logical limits among sequential diagnoses in static event variables) but also variable dependencies (logical inferences exist between different variables). In the following, we provide an overview of existing data assurance methods.</p><p>A few existing studies have addressed clinical constraints in medical time-series data generation. As shown in <xref rid="sensors-25-05482-t001" ref-type="table">Table 1</xref>, some methods perform pre-generation quality assurance by incorporating quality assurance mechanisms directly within the generative model architecture [<xref rid="B16-sensors-25-05482" ref-type="bibr">16</xref>,<xref rid="B24-sensors-25-05482" ref-type="bibr">24</xref>] or leveraging the reasoning capabilities of LLMs to ensure logical consistency [<xref rid="B24-sensors-25-05482" ref-type="bibr">24</xref>]. Other methods [<xref rid="B34-sensors-25-05482" ref-type="bibr">34</xref>] perform post-generation quality assurance by employing sampling and data transformation techniques to maintain value ranges and data integrity. Although these methods can enforce numerical value ranges for temporal data, they fall short in validating static event data, which require logical constraints. For example, a patient cannot have a diagnosis of poliomyelitis immediately followed by Alzheimer&#8217;s.</p><p>Due to the complex logical relationships among variables in medical time-series data, very few studies have addressed the assurance of variable dependencies in generated data. Existing work, such as PromptEHR [<xref rid="B19-sensors-25-05482" ref-type="bibr">19</xref>], leverages the reasoning capabilities of LLMs to infer dependencies from one variable to another during the generation process. However, the generation process of LLMs is prone to hallucination [<xref rid="B35-sensors-25-05482" ref-type="bibr">35</xref>], which limits the reliability of such inferred dependencies. As a result, though LLMs may capture dependencies among variables when generating data, it is also essential to validate the variable dependencies of the generated medical time-series data again by post-generation assurance.</p></sec><sec id="sec2dot4-sensors-25-05482"><title>2.4. Interpretability of Data&#160;Generation</title><p>Traditional medical time-series data generation methods, such as GANs [<xref rid="B20-sensors-25-05482" ref-type="bibr">20</xref>,<xref rid="B21-sensors-25-05482" ref-type="bibr">21</xref>,<xref rid="B22-sensors-25-05482" ref-type="bibr">22</xref>,<xref rid="B25-sensors-25-05482" ref-type="bibr">25</xref>,<xref rid="B26-sensors-25-05482" ref-type="bibr">26</xref>] and VAEs [<xref rid="B23-sensors-25-05482" ref-type="bibr">23</xref>,<xref rid="B28-sensors-25-05482" ref-type="bibr">28</xref>], are inherently black-box models, making it difficult to provide meaningful explanations for the data generation process. Moreover, existing LLM-based methods [<xref rid="B9-sensors-25-05482" ref-type="bibr">9</xref>,<xref rid="B10-sensors-25-05482" ref-type="bibr">10</xref>,<xref rid="B19-sensors-25-05482" ref-type="bibr">19</xref>,<xref rid="B24-sensors-25-05482" ref-type="bibr">24</xref>] also lack the interpretability of data generation. However, the interpretability of medical time-series data generation is essential for researchers, making the interpretability of the data generation process crucial.</p></sec></sec><sec id="sec3-sensors-25-05482"><title>3. QAMT&#160;Overview</title><p>QAMT enables the joint generation of high-quality medical time-series data while preserving the interpretability throughout the generation process. As illustrated in <xref rid="sensors-25-05482-f001" ref-type="fig">Figure 1</xref>, this framework consists of four main modules. The health knowledge graph module provides domain-specific knowledge to LLMs. The GAN-based temporal data generation module and the LLM-based static event data generation module are responsible for jointly generating medical time-series data. The medical time-series data quality assurance module evaluates the generated data to ensure the overall quality and clinical plausibility of the final generated data. The entire medical time-series data generation and quality assurance process can be divided into the following steps:</p><list list-type="simple"><list-item><label>(a)</label><p>Based on real-world medical time-series datasets and open knowledge bases, a health knowledge graph (HKG) is constructed using an existing Health Knowledge Graph Builder (HKGB). This knowledge graph serves as a domain-specific knowledge resource for downstream LLMs (<xref rid="sec4dot1-sensors-25-05482" ref-type="sec">Section 4.1</xref>).</p></list-item><list-item><label>(b)</label><p>Construct HKG-CoT, a chain-of-thought (CoT) reasoning process enriched with clinical knowledge from the HKG, which provides healthcare-specific inference capabilities (<xref rid="sec4dot2-sensors-25-05482" ref-type="sec">Section 4.2</xref>).</p></list-item><list-item><label>(c)</label><p>The static event data generation module uses Retrieval-Augmented Generation (RAG) guided by the HKG to generate static event data <inline-formula><mml:math id="mm22" overflow="scroll"><mml:mrow><mml:msup><mml:mi>m</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (<xref rid="sec5dot1-sensors-25-05482" ref-type="sec">Section 5.1</xref>), referred to as Health Knowledge Graph-based Retrieval Augmented Generation (HKG-RAG):<disp-formula id="FD1-sensors-25-05482"><label>(1)</label><mml:math id="mm23" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>m</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mi>HKG</mml:mi><mml:mtext>-</mml:mtext><mml:mi>RAG</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi><mml:mi>K</mml:mi><mml:mi>G</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item><list-item><label>(d)</label><p>The medical time-series data quality assurance module then evaluates the generated static event data using HKG-CoT (<xref rid="sec6dot1-sensors-25-05482" ref-type="sec">Section 6.1</xref>), obtaining constrained static event data <inline-formula><mml:math id="mm24" overflow="scroll"><mml:mrow><mml:msup><mml:mi>m</mml:mi><mml:mrow><mml:mo>&#8243;</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> with clinical constraints and logical consistency. Then, the evaluation results are fed back to the static event data generation module:<disp-formula id="FD2-sensors-25-05482"><label>(2)</label><mml:math id="mm25" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>Constraint</mml:mi><mml:mspace width="4.pt"/><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo></mml:mrow><mml:mspace width="4.pt"/><mml:mi>C</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>HKG</mml:mi><mml:mtext>-</mml:mtext><mml:mi>CoT</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>H</mml:mi><mml:mi>K</mml:mi><mml:mi>G</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#8712;</mml:mo><mml:mfenced separators="" open="{" close="}"><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="FD3-sensors-25-05482"><label>(3)</label><mml:math id="mm26" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>m</mml:mi><mml:mrow><mml:mo>&#8243;</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#183;</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item><list-item><label>(e)</label><p>The temporal data generation module uses a GAN to generate temporal data <inline-formula><mml:math id="mm27" overflow="scroll"><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (<xref rid="sec5dot2-sensors-25-05482" ref-type="sec">Section 5.2</xref>), leveraging constrained static event data as conditional guidance:<disp-formula id="FD4-sensors-25-05482"><label>(4)</label><mml:math id="mm28" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mi>GAN</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mrow><mml:mo>&#8243;</mml:mo></mml:mrow></mml:msup></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item><list-item><label>(f)</label><p>The generated temporal data are further validated by the medical time-series data quality assurance module, using the Concept Knowledge Graph (CKG), which is a subgraph within the HKG (<xref rid="sec6dot2-sensors-25-05482" ref-type="sec">Section 6.2</xref>), to check for clinical value range constraints and plausibility and obtain constrained temporal data:<disp-formula id="FD5-sensors-25-05482"><label>(5)</label><mml:math id="mm29" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>Constraint</mml:mi><mml:mspace width="4.pt"/><mml:mrow><mml:mn>2</mml:mn><mml:mo>:</mml:mo></mml:mrow><mml:mspace width="4.pt"/><mml:mi>C</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mfenced separators="" open="(" close=")"><mml:msup><mml:mi>t</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup></mml:mfenced><mml:mo>=</mml:mo><mml:mi>CKG</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:msup><mml:mi>t</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>H</mml:mi><mml:mi>K</mml:mi><mml:mi>G</mml:mi></mml:mfenced><mml:mo>&#8712;</mml:mo><mml:mfenced separators="" open="{" close="}"><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item><list-item><label>(g)</label><p>The constrained temporal data are then input to an LLM-based diagnostic model, LLM-EvPredict, which predicts its corresponding static event data. Then, the medical time-series data quality assurance module compares the predicted static event data with the previously constrained static event data using the LLM-TSAssure (<xref rid="sec6dot3-sensors-25-05482" ref-type="sec">Section 6.3</xref>):<disp-formula id="FD6-sensors-25-05482"><label>(6)</label><mml:math id="mm30" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>Constraint</mml:mi><mml:mspace width="4.pt"/><mml:mrow><mml:mn>3</mml:mn><mml:mo>:</mml:mo></mml:mrow><mml:mspace width="4.pt"/><mml:mi>V</mml:mi><mml:mi>D</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>LLM</mml:mi><mml:mtext>-</mml:mtext><mml:mi>TSAssure</mml:mi></mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:msup><mml:mi>m</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mi>LLM</mml:mi><mml:mtext>-</mml:mtext><mml:mi>EvPredict</mml:mi></mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:msup><mml:mi>t</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup></mml:mfenced></mml:mfenced><mml:mo>&#8712;</mml:mo><mml:mfenced separators="" open="{" close="}"><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item><list-item><label>(h)</label><p>Finally, if the predicted static event data and constrained static event data are deemed consistent, the static event data and temporal data are considered to satisfy variable dependencies and are jointly assembled into final, reliable synthetic medical time-series data <inline-formula><mml:math id="mm31" overflow="scroll"><mml:mrow><mml:msup><mml:mi>V</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (<xref rid="sec6dot3-sensors-25-05482" ref-type="sec">Section 6.3</xref>):<disp-formula id="FD7-sensors-25-05482"><label>(7)</label><mml:math id="mm32" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>V</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mi>V</mml:mi><mml:mi>D</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:msup><mml:mi>m</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup></mml:mfenced><mml:mfenced separators="" open="(" close=")"><mml:mi>C</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mfenced separators="" open="(" close=")"><mml:msup><mml:mi>m</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup></mml:mfenced><mml:mo>&#183;</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup><mml:mo>&#8853;</mml:mo><mml:mi>C</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mfenced separators="" open="(" close=")"><mml:msup><mml:mi>t</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup></mml:mfenced><mml:mo>&#183;</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p></list-item></list><p>The following sections provide a detailed description of each module and explain how they contribute to the joint generation and quality assurance of medical time-series data.</p></sec><sec id="sec4-sensors-25-05482"><title>4. Health Knowledge Graph&#160;Module</title><p>The emergence of LLMs has introduced new potential for data generation. However, existing LLMs lack sufficient domain-specific knowledge in the medical time-series data generation task, leading them to generate hallucinated information. One solution involves pretraining LLMs on domain-specific corpora to enhance their medical knowledge [<xref rid="B36-sensors-25-05482" ref-type="bibr">36</xref>,<xref rid="B37-sensors-25-05482" ref-type="bibr">37</xref>]. However, it is computationally expensive. Another strategy involves prompt tuning to improve LLM performance [<xref rid="B37-sensors-25-05482" ref-type="bibr">37</xref>,<xref rid="B38-sensors-25-05482" ref-type="bibr">38</xref>], which requires relevant domain knowledge. Therefore, an increasingly explored method is to integrate knowledge graphs (KGs) with LLMs [<xref rid="B39-sensors-25-05482" ref-type="bibr">39</xref>,<xref rid="B40-sensors-25-05482" ref-type="bibr">40</xref>,<xref rid="B41-sensors-25-05482" ref-type="bibr">41</xref>,<xref rid="B42-sensors-25-05482" ref-type="bibr">42</xref>,<xref rid="B43-sensors-25-05482" ref-type="bibr">43</xref>]. By leveraging the structured domain knowledge encoded in KGs, LLMs can be guided toward more accurate generation and reasoning. In this paper, we construct a health knowledge graph module to provide domain-specific expertise to the LLMs. In <xref rid="sec4dot1-sensors-25-05482" ref-type="sec">Section 4.1</xref>, we describe how we construct the HKG. In <xref rid="sec4dot2-sensors-25-05482" ref-type="sec">Section 4.2</xref>, we explain how HKG is used to guide reliable CoT reasoning. In <xref rid="sec4dot3-sensors-25-05482" ref-type="sec">Section 4.3</xref>, we demonstrate how HKG assists in generating trustworthy medical information.</p><sec id="sec4dot1-sensors-25-05482"><title>4.1. HKG</title><p>To construct a reliable HKG, we leverage an existing HKGB [<xref rid="B30-sensors-25-05482" ref-type="bibr">30</xref>]. As shown in <xref rid="sensors-25-05482-f002" ref-type="fig">Figure 2</xref>, the HKGB is an end-to-end platform designed to construct disease-specific and scalable health knowledge graphs (HKGs) from diverse sources as well as evaluate its generated HKG. In this study, we built a reliable HKG by leveraging external knowledge bases together with medical time-series data (e.g., MIMIC-III and eICU). The HKG constructed by the HKGB consists of three types of nodes: concept nodes, entity nodes, and event nodes. Among them, concept nodes are extracted from open knowledge bases and include medical information such as diseases, symptoms, drugs, treatments, clinical indicators, and clinical constraints. We refer to the subgraph containing only concept nodes as the Concept Knowledge Graph (CKG). Since the construction of the CKG relies on external knowledge bases, its update is relatively slow.</p><p>In contrast, entity nodes and event nodes are derived from real medical time-series datasets. Entity nodes, which represent patient information (e.g., demographic) or contextual information, are obtained through event extraction, and event nodes, which capture static clinical events in the medical time-series data, are extracted through entity extraction. Furthermore, we use ER-RDF to extract column-level information from the datasets to enrich the node information. We refer to the subgraph containing entity and event nodes as the Instance Knowledge Graph (IKG). Since the construction of the IKG depends on real medical time-series datasets, it is frequently updated and continuously expanded as new medical time-series data become available.</p><p>In this work, the HKG is defined as the integration of the CKG and IKG, thereby capturing both general medical knowledge and instance-level clinical information. Given the complexity and heterogeneity of these nodes, the HKG defines edges to represent relationships between them, with several illustrative examples provided in <xref rid="sensors-25-05482-t002" ref-type="table">Table 2</xref>.</p></sec><sec id="sec4dot2-sensors-25-05482"><title>4.2. HKG-CoT</title><p>Handling reasoning tasks such as arithmetic, commonsense, and symbolic reasoning has always been a challenge [<xref rid="B44-sensors-25-05482" ref-type="bibr">44</xref>]. Previous studies have explored the use of KGs for logical reasoning [<xref rid="B45-sensors-25-05482" ref-type="bibr">45</xref>]. However, selecting nodes based solely on similarity does not necessarily lead to correct or complete reasoning outcomes. With the rapid development of LLMs, recent work has explored LLMs&#8217; potential in reasoning by constructing a CoT [<xref rid="B38-sensors-25-05482" ref-type="bibr">38</xref>], which aims to solve complex reasoning problems by generating a sequence of intermediate reasoning steps through manually designed prompts. Although CoT prompting has demonstrated promising performance in reasoning, it often suffers from hallucinations when applied to knowledge-intensive tasks, primarily due to the lack of related knowledge. To address this limitation, recent work proposed the concept of KG-CoT [<xref rid="B41-sensors-25-05482" ref-type="bibr">41</xref>], which combines the explicit relational structure of KGs with the step-by-step reasoning capabilities of CoT prompting. This method decomposes complex problem-solving into manageable steps, enhancing the reasoning capabilities of LLMs while providing an observable reasoning process that improves interpretability [<xref rid="B35-sensors-25-05482" ref-type="bibr">35</xref>]. However, its multi-turn question mechanism inevitably leads to increased computational cost [<xref rid="B46-sensors-25-05482" ref-type="bibr">46</xref>]. Since the generated static event data consist of various events for multiple patients, and there should be certain logical constraints among the events of each individual, it is reasonable to use a CoT to infer the logic between a patient&#8217;s multiple events. Therefore, in this paper, we construct an HKG-CoT to fulfill static event data quality assurance.</p></sec><sec id="sec4dot3-sensors-25-05482"><title>4.3. HKG-RAG</title><p>To address the limitations of LLMs in accessing external domain-specific knowledge, many studies have adopted Retrieval-Augmented Generation (RAG) [<xref rid="B47-sensors-25-05482" ref-type="bibr">47</xref>], which enhances LLMs by incorporating few-shot prompts retrieved from external sources (e.g., real-world medical time-series data or open knowledge bases). However, information retrieved directly from data-rich databases often lacks reliability and interpretability [<xref rid="B48-sensors-25-05482" ref-type="bibr">48</xref>]. Recent research has therefore focused on integrating KGs into retrieval strategies to strengthen LLMs&#8217; generation ability [<xref rid="B49-sensors-25-05482" ref-type="bibr">49</xref>,<xref rid="B50-sensors-25-05482" ref-type="bibr">50</xref>]. Compared to databases, KGs provide structured and inferable knowledge, making them more suitable for enhancing RAG. Recent work proposed KG-RAG [<xref rid="B40-sensors-25-05482" ref-type="bibr">40</xref>], demonstrating that KGs could effectively enhance the performance of LLMs. In the generation tasks, RAG has the advantage of encoding sensitive data in a secure manner, thereby reducing the risk of privacy leakage. Furthermore, compared to a CoT, RAG can eliminate certain intermediate generation steps, thus lowering computational costs. Given that static event data generation requires the rapid synthesis of large volumes of data while minimizing privacy risks during the generation process, we propose a method, HKG-RAG, to support the generation of static event data.</p></sec></sec><sec id="sec5-sensors-25-05482"><title>5. Medical Time-Series Data Generation&#160;Module</title><p>As analyzed in <xref rid="sec2dot2-sensors-25-05482" ref-type="sec">Section 2.2</xref>, since GANs and LLMs each have their advantages in static event data generation and temporal data generation, respectively, QAMT adopts dual modules to accomplish joint medical time-series data generation: the LLM-based static event data generation module (<xref rid="sec5dot1-sensors-25-05482" ref-type="sec">Section 5.1</xref>) and the GAN-based temporal data generation module (<xref rid="sec5dot2-sensors-25-05482" ref-type="sec">Section 5.2</xref>).</p><sec id="sec5dot1-sensors-25-05482"><title>5.1. Static Event Data Generation&#160;Module</title><p>In the static event data generation module, we employ the HKG-RAG introduced in <xref rid="sec4dot3-sensors-25-05482" ref-type="sec">Section 4.3</xref>. As illustrated in <xref rid="sensors-25-05482-f003" ref-type="fig">Figure 3</xref>, the process of static event data generation consists of the following steps:</p><p><bold>Step 1: Privacy-insensitive demographic sampling and prompt customization.</bold> Demographic information <italic toggle="yes">c</italic>, such as patient ID, age, diagnosis time, religion, and marital status, is randomly sampled from real-world medical time-series data. This information is first checked by an LLM, obtaining reliable demographic information <inline-formula><mml:math id="mm33" overflow="scroll"><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> as shown in Equation (<xref rid="FD8-sensors-25-05482" ref-type="disp-formula">8</xref>), and then used to construct a customized prompt <italic toggle="yes">q</italic>, which is fed into another LLM:<disp-formula id="FD8-sensors-25-05482"><label>(8)</label><mml:math id="mm34" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mi>LLM</mml:mi><mml:mtext>-</mml:mtext><mml:mi>judge</mml:mi></mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:mi>S</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mfenced open="(" close=")"><mml:mi>c</mml:mi></mml:mfenced></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p><bold>Step 2: Entity recognition.</bold> Entities <inline-formula><mml:math id="mm35" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mfenced separators="" open="{" close="}"><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>&#8230;</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mfenced><mml:mo>&#8838;</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> are extracted from the input prompt <inline-formula><mml:math id="mm36" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mi>L</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:msup><mml:mi>c</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> and matched to corresponding nodes in the HKG:<disp-formula id="FD9-sensors-25-05482"><label>(9)</label><mml:math id="mm37" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfenced separators="" open="{" close="}"><mml:mi>n</mml:mi><mml:mo>&#8739;</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mfenced><mml:mo>&gt;</mml:mo><mml:mi>&#964;</mml:mi></mml:mfenced><mml:mo>&#8838;</mml:mo><mml:mi>HKG</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm38" overflow="scroll"><mml:mrow><mml:mi>&#964;</mml:mi></mml:mrow></mml:math></inline-formula> is the threshold value. During the entity extraction, QAMT employs zero-shot prompting on an LLM distinct from the previous one to ensure accuracy. Next, entity linking is performed to obtain the corresponding entities in the HKG. We utilize the sentence embedding model &#8220;all-MiniLM-L6-v2&#8221; to encode entity nodes into dense vector representations [<xref rid="B51-sensors-25-05482" ref-type="bibr">51</xref>]. The similarity between the extracted entities and HKG nodes is then calculated in this embedding space to determine the best match.</p><p><bold>Step 3: Contextual retrieval of clinical outcomes and events based on the HKG.</bold> In the HKG, entity nodes are connected to event nodes through contextual triples (Subject, Predicate, Object), following a defined schema as shown in <xref rid="sensors-25-05482-t002" ref-type="table">Table 2</xref>. Since multiple entities may be extracted from one prompt and may correspond to several entity nodes in the HKG, we select the top-K<italic toggle="yes"><sub>rag</sub></italic> most frequently occurring objects across inferred triples as the final context targets. These are then structured into n-ary tuples: (Subject<sub>1</sub>, Subject<sub>2</sub>, &#8230;, Subject<italic toggle="yes"><sub>n</sub></italic>, Predicate, Object). These tuples can be directly transformed into a natural language sentence using the following pattern: (Subject<sub>1</sub>, Subject<sub>2</sub>, &#8230;, Subject<italic toggle="yes"><sub>n</sub></italic>, Predicate, Object) &#8594; Subjects predicateName Object.</p><p><bold>Step 4: Generation of clinical outcomes and events.</bold> The prompt-aware content is used as few-shot prompts for the LLM to generate the final output. The generated clinical outcomes and events are then matched with the corresponding demographic information to form the final generated static event data.<disp-formula id="FD10-sensors-25-05482"><label>(10)</label><mml:math id="mm46" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>m</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>m</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">&#732;</mml:mo></mml:mover><mml:mo>&#8853;</mml:mo><mml:mrow><mml:mi>HKG</mml:mi><mml:mtext>-</mml:mtext><mml:mi>RAG</mml:mi></mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:mover accent="true"><mml:msub><mml:mi>m</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">&#732;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mo>&#160;</mml:mo><mml:mi>f</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p><bold>Step 5: Feedback mechanism.</bold> In the initial generation process, we set the size of top-K<italic toggle="yes">rag</italic> to 5. Subsequently, the medical time-series data quality assurance module evaluates the generated static event data (<xref rid="sec6dot1-sensors-25-05482" ref-type="sec">Section 6.1</xref>). If the data generated by HKG-RAG fail to satisfy the clinical constraints, we expand top-K<italic toggle="yes">rag</italic> to 10, enabling the generation of more diverse results and correcting previously erroneous outputs. By feeding back the evaluation results from the time-series data quality assurance module to the static event data generation module, the efficiency of data generation can be improved.</p></sec><sec id="sec5dot2-sensors-25-05482"><title>5.2. Temporal Data Generation&#160;Module</title><p>In the temporal data generation module, we adopt a GAN, which has demonstrated strong performance in continuous data generation. To establish a connection between it and the static event data generation module, we incorporate the statistical information of constrained static event data <inline-formula><mml:math id="mm49" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>&#8242;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> after validation (<xref rid="sec6dot1-sensors-25-05482" ref-type="sec">Section 6.1</xref>) as input to assist the generation of temporal data [<xref rid="B52-sensors-25-05482" ref-type="bibr">52</xref>]:<disp-formula id="FD11-sensors-25-05482"><label>(11)</label><mml:math id="mm50" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:munder><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mi>G</mml:mi></mml:munder><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mi>D</mml:mi></mml:munder><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#8764;</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>real</mml:mi><mml:mspace width="4.pt"/></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mo form="prefix">log</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>&#8739;</mml:mo><mml:msub><mml:mi>&#952;</mml:mi><mml:mi>D</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mi>z</mml:mi><mml:mo>&#8764;</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mo form="prefix">log</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup><mml:mo>&#8739;</mml:mo><mml:msub><mml:mi>&#952;</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>In this GAN model, we introduce an attention mechanism to mitigate the impact of noise. Additionally, we incorporate learned positional encoding to integrate position information into the attention computation process, preserving relative distance information within the sequence.</p><p>The generator accepts input random noise vectors <italic toggle="yes">z</italic> and statistical information derived from the static event data <italic toggle="yes">c</italic>, generating time-series data <inline-formula><mml:math id="mm51" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>&#952;</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, which captures variable dependencies between the static event data and temporal data.</p></sec></sec><sec id="sec6-sensors-25-05482"><title>6. Medical Time-Series Data Quality Assurance&#160;Module</title><p>Real-world medical time-series data often exhibit multiple constraints, including logical constraints within a single patient&#8217;s static event data (e.g., a patient diagnosed with poliomyelitis is unlikely to be diagnosed with Alzheimer&#8217;s disease in a short time) and value constraints on temporal data (e.g., heart rate values cannot be zero). Moreover, there are typically variable dependencies among variables (e.g., patients with high systolic blood pressure are more likely to have hypertension).</p><p>To ensure higher quality in the generated medical time-series data, we apply the HKG-CoT (<xref rid="sec6dot1-sensors-25-05482" ref-type="sec">Section 6.1</xref>) and CKG (<xref rid="sec6dot2-sensors-25-05482" ref-type="sec">Section 6.2</xref>) to enforce constraints on the outputs from the static event data and the temporal data generation module, respectively. In addition, we use LLMs to predict the static event data corresponding to the constrained temporal data. By comparing the predicted static event data with the constrained static event data, we validate the variable dependencies in the generated medical time-series data (<xref rid="sec6dot3-sensors-25-05482" ref-type="sec">Section 6.3</xref>).</p><sec id="sec6dot1-sensors-25-05482"><title>6.1. Clinical Constraint Assurance in Static Event Data</title><p>Since static event data often exhibit inherent logical relationships, we apply the HKG-CoT introduced in <xref rid="sec4dot2-sensors-25-05482" ref-type="sec">Section 4.2</xref> to enforce logical constraints on the generated static event data. <xref rid="sensors-25-05482-f004" ref-type="fig">Figure 4</xref> illustrates the detailed process of the HKG-CoT:</p><p><bold>Step 1: Step-by-step graph reasoning model.</bold> Let <italic toggle="yes">n</italic> denote the number of entities in the HKG. We first initialize an entity state <inline-formula><mml:math id="mm52" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mn>0</mml:mn></mml:msup><mml:mo>&#8712;</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. If the <italic toggle="yes">i</italic>th entity is mentioned in the question, <inline-formula><mml:math id="mm53" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>e</mml:mi><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is initialized to 1; otherwise, it is set to 0. The question is transformed into a one-dimensional vector <italic toggle="yes">q</italic> through embedding. Divide the graph reasoning process into <italic toggle="yes">T</italic> steps, and through the design of an attention-related function <inline-formula><mml:math id="mm54" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, obtain the question representation <inline-formula><mml:math id="mm55" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>q</mml:mi><mml:mi>t</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> at step <italic toggle="yes">t</italic>, <inline-formula><mml:math id="mm56" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>,</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. The question representations focus on different parts of the question context at different steps. Then, we can obtain the scores of all relations in the HKG at step <italic toggle="yes">t</italic> by using a multi-layer perception (MLP). We define a transition matrix <inline-formula><mml:math id="mm57" overflow="scroll"><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mi>t</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> and the update formula for <italic toggle="yes">e</italic> is <inline-formula><mml:math id="mm58" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>W</mml:mi><mml:mi>t</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. After <italic toggle="yes">T</italic> steps of reasoning, we can obtain the confidence score of each entity based on <inline-formula><mml:math id="mm59" overflow="scroll"><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>.</p><p><bold>Step 2: Reasoning path generation method.</bold> Based on the results of the step-by-step graph reasoning model, obtain the <italic toggle="yes">k</italic> entities with the highest confidence, denoted as <inline-formula><mml:math id="mm60" overflow="scroll"><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>. Perform <italic toggle="yes">T</italic> steps of reasoning, and for each reasoning path, calculate its score based on rules. Take the entity in question as the initial entity. At step <italic toggle="yes">t</italic>, select the top-<italic toggle="yes">k</italic> intermediate reasoning paths based on the scores and add these paths to the candidate paths. After <italic toggle="yes">T</italic> steps of reasoning, select the top-<italic toggle="yes">k</italic> candidate reasoning paths with the highest scores to form the final reasoning paths: <inline-formula><mml:math id="mm61" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>Path</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mspace width="4.pt"/><mml:msub><mml:mi>Path</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mspace width="4.pt"/><mml:mrow><mml:mo>&#8230;</mml:mo><mml:mo>,</mml:mo></mml:mrow><mml:mspace width="4.pt"/><mml:msub><mml:mi>Path</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p><bold>Step 3: Reasoning.</bold> Serialize the selected <italic toggle="yes">k</italic> final reasoning paths and use detailed instructions to prompt the LLM to generate answers using these reasoning paths. Since generated static event data consist of multiple events of a single patient, we form a question by combining the first event (the event data are sorted by timestamp) with a pre-defined prompt. If the answer produced by the HKG-CoT does not contain the entity of the second event, we consider the patient&#8217;s event data to be incorrect. If this is the first time the data undergo validation, the validation results are fed back to the static event generation module for correction (<xref rid="sec5dot1-sensors-25-05482" ref-type="sec">Section 5.1</xref>). If the data remain incorrect even after feedback-based revision, they are discarded. Conversely, if the event data are deemed correct, we consider the first event as passed and continue to ask questions about the second event until the set of event data is discarded or all events of this patient are passed. After the data quality assurance conducted by the HKG-CoT, we consider the generated event data to be constrained.</p></sec><sec id="sec6dot2-sensors-25-05482"><title>6.2. Clinical Constraint&#160;Assurance in Temporal Data</title><p>Temporal data are often subject to value constraints. However, due to the structural complexity of medical time-series data, different datasets may record different variables, making it difficult to manually define value constraints for each variable. The CKG within the HKG introduced in <xref rid="sec4dot1-sensors-25-05482" ref-type="sec">Section 4.1</xref> captures clinical constraints associated with various clinical indicators and serves as a reliable and comprehensive knowledge base. Therefore, QAMT leverages the CKG to apply value constraints to the temporal data, thereby enabling data quality assurance.</p><p>For the generated temporal data, we extract each variable and perform similarity matching with the clinical indicator nodes (concept nodes) in the CKG. By leveraging the relationships between clinical indicators and clinical constraints, we obtain the corresponding value constraints for each variable. If a variable in the temporal data exceeds its specified value range, the data are considered unreliable. Otherwise, if all values fall within the range, the data are constrained.</p></sec><sec id="sec6dot3-sensors-25-05482"><title>6.3. Assurance of Variable Dependencies</title><p>Due to the complex relationships among variables in medical time-series data, it is necessary to verify the dependencies between temporal data and static event data. For example, suppose a patient&#8217;s temporal data show elevated systolic blood pressure (within the acceptable value range), but the corresponding static event data indicate a diagnosis of hypotension. This inconsistency suggests that the generated medical time-series data are unreliable. Given the diagnostic relationship between temporal data and static event data, we utilize an LLM to predict diagnostic outcomes in the static event data based on the constrained temporal data. If the predicted static event data are similar to the originally constrained static event data, the generated medical time-series data are considered reliable.</p><p>Previous studies have shown that with carefully designed prompts, LLMs can successfully predict static event data from temporal inputs [<xref rid="B53-sensors-25-05482" ref-type="bibr">53</xref>,<xref rid="B54-sensors-25-05482" ref-type="bibr">54</xref>]. Therefore, we designed LLM-EvPredict, a static event prediction model based on temporal data. This LLM formats a patient&#8217;s temporal data into queries by organizing the variables into tuples (variable: values)<italic toggle="yes"><sub>n</sub></italic>, and construct the corresponding prompt as: <inline-formula><mml:math id="mm63" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>Prompt</mml:mi><mml:mspace width="4.pt"/><mml:mo>=</mml:mo><mml:mspace width="4.pt"/><mml:msub><mml:mi>Instruction</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mspace width="4.pt"/><mml:mo>+</mml:mo><mml:mspace width="4.pt"/><mml:mi>Context</mml:mi><mml:mspace width="4.pt"/><mml:mo>+</mml:mo><mml:mspace width="4.pt"/><mml:msub><mml:mi>Instruction</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>The results obtained by LLM-EvPredict are written in the form of event tuples (<inline-formula><mml:math id="mm64" overflow="scroll"><mml:mrow><mml:msub><mml:mi>PreEvent</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm65" overflow="scroll"><mml:mrow><mml:msub><mml:mi>PreEvent</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, &#8230;, <inline-formula><mml:math id="mm66" overflow="scroll"><mml:mrow><mml:msub><mml:mi>PreEvent</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>). Another model, LLM-TSAssure, is then used to compare the predicted static event data (in tuple form) with the constrained static event data of the corresponding patient (also in tuple form). If LLM-TSAssure determines that the two sets of static events are likely to come from the same patient, we consider that variable dependencies exist between the generated temporal data and static event data and retain the data. Otherwise, the data are discarded.</p></sec></sec><sec id="sec7-sensors-25-05482"><title>7. The Interpretability of Medical Time-Series Data&#160;Generation</title><p>Due to the high modularity of QAMT and its multiple usage of LLMs throughout the time-series data generation and quality assurance, the framework offers an interpretable generation pipeline.</p><p><bold>(1) Clearly defined modularization.</bold> As shown in <xref rid="sensors-25-05482-f001" ref-type="fig">Figure 1</xref>, QAMT consists of four modules, each functioning independently. Specifically, steps such as (c) static event data generation, (d) static event data quality assurance, (g) static event data prediction, and (h) assurance of variable dependencies involve the formulation of question prompts and the use of LLMs to produce outputs. These interactions with the LLMs, comprising formulated questions and corresponding answers, reflect the logical flow of medical time-series data generation, thereby providing QAMT&#8217;s interpretability.</p><p><bold>(2) Clear collaboration between modules.</bold>&#160;<xref rid="sensors-25-05482-f005" ref-type="fig">Figure 5</xref> illustrates the process of generating and validating static event data based on randomly sampled demographic information. The output of each step serves as input for the next, and the question&#8211;answer pairs at each step make the generation process interpretable, demonstrating the collaboration of the data generation task. Moreover, some steps, such as the clinical constraint assurance in static event data based on the HKG-CoT, further enhance interpretability by providing insight into the reasoning steps within the step itself.</p></sec><sec id="sec8-sensors-25-05482"><title>8. Experimental&#160;Results</title><sec id="sec8dot1-sensors-25-05482"><title>8.1. Experimental&#160;Setup</title><sec id="sec8dot1dot1-sensors-25-05482"><title>8.1.1. Datasets</title><p>We conducted experiments using the MIMIC-III [<xref rid="B8-sensors-25-05482" ref-type="bibr">8</xref>] and eICU [<xref rid="B7-sensors-25-05482" ref-type="bibr">7</xref>] datasets. MIMIC-III is a large, publicly available database that contains a wide range of medical time-series data. In this study, we extracted 40 thousand data samples following the methodology adopted in previous work [<xref rid="B10-sensors-25-05482" ref-type="bibr">10</xref>]. Specifically, we employed the preprocessing pipeline in [<xref rid="B55-sensors-25-05482" ref-type="bibr">55</xref>] to extract relevant data. Except for patient demographic information (age and gender), we selected 25 phenotype labels as static event data for each visit. Furthermore, we included 41 continuous temporal variables derived from vital signs and laboratory measurements. The eICU Collaborative Research Database is a comprehensive and publicly available resource that contains data on approximately 200,000 hospitalized patients. In this study, similar to previous work [<xref rid="B52-sensors-25-05482" ref-type="bibr">52</xref>], we extracted 13 thousand data samples. In addition to patient demographic information (age, gender, and ethnicity), we selected seven phenotype labels as static event variables and 40 continuous vital signs and laboratory measurements as temporal variables.</p></sec><sec id="sec8dot1dot2-sensors-25-05482"><title>8.1.2. Evaluation&#160;Metrics</title><p>We evaluated the generated time-series data based on fidelity, utility, and privacy [<xref rid="B10-sensors-25-05482" ref-type="bibr">10</xref>,<xref rid="B52-sensors-25-05482" ref-type="bibr">52</xref>].</p><list list-type="simple"><list-item><p><bold>Fidelity.</bold> For static event data, we assessed fidelity using the probabilities of unigram, bigram, and trigram within each visit, as well as the probabilities of sequential bigram between continuous visits. For example, the probability of a continuous visit as <inline-formula><mml:math id="mm67" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mn>13</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mn>920</mml:mn></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> was computed by dividing its frequency by the total number of patients. We then calculated the Pearson Correlation between the top 1000 <italic toggle="yes">n</italic>-gram probabilities in the real and generated datasets to evaluate the similarity in their distributions.</p></list-item></list><p>For temporal data, we first constructed embeddings for each patient by calculating the statistical features of their first 48 h of temporal data (minimum, maximum, mean, and standard deviation). Using these embeddings, we evaluated the fidelity by calculating the precision, recall, density, and coverage (PRDC) between the embeddings of the generated data and real data. Furthermore, we compared the correlation matrices of the real and generated data and report the mean squared error (<inline-formula><mml:math id="mm68" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>) as overall correlation fidelity.</p><list list-type="simple"><list-item><p><bold>Utility.</bold> We assessed the utility of the generated data by evaluating their performance across four downstream tasks involving two disease types: sepsis clustering [<xref rid="B56-sensors-25-05482" ref-type="bibr">56</xref>], sepsis treatment strategy modeling [<xref rid="B57-sensors-25-05482" ref-type="bibr">57</xref>], ARDS (Acute Respiratory Distress Syndrome) prediction [<xref rid="B58-sensors-25-05482" ref-type="bibr">58</xref>], and ARDS treatment strategy modeling [<xref rid="B59-sensors-25-05482" ref-type="bibr">59</xref>]. A smaller difference between the generated data and real data in downstream tasks indicates more similarity. For the sepsis clustering task, the study evaluated the results before and after applying its proposed method using the Sum of Squares Error (SSE) metric. Accordingly, we adopted the difference in SSE improvement between real and generated data as our evaluation metric. For the sepsis treatment strategy task, we measured the difference in patient condition improvement <inline-formula><mml:math id="mm69" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> between models trained on generated data and real data. For ARDS prediction, we compared the AUROC scores of classifiers trained on real data and generated data within a 12 h window before onset. For ARDS treatment strategy modeling, we compared the average reduction in mortality achieved by reinforcement learning algorithms when trained on real or generated data.</p></list-item><list-item><p><bold>Privacy.</bold> We adopted the Membership Inference Attack (MIA) as the evaluation metric of privacy to determine whether specific data points were included in the data [<xref rid="B27-sensors-25-05482" ref-type="bibr">27</xref>]. We fit a K-Nearest Neighbors (KNN) model on the generated data and the real dataset and calculated their nearest distances for each patient. A significant disparity between the distance distributions in the generated and real sets indicates lower privacy. We used the Hamming distance for static event sequences and the Euclidean distance for temporal embeddings. We then fit Gaussian distributions to these distances and assess the differences between the two distributions using the Wasserstein Distance (WD), Jensen&#8211;Shannon Divergence (JSD), and Area Under the Receiver Operating Characteristic (AUROC) metrics.</p></list-item></list></sec><sec id="sec8dot1dot3-sensors-25-05482"><title>8.1.3. Baselines</title><p>Since QAMT is capable of jointly generating medical time-series data, we compared our method, based on <xref rid="sensors-25-05482-t001" ref-type="table">Table 1</xref>, with HGAN [<xref rid="B16-sensors-25-05482" ref-type="bibr">16</xref>], HALO [<xref rid="B9-sensors-25-05482" ref-type="bibr">9</xref>], SynEHRgy [<xref rid="B10-sensors-25-05482" ref-type="bibr">10</xref>], and SynTEG [<xref rid="B20-sensors-25-05482" ref-type="bibr">20</xref>].</p></sec><sec id="sec8dot1dot4-sensors-25-05482"><title>8.1.4. Experimental&#160;Details</title><p>Since QAMT utilizes LLMs across multiple steps, including static event data generation, clinical constraint assurance in static event data, static event data prediction, and assurance of variable dependencies, we employed different models for different steps, including LLaMA 2 [<xref rid="B60-sensors-25-05482" ref-type="bibr">60</xref>], GPT-3.5, Gemini [<xref rid="B61-sensors-25-05482" ref-type="bibr">61</xref>], and GPT-4 [<xref rid="B62-sensors-25-05482" ref-type="bibr">62</xref>]. The experiments were conducted in an environment equipped with an NVIDIA RTX A5000 GPU (Santa Clara, CA, USA).</p></sec></sec><sec id="sec8dot2-sensors-25-05482"><title>8.2. Medical Time-Series Data Fidelity&#160;Evaluation</title><p><xref rid="sensors-25-05482-t003" ref-type="table">Table 3</xref> presents the correlation values of <italic toggle="yes">n</italic>-gram probabilities between real and generated static event data. On the MIMIC-III dataset, although SynEHRgy achieved the best performance on trigram probabilities, our method consistently outperformed all baselines, particularly in unigram, bigram, and sequential bigram probabilities. Similarly, on the eICU dataset, our method demonstrated superior performance in unigram, trigram, and sequential bigram probabilities. These results confirm that our method is capable of generating high-quality static event data.</p><p><xref rid="sensors-25-05482-t004" ref-type="table">Table 4</xref> reports the PRDC metrics, along with the correlation difference (<inline-formula><mml:math id="mm70" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>) for evaluating the fidelity of temporal data. We found that our proposed framework achieved either the best or second-best performance in the PRDC metrics compared to the baselines. This is attributed to our modular design, which incorporates a GAN model better suited for temporal data generation. Moreover, our model achieved the lowest <inline-formula><mml:math id="mm71" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, indicating that QAMT excels in capturing variable-level correlations, thanks to the variable dependencies described in <xref rid="sec5dot2-sensors-25-05482" ref-type="sec">Section 5.2</xref> and <xref rid="sec6-sensors-25-05482" ref-type="sec">Section 6</xref>.</p></sec><sec id="sec8dot3-sensors-25-05482"><title>8.3. Medical Time-Series Data Utility&#160;Evaluation</title><p><xref rid="sensors-25-05482-t005" ref-type="table">Table 5</xref> presents the performance of different models across various downstream tasks. We found that our proposed method achieved the best performance on all tasks in the MIMIC-III dataset. On the eICU dataset, our model performed best on the SepsisClustering and SepsisTreatment tasks. Compared with the MIMIC-III dataset, we included three demographic variables (static event variables) in the eICU dataset. Although these variables were also subject to quality assurance, they were randomly generated and thus carried uncertainty. As a result, our model showed some instability in the ARDSPrediction and ARDSTreatment tasks of eICU.</p><p>In addition, we applied QAMT to generate sepsis time-series data based on the real data provided by the Emergency Department of Peking University People&#8217;s Hospital. First, the generated data improved the sepsis prediction model&#8217;s accuracy as the training data [<xref rid="B57-sensors-25-05482" ref-type="bibr">57</xref>], which assisted doctors in clinical decisions. Second, the generated data supported clinical research on sepsis, particularly in sepsis subphenotypes, revealing significant heterogeneity in inflammatory biomarkers, treatments, and consistency across cohorts [<xref rid="B63-sensors-25-05482" ref-type="bibr">63</xref>]. Due to privacy considerations, the related medical data cannot be publicly released.</p></sec><sec id="sec8dot4-sensors-25-05482"><title>8.4. Medical Time-Series Data Privacy&#160;Evaluation</title><p>MIA metrics are reported in <xref rid="sensors-25-05482-t006" ref-type="table">Table 6</xref>. Here, we computed privacy metrics by using the Hamming distance of static event data and the Euclidean distance of temporal data. We found that none of the methods showed a privacy risk.</p></sec><sec id="sec8dot5-sensors-25-05482"><title>8.5. Robustness&#160;Analysis</title><sec id="sec8dot5dot1-sensors-25-05482"><title>8.5.1. Statistical Significance&#160;Test</title><p>To ensure the statistical reliability of the experimental conclusions, we repeated several experiments using the MIMIC-III dataset. For the static event data, we selected the probability of unigram and bigram in each visit as the evaluation metrics. For temporal data, we chose precision and recall as evaluation metrics. For time-series data, we selected the performance in the downstream tasks of sepsis clustering and sepsis treatment as the evaluation index. We measured the mean of the results and their 95% confidence intervals. The results are shown in <xref rid="sensors-25-05482-t007" ref-type="table">Table 7</xref>. We found that the experimental results fell in a certain interval with high probability, and the worst value of that interval was still better than the vast majority of baseline methods. Therefore, our experimental conclusions are statistically significant.</p></sec><sec id="sec8dot5dot2-sensors-25-05482"><title>8.5.2. Noise Robustness&#160;Analysis</title><p>We injected 0% to 20% Gaussian noise into MIMIC-III time-series data and used the fidelity of temporal data as the evaluation metric to evaluate the noise robustness of QAMT. The results are shown in <xref rid="sensors-25-05482-t008" ref-type="table">Table 8</xref>. We found that QAMT was less affected by noise, as its quality assurance module performed quality validations on the generated data. As a result, QAMT demonstrates robustness against noise.</p></sec></sec><sec id="sec8dot6-sensors-25-05482"><title>8.6. Parameter Sensitivity&#160;Analysis</title><p>We also tested the sensitivity of QAMT by varying <italic toggle="yes">k</italic>, which is the number of inference paths selected in the KG-CoT (<xref rid="sec5dot1-sensors-25-05482" ref-type="sec">Section 5.1</xref>). The results are shown in <xref rid="sensors-25-05482-t009" ref-type="table">Table 9</xref>. We found that the improvement of the fidelity of temporal data became smaller as <italic toggle="yes">k</italic> increased. Moreover, when <italic toggle="yes">k</italic> &gt; 7, the fidelity of temporal data was no longer significantly improved by increasing <italic toggle="yes">k</italic>.</p></sec><sec id="sec8dot7-sensors-25-05482"><title>8.7. Ablation&#160;Experiments</title><p>To validate the importance of each module in the proposed QAMT framework, we conducted an ablation study. Specifically, QAMT<sub>0</sub> only used a GAN to generate all static event data and temporal data, QAMT<sub>1</sub> only used an LLM to generate all static event data and temporal data, and QAMT<sub>2</sub> used a GAN to generate temporal data and an LLM to generate static event data. On the basis of QAMT<sub>2</sub>, QAMT<sub>3</sub> added CoT prompting to ensure clinical constraints to the generated static event data. QAMT<sub>4</sub> introduced the external knowledge graph HKG based on QAMT<sub>3</sub>. We compared the full QAMT against QAMT<sub>0</sub>, QAMT<sub>1</sub>, QAMT<sub>2</sub>, QAMT<sub>3</sub>, and QAMT<sub>4</sub> across fidelity, utility, and privacy metrics on the MIMIC-III dataset to demonstrate the contribution and necessity of each module in the framework.</p><sec id="sec8dot7dot1-sensors-25-05482"><title>8.7.1. Fidelity&#160;Evaluation</title><p>As shown in <xref rid="sensors-25-05482-f006" ref-type="fig">Figure 6</xref>, from QAMT to QAMT<sub>0</sub>, the fidelity of the data generated with fewer modules in QAMT shows a step-like decreasing trend. The results of the fidelity evaluation experiments clearly demonstrate that omitting the variable dependencies assurance (QAMT<sub>4</sub>) leads to a decline in data quality. Similarly, comparing QAMT<sub>4</sub> and QAMT<sub>3</sub>, the lack of HKG leads to a significant performance decrease, with a more noticeable drop compared to the exclusion of variable dependencies. It shows that the external knowledge provided by the HKG helps with higher-quality medical time-series data generation. Moreover, the data generated without clinical constraints (QAMT<sub>2</sub>) also result in decreased fidelity performance. This is because during the data generation process, both GANs and LLMs may produce incorrect outputs. Therefore, comparing QAMT<sub>2</sub> and QAMT<sub>4</sub>, we find that the clinical constraints applied after generation using the HKG-CoT and CKG can effectively eliminate these errors. We find that the medical time-series data generated with the simultaneous usage of LLM and GAN (QAMT<sub>2</sub>) have higher fidelity compared with the single usage of LLM or GAN for data generation (QAMT<sub>1</sub> and QAMT<sub>0</sub>), showing that the modularization of the generation process in QAMT is important.</p></sec><sec id="sec8dot7dot2-sensors-25-05482"><title>8.7.2. Utility&#160;Evaluation</title><p><xref rid="sensors-25-05482-f007" ref-type="fig">Figure 7</xref> demonstrates that, in downstream tasks, medical time-series data generated without applying the simultaneous usage of the LLM and GAN, HKG, clinical constraints, and variable dependencies perform worse than the data generated by QAMT. This further demonstrates the importance of our modular design in QAMT.</p></sec><sec id="sec8dot7dot3-sensors-25-05482"><title>8.7.3. Privacy&#160;Evaluation</title><p><xref rid="sensors-25-05482-t010" ref-type="table">Table 10</xref> reports that the privacy risk of the data generated by QAMT, QAMT<sub>4</sub>, QAMT<sub>3</sub>, QAMT<sub>2</sub>, QAMT<sub>1</sub>, and QAMT<sub>0</sub> show a step-like increasing trend, indicating the significance of our modular design in QAMT.</p></sec></sec></sec><sec sec-type="conclusions" id="sec9-sensors-25-05482"><title>9. Conclusions</title><p>In this study, we proposed QAMT, an LLM-based framework for quality-assured medical time-series data generation. The framework constructs a reliable HKG to inject medical expertise into LLMs and uses a dual-module method to jointly generate medical time-series data, including static event data and temporal data. In addition, QAMT incorporates a quality assurance module to evaluate the generated data. It provides clinical constraint assurance in static event data based on an HKG-CoT and in temporal data based on a CKG and employs LLM-based prediction to ensure variable dependencies. Unlike existing methods, QAMT maintains the modularity and high-level pipeline structure of the generation process, preserving interpretability.</p><p>Currently, the proposed QAMT is only applicable to the medical domain. Other domain-specific areas, such as energy [<xref rid="B29-sensors-25-05482" ref-type="bibr">29</xref>], also involve time-series data generation tasks. Therefore, in the future, we plan to extend QAMT to other domains to support other time-series data generation tasks.</p></sec></body><back><fn-group><fn><p><bold>Disclaimer/Publisher&#8217;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><notes><title>Author Contributions</title><p>Conceptualization, Y.L., Y.Z., C.X. and P.R.; Methodology, Y.L. and Y.Z.; Investigation, Y.L., P.R. and X.L.; Writing&#8212;original draft, Y.L. and X.L.; Writing&#8212;review &amp; editing, Y.L., Y.Z., C.X. and P.R.; Visualization, Y.L. and X.L.; Supervision, Y.Z. and C.X. All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Institutional Review Board Statement</title><p>Not applicable.</p></notes><notes><title>Informed Consent Statement</title><p>Not applicable.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>We use the open source data MIMIC-III and eICU. The data provided by the Emergency Department of Peking University People&#8217;s Hospital is unavailable due to privacy concerns.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflicts of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-25-05482"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cruz-Vega</surname><given-names>I.B.</given-names></name><name name-style="western"><surname>&#193;vila Vanzzini</surname><given-names>N.</given-names></name><name name-style="western"><surname>Gonz&#225;lez-G&#243;mez</surname><given-names>G.H.</given-names></name><name name-style="western"><surname>Springall</surname><given-names>R.</given-names></name><name name-style="western"><surname>Echeverr&#237;a</surname><given-names>J.C.</given-names></name><name name-style="western"><surname>Lerma</surname><given-names>C.</given-names></name></person-group><article-title>Dynamic Response of Heart Rate Variability to Active Standing in Aortic Valve Disease: Insights from Recurrence Quantification Analysis</article-title><source>Sensors</source><year>2025</year><volume>25</volume><elocation-id>1535</elocation-id><pub-id pub-id-type="doi">10.3390/s25051535</pub-id><pub-id pub-id-type="pmid">40096400</pub-id><pub-id pub-id-type="pmcid">PMC11902333</pub-id></element-citation></ref><ref id="B2-sensors-25-05482"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fan</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Dang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Guo</surname><given-names>Y.</given-names></name></person-group><article-title>Fault Identification Model Using Convolutional Neural Networks with Transformer Architecture</article-title><source>Sensors</source><year>2025</year><volume>25</volume><elocation-id>3897</elocation-id><pub-id pub-id-type="doi">10.3390/s25133897</pub-id><pub-id pub-id-type="pmid">40648155</pub-id><pub-id pub-id-type="pmcid">PMC12252208</pub-id></element-citation></ref><ref id="B3-sensors-25-05482"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rupprechter</surname><given-names>S.</given-names></name><name name-style="western"><surname>Morinan</surname><given-names>G.</given-names></name><name name-style="western"><surname>Peng</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Foltynie</surname><given-names>T.</given-names></name><name name-style="western"><surname>Sibley</surname><given-names>K.</given-names></name><name name-style="western"><surname>Weil</surname><given-names>R.S.</given-names></name><name name-style="western"><surname>Leyland</surname><given-names>L.A.</given-names></name><name name-style="western"><surname>Baig</surname><given-names>F.</given-names></name><name name-style="western"><surname>Morgante</surname><given-names>F.</given-names></name><name name-style="western"><surname>Gilron</surname><given-names>R.</given-names></name><etal/></person-group><article-title>A Clinically Interpretable Computer-Vision Based Method for Quantifying Gait in Parkinson&#8217;s Disease</article-title><source>Sensors</source><year>2021</year><volume>21</volume><elocation-id>5437</elocation-id><pub-id pub-id-type="doi">10.3390/s21165437</pub-id><pub-id pub-id-type="pmid">34450879</pub-id><pub-id pub-id-type="pmcid">PMC8399017</pub-id></element-citation></ref><ref id="B4-sensors-25-05482"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kalahasty</surname><given-names>R.</given-names></name><name name-style="western"><surname>Yerrapragada</surname><given-names>G.</given-names></name><name name-style="western"><surname>Lee</surname><given-names>J.</given-names></name><name name-style="western"><surname>Gopalakrishnan</surname><given-names>K.</given-names></name><name name-style="western"><surname>Kaur</surname><given-names>A.</given-names></name><name name-style="western"><surname>Muddaloor</surname><given-names>P.</given-names></name><name name-style="western"><surname>Sood</surname><given-names>D.</given-names></name><name name-style="western"><surname>Parikh</surname><given-names>C.</given-names></name><name name-style="western"><surname>Gohri</surname><given-names>J.</given-names></name><name name-style="western"><surname>Panjwani</surname><given-names>G.A.R.</given-names></name><etal/></person-group><article-title>A Novel You Only Listen Once (YOLO) Deep Learning Model for Automatic Prominent Bowel Sounds Detection: Feasibility Study in Healthy Subjects</article-title><source>Sensors</source><year>2025</year><volume>25</volume><elocation-id>4735</elocation-id><pub-id pub-id-type="doi">10.3390/s25154735</pub-id><pub-id pub-id-type="pmid">40807899</pub-id><pub-id pub-id-type="pmcid">PMC12349269</pub-id></element-citation></ref><ref id="B5-sensors-25-05482"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dang</surname><given-names>T.H.</given-names></name><name name-style="western"><surname>Kim</surname><given-names>S.m.</given-names></name><name name-style="western"><surname>Choi</surname><given-names>M.s.</given-names></name><name name-style="western"><surname>Hwan</surname><given-names>S.n.</given-names></name><name name-style="western"><surname>Min</surname><given-names>H.k.</given-names></name><name name-style="western"><surname>Bien</surname><given-names>F.</given-names></name></person-group><article-title>An Automated Algorithm for Obstructive Sleep Apnea Detection Using a Wireless Abdomen-Worn Sensor</article-title><source>Sensors</source><year>2025</year><volume>25</volume><elocation-id>2412</elocation-id><pub-id pub-id-type="doi">10.3390/s25082412</pub-id><pub-id pub-id-type="pmid">40285102</pub-id><pub-id pub-id-type="pmcid">PMC12031466</pub-id></element-citation></ref><ref id="B6-sensors-25-05482"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Randazzo</surname><given-names>V.</given-names></name><name name-style="western"><surname>Caligari</surname><given-names>S.</given-names></name><name name-style="western"><surname>Pasero</surname><given-names>E.</given-names></name><name name-style="western"><surname>Giustetto</surname><given-names>C.</given-names></name><name name-style="western"><surname>Saglietto</surname><given-names>A.</given-names></name><name name-style="western"><surname>Bertarello</surname><given-names>W.</given-names></name><name name-style="western"><surname>Averbuch</surname><given-names>A.</given-names></name><name name-style="western"><surname>Marcus-Kalish</surname><given-names>M.</given-names></name><name name-style="western"><surname>Zheludev</surname><given-names>V.</given-names></name><name name-style="western"><surname>Gaita</surname><given-names>F.</given-names></name></person-group><article-title>A Vision Transformer Model for the Prediction of Fatal Arrhythmic Events in Patients with Brugada Syndrome</article-title><source>Sensors</source><year>2025</year><volume>25</volume><elocation-id>824</elocation-id><pub-id pub-id-type="doi">10.3390/s25030824</pub-id><pub-id pub-id-type="pmid">39943462</pub-id><pub-id pub-id-type="pmcid">PMC11820670</pub-id></element-citation></ref><ref id="B7-sensors-25-05482"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pollard</surname><given-names>T.J.</given-names></name><name name-style="western"><surname>Johnson</surname><given-names>A.E.</given-names></name><name name-style="western"><surname>Raffa</surname><given-names>J.D.</given-names></name><name name-style="western"><surname>Celi</surname><given-names>L.A.</given-names></name><name name-style="western"><surname>Mark</surname><given-names>R.G.</given-names></name><name name-style="western"><surname>Badawi</surname><given-names>O.</given-names></name></person-group><article-title>The eICU Collaborative Research Database, a freely available multi-center database for critical care research</article-title><source>Sci. Data</source><year>2018</year><volume>5</volume><fpage>180178</fpage><pub-id pub-id-type="doi">10.1038/sdata.2018.178</pub-id><pub-id pub-id-type="pmid">30204154</pub-id><pub-id pub-id-type="pmcid">PMC6132188</pub-id></element-citation></ref><ref id="B8-sensors-25-05482"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Johnson</surname><given-names>A.E.</given-names></name><name name-style="western"><surname>Pollard</surname><given-names>T.J.</given-names></name><name name-style="western"><surname>Shen</surname><given-names>L.</given-names></name><name name-style="western"><surname>Lehman</surname><given-names>L.w.H.</given-names></name><name name-style="western"><surname>Feng</surname><given-names>M.</given-names></name><name name-style="western"><surname>Ghassemi</surname><given-names>M.</given-names></name><name name-style="western"><surname>Moody</surname><given-names>B.</given-names></name><name name-style="western"><surname>Szolovits</surname><given-names>P.</given-names></name><name name-style="western"><surname>Anthony Celi</surname><given-names>L.</given-names></name><name name-style="western"><surname>Mark</surname><given-names>R.G.</given-names></name></person-group><article-title>MIMIC-III, a freely accessible critical care database</article-title><source>Sci. Data</source><year>2016</year><volume>3</volume><fpage>160035</fpage><pub-id pub-id-type="doi">10.1038/sdata.2016.35</pub-id><pub-id pub-id-type="pmid">27219127</pub-id><pub-id pub-id-type="pmcid">PMC4878278</pub-id></element-citation></ref><ref id="B9-sensors-25-05482"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Theodorou</surname><given-names>B.</given-names></name><name name-style="western"><surname>Xiao</surname><given-names>C.</given-names></name><name name-style="western"><surname>Sun</surname><given-names>J.</given-names></name></person-group><article-title>Synthesize high-dimensional longitudinal electronic health records via hierarchical autoregressive language model</article-title><source>Nat. Commun.</source><year>2023</year><volume>14</volume><fpage>5305</fpage><pub-id pub-id-type="doi">10.1038/s41467-023-41093-0</pub-id><pub-id pub-id-type="pmid">37652934</pub-id><pub-id pub-id-type="pmcid">PMC10471716</pub-id></element-citation></ref><ref id="B10-sensors-25-05482"><label>10.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Karami</surname><given-names>H.</given-names></name><name name-style="western"><surname>Atienza Alonso</surname><given-names>D.</given-names></name><name name-style="western"><surname>Ionescu</surname><given-names>A.</given-names></name></person-group><article-title>SynEHRgy: Synthesizing Mixed-Type Structured Electronic Health Records using Decoder-Only Transformers</article-title><source>Proceedings of the 38th Annual Conference on Neural Information Processing Systems</source><conf-loc>Vancouver, BC, Canada</conf-loc><conf-date>10&#8211;15 December 2024</conf-date></element-citation></ref><ref id="B11-sensors-25-05482"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>El Emam</surname><given-names>K.</given-names></name><name name-style="western"><surname>Buckeridge</surname><given-names>D.</given-names></name><name name-style="western"><surname>Tamblyn</surname><given-names>R.</given-names></name><name name-style="western"><surname>Neisa</surname><given-names>A.</given-names></name><name name-style="western"><surname>Jonker</surname><given-names>E.</given-names></name><name name-style="western"><surname>Verma</surname><given-names>A.</given-names></name></person-group><article-title>The re-identification risk of Canadians from longitudinal demographics</article-title><source>BMC Med. Inform. Decis. Mak.</source><year>2011</year><volume>11</volume><elocation-id>46</elocation-id><pub-id pub-id-type="doi">10.1186/1472-6947-11-46</pub-id><pub-id pub-id-type="pmid">21696636</pub-id><pub-id pub-id-type="pmcid">PMC3151203</pub-id></element-citation></ref><ref id="B12-sensors-25-05482"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Benitez</surname><given-names>K.</given-names></name><name name-style="western"><surname>Malin</surname><given-names>B.</given-names></name></person-group><article-title>Evaluating re-identification risks with respect to the HIPAA privacy rule</article-title><source>J. Am. Med. Inform. Assoc.</source><year>2010</year><volume>17</volume><fpage>169</fpage><lpage>177</lpage><pub-id pub-id-type="doi">10.1136/jamia.2009.000026</pub-id><pub-id pub-id-type="pmid">20190059</pub-id><pub-id pub-id-type="pmcid">PMC3000773</pub-id></element-citation></ref><ref id="B13-sensors-25-05482"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Abbas</surname><given-names>S.R.</given-names></name><name name-style="western"><surname>Abbas</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Zahir</surname><given-names>A.</given-names></name><name name-style="western"><surname>Lee</surname><given-names>S.W.</given-names></name></person-group><article-title>Federated learning in smart healthcare: A comprehensive review on privacy, security, and predictive analytics with IoT integration</article-title><source>Healthcare</source><year>2024</year><volume>12</volume><elocation-id>2587</elocation-id><pub-id pub-id-type="doi">10.3390/healthcare12242587</pub-id><pub-id pub-id-type="pmid">39766014</pub-id><pub-id pub-id-type="pmcid">PMC11728217</pub-id></element-citation></ref><ref id="B14-sensors-25-05482"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kingma</surname><given-names>D.P.</given-names></name><name name-style="western"><surname>Welling</surname><given-names>M.</given-names></name></person-group><article-title>An introduction to variational autoencoders</article-title><source>Found. Trends&#174; Mach. Learn.</source><year>2019</year><volume>12</volume><fpage>307</fpage><lpage>392</lpage><pub-id pub-id-type="doi">10.1561/2200000056</pub-id></element-citation></ref><ref id="B15-sensors-25-05482"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Goodfellow</surname><given-names>I.</given-names></name><name name-style="western"><surname>Pouget-Abadie</surname><given-names>J.</given-names></name><name name-style="western"><surname>Mirza</surname><given-names>M.</given-names></name><name name-style="western"><surname>Xu</surname><given-names>B.</given-names></name><name name-style="western"><surname>Warde-Farley</surname><given-names>D.</given-names></name><name name-style="western"><surname>Ozair</surname><given-names>S.</given-names></name><name name-style="western"><surname>Courville</surname><given-names>A.</given-names></name><name name-style="western"><surname>Bengio</surname><given-names>Y.</given-names></name></person-group><article-title>Generative adversarial networks</article-title><source>Commun. ACM</source><year>2020</year><volume>63</volume><fpage>139</fpage><lpage>144</lpage><pub-id pub-id-type="doi">10.1145/3422622</pub-id></element-citation></ref><ref id="B16-sensors-25-05482"><label>16.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Yan</surname><given-names>C.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Nyemba</surname><given-names>S.</given-names></name><name name-style="western"><surname>Malin</surname><given-names>B.A.</given-names></name></person-group><article-title>Generating Electronic Health Records with Multiple Data Types and Constraints</article-title><source>Proceedings of the AMIA 2020, American Medical Informatics Association Annual Symposium</source><conf-loc>Virtual</conf-loc><conf-date>14&#8211;18 November 2020</conf-date><pub-id pub-id-type="pmcid">PMC8075510</pub-id><pub-id pub-id-type="pmid">33936510</pub-id></element-citation></ref><ref id="B17-sensors-25-05482"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Xu</surname><given-names>L.</given-names></name><name name-style="western"><surname>Skoularidou</surname><given-names>M.</given-names></name><name name-style="western"><surname>Cuesta-Infante</surname><given-names>A.</given-names></name><name name-style="western"><surname>Veeramachaneni</surname><given-names>K.</given-names></name></person-group><article-title>Modeling tabular data using conditional gan</article-title><source>arXiv</source><year>2019</year><pub-id pub-id-type="doi">10.48550/arXiv.1907.00503</pub-id><pub-id pub-id-type="arxiv">1907.00503</pub-id></element-citation></ref><ref id="B18-sensors-25-05482"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pradhan</surname><given-names>P.K.</given-names></name><name name-style="western"><surname>Das</surname><given-names>A.</given-names></name><name name-style="western"><surname>Kumar</surname><given-names>A.</given-names></name><name name-style="western"><surname>Baruah</surname><given-names>U.</given-names></name><name name-style="western"><surname>Sen</surname><given-names>B.</given-names></name><name name-style="western"><surname>Ghosal</surname><given-names>P.</given-names></name></person-group><article-title>SwinSight: A hierarchical vision transformer using shifted windows to leverage aerial image classification</article-title><source>Multim. Tools Appl.</source><year>2024</year><volume>83</volume><fpage>86457</fpage><lpage>86478</lpage><pub-id pub-id-type="doi">10.1007/s11042-024-19615-9</pub-id></element-citation></ref><ref id="B19-sensors-25-05482"><label>19.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Sun</surname><given-names>J.</given-names></name></person-group><article-title>PromptEHR: Conditional Electronic Healthcare Records Generation with Prompt Learning</article-title><source>Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022</source><conf-loc>Abu Dhabi, United Arab Emirates</conf-loc><conf-date>7&#8211;11 December 2022</conf-date><person-group person-group-type="editor"><name name-style="western"><surname>Goldberg</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Kozareva</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>Y.</given-names></name></person-group><publisher-name>Association for Computational Linguistics</publisher-name><publisher-loc>Stroudsburg, PA, USA</publisher-loc><year>2022</year><fpage>2873</fpage><lpage>2885</lpage><pub-id pub-id-type="doi">10.18653/V1/2022.EMNLP-MAIN.185</pub-id><pub-id pub-id-type="pmcid">PMC11824924</pub-id><pub-id pub-id-type="pmid">39949499</pub-id></element-citation></ref><ref id="B20-sensors-25-05482"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Yan</surname><given-names>C.</given-names></name><name name-style="western"><surname>Lasko</surname><given-names>T.A.</given-names></name><name name-style="western"><surname>Sun</surname><given-names>J.</given-names></name><name name-style="western"><surname>Malin</surname><given-names>B.A.</given-names></name></person-group><article-title>SynTEG: A framework for temporal structured electronic health data simulation</article-title><source>J. Am. Med. Inform. Assoc.</source><year>2021</year><volume>28</volume><fpage>596</fpage><lpage>604</lpage><pub-id pub-id-type="doi">10.1093/jamia/ocaa262</pub-id><pub-id pub-id-type="pmid">33277896</pub-id><pub-id pub-id-type="pmcid">PMC7936402</pub-id></element-citation></ref><ref id="B21-sensors-25-05482"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Baowaly</surname><given-names>M.K.</given-names></name><name name-style="western"><surname>Lin</surname><given-names>C.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>C.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>K.</given-names></name></person-group><article-title>Synthesizing electronic health records using improved generative adversarial networks</article-title><source>J. Am. Med. Inform. Assoc.</source><year>2019</year><volume>26</volume><fpage>228</fpage><lpage>241</lpage><pub-id pub-id-type="doi">10.1093/jamia/ocy142</pub-id><pub-id pub-id-type="pmid">30535151</pub-id><pub-id pub-id-type="pmcid">PMC7647178</pub-id></element-citation></ref><ref id="B22-sensors-25-05482"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lu</surname><given-names>C.</given-names></name><name name-style="western"><surname>Reddy</surname><given-names>C.K.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>P.</given-names></name><name name-style="western"><surname>Nie</surname><given-names>D.</given-names></name><name name-style="western"><surname>Ning</surname><given-names>Y.</given-names></name></person-group><article-title>Multi-Label Clinical Time-Series Generation via Conditional GAN</article-title><source>IEEE Trans. Knowl. Data Eng.</source><year>2024</year><volume>36</volume><fpage>1728</fpage><lpage>1740</lpage><pub-id pub-id-type="doi">10.1109/TKDE.2023.3310909</pub-id></element-citation></ref><ref id="B23-sensors-25-05482"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nikolentzos</surname><given-names>G.</given-names></name><name name-style="western"><surname>Vazirgiannis</surname><given-names>M.</given-names></name><name name-style="western"><surname>Xypolopoulos</surname><given-names>C.</given-names></name><name name-style="western"><surname>Lingman</surname><given-names>M.</given-names></name><name name-style="western"><surname>Brandt</surname><given-names>E.G.</given-names></name></person-group><article-title>Synthetic electronic health records generated with variational graph autoencoders</article-title><source>Npj Digit. Med.</source><year>2023</year><volume>6</volume><fpage>83</fpage><pub-id pub-id-type="doi">10.1038/s41746-023-00822-x</pub-id><pub-id pub-id-type="pmid">37120594</pub-id><pub-id pub-id-type="pmcid">PMC10148837</pub-id></element-citation></ref><ref id="B24-sensors-25-05482"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pang</surname><given-names>C.</given-names></name><name name-style="western"><surname>Jiang</surname><given-names>X.</given-names></name><name name-style="western"><surname>Pavinkurve</surname><given-names>N.P.</given-names></name><name name-style="western"><surname>Kalluri</surname><given-names>K.S.</given-names></name><name name-style="western"><surname>Minto</surname><given-names>E.L.</given-names></name><name name-style="western"><surname>Patterson</surname><given-names>J.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>L.</given-names></name><name name-style="western"><surname>Hripcsak</surname><given-names>G.</given-names></name><name name-style="western"><surname>Elhadad</surname><given-names>N.</given-names></name><name name-style="western"><surname>Natarajan</surname><given-names>K.</given-names></name></person-group><article-title>CEHR-GPT: Generating Electronic Health Records with Chronological Patient Timelines</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type="doi">10.48550/arXiv.2402.04400</pub-id><pub-id pub-id-type="arxiv">2402.04400</pub-id></element-citation></ref><ref id="B25-sensors-25-05482"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Esteban</surname><given-names>C.</given-names></name><name name-style="western"><surname>Hyland</surname><given-names>S.L.</given-names></name><name name-style="western"><surname>R&#228;tsch</surname><given-names>G.</given-names></name></person-group><article-title>Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs</article-title><source>arXiv</source><year>2017</year><pub-id pub-id-type="doi">10.48550/arXiv.1706.02633</pub-id><pub-id pub-id-type="arxiv">1706.02633</pub-id></element-citation></ref><ref id="B26-sensors-25-05482"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Karami</surname><given-names>H.</given-names></name><name name-style="western"><surname>Hartley</surname><given-names>M.</given-names></name><name name-style="western"><surname>Atienza</surname><given-names>D.</given-names></name><name name-style="western"><surname>Ionescu</surname><given-names>A.</given-names></name></person-group><article-title>TimEHR: Image-based Time Series Generation for Electronic Health Records</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type="arxiv">2402.06318</pub-id><pub-id pub-id-type="doi">10.1109/JBHI.2025.3577328</pub-id><pub-id pub-id-type="pmid">40478706</pub-id></element-citation></ref><ref id="B27-sensors-25-05482"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yoon</surname><given-names>J.</given-names></name><name name-style="western"><surname>Mizrahi</surname><given-names>M.J.</given-names></name><name name-style="western"><surname>Ghalaty</surname><given-names>N.F.</given-names></name><name name-style="western"><surname>Jarvinen</surname><given-names>T.</given-names></name><name name-style="western"><surname>Ravi</surname><given-names>A.S.</given-names></name><name name-style="western"><surname>Brune</surname><given-names>P.</given-names></name><name name-style="western"><surname>Kong</surname><given-names>F.</given-names></name><name name-style="western"><surname>Anderson</surname><given-names>D.</given-names></name><name name-style="western"><surname>Lee</surname><given-names>G.</given-names></name><name name-style="western"><surname>Meir</surname><given-names>A.</given-names></name><etal/></person-group><article-title>EHR-Safe: Generating high-fidelity and privacy-preserving synthetic electronic health records</article-title><source>Npj Digit. Med.</source><year>2023</year><volume>6</volume><fpage>141</fpage><pub-id pub-id-type="doi">10.1038/s41746-023-00888-7</pub-id><pub-id pub-id-type="pmid">37567968</pub-id><pub-id pub-id-type="pmcid">PMC10421926</pub-id></element-citation></ref><ref id="B28-sensors-25-05482"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lee</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Chae</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Jung</surname><given-names>K.</given-names></name></person-group><article-title>Leveraging VQ-VAE tokenization for autoregressive modeling of medical time series</article-title><source>Artif. Intell. Med.</source><year>2024</year><volume>154</volume><fpage>102925</fpage><pub-id pub-id-type="doi">10.1016/j.artmed.2024.102925</pub-id><pub-id pub-id-type="pmid">38968921</pub-id></element-citation></ref><ref id="B29-sensors-25-05482"><label>29.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Zhou</surname><given-names>X.</given-names></name><name name-style="western"><surname>Jia</surname><given-names>Q.</given-names></name><name name-style="western"><surname>Hu</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Xie</surname><given-names>R.</given-names></name><name name-style="western"><surname>Huang</surname><given-names>T.</given-names></name><name name-style="western"><surname>Yu</surname><given-names>F.R.</given-names></name></person-group><article-title>GenG: An LLM-Based Generic Time Series Data Generation Approach for Edge Intelligence via Cross-Domain Collaboration</article-title><source>Proceedings of the IEEE INFOCOM 2024&#8212;IEEE Conference on Computer Communications Workshops</source><conf-loc>Vancouver, BC, Canada</conf-loc><conf-date>20 May 2024</conf-date><pub-id pub-id-type="doi">10.1109/INFOCOMWKSHPS61880.2024.10620716</pub-id></element-citation></ref><ref id="B30-sensors-25-05482"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Sheng</surname><given-names>M.</given-names></name><name name-style="western"><surname>Zhou</surname><given-names>R.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Han</surname><given-names>G.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>H.</given-names></name><name name-style="western"><surname>Xing</surname><given-names>C.</given-names></name><name name-style="western"><surname>Dong</surname><given-names>J.</given-names></name></person-group><article-title>HKGB: An inclusive, extensible, intelligent, semi-auto-constructed knowledge graph framework for healthcare with clinicians&#8217; expertise incorporated</article-title><source>Inf. Process. Manag.</source><year>2020</year><volume>57</volume><fpage>102324</fpage><pub-id pub-id-type="doi">10.1016/j.ipm.2020.102324</pub-id></element-citation></ref><ref id="B31-sensors-25-05482"><label>31.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Borisov</surname><given-names>V.</given-names></name><name name-style="western"><surname>Se&#223;ler</surname><given-names>K.</given-names></name><name name-style="western"><surname>Leemann</surname><given-names>T.</given-names></name><name name-style="western"><surname>Pawelczyk</surname><given-names>M.</given-names></name><name name-style="western"><surname>Kasneci</surname><given-names>G.</given-names></name></person-group><article-title>Language Models are Realistic Tabular Data Generators</article-title><source>Proceedings of the The Eleventh International Conference on Learning Representations, ICLR 2023</source><conf-loc>Kigali, Rwanda</conf-loc><conf-date>1&#8211;5 May 2023</conf-date></element-citation></ref><ref id="B32-sensors-25-05482"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hernandez</surname><given-names>M.</given-names></name><name name-style="western"><surname>Epelde</surname><given-names>G.</given-names></name><name name-style="western"><surname>Alberdi</surname><given-names>A.</given-names></name><name name-style="western"><surname>Cilla</surname><given-names>R.</given-names></name><name name-style="western"><surname>Rankin</surname><given-names>D.</given-names></name></person-group><article-title>Synthetic data generation for tabular health records: A systematic review</article-title><source>Neurocomputing</source><year>2022</year><volume>493</volume><fpage>28</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2022.04.053</pub-id></element-citation></ref><ref id="B33-sensors-25-05482"><label>33.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Viana</surname><given-names>D.</given-names></name><name name-style="western"><surname>Teixeira</surname><given-names>R.</given-names></name><name name-style="western"><surname>Baptista</surname><given-names>J.</given-names></name><name name-style="western"><surname>Pinto</surname><given-names>T.</given-names></name></person-group><article-title>Synthetic Data Generation Models for Time Series: A Literature Review</article-title><source>Proceedings of the International Conference on Electrical, Computer and Energy Technologies, ICECET 2024</source><conf-loc>Sydney, Australia</conf-loc><conf-date>25&#8211;27 July 2024</conf-date><pub-id pub-id-type="doi">10.1109/ICECET61485.2024.10698494</pub-id></element-citation></ref><ref id="B34-sensors-25-05482"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Inan</surname><given-names>M.S.K.</given-names></name><name name-style="western"><surname>Hossain</surname><given-names>S.</given-names></name><name name-style="western"><surname>Uddin</surname><given-names>M.N.</given-names></name></person-group><article-title>Data augmentation guided breast cancer diagnosis and prognosis using an integrated deep-generative framework based on breast tumor&#8217;s morphological information</article-title><source>Inform. Med. Unlocked</source><year>2023</year><volume>37</volume><fpage>101171</fpage><pub-id pub-id-type="doi">10.1016/j.imu.2023.101171</pub-id></element-citation></ref><ref id="B35-sensors-25-05482"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chu</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>J.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>Q.</given-names></name><name name-style="western"><surname>Yu</surname><given-names>W.</given-names></name><name name-style="western"><surname>He</surname><given-names>T.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>H.</given-names></name><name name-style="western"><surname>Peng</surname><given-names>W.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>M.</given-names></name><name name-style="western"><surname>Qin</surname><given-names>B.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>T.</given-names></name></person-group><article-title>Navigate through enigmatic labyrinth a survey of chain of thought reasoning: Advances, frontiers and future</article-title><source>arXiv</source><year>2023</year><pub-id pub-id-type="arxiv">2309.15402</pub-id></element-citation></ref><ref id="B36-sensors-25-05482"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lee</surname><given-names>J.</given-names></name><name name-style="western"><surname>Yoon</surname><given-names>W.</given-names></name><name name-style="western"><surname>Kim</surname><given-names>S.</given-names></name><name name-style="western"><surname>Kim</surname><given-names>D.</given-names></name><name name-style="western"><surname>Kim</surname><given-names>S.</given-names></name><name name-style="western"><surname>So</surname><given-names>C.H.</given-names></name><name name-style="western"><surname>Kang</surname><given-names>J.</given-names></name></person-group><article-title>BioBERT: A pre-trained biomedical language representation model for biomedical text mining</article-title><source>Bioinformatics</source><year>2020</year><volume>36</volume><fpage>1234</fpage><lpage>1240</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btz682</pub-id><pub-id pub-id-type="pmid">31501885</pub-id><pub-id pub-id-type="pmcid">PMC7703786</pub-id></element-citation></ref><ref id="B37-sensors-25-05482"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Peng</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Yan</surname><given-names>S.</given-names></name><name name-style="western"><surname>Lu</surname><given-names>Z.</given-names></name></person-group><article-title>Transfer learning in biomedical natural language processing: An evaluation of BERT and ELMo on ten benchmarking datasets</article-title><source>arXiv</source><year>2019</year><pub-id pub-id-type="doi">10.48550/arXiv.1906.05474</pub-id><pub-id pub-id-type="arxiv">1906.05474</pub-id></element-citation></ref><ref id="B38-sensors-25-05482"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wei</surname><given-names>J.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>X.</given-names></name><name name-style="western"><surname>Schuurmans</surname><given-names>D.</given-names></name><name name-style="western"><surname>Bosma</surname><given-names>M.</given-names></name><name name-style="western"><surname>Xia</surname><given-names>F.</given-names></name><name name-style="western"><surname>Chi</surname><given-names>E.</given-names></name><name name-style="western"><surname>Le</surname><given-names>Q.V.</given-names></name><name name-style="western"><surname>Zhou</surname><given-names>D.</given-names></name></person-group><article-title>Chain-of-thought prompting elicits reasoning in large language models</article-title><source>Adv. Neural Inf. Process. Syst.</source><year>2022</year><volume>35</volume><fpage>24824</fpage><lpage>24837</lpage></element-citation></ref><ref id="B39-sensors-25-05482"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lin</surname><given-names>B.Y.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>X.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>J.</given-names></name><name name-style="western"><surname>Ren</surname><given-names>X.</given-names></name></person-group><article-title>Kagnet: Knowledge-aware graph networks for commonsense reasoning</article-title><source>arXiv</source><year>2019</year><pub-id pub-id-type="arxiv">1909.02151</pub-id></element-citation></ref><ref id="B40-sensors-25-05482"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Soman</surname><given-names>K.</given-names></name><name name-style="western"><surname>Rose</surname><given-names>P.W.</given-names></name><name name-style="western"><surname>Morris</surname><given-names>J.H.</given-names></name><name name-style="western"><surname>Akbas</surname><given-names>R.E.</given-names></name><name name-style="western"><surname>Smith</surname><given-names>B.</given-names></name><name name-style="western"><surname>Peetoom</surname><given-names>B.</given-names></name><name name-style="western"><surname>Villouta-Reyes</surname><given-names>C.</given-names></name><name name-style="western"><surname>Cerono</surname><given-names>G.</given-names></name><name name-style="western"><surname>Shi</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Rizk-Jackson</surname><given-names>A.</given-names></name><etal/></person-group><article-title>Biomedical knowledge graph-optimized prompt generation for large language models</article-title><source>Bioinformatics</source><year>2024</year><volume>40</volume><elocation-id>btae560</elocation-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btae560</pub-id><pub-id pub-id-type="pmid">39288310</pub-id><pub-id pub-id-type="pmcid">PMC11441322</pub-id></element-citation></ref><ref id="B41-sensors-25-05482"><label>41.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Zhao</surname><given-names>R.</given-names></name><name name-style="western"><surname>Zhao</surname><given-names>F.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>L.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>X.</given-names></name><name name-style="western"><surname>Xu</surname><given-names>G.</given-names></name></person-group><article-title>Kg-cot: Chain-of-thought prompting of large language models over knowledge graphs for knowledge-aware question answering</article-title><source>Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence (IJCAI-24)</source><conf-loc>Jeju, Republic of Korea</conf-loc><conf-date>3&#8211;9 August 2024</conf-date><fpage>6642</fpage><lpage>6650</lpage></element-citation></ref><ref id="B42-sensors-25-05482"><label>42.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Matsumoto</surname><given-names>N.</given-names></name><name name-style="western"><surname>Moran</surname><given-names>J.</given-names></name><name name-style="western"><surname>Choi</surname><given-names>H.</given-names></name><name name-style="western"><surname>Hernandez</surname><given-names>M.E.</given-names></name><name name-style="western"><surname>Venkatesan</surname><given-names>M.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>P.</given-names></name><name name-style="western"><surname>Moore</surname><given-names>J.H.</given-names></name></person-group><article-title>KRAGEN: A knowledge graph-enhanced RAG framework for biomedical problem solving using large language models</article-title><source>Bioinformatics</source><year>2024</year><volume>40</volume><elocation-id>btae353</elocation-id><pub-id pub-id-type="doi">10.1093/bioinformatics/btae353</pub-id><pub-id pub-id-type="pmid">38830083</pub-id><pub-id pub-id-type="pmcid">PMC11164829</pub-id></element-citation></ref><ref id="B43-sensors-25-05482"><label>43.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Shao</surname><given-names>S.</given-names></name><name name-style="western"><surname>Lin</surname><given-names>S.</given-names></name><name name-style="western"><surname>Huang</surname><given-names>Z.</given-names></name></person-group><article-title>A Medical Consultation System for Geriatric Disease Based on Multi-agent Architecture and Knowledge Graph</article-title><source>Proceedings of the Health Information Science-13th International Conference, HIS 2024, Hong Kong, China, 8&#8211;10 December 2024</source><comment>Proceedings</comment><person-group person-group-type="editor"><name name-style="western"><surname>Siuly</surname><given-names>S.</given-names></name><name name-style="western"><surname>Xing</surname><given-names>C.</given-names></name><name name-style="western"><surname>Li</surname><given-names>X.</given-names></name><name name-style="western"><surname>Zhou</surname><given-names>R.</given-names></name></person-group><series>Lecture Notes in Computer Science</series><publisher-name>Springer</publisher-name><publisher-loc>Singapore</publisher-loc><year>2024</year><volume>Volume 15336</volume><fpage>313</fpage><lpage>325</lpage><pub-id pub-id-type="doi">10.1007/978-981-96-5597-7_28</pub-id></element-citation></ref><ref id="B44-sensors-25-05482"><label>44.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rae</surname><given-names>J.W.</given-names></name><name name-style="western"><surname>Borgeaud</surname><given-names>S.</given-names></name><name name-style="western"><surname>Cai</surname><given-names>T.</given-names></name><name name-style="western"><surname>Millican</surname><given-names>K.</given-names></name><name name-style="western"><surname>Hoffmann</surname><given-names>J.</given-names></name><name name-style="western"><surname>Song</surname><given-names>F.</given-names></name><name name-style="western"><surname>Aslanides</surname><given-names>J.</given-names></name><name name-style="western"><surname>Henderson</surname><given-names>S.</given-names></name><name name-style="western"><surname>Ring</surname><given-names>R.</given-names></name><name name-style="western"><surname>Young</surname><given-names>S.</given-names></name><etal/></person-group><article-title>Scaling language models: Methods, analysis &amp; insights from training gopher</article-title><source>arXiv</source><year>2021</year><pub-id pub-id-type="arxiv">2112.11446</pub-id></element-citation></ref><ref id="B45-sensors-25-05482"><label>45.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ma</surname><given-names>K.</given-names></name><name name-style="western"><surname>Cheng</surname><given-names>H.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>X.</given-names></name><name name-style="western"><surname>Nyberg</surname><given-names>E.</given-names></name><name name-style="western"><surname>Gao</surname><given-names>J.</given-names></name></person-group><article-title>Open-domain question answering via chain of reasoning over heterogeneous knowledge</article-title><source>arXiv</source><year>2022</year><pub-id pub-id-type="doi">10.48550/arXiv.2210.12338</pub-id><pub-id pub-id-type="arxiv">2210.12338</pub-id></element-citation></ref><ref id="B46-sensors-25-05482"><label>46.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Xia</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>R.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>X.</given-names></name><name name-style="western"><surname>Li</surname><given-names>M.</given-names></name><name name-style="western"><surname>Yu</surname><given-names>T.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>X.</given-names></name><name name-style="western"><surname>McAuley</surname><given-names>J.</given-names></name><name name-style="western"><surname>Li</surname><given-names>S.</given-names></name></person-group><article-title>Beyond chain-of-thought: A survey of chain-of-x paradigms for llms</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type="arxiv">2404.15676</pub-id></element-citation></ref><ref id="B47-sensors-25-05482"><label>47.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lewis</surname><given-names>P.</given-names></name><name name-style="western"><surname>Perez</surname><given-names>E.</given-names></name><name name-style="western"><surname>Piktus</surname><given-names>A.</given-names></name><name name-style="western"><surname>Petroni</surname><given-names>F.</given-names></name><name name-style="western"><surname>Karpukhin</surname><given-names>V.</given-names></name><name name-style="western"><surname>Goyal</surname><given-names>N.</given-names></name><name name-style="western"><surname>K&#252;ttler</surname><given-names>H.</given-names></name><name name-style="western"><surname>Lewis</surname><given-names>M.</given-names></name><name name-style="western"><surname>Yih</surname><given-names>W.t.</given-names></name><name name-style="western"><surname>Rockt&#228;schel</surname><given-names>T.</given-names></name><etal/></person-group><article-title>Retrieval-augmented generation for knowledge-intensive nlp tasks</article-title><source>Adv. Neural Inf. Process. Syst.</source><year>2020</year><volume>33</volume><fpage>9459</fpage><lpage>9474</lpage></element-citation></ref><ref id="B48-sensors-25-05482"><label>48.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Zhao</surname><given-names>X.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>S.</given-names></name><name name-style="western"><surname>Yang</surname><given-names>S.Y.</given-names></name><name name-style="western"><surname>Miao</surname><given-names>C.</given-names></name></person-group><article-title>Medrag: Enhancing retrieval-augmented generation with knowledge graph-elicited reasoning for healthcare copilot</article-title><source>Proceedings of the Proceedings of the ACM on Web Conference 2025</source><conf-loc>Sydney, Australia</conf-loc><conf-date>28 April&#8211;2 May 2025</conf-date><fpage>4442</fpage><lpage>4457</lpage></element-citation></ref><ref id="B49-sensors-25-05482"><label>49.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jiang</surname><given-names>J.</given-names></name><name name-style="western"><surname>Zhou</surname><given-names>K.</given-names></name><name name-style="western"><surname>Zhao</surname><given-names>W.X.</given-names></name><name name-style="western"><surname>Li</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Wen</surname><given-names>J.R.</given-names></name></person-group><article-title>ReasoningLM: Enabling structural subgraph reasoning in pre-trained language models for question answering over knowledge graph</article-title><source>arXiv</source><year>2023</year><pub-id pub-id-type="arxiv">2401.00158</pub-id></element-citation></ref><ref id="B50-sensors-25-05482"><label>50.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kang</surname><given-names>M.</given-names></name><name name-style="western"><surname>Kwak</surname><given-names>J.M.</given-names></name><name name-style="western"><surname>Baek</surname><given-names>J.</given-names></name><name name-style="western"><surname>Hwang</surname><given-names>S.J.</given-names></name></person-group><article-title>Knowledge graph-augmented language models for knowledge-grounded dialogue generation</article-title><source>arXiv</source><year>2023</year><pub-id pub-id-type="arxiv">2305.18846</pub-id></element-citation></ref><ref id="B51-sensors-25-05482"><label>51.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Reimers</surname><given-names>N.</given-names></name><name name-style="western"><surname>Gurevych</surname><given-names>I.</given-names></name></person-group><article-title>Sentence-bert: Sentence embeddings using siamese bert-networks</article-title><source>arXiv</source><year>2019</year><pub-id pub-id-type="doi">10.48550/arXiv.1908.10084</pub-id><pub-id pub-id-type="arxiv">1908.10084</pub-id></element-citation></ref><ref id="B52-sensors-25-05482"><label>52.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Luo</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Sheng</surname><given-names>M.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>X.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>K.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Zhao</surname><given-names>H.</given-names></name></person-group><article-title>Ltgan: Multi-label time-series gan with constraints for electronic health records generation</article-title><source>Proceedings of the International Conference on Health Information Science</source><conf-loc>Hong Kong, China</conf-loc><conf-date>8&#8211;10 December 2024</conf-date><publisher-name>Springer</publisher-name><publisher-loc>Singapore</publisher-loc><year>2025</year><fpage>36</fpage><lpage>47</lpage></element-citation></ref><ref id="B53-sensors-25-05482"><label>53.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kim</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Xu</surname><given-names>X.</given-names></name><name name-style="western"><surname>McDuff</surname><given-names>D.</given-names></name><name name-style="western"><surname>Breazeal</surname><given-names>C.</given-names></name><name name-style="western"><surname>Park</surname><given-names>H.W.</given-names></name></person-group><article-title>Health-llm: Large language models for health prediction via wearable sensor data</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type="doi">10.48550/arXiv.2401.06866</pub-id><pub-id pub-id-type="arxiv">2401.06866</pub-id></element-citation></ref><ref id="B54-sensors-25-05482"><label>54.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jin</surname><given-names>M.</given-names></name><name name-style="western"><surname>Yu</surname><given-names>Q.</given-names></name><name name-style="western"><surname>Shu</surname><given-names>D.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>C.</given-names></name><name name-style="western"><surname>Fan</surname><given-names>L.</given-names></name><name name-style="western"><surname>Hua</surname><given-names>W.</given-names></name><name name-style="western"><surname>Zhu</surname><given-names>S.</given-names></name><name name-style="western"><surname>Meng</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Du</surname><given-names>M.</given-names></name><etal/></person-group><article-title>Health-LLM: Personalized retrieval-augmented disease prediction system</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type="arxiv">2402.00746</pub-id></element-citation></ref><ref id="B55-sensors-25-05482"><label>55.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Harutyunyan</surname><given-names>H.</given-names></name><name name-style="western"><surname>Khachatrian</surname><given-names>H.</given-names></name><name name-style="western"><surname>Kale</surname><given-names>D.C.</given-names></name><name name-style="western"><surname>Ver Steeg</surname><given-names>G.</given-names></name><name name-style="western"><surname>Galstyan</surname><given-names>A.</given-names></name></person-group><article-title>Multitask learning and benchmarking with clinical time series data</article-title><source>Sci. Data</source><year>2019</year><volume>6</volume><fpage>96</fpage><pub-id pub-id-type="doi">10.1038/s41597-019-0103-9</pub-id><pub-id pub-id-type="pmid">31209213</pub-id><pub-id pub-id-type="pmcid">PMC6572845</pub-id></element-citation></ref><ref id="B56-sensors-25-05482"><label>56.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Hao</surname><given-names>R.</given-names></name><name name-style="western"><surname>Sheng</surname><given-names>M.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Zhao</surname><given-names>H.</given-names></name><name name-style="western"><surname>Hao</surname><given-names>C.</given-names></name><name name-style="western"><surname>Li</surname><given-names>W.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>L.</given-names></name><name name-style="western"><surname>Li</surname><given-names>C.</given-names></name></person-group><article-title>Enhancing clustering performance in sepsis time series data using gravity field</article-title><source>Proceedings of the International Conference on Health Information Science</source><conf-loc>Melbourne, Australia</conf-loc><conf-date>23&#8211;24 October 2023</conf-date><publisher-name>Springer</publisher-name><publisher-loc>Singapore</publisher-loc><year>2023</year><fpage>199</fpage><lpage>212</lpage></element-citation></ref><ref id="B57-sensors-25-05482"><label>57.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Zhao</surname><given-names>H.</given-names></name><name name-style="western"><surname>Ren</surname><given-names>P.</given-names></name><name name-style="western"><surname>Zhou</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Sheng</surname><given-names>M.</given-names></name></person-group><article-title>Learning optimal treatment strategies for sepsis using offline reinforcement learning in continuous space</article-title><source>Proceedings of the International Conference on Health Information Science</source><conf-loc>Virtual</conf-loc><conf-date>28&#8211;30 October 2022</conf-date><publisher-name>Springer</publisher-name><publisher-loc>Cham, Switzerland</publisher-loc><year>2022</year><fpage>113</fpage><lpage>124</lpage></element-citation></ref><ref id="B58-sensors-25-05482"><label>58.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Le</surname><given-names>S.</given-names></name><name name-style="western"><surname>Pellegrini</surname><given-names>E.</given-names></name><name name-style="western"><surname>Green-Saxena</surname><given-names>A.</given-names></name><name name-style="western"><surname>Summers</surname><given-names>C.</given-names></name><name name-style="western"><surname>Hoffman</surname><given-names>J.</given-names></name><name name-style="western"><surname>Calvert</surname><given-names>J.</given-names></name><name name-style="western"><surname>Das</surname><given-names>R.</given-names></name></person-group><article-title>Supervised machine learning for the early prediction of acute respiratory distress syndrome (ARDS)</article-title><source>J. Crit. Care</source><year>2020</year><volume>60</volume><fpage>96</fpage><lpage>102</lpage><pub-id pub-id-type="doi">10.1016/j.jcrc.2020.07.019</pub-id><pub-id pub-id-type="pmid">32777759</pub-id></element-citation></ref><ref id="B59-sensors-25-05482"><label>59.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zheng</surname><given-names>H.</given-names></name><name name-style="western"><surname>Zhu</surname><given-names>J.</given-names></name><name name-style="western"><surname>Xie</surname><given-names>W.</given-names></name><name name-style="western"><surname>Zhong</surname><given-names>J.</given-names></name></person-group><article-title>Reinforcement learning assisted oxygen therapy for COVID-19 patients under intensive care</article-title><source>BMC Med. Inform. Decis. Mak.</source><year>2021</year><volume>21</volume><elocation-id>350</elocation-id><pub-id pub-id-type="doi">10.1186/s12911-021-01712-6</pub-id><pub-id pub-id-type="pmid">34920724</pub-id><pub-id pub-id-type="pmcid">PMC8678583</pub-id></element-citation></ref><ref id="B60-sensors-25-05482"><label>60.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Touvron</surname><given-names>H.</given-names></name><name name-style="western"><surname>Martin</surname><given-names>L.</given-names></name><name name-style="western"><surname>Stone</surname><given-names>K.</given-names></name><name name-style="western"><surname>Albert</surname><given-names>P.</given-names></name><name name-style="western"><surname>Almahairi</surname><given-names>A.</given-names></name><name name-style="western"><surname>Babaei</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Bashlykov</surname><given-names>N.</given-names></name><name name-style="western"><surname>Batra</surname><given-names>S.</given-names></name><name name-style="western"><surname>Bhargava</surname><given-names>P.</given-names></name><name name-style="western"><surname>Bhosale</surname><given-names>S.</given-names></name><etal/></person-group><article-title>Llama 2: Open foundation and fine-tuned chat models</article-title><source>arXiv</source><year>2023</year><pub-id pub-id-type="doi">10.48550/arXiv.2307.09288</pub-id><pub-id pub-id-type="arxiv">2307.09288</pub-id></element-citation></ref><ref id="B61-sensors-25-05482"><label>61.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Team</surname><given-names>G.</given-names></name><name name-style="western"><surname>Georgiev</surname><given-names>P.</given-names></name><name name-style="western"><surname>Lei</surname><given-names>V.I.</given-names></name><name name-style="western"><surname>Burnell</surname><given-names>R.</given-names></name><name name-style="western"><surname>Bai</surname><given-names>L.</given-names></name><name name-style="western"><surname>Gulati</surname><given-names>A.</given-names></name><name name-style="western"><surname>Tanzer</surname><given-names>G.</given-names></name><name name-style="western"><surname>Vincent</surname><given-names>D.</given-names></name><name name-style="western"><surname>Pan</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>S.</given-names></name><etal/></person-group><article-title>Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type="doi">10.48550/arXiv.2403.05530</pub-id><pub-id pub-id-type="arxiv">2403.05530</pub-id></element-citation></ref><ref id="B62-sensors-25-05482"><label>62.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Brown</surname><given-names>T.</given-names></name><name name-style="western"><surname>Mann</surname><given-names>B.</given-names></name><name name-style="western"><surname>Ryder</surname><given-names>N.</given-names></name><name name-style="western"><surname>Subbiah</surname><given-names>M.</given-names></name><name name-style="western"><surname>Kaplan</surname><given-names>J.D.</given-names></name><name name-style="western"><surname>Dhariwal</surname><given-names>P.</given-names></name><name name-style="western"><surname>Neelakantan</surname><given-names>A.</given-names></name><name name-style="western"><surname>Shyam</surname><given-names>P.</given-names></name><name name-style="western"><surname>Sastry</surname><given-names>G.</given-names></name><name name-style="western"><surname>Askell</surname><given-names>A.</given-names></name><etal/></person-group><article-title>Language models are few-shot learners</article-title><source>Adv. Neural Inf. Process. Syst.</source><year>2020</year><volume>33</volume><fpage>1877</fpage><lpage>1901</lpage></element-citation></ref><ref id="B63-sensors-25-05482"><label>63.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hao</surname><given-names>C.</given-names></name><name name-style="western"><surname>Hao</surname><given-names>R.</given-names></name><name name-style="western"><surname>Zhao</surname><given-names>H.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Sheng</surname><given-names>M.</given-names></name><name name-style="western"><surname>An</surname><given-names>Y.</given-names></name></person-group><article-title>Identification and validation of sepsis subphenotypes using time-series data</article-title><source>Heliyon</source><year>2024</year><volume>10</volume><fpage>e28520</fpage><pub-id pub-id-type="doi">10.1016/j.heliyon.2024.e28520</pub-id><pub-id pub-id-type="pmid">38689952</pub-id><pub-id pub-id-type="pmcid">PMC11059505</pub-id></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-05482-f001" orientation="portrait"><label>Figure 1</label><caption><p>The framework of QAMT, where the blue rounded rectangles represent data, red rectangles represent generative models, green rectangles represent medical time-series data quality assurance models, and yellow rectangles represent the health knowledge graphs. The parts marked with icons indicate the use of LLMs.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05482-g001.jpg"/></fig><fig position="float" id="sensors-25-05482-f002" orientation="portrait"><label>Figure 2</label><caption><p>The detailed workflow of the HKGB to construct an HKG.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05482-g002.jpg"/></fig><fig position="float" id="sensors-25-05482-f003" orientation="portrait"><label>Figure 3</label><caption><p>HKG-RAG workflow. The demographic information is randomly generated. An LLM is then used to assess its validity to avoid logically inconsistent cases, such as an age of &#8220;6&#8221; with a marital status of &#8220;MARRIED&#8221;. Only demographic data that pass this logical check are used as input for generating complete static event data.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05482-g003.jpg"/></fig><fig position="float" id="sensors-25-05482-f004" orientation="portrait"><label>Figure 4</label><caption><p>HKG-CoT workflow. It presents an example of how the HKG-CoT is used for static event data quality assurance. The solid lines indicate that the first event in the generated data is extracted and inserted into a customized prompt, which is then submitted to the LLM for reasoning. The HKG-CoT generates a response Type 2 Diabetes Mellitus, Diabetes Insipidus, Primary Polydipsia for the question. Since Type 2 Diabetes Mellitus matches the second event in the data sequence, showing as a check mark, the first event passes the validation, and the process continues by questioning the next event, and so on. If all events pass this validation, the entire dataset is considered trustworthy. In contrast, as shown by the dashed lines, if the LLM&#8217;s response does not match the event, showing as a cross mark, and does not contain the next event, the event sequence is deemed invalid and discarded.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05482-g004.jpg"/></fig><fig position="float" id="sensors-25-05482-f005" orientation="portrait"><label>Figure 5</label><caption><p>Interpretable prompt example, where (c), (d), (g) and (h) corresponds to the step introduced in <xref rid="sec3-sensors-25-05482" ref-type="sec">Section 3</xref>.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05482-g005.jpg"/></fig><fig position="float" id="sensors-25-05482-f006" orientation="portrait"><label>Figure 6</label><caption><p>Fidelity metrics for medical time-series data in ablation experiments. Static event data results are on the left, and temporal data results are on the right.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05482-g006.jpg"/></fig><fig position="float" id="sensors-25-05482-f007" orientation="portrait"><label>Figure 7</label><caption><p>Utility metrics for medical time-series data in ablation experiments. Each point in the line chart represents the difference between <inline-formula><mml:math id="mm99" overflow="scroll"><mml:mrow><mml:msub><mml:mi>QAMT</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and the real data.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05482-g007.jpg"/></fig><table-wrap position="float" id="sensors-25-05482-t001" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05482-t001_Table 1</object-id><label>Table 1</label><caption><p>Comparison of medical time-series data generation methods.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Method</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Type</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Domain</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">JointGeneration</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">QualityAssurance <sup>1</sup></th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Interpretability</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">SynTEG [<xref rid="B20-sensors-25-05482" ref-type="bibr">20</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">GAN-based</td><td align="center" valign="middle" rowspan="1" colspan="1">Medical</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td><td align="center" valign="middle" rowspan="1" colspan="1">-</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">BGAN [<xref rid="B21-sensors-25-05482" ref-type="bibr">21</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">GAN-based</td><td align="center" valign="middle" rowspan="1" colspan="1">Medical</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td><td align="center" valign="middle" rowspan="1" colspan="1">-</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">MTGAN [<xref rid="B22-sensors-25-05482" ref-type="bibr">22</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">GAN-based</td><td align="center" valign="middle" rowspan="1" colspan="1">Medical</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td><td align="center" valign="middle" rowspan="1" colspan="1">-</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">VGAE [<xref rid="B23-sensors-25-05482" ref-type="bibr">23</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">VAE-based</td><td align="center" valign="middle" rowspan="1" colspan="1">Medical</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td><td align="center" valign="middle" rowspan="1" colspan="1">-</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">PromptEHR [<xref rid="B19-sensors-25-05482" ref-type="bibr">19</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">LLM-based</td><td align="center" valign="middle" rowspan="1" colspan="1">Medical</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td><td align="center" valign="middle" rowspan="1" colspan="1">CC, VD</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">CEHR-GPT [<xref rid="B24-sensors-25-05482" ref-type="bibr">24</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">LLM-based</td><td align="center" valign="middle" rowspan="1" colspan="1">Medical</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td><td align="center" valign="middle" rowspan="1" colspan="1">CC</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">RTSGAN [<xref rid="B25-sensors-25-05482" ref-type="bibr">25</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">GAN-based</td><td align="center" valign="middle" rowspan="1" colspan="1">Medical</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td><td align="center" valign="middle" rowspan="1" colspan="1">-</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">TimEHR [<xref rid="B26-sensors-25-05482" ref-type="bibr">26</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">GAN-based</td><td align="center" valign="middle" rowspan="1" colspan="1">Medical</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td><td align="center" valign="middle" rowspan="1" colspan="1">-</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">EHR-Safe [<xref rid="B27-sensors-25-05482" ref-type="bibr">27</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">GAN-based</td><td align="center" valign="middle" rowspan="1" colspan="1">Medical</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td><td align="center" valign="middle" rowspan="1" colspan="1">-</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">CodeAR [<xref rid="B28-sensors-25-05482" ref-type="bibr">28</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">VAE-based</td><td align="center" valign="middle" rowspan="1" colspan="1">Medical</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td><td align="center" valign="middle" rowspan="1" colspan="1">-</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">GenG [<xref rid="B29-sensors-25-05482" ref-type="bibr">29</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">LLM-based</td><td align="center" valign="middle" rowspan="1" colspan="1">Energy</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td><td align="center" valign="middle" rowspan="1" colspan="1">-</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">HGAN [<xref rid="B16-sensors-25-05482" ref-type="bibr">16</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">GAN-based</td><td align="center" valign="middle" rowspan="1" colspan="1">Medical</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10003;</td><td align="center" valign="middle" rowspan="1" colspan="1">CC, VD</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">HALO [<xref rid="B9-sensors-25-05482" ref-type="bibr">9</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">LLM-based</td><td align="center" valign="middle" rowspan="1" colspan="1">Medical</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10003;</td><td align="center" valign="middle" rowspan="1" colspan="1">CC</td><td align="center" valign="middle" rowspan="1" colspan="1">&#10007;</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SynEHRgy [<xref rid="B10-sensors-25-05482" ref-type="bibr">10</xref>]</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">LLM-based</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Medical</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#10003;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#10007;</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">QAMT (ours)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">LLM-based</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">medical</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#10003;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">CC, VD</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#10003;</td></tr></tbody></table><table-wrap-foot><fn><p><sup>1</sup> &#8220;CC&#8221; refers to clinical constraints, and &#8220;VD&#8221; refers to variable dependencies. &#8220;&#10003;&#8221; indicates that the method has solved the corresponding challenge, while &#8220;&#10007;&#8221; indicates that it has not been solved.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-05482-t002" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05482-t002_Table 2</object-id><label>Table 2</label><caption><p>Examples of edge relationships in the HKG.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Relation</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Source Node <sup>1,2</sup></th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Target Node <sup>1,2</sup></th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Example</th></tr></thead><tbody><tr><td colspan="4" align="left" valign="middle" style="border-bottom:solid thin" rowspan="1">Concept &#8594; Concept</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">_has_symptom_</td><td align="left" valign="middle" rowspan="1" colspan="1">Dis</td><td align="left" valign="middle" rowspan="1" colspan="1">Sym</td><td align="left" valign="middle" rowspan="1" colspan="1">COPD -_has_symptom_&#8594; fever</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">_is_treated_by_</td><td align="left" valign="middle" rowspan="1" colspan="1">Dis/Sym</td><td align="left" valign="middle" rowspan="1" colspan="1">Med/Tre</td><td align="left" valign="middle" rowspan="1" colspan="1">COPD -_is_treated_by_&#8594; <inline-formula><mml:math id="mm100" overflow="scroll"><mml:mrow><mml:mi>&#946;</mml:mi></mml:mrow></mml:math></inline-formula>-agonist</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">_indicated_by_</td><td align="left" valign="middle" rowspan="1" colspan="1">Dis</td><td align="left" valign="middle" rowspan="1" colspan="1">CI</td><td align="left" valign="middle" rowspan="1" colspan="1">Diabetes -_indicated_by_&#8594; HbA1c</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">_progresses_to_</td><td align="left" valign="middle" rowspan="1" colspan="1">Dis</td><td align="left" valign="middle" rowspan="1" colspan="1">Dis</td><td align="left" valign="middle" rowspan="1" colspan="1">Prediabetes -_progresses_to_&#8594; Type 2&#160;Diabetes</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">_treated_</td><td align="left" valign="middle" rowspan="1" colspan="1">Med/Tre</td><td align="left" valign="middle" rowspan="1" colspan="1">Dis/Sym</td><td align="left" valign="middle" rowspan="1" colspan="1"><inline-formula><mml:math id="mm101" overflow="scroll"><mml:mrow><mml:mi>&#946;</mml:mi></mml:mrow></mml:math></inline-formula>-agonist -_treated_&#8594; COPD</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">_cause_</td><td align="left" valign="middle" rowspan="1" colspan="1">Sym</td><td align="left" valign="middle" rowspan="1" colspan="1">Dis</td><td align="left" valign="middle" rowspan="1" colspan="1">fever -_cause_&#8594; COPD</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">_measured_</td><td align="left" valign="middle" rowspan="1" colspan="1">CI</td><td align="left" valign="middle" rowspan="1" colspan="1">Dis</td><td align="left" valign="middle" rowspan="1" colspan="1">PaO<sub>2</sub> -_measured_&#8594; COPD</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">_constraints_</td><td align="left" valign="middle" rowspan="1" colspan="1">CI</td><td align="left" valign="middle" rowspan="1" colspan="1">CC</td><td align="left" valign="middle" rowspan="1" colspan="1">PaO<sub>2</sub> -_constraints_&#8594; 20&#8211;50&#160;mmHg</td></tr><tr><td colspan="4" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">&#8230;</td></tr><tr><td colspan="4" align="left" valign="middle" style="border-bottom:solid thin" rowspan="1">Entity/Event &#8594; Concept</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">_conforms_to_</td><td align="left" valign="middle" rowspan="1" colspan="1">Entity/Event</td><td align="left" valign="middle" rowspan="1" colspan="1">CC</td><td align="left" valign="middle" rowspan="1" colspan="1">EUI:67178.Lab Result -_conforms_to_&#8594; HbA1c &gt; 7%</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">_diagnoses_</td><td align="left" valign="middle" rowspan="1" colspan="1">Event</td><td align="left" valign="middle" rowspan="1" colspan="1">Dis</td><td align="left" valign="middle" rowspan="1" colspan="1">EUI:43613.Description -_diagnoses_&#8594; Hypertension</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">_prescribes_</td><td align="left" valign="middle" rowspan="1" colspan="1">Event</td><td align="left" valign="middle" rowspan="1" colspan="1">Med/Tre</td><td align="left" valign="middle" rowspan="1" colspan="1">EUI:54241.Prescription -_prescribes_&#8594; Amoxicillin</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">_associated_with_</td><td align="left" valign="middle" rowspan="1" colspan="1">Event</td><td align="left" valign="middle" rowspan="1" colspan="1">CI</td><td align="left" valign="middle" rowspan="1" colspan="1">EUI:67129.Indicators -_associated_with_&#8594; <inline-formula><mml:math id="mm104" overflow="scroll"><mml:mrow><mml:msub><mml:mi>PaO</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="4" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">&#8230;</td></tr><tr><td colspan="4" align="left" valign="middle" style="border-bottom:solid thin" rowspan="1">Entity/Event &#8594; Entity/Event</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">_participate_in_</td><td align="left" valign="middle" rowspan="1" colspan="1">Entity</td><td align="left" valign="middle" rowspan="1" colspan="1">Event</td><td align="left" valign="middle" rowspan="1" colspan="1">IUI:7657 -_participate_in_&#8594; EUI:67129</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">_associate_with_</td><td align="left" valign="middle" rowspan="1" colspan="1">Entity (A/Eth)</td><td align="left" valign="middle" rowspan="1" colspan="1">Event</td><td align="left" valign="middle" rowspan="1" colspan="1">Age 65 -_associate_with_&#8594; EUI:412546</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">_occurs_at_</td><td align="left" valign="middle" rowspan="1" colspan="1">Event</td><td align="left" valign="middle" rowspan="1" colspan="1">Entity (L)</td><td align="left" valign="middle" rowspan="1" colspan="1">EUI:63415 -_occurs_at_&#8594; Beijing</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">_time_is_</td><td align="left" valign="middle" rowspan="1" colspan="1">Event</td><td align="left" valign="middle" rowspan="1" colspan="1">Entity (T)</td><td align="left" valign="middle" rowspan="1" colspan="1">EUI:132807 -_time_is_&#8594; Year&#160;2010</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">_event_type_is_</td><td align="left" valign="middle" rowspan="1" colspan="1">Event</td><td align="left" valign="middle" rowspan="1" colspan="1">Entity (ET)</td><td align="left" valign="middle" rowspan="1" colspan="1">EUI:67129 -_event_type_is_&#8594; Surgery</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">_after_/_before_</td><td align="left" valign="middle" rowspan="1" colspan="1">Event</td><td align="left" valign="middle" rowspan="1" colspan="1">Event</td><td align="left" valign="middle" rowspan="1" colspan="1">EUI:67129 -_after_&#8594; EUI:162308</td></tr><tr><td colspan="4" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">&#8230;</td></tr></tbody></table><table-wrap-foot><fn><p><sup>1</sup> For concept nodes, &#8220;Dis&#8221; refers to diseases, &#8220;Sym&#8221; refers to symptoms, &#8220;Med&#8221; refers to medications, &#8220;Tre&#8221; refers to treatments, &#8220;CI&#8221; refers to clinical indicators, and &#8220;CC&#8221; refers to clinical constraints. <sup>2</sup> For entity nodes, &#8220;A&#8221; refers to age, &#8220;Eth&#8221; refers to ethnicity, &#8220;L&#8221; refers to location, &#8220;T&#8221; refers to time, &#8220;ET&#8221; refers to static event type.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-05482-t003" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05482-t003_Table 3</object-id><label>Table 3</label><caption><p>Fidelity metrics for static event data <sup>1</sup>.</p></caption><table frame="hsides" rules="groups"><tbody><tr><td align="left" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">
</td><td colspan="4" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">MIMIC-III dataset</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Unigram</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Bigram</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Trigram</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sequential&#160;Bigram</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">HGAN</td><td align="center" valign="middle" rowspan="1" colspan="1">0.832</td><td align="center" valign="middle" rowspan="1" colspan="1">0.445</td><td align="center" valign="middle" rowspan="1" colspan="1">0.513</td><td align="center" valign="middle" rowspan="1" colspan="1">0.487</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">SynEHRgy</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>0.907</underline>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>0.717</underline>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.738</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>0.571</underline>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">HALO</td><td align="center" valign="middle" rowspan="1" colspan="1">0.872</td><td align="center" valign="middle" rowspan="1" colspan="1">0.287</td><td align="center" valign="middle" rowspan="1" colspan="1">0.313</td><td align="center" valign="middle" rowspan="1" colspan="1">0.521</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">SynTEG</td><td align="center" valign="middle" rowspan="1" colspan="1">0.858</td><td align="center" valign="middle" rowspan="1" colspan="1">0.501</td><td align="center" valign="middle" rowspan="1" colspan="1">0.647</td><td align="center" valign="middle" rowspan="1" colspan="1">0.562</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">QAMT</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.928</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.721</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<underline>0.718</underline>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.631</bold>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">
</td><td colspan="4" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">eICU dataset</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Unigram</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Bigram</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Trigram</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sequential&#160;Bigram</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">HGAN</td><td align="center" valign="middle" rowspan="1" colspan="1">0.799</td><td align="center" valign="middle" rowspan="1" colspan="1">0.319</td><td align="center" valign="middle" rowspan="1" colspan="1">0.483</td><td align="center" valign="middle" rowspan="1" colspan="1">0.366</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">SynEHRgy</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>0.848</underline>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.763</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>0.711</underline>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>0.500</underline>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">HALO</td><td align="center" valign="middle" rowspan="1" colspan="1">0.769</td><td align="center" valign="middle" rowspan="1" colspan="1">0.293</td><td align="center" valign="middle" rowspan="1" colspan="1">0.281</td><td align="center" valign="middle" rowspan="1" colspan="1">0.474</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">SynTEG</td><td align="center" valign="middle" rowspan="1" colspan="1">0.787</td><td align="center" valign="middle" rowspan="1" colspan="1">0.579</td><td align="center" valign="middle" rowspan="1" colspan="1">0.663</td><td align="center" valign="middle" rowspan="1" colspan="1">0.492</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">QAMT</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.897</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<underline>0.755</underline>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.736</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.592</bold>
</td></tr></tbody></table><table-wrap-foot><fn><p><sup>1</sup>&#160;<bold>Bold</bold> and <underline>underline</underline> values indicate the best and second-best results, respectively.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-05482-t004" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05482-t004_Table 4</object-id><label>Table 4</label><caption><p>Fidelity metrics for temporal data <sup>1</sup>.</p></caption><table frame="hsides" rules="groups"><tbody><tr><td align="left" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">
</td><td colspan="5" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">MIMIC-III dataset</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Precision</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Recall</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Density</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Coverage</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm105" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">SynEHRgy</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>0.781 (0.011)</underline>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>0.853 (0.003)</underline>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0.711 (0.016)</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.852 (0.008)</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>0.036</underline>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">HGAN</td><td align="center" valign="middle" rowspan="1" colspan="1">0.731 (0.023)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.617 (0.028)</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.745 (0.045)</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0.315 (0.004)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.083</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">HALO</td><td align="center" valign="middle" rowspan="1" colspan="1">0.503 (0.038)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.461 (0.002)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.372 (0.029)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.215 (0.009)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.075</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">SynTEG</td><td align="center" valign="middle" rowspan="1" colspan="1">0.610 (0.013)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.721 (0.006)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.672 (0.031)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.507 (0.005)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.045</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">QAMT</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.811 (0.009)</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.859 (0.011)</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<underline>0.739 (0.036)</underline>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<underline>0.638 (0.003)</underline>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.024</bold>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">
</td><td colspan="5" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">eICU dataset</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Precision</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Recall</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Density</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Coverage</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm106" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">SynEHRgy</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>0.814 (0.018)</underline>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.822 (0.005)</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>0.701 (0.011)</underline>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>0.714 (0.007)</underline>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>0.042</underline>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">HGAN</td><td align="center" valign="middle" rowspan="1" colspan="1">0.669 (0.037)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.691 (0.042)</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.728 (0.032)</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0.594 (0.004)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.045</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">HALO</td><td align="center" valign="middle" rowspan="1" colspan="1">0.400 (0.061)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.417 (0.024)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.296 (0.018)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.395 (0.013)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.062</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">SynTEG</td><td align="center" valign="middle" rowspan="1" colspan="1">0.523 (0.020)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.806 (0.012)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.633 (0.022)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.678 (0.006)</td><td align="center" valign="middle" rowspan="1" colspan="1">0.051</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">QAMT</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.863 (0.017)</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<underline>0.817 (0.009)</underline>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.698 (0.025)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.743 (0.005)</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.033</bold>
</td></tr></tbody></table><table-wrap-foot><fn><p><sup>1</sup>&#160;<bold>Bold</bold> and <underline>underline</underline> values indicate the best and second-best results, respectively.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-05482-t005" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05482-t005_Table 5</object-id><label>Table 5</label><caption><p>Utility metrics for medical time-series data <sup>1</sup>.</p></caption><table frame="hsides" rules="groups"><tbody><tr><td align="left" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">
</td><td colspan="4" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">MIMIC-III dataset</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SpesisClustering <break/> (<inline-formula><mml:math id="mm107" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> %)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SpesisTreatment <break/>(<inline-formula><mml:math id="mm108" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ARDSPrediction <break/>(AUROC)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ARDSTreatment <break/>(<inline-formula><mml:math id="mm109" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>M</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mi>R</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> %)</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Real data</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;32.37</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.217</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.809</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;2.33</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">HGAN</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>&#8722;28.67</underline>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0.189</td><td align="center" valign="middle" rowspan="1" colspan="1">0.764</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;1.73</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">SynEHRgy</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;28.11</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>0.203</underline>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>0.818</underline>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>&#8722;2.17</underline>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">HALO</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;27.72</td><td align="center" valign="middle" rowspan="1" colspan="1">0.195</td><td align="center" valign="middle" rowspan="1" colspan="1">0.793</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;2.11</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">SynTEG</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;28.02</td><td align="center" valign="middle" rowspan="1" colspan="1">0.191</td><td align="center" valign="middle" rowspan="1" colspan="1">0.799</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;2.13</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">QAMT</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>&#8722;29.91</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.214</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.801</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>&#8722;2.28</bold>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">
</td><td colspan="4" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">eICU dataset</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SpesisClustering <break/> (<inline-formula><mml:math id="mm110" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> %)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SpesisTreatment <break/>(<inline-formula><mml:math id="mm111" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ARDSPrediction <break/>(AUROC)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ARDSTreatment <break/>(<inline-formula><mml:math id="mm112" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>M</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mi>R</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> %)</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Real data</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;40.82</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.172</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.813</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;2.49</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">HGAN</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>&#8722;38.82</underline>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0.161</td><td align="center" valign="middle" rowspan="1" colspan="1">0.825</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;2.01</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">SynEHRgy</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;37.41</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>0.167</underline>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<underline>0.816</underline>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>&#8722;2.31</bold>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">HALO</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;43.58</td><td align="center" valign="middle" rowspan="1" colspan="1">0.165</td><td align="center" valign="middle" rowspan="1" colspan="1">
<bold>0.814</bold>
</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;2.16</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">SynTEG</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;40.07</td><td align="center" valign="middle" rowspan="1" colspan="1">0.162</td><td align="center" valign="middle" rowspan="1" colspan="1">0.820</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;2.20</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">QAMT</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>&#8722;42.17</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>0.173</bold>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.807</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<underline>&#8722;2.24</underline>
</td></tr></tbody></table><table-wrap-foot><fn><p><sup>1</sup>&#160;<bold>Bold</bold> and <underline>underline</underline> values indicate the best and second-best results, respectively.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-05482-t006" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05482-t006_Table 6</object-id><label>Table 6</label><caption><p>Privacy metrics for medical time-series data.</p></caption><table frame="hsides" rules="groups"><tbody><tr><td colspan="9" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">MIMIC-III Dataset</td></tr><tr><td colspan="4" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Static Event Data</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td colspan="4" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Temporal Data</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Method</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">JSD</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">WD</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">AUROC</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Method</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">JSD</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">WD</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">AUROC</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">HGAN</td><td align="center" valign="middle" rowspan="1" colspan="1">0.015</td><td align="center" valign="middle" rowspan="1" colspan="1">0.001</td><td align="center" valign="middle" rowspan="1" colspan="1">0.482</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">HGAN</td><td align="center" valign="middle" rowspan="1" colspan="1">0.001</td><td align="center" valign="middle" rowspan="1" colspan="1">0.003</td><td align="center" valign="middle" rowspan="1" colspan="1">0.482</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">SynEHRgy</td><td align="center" valign="middle" rowspan="1" colspan="1">0.014</td><td align="center" valign="middle" rowspan="1" colspan="1">0.001</td><td align="center" valign="middle" rowspan="1" colspan="1">0.461</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">SynEHRgy</td><td align="center" valign="middle" rowspan="1" colspan="1">0.002</td><td align="center" valign="middle" rowspan="1" colspan="1">0.002</td><td align="center" valign="middle" rowspan="1" colspan="1">0.492</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">HALO</td><td align="center" valign="middle" rowspan="1" colspan="1">0.013</td><td align="center" valign="middle" rowspan="1" colspan="1">0.000</td><td align="center" valign="middle" rowspan="1" colspan="1">0.477</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">HALO</td><td align="center" valign="middle" rowspan="1" colspan="1">0.003</td><td align="center" valign="middle" rowspan="1" colspan="1">0.001</td><td align="center" valign="middle" rowspan="1" colspan="1">0.493</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">SynTEG</td><td align="center" valign="middle" rowspan="1" colspan="1">0.014</td><td align="center" valign="middle" rowspan="1" colspan="1">0.000</td><td align="center" valign="middle" rowspan="1" colspan="1">0.469</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">SynTEG</td><td align="center" valign="middle" rowspan="1" colspan="1">0.002</td><td align="center" valign="middle" rowspan="1" colspan="1">0.001</td><td align="center" valign="middle" rowspan="1" colspan="1">0.488</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">QAMT</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.013</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.000</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.456</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">QAMT</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.001</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.002</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.477</td></tr><tr><td colspan="9" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">eICU Dataset</td></tr><tr><td colspan="4" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Static Event Data</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td colspan="4" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Temporal Data</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Method</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">JSD</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">WD</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">AUROC</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Method</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">JSD</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">WD</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">AUROC</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">HGAN</td><td align="center" valign="middle" rowspan="1" colspan="1">0.015</td><td align="center" valign="middle" rowspan="1" colspan="1">0.002</td><td align="center" valign="middle" rowspan="1" colspan="1">0.496</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">HGAN</td><td align="center" valign="middle" rowspan="1" colspan="1">0.001</td><td align="center" valign="middle" rowspan="1" colspan="1">0.001</td><td align="center" valign="middle" rowspan="1" colspan="1">0.497</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">SynEHRgy</td><td align="center" valign="middle" rowspan="1" colspan="1">0.015</td><td align="center" valign="middle" rowspan="1" colspan="1">0.002</td><td align="center" valign="middle" rowspan="1" colspan="1">0.479</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">SynEHRgy</td><td align="center" valign="middle" rowspan="1" colspan="1">0.001</td><td align="center" valign="middle" rowspan="1" colspan="1">0.002</td><td align="center" valign="middle" rowspan="1" colspan="1">0.508</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">HALO</td><td align="center" valign="middle" rowspan="1" colspan="1">0.015</td><td align="center" valign="middle" rowspan="1" colspan="1">0.001</td><td align="center" valign="middle" rowspan="1" colspan="1">0.486</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">HALO</td><td align="center" valign="middle" rowspan="1" colspan="1">0.003</td><td align="center" valign="middle" rowspan="1" colspan="1">0.002</td><td align="center" valign="middle" rowspan="1" colspan="1">0.509</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">SynTEG</td><td align="center" valign="middle" rowspan="1" colspan="1">0.015</td><td align="center" valign="middle" rowspan="1" colspan="1">0.001</td><td align="center" valign="middle" rowspan="1" colspan="1">0.481</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">SynTEG</td><td align="center" valign="middle" rowspan="1" colspan="1">0.002</td><td align="center" valign="middle" rowspan="1" colspan="1">0.002</td><td align="center" valign="middle" rowspan="1" colspan="1">0.506</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">QAMT</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.015</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.001</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.456</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">QAMT</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.001</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.002</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.504</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05482-t007" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05482-t007_Table 7</object-id><label>Table 7</label><caption><p>Statistical significance test.</p></caption><table frame="hsides" rules="groups"><tbody><tr><td align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">
</td><td colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Static event data</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Unigram</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Bigram</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Value</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">0.928</td><td align="center" valign="middle" rowspan="1" colspan="1">0.721</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">95% CI</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">[0.905, 0.951]</td><td align="center" valign="middle" rowspan="1" colspan="1">[0.712, 0.730]</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<italic toggle="yes">p</italic>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><italic toggle="yes">p</italic> &lt;&#160;0.05</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><italic toggle="yes">p</italic> &lt;&#160;0.05</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Temporal data</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Precision</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Recall</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Value</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">0.811</td><td align="center" valign="middle" rowspan="1" colspan="1">0.859</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">95% CI</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">[0.802, 0.820]</td><td align="center" valign="middle" rowspan="1" colspan="1">[0.852, 0.866]</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<italic toggle="yes">p</italic>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><italic toggle="yes">p</italic> &lt;&#160;0.05</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><italic toggle="yes">p</italic> &lt;&#160;0.05</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Time-series data</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SpesisClustering <break/> (<inline-formula><mml:math id="mm113" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> %)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SpesisTreatment <break/>(<inline-formula><mml:math id="mm114" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>)</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Value</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;29.91</td><td align="center" valign="middle" rowspan="1" colspan="1">0.214</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">95% CI</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">[&#8722;30.27, &#8722;29.55]</td><td align="center" valign="middle" rowspan="1" colspan="1">[0.211, 0.217]</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<italic toggle="yes">p</italic>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><italic toggle="yes">p</italic>&#160;&lt;&#160;0.05</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><italic toggle="yes">p</italic> &lt;&#160;0.01</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05482-t008" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05482-t008_Table 8</object-id><label>Table 8</label><caption><p>Noise robustness analysis.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Noise Intensity</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Precision</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Recall</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Density</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Coverage</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm115" overflow="scroll"><mml:mrow><mml:mstyle mathvariant="bold"><mml:msub><mml:mi mathvariant="bold-italic">MSE</mml:mi><mml:mi mathvariant="bold-italic">corr</mml:mi></mml:msub></mml:mstyle></mml:mrow></mml:math>
</inline-formula>
</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">0%</td><td align="center" valign="middle" rowspan="1" colspan="1">0.811</td><td align="center" valign="middle" rowspan="1" colspan="1">0.859</td><td align="center" valign="middle" rowspan="1" colspan="1">0.739</td><td align="center" valign="middle" rowspan="1" colspan="1">0.638</td><td align="center" valign="middle" rowspan="1" colspan="1">0.024</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">10%</td><td align="center" valign="middle" rowspan="1" colspan="1">0.806</td><td align="center" valign="middle" rowspan="1" colspan="1">0.848</td><td align="center" valign="middle" rowspan="1" colspan="1">0.735</td><td align="center" valign="middle" rowspan="1" colspan="1">0.636</td><td align="center" valign="middle" rowspan="1" colspan="1">0.025</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">20%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.803</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.841</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.728</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.633</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.025</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Influence</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.6%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2.1%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.5%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.8%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4.2%</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05482-t009" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05482-t009_Table 9</object-id><label>Table 9</label><caption><p>Parameter sensitivity analysis.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">
<italic toggle="yes">k</italic>
</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Precision</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Recall</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Density</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Coverage</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm116" overflow="scroll"><mml:mrow><mml:mstyle mathvariant="bold"><mml:msub><mml:mi mathvariant="bold-italic">MSE</mml:mi><mml:mi mathvariant="bold-italic">corr</mml:mi></mml:msub></mml:mstyle></mml:mrow></mml:math>
</inline-formula>
</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">0.790</td><td align="center" valign="middle" rowspan="1" colspan="1">0.837</td><td align="center" valign="middle" rowspan="1" colspan="1">0.728</td><td align="center" valign="middle" rowspan="1" colspan="1">0.615</td><td align="center" valign="middle" rowspan="1" colspan="1">0.022</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">0.811</td><td align="center" valign="middle" rowspan="1" colspan="1">0.859</td><td align="center" valign="middle" rowspan="1" colspan="1">0.739</td><td align="center" valign="middle" rowspan="1" colspan="1">0.638</td><td align="center" valign="middle" rowspan="1" colspan="1">0.024</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">7</td><td align="center" valign="middle" rowspan="1" colspan="1">0.814</td><td align="center" valign="middle" rowspan="1" colspan="1">0.871</td><td align="center" valign="middle" rowspan="1" colspan="1">0.743</td><td align="center" valign="middle" rowspan="1" colspan="1">0.644</td><td align="center" valign="middle" rowspan="1" colspan="1">0.025</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.815</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.873</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.744</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.646</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.025</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05482-t010" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05482-t010_Table 10</object-id><label>Table 10</label><caption><p>Privacy metrics for medical time-series data in ablation experiments.</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="4" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Static Event Data</th><th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">
</th><th colspan="4" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Temporal Data</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Method</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">JSD</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">WD</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">AUROC</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Method</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">JSD</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">WD</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">AUROC</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">QAMT</td><td align="center" valign="middle" rowspan="1" colspan="1">0.013</td><td align="center" valign="middle" rowspan="1" colspan="1">0.000</td><td align="center" valign="middle" rowspan="1" colspan="1">0.456</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">QAMT</td><td align="center" valign="middle" rowspan="1" colspan="1">0.001</td><td align="center" valign="middle" rowspan="1" colspan="1">0.002</td><td align="center" valign="middle" rowspan="1" colspan="1">0.477</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">QAMT<sub>4</sub></td><td align="center" valign="middle" rowspan="1" colspan="1">0.016</td><td align="center" valign="middle" rowspan="1" colspan="1">0.004</td><td align="center" valign="middle" rowspan="1" colspan="1">0.457</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">QAMT<sub>4</sub></td><td align="center" valign="middle" rowspan="1" colspan="1">0.002</td><td align="center" valign="middle" rowspan="1" colspan="1">0.002</td><td align="center" valign="middle" rowspan="1" colspan="1">0.478</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">QAMT<sub>3</sub></td><td align="center" valign="middle" rowspan="1" colspan="1">0.044</td><td align="center" valign="middle" rowspan="1" colspan="1">0.013</td><td align="center" valign="middle" rowspan="1" colspan="1">0.462</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">QAMT<sub>3</sub></td><td align="center" valign="middle" rowspan="1" colspan="1">0.005</td><td align="center" valign="middle" rowspan="1" colspan="1">0.006</td><td align="center" valign="middle" rowspan="1" colspan="1">0.484</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">QAMT<sub>2</sub></td><td align="center" valign="middle" rowspan="1" colspan="1">0.050</td><td align="center" valign="middle" rowspan="1" colspan="1">0.014</td><td align="center" valign="middle" rowspan="1" colspan="1">0.465</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">QAMT<sub>2</sub></td><td align="center" valign="middle" rowspan="1" colspan="1">0.005</td><td align="center" valign="middle" rowspan="1" colspan="1">0.007</td><td align="center" valign="middle" rowspan="1" colspan="1">0.486</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">QAMT<sub>1</sub></td><td align="center" valign="middle" rowspan="1" colspan="1">0.071</td><td align="center" valign="middle" rowspan="1" colspan="1">0.019</td><td align="center" valign="middle" rowspan="1" colspan="1">0.470</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">QAMT<sub>1</sub></td><td align="center" valign="middle" rowspan="1" colspan="1">0.006</td><td align="center" valign="middle" rowspan="1" colspan="1">0.008</td><td align="center" valign="middle" rowspan="1" colspan="1">0.491</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">QAMT<sub>0</sub></td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.068</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.018</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.469</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">QAMT<sub>0</sub></td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.006</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.008</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.492</td></tr></tbody></table></table-wrap></floats-group></article></pmc-articleset>