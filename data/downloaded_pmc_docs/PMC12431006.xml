<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xml:lang="en" article-type="research-article" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="pmc-domain-id">1660</journal-id><journal-id journal-id-type="pmc-domain">sensors</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>Multidisciplinary Digital Publishing Institute  (MDPI)</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12431006</article-id><article-id pub-id-type="pmcid-ver">PMC12431006.1</article-id><article-id pub-id-type="pmcaid">12431006</article-id><article-id pub-id-type="pmcaiid">12431006</article-id><article-id pub-id-type="doi">10.3390/s25175230</article-id><article-id pub-id-type="publisher-id">sensors-25-05230</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>A Fusion Model for Intelligent Diagnosis of Gear Faults with Small Sample Sizes</article-title></title-group><contrib-group><contrib contrib-type="author"><name name-style="western"><surname>Huang</surname><given-names initials="J">Jianing</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><xref rid="af1-sensors-25-05230" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Liu</surname><given-names initials="Z">Zikang</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><xref rid="af2-sensors-25-05230" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Han</surname><given-names initials="J">Jianggui</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role><xref rid="af1-sensors-25-05230" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Cao</surname><given-names initials="C">Chenghao</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><xref rid="af1-sensors-25-05230" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Li</surname><given-names initials="X">Xiaofeng</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><xref rid="af1-sensors-25-05230" ref-type="aff">1</xref><xref rid="c1-sensors-25-05230" ref-type="corresp">*</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name name-style="western"><surname>Li</surname><given-names initials="Y">Yongbo</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name name-style="western"><surname>Wang</surname><given-names initials="T">Teng</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name name-style="western"><surname>Noman</surname><given-names initials="K">Khandaker</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name name-style="western"><surname>Li</surname><given-names initials="B">Bing</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-05230"><label>1</label>College of Power Engineering, Naval University of Engineering, Wuhan 430072, China; <email>1920191014@nue.edu.cn</email> (J.H.); </aff><aff id="af2-sensors-25-05230"><label>2</label>Zhejiang University-University of Illinois Urbana-Champaign Institute, Zhejiang University, Haining 314400, China</aff><author-notes><corresp id="c1-sensors-25-05230"><label>*</label>Correspondence: <email>xiaofengli@whu.edu.cn</email>; Tel.: +86-13080684008</corresp></author-notes><pub-date pub-type="epub"><day>22</day><month>8</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>9</month><year>2025</year></pub-date><volume>25</volume><issue>17</issue><issue-id pub-id-type="pmc-issue-id">496815</issue-id><elocation-id>5230</elocation-id><history><date date-type="received"><day>29</day><month>6</month><year>2025</year></date><date date-type="rev-recd"><day>28</day><month>7</month><year>2025</year></date><date date-type="accepted"><day>31</day><month>7</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>22</day><month>08</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>13</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-13 17:25:36.317"><day>13</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="sensors-25-05230.pdf"/><abstract><p>Gear faults are a frequent cause of rotating machinery breakdowns. There are two open issues in the current intelligent diagnosis model of gear faults. (1) Shallow models demand fewer data but necessitate feature extraction from raw signals, relying on prior knowledge. (2) Deep networks can adaptively extract fault features but require large datasets to train hyperparameters. In this paper, a novel fusion model, called CBAM-TCN-SVM, is proposed for intelligent gear fault diagnosis. It consists of a temporal convolutional network module (TCN), a convolutional block attention module (CBAM), and a support vector machine (SVM) module. More specifically, the frequency-domain sequence data are fed into the CBAM-TCN model, which effectively extracts deep fault features via multiple convolutional layers, channel attention mechanisms, and spatial attention mechanisms. Then, the SVM classifier is employed for intelligent classification. The fusion model combines the advantages of deep networks and shallow classifiers, addressing the issues that arise when the accuracy of fault diagnoses is constrained by the data scale and feature extractions rely on prior knowledge. The experiments result in the proposed method achieving a classification accuracy of 98.3% and demonstrate that it is a feasible approach for predicting gear faults.</p></abstract><kwd-group><kwd>fusion model</kwd><kwd>gear fault</kwd><kwd>intelligent diagnosis</kwd><kwd>small sample size</kwd></kwd-group><funding-group><award-group><funding-source>Postdoctoral Fellowship Program of CPSF</funding-source><award-id>GZC20233550</award-id></award-group><funding-statement>This work is supported by the Postdoctoral Fellowship Program of CPSF (Grant No. GZC20233550).</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-05230"><title>1. Introduction</title><p>Rotating machinery is a cornerstone of modern industrial systems, in which the gears serve as the pivotal components responsible for transmitting motion and power within these configurations. The reliable operation of gears is crucial, as gear faults are among the most prevalent causes of breakdowns for rotating machinery. The faults, if not promptly identified and addressed, can lead to extensive damage, potential safety hazards, and significant financial loss [<xref rid="B1-sensors-25-05230" ref-type="bibr">1</xref>,<xref rid="B2-sensors-25-05230" ref-type="bibr">2</xref>,<xref rid="B3-sensors-25-05230" ref-type="bibr">3</xref>]. Consequently, the development of intelligent gear fault detection and diagnosis methods has emerged as a critical area of research, particularly for methods that leverage advanced deep learning algorithms without the need for equipment disassembly [<xref rid="B4-sensors-25-05230" ref-type="bibr">4</xref>].</p><p>In the realm of gear fault diagnosis, diagnostic techniques by shallow models and deep network models have been widely explored [<xref rid="B5-sensors-25-05230" ref-type="bibr">5</xref>,<xref rid="B6-sensors-25-05230" ref-type="bibr">6</xref>]. The shallow models, such as support vector machines (SVMs) and decision trees, are known for their relatively low data requirements [<xref rid="B7-sensors-25-05230" ref-type="bibr">7</xref>]. These models can perform well with limited training samples, making them suitable for scenarios where data acquisition is challenging or expensive [<xref rid="B8-sensors-25-05230" ref-type="bibr">8</xref>]. However, a major drawback of shallow models lies in their reliance on feature extractions from raw signals, a process that heavily depends on prior knowledge of the system and the nature of the faults [<xref rid="B9-sensors-25-05230" ref-type="bibr">9</xref>]. For example, Moshrefzadeh [<xref rid="B10-sensors-25-05230" ref-type="bibr">10</xref>] proposed a new spectral amplitude modulation technique to isolate signaling components across varying energy levels, independent of load and speed conditions. By analyzing the envelope spectrum impulses of these extracted signals, the operational smoothness could be quantified. These metrics serve as inputs for machine learning algorithms, enabling intelligent bearing fault diagnoses. The researchers had to carefully select and extract relevant features from the raw vibration signals, such as time-domain statistics and frequency-domain spectral features, to achieve an acceptable diagnostic accuracy. This manual feature extraction process not only demands significant time and effort but also limits the model&#8217;s generalizability to new and unseen fault patterns [<xref rid="B11-sensors-25-05230" ref-type="bibr">11</xref>].</p><p>The deep network models, including convolutional neural networks (CNNs) [<xref rid="B12-sensors-25-05230" ref-type="bibr">12</xref>], recurrent neural networks (RNNs) [<xref rid="B13-sensors-25-05230" ref-type="bibr">13</xref>], and temporal convolutional networks (TCNs) [<xref rid="B14-sensors-25-05230" ref-type="bibr">14</xref>], have gained popularity due to their ability to adaptively extract fault features from raw data. These models can automatically learn hierarchical representations of the input data, capturing complex patterns and relationships that may be difficult to identify through manual feature engineering. For example, Yuan et al. [<xref rid="B15-sensors-25-05230" ref-type="bibr">15</xref>] developed a sophisticated fault diagnosis framework grounded in big data and deep learning. They trained CNN models on diverse signals, including vibration, voltage, current, and acoustic data, enabling high-accuracy fault detection and wear prediction across more than ten types of rotating machinery, such as rolling bearings and gearboxes. The deep network models can directly process vibration signals and learn meaningful features through multiple convolutional and pooling layers, achieving high diagnostic accuracies. However, deep networks typically require large datasets to train the numerous hyperparameters within the network structure [<xref rid="B16-sensors-25-05230" ref-type="bibr">16</xref>]. Insufficient training data can lead to overfitting, where the model performs well on the training data but fails to generalize to new, unseen data [<xref rid="B17-sensors-25-05230" ref-type="bibr">17</xref>]. Moreover, training deep networks can be computationally expensive and time-consuming, especially when dealing with high-dimensional data.</p><p>Current research in fault diagnosis with limited data samples primarily addresses data scarcity, class imbalance, and noisy or variable operating conditions through synergistic strategies. For instance, Li et al. [<xref rid="B18-sensors-25-05230" ref-type="bibr">18</xref>] proposed auxiliary generative mutual adversarial networks (AGMANs) with dual discriminators to mitigate class imbalance, improving gearbox diagnosis accuracy by 12% under the small samples. Similarly, Liu et al. [<xref rid="B19-sensors-25-05230" ref-type="bibr">19</xref>] integrated CNN-LSTM-GAN to handle biased hydropower data, boosting fault recall by 160%. Transfer learning leverages pretrained knowledge for new domains. Zhang et al. [<xref rid="B20-sensors-25-05230" ref-type="bibr">20</xref>] utilized LSTM networks pretrained on normal operational data, reducing prediction errors by 22% with only 10 fault samples in electric drive systems. Additionally, attention-based hybrid models improve noise robustness. Ma et al. [<xref rid="B21-sensors-25-05230" ref-type="bibr">21</xref>] combined multiscale depthwise separable convolution, bidirectional GRU, and squeeze-excitation mechanisms to attain 94.3% accuracy for gearbox diagnosis under 10 dB noise. Physics-informed methods embed mechanical constraints into deep learning. Sun et al. estimated fault severity with 95.4% accuracy using only one real sample, by compensating for transfer function discrepancies via gear dynamics equations [<xref rid="B22-sensors-25-05230" ref-type="bibr">22</xref>]. Benefiting from previous valuable works, significant contributions to the service reliability of bearings, gears, etc., have been made. However, challenges persist in computational efficiency and cross-domain adaptability in fault diagnosis with a limited data sample.</p><p>Given the limitations of both the shallow and deep models, the development of hybrid models, which can combine the advantages of the different approaches, has become an active area of research. Hybrid models aim to leverage the low data requirements of shallow models and the adaptive feature extraction capabilities of deep networks to achieve better fault diagnosis results [<xref rid="B23-sensors-25-05230" ref-type="bibr">23</xref>]. One such approach is to use a deep network for feature extraction and a shallow classifier for final classification. For example, Ding et al. [<xref rid="B24-sensors-25-05230" ref-type="bibr">24</xref>] proposed a gearbox fault intelligent recognition method that combines a TCN with a soft thresholding algorithm (SAM-TCNST). The TCN is used to extract features from raw vibration signals, and a soft thresholding algorithm is applied to denoise the features. However, this method still requires preprocessing of the raw vibration signals, and fails to achieve an end-to-end gearbox fault diagnosis.</p><p>Another aspect that needs to be considered in gear fault diagnosis is the choice of classifier. The traditional TCNs used for fault diagnosis often employ Softmax classifiers for fault classification. While Softmax classifiers can effectively integrate with the network during training and facilitate weight updates in TCN models, they have several drawbacks. They may perform poorly in nonlinear problems, have insufficient model generalizability, and be susceptible to overfitting, especially when dealing with small sample sizes [<xref rid="B25-sensors-25-05230" ref-type="bibr">25</xref>,<xref rid="B26-sensors-25-05230" ref-type="bibr">26</xref>,<xref rid="B27-sensors-25-05230" ref-type="bibr">27</xref>]. In contrast, SVMs are known for their excellent performance in handling small sample sizes and nonlinear problems. SVMs can find the optimal hyperplane that maximally separates different classes in the feature space, exhibiting stronger generalization capabilities [<xref rid="B28-sensors-25-05230" ref-type="bibr">28</xref>,<xref rid="B29-sensors-25-05230" ref-type="bibr">29</xref>,<xref rid="B30-sensors-25-05230" ref-type="bibr">30</xref>,<xref rid="B31-sensors-25-05230" ref-type="bibr">31</xref>]. Therefore, replacing the Softmax classifier with an SVM classifier in a hybrid model can potentially improve the diagnostic accuracy and robustness of the system.</p><p>In this paper, we propose a novel fusion model, called CBAM-TCN-SVM, for intelligent gear fault diagnoses with small sample sizes. The model combines the advantages of different components to address the limitations of the existing approaches. First, fast Fourier transform (FFT) is used as a preprocessing step to transform the raw time-domain data of gear faults into the frequency domain, reducing noise and highlighting the key frequency components. The frequency-domain sequence data are subsequently fed into the CBAM-TCN model. The TCN module consists of multiple convolutional layers that can adaptively extract deep fault features from the input data. The CBAM module is incorporated into the TCN to enhance its feature extraction capabilities. CBAM enables the model to selectively focus on channels with key information, particularly in regions with significant signal morphology changes, highlighting the target detail information and reducing the redundant information. Finally, to further enhance the network&#8217;s classification capabilities, the SVM classifier is employed for intelligent classification.</p><p>The proposed fusion model addresses the two open issues in the current gear fault intelligent diagnosis model. The model combines the low data requirements of shallow models and the adaptive feature extraction capabilities of deep networks, reducing the dependence on prior knowledge for feature extractions and improving the diagnostic accuracy, even with small sample sizes. The experimental results demonstrate that the proposed method achieves a classification accuracy of 98.3%, providing a feasible approach for predicting gear faults. In summary, the main contributions of this paper are threefold.</p><list list-type="order"><list-item><p>The integration of CBAM into the TCN allows the fusion model to adaptively focus on channels with critical information, thereby enhancing the feature extractions and reducing the reliance on prior knowledge for manual feature engineering.</p></list-item><list-item><p>The proposed hybrid model leverages SVM&#8217;s superior performance in handling small sample sizes, which improves the model&#8217;s generalizability and robustness when dealing with limited training data, enhancing the overall diagnostic accuracy.</p></list-item><list-item><p>The fusion model addresses the limitations of both the shallow and deep models, providing a more effective and efficient approach for intelligent gear fault diagnosis, especially in scenarios with small sample sizes.</p></list-item></list><p>The remainder of our paper is organized as follows. <xref rid="sec2-sensors-25-05230" ref-type="sec">Section 2</xref> explains the theoretical background of the CBAM, TCN, SVM, and our fusion model. <xref rid="sec3-sensors-25-05230" ref-type="sec">Section 3</xref> introduces the experimental platform and analyzes the vibration data. <xref rid="sec4-sensors-25-05230" ref-type="sec">Section 4</xref> describes the comparative fault diagnosis results. <xref rid="sec5-sensors-25-05230" ref-type="sec">Section 5</xref> summarizes the methods presented in this paper.</p></sec><sec id="sec2-sensors-25-05230"><title>2. Theory and Modeling</title><p>Feature extraction via the convolutional block attention module and temporal convolutional network (CBAM-TCN) is an advanced method for capturing complex fault patterns. It merges the TCN&#8217;s hierarchical, adaptive feature learning over time (handling short-and long-term temporal dependencies for gear faults) with the CBAM&#8217;s attention-enhancing mechanism. The CBAM, with channel and spatial attention, selects key channels for gear faults by weighting them, and focuses on spatial locations with significant signal changes. This combination enables the CBAM-TCN to extract deep, discriminative features, reducing manual feature engineering and boosting the gear fault diagnosis performance.</p><sec id="sec2dot1-sensors-25-05230"><title>2.1. Basic Theory of the TCN</title><p>A TCN is a variant of a convolutional neural network (CNN) specifically designed for sequential tasks. Its core idea is to effectively enhance the network&#8217;s ability to process time series information by introducing causal convolutions and dilated convolutions, as well as using residual connections to construct CNNs. In the TCN, the causal convolutions, dilated convolutions, and residual connections are included. In the causal convolutions section, the design of the TCN must obey the following rules: first, the output data must be causal in the time dimension; then, the data scale must remain unchanged. To ensure causality, only neurons at time t and earlier are used to compute the neuron at time t in the second layer. When gradually computing neurons closer to time 0 in the next layer, there may be insufficient neurons in the previous layer [<xref rid="B25-sensors-25-05230" ref-type="bibr">25</xref>]. To maintain an unchanged sequence length, zero padding is performed on the left side. Currently, causal convolutions have a problem. To expand the receptive field, the convolution kernel dimension or the number of layers needs to be increased, which increases the network&#8217;s complexity and training difficulty.</p><p>Using dilated convolutions can solve this problem by skipping some elements during the convolution, which expands the receptive field without increasing the network&#8217;s depth or the number of parameters. The dilated convolution function <italic toggle="yes">F</italic>(<italic toggle="yes">x</italic>) for an input sequence <italic toggle="yes">x</italic> and convolution kernel <italic toggle="yes">C</italic> can be represented by Formula (1):<disp-formula id="FD1-sensors-25-05230"><label>(1)</label><mml:math id="mm1" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">k</italic> is the convolution kernel size, <italic toggle="yes">i</italic> is the position of the convolution kernel, <italic toggle="yes">d</italic> is the dilation factor, and <italic toggle="yes">s&#8722;di</italic> represents the element of the previous convolutional layer.</p><p>To solve the vanishing and exploding gradient problems often encountered in deep network training, residual connections are introduced. Residual connections solve the problem of gradient instability in temporal convolutional networks by adding a direct pathway between convolutional layers. The calculation method involves adding the network&#8217;s output <italic toggle="yes">F</italic>(<italic toggle="yes">x</italic>) to the input x and then passing it through an activation function to obtain the output P, as shown in Formula (2):<disp-formula id="FD2-sensors-25-05230"><label>(2)</label><mml:math id="mm2" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p><italic toggle="yes">A</italic> residual block consists of dilated causal convolutions, weight normalization, ReLU activation functions, and dropouts. The TCN network is composed of many stacked residual blocks, as shown in <xref rid="sensors-25-05230-f001" ref-type="fig">Figure 1</xref>, which illustrates a TCN network with n stacked residual blocks. Each residual block has a convolution kernel size of k and a dilation factor of 2n &#8722; 1 in the n-th residual block.</p></sec><sec id="sec2dot2-sensors-25-05230"><title>2.2. Basic Theory of CBAM</title><p>CBAM is a simple yet effective attention mechanism applicable to feedforward convolutional neural networks. It innovatively designs a channel attention module and a spatial attention module to emphasize meaningful features along the channel axis and spatial axis, respectively. The overall architecture of CBAM is shown in <xref rid="sensors-25-05230-f002" ref-type="fig">Figure 2</xref>:</p><p>CBAM models the relationships between different channels to learn the important weights of each channel while also focusing on the spatial dimension by learning the weights of each pixel position to emphasize important regions in the feature map. Introducing a CBAM layer after the TCN layer enables the TCN to focus more on the important features in the feature map, improving the network&#8217;s expressive capabilities and performance, which is beneficial for enhancing the accuracy and robustness of fault diagnoses.</p></sec><sec id="sec2dot3-sensors-25-05230"><title>2.3. Support Vector Machine</title><p>SVM stands as a statistical-theory-driven machine learning approach, adept at tackling classification challenges. It has gained extensive traction in the field of nonlinear and high-dimensional pattern recognition tasks. In gear mechanisms, a prevalent issue is the scarcity of collected data, which hampers the acquisition of sufficient fault samples and yields a constrained dataset [<xref rid="B32-sensors-25-05230" ref-type="bibr">32</xref>]. Given this, SVM is frequently employed for diagnosing gear faults. Its core mechanism involves transforming the initial nonlinear problem from a low-dimensional input space into a high-dimensional feature space to derive a viable solution, with the optimal function formulated accordingly:<disp-formula id="FD3-sensors-25-05230"><label>(3)</label><mml:math id="mm3" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>sgn</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>&#945;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>*</mml:mo></mml:mrow></mml:mstyle><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Typical kernel functions encompass linear, polynomial, radial basis function (RBF), and sigmoid kernels. For tackling nonlinear classification tasks, the RBF kernel offers distinct benefits, including its capacity to project samples nonlinearly into a higher-dimensional space and its leniency regarding numerical constraints. Hence, this study opts for the RBF kernel, with the resultant decision classification function formulated as below:<disp-formula id="FD4-sensors-25-05230"><label>(4)</label><mml:math id="mm4" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>sgn</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>&#945;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>*</mml:mo></mml:mrow></mml:mstyle><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>exp</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mo>&#8722;</mml:mo><mml:msup><mml:mrow><mml:mfenced close="&#x2016;" open="&#x2016;"><mml:mrow><mml:mi>x</mml:mi><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>In the formula, <italic toggle="yes">g</italic> denotes the kernel parameter governing the scope of the kernel function&#8217;s influence. The SVM&#8217;s classification efficacy hinges on the choice of pivotal parameters, with the penalty parameter <italic toggle="yes">C</italic> and kernel parameter g exerting a profound effect on classification precision and generalization performance. The penalty parameter <italic toggle="yes">C</italic> balances the reduction of model complexity against the minimization of empirical risk, while the kernel parameter <italic toggle="yes">g</italic> influences the correlation intensity among support vectors. Excessively large values may cause overfitting to training data, whereas overly small values may limit flexibility. Parameter optimization is performed using a grid search. All possible parameter combinations are generated within a predefined parameter space, and k-fold cross-validation is employed to evaluate the model performance of each combination. After traversing all parameter combinations, the (<italic toggle="yes">C</italic>, <italic toggle="yes">g</italic>) with the highest cross-validation score is selected as the optimal parameter.</p></sec><sec id="sec2dot4-sensors-25-05230"><title>2.4. Model Establishment</title><p>The proposed FFT-CBAM-TCN-SVM hybrid model fault diagnosis process is shown in <xref rid="sensors-25-05230-f003" ref-type="fig">Figure 3</xref>. The model&#8217;s overall structure comprises three key stages: fault signal preprocessing, feature extraction, and fault diagnosis. During fault signal preprocessing, vibration signals are gathered from bearings, and sample lengths are defined. Each sample undergoes standardization to enhance the integrity and dependability of the extracted fault data. FFT is employed for data preprocessing, after which the dataset is divided into training, validation, and test sets based on a predetermined ratio. In the feature extraction phase, the processed data are fed into the CBAM-TCN model for feature mining. This study incorporates two CBAM-TCN residual blocks, with 64 convolution kernels, a kernel size of 10, and dilation factors of 1 and 2. Each residual block applies weight normalization post-convolution, utilizing the ReLU activation function. The dropout rate is configured to 0.005, and the learning rate is set at 0.001.</p><p>The extracted temporal features are fed into an SVM for training and classification. As indicated by the dashed line in <xref rid="sensors-25-05230-f003" ref-type="fig">Figure 3</xref>, the CBAM-TCN and grid search parameter optimization components undergo independent stagewise training. First, the CBAM-TCN network is trained end-to-end using backpropagation to learn hierarchical representations of frequency-domain features. Subsequently, with the CBAM-TCN parameters frozen, the extracted features are input to the SVM classifier, where hyperparameter optimization is performed via grid search. This approach circumvents gradient interference during joint backpropagation, thus enhancing training stability under small-sample scenarios.</p></sec></sec><sec id="sec3-sensors-25-05230"><title>3. Testing Platform</title><p>This study focuses on the diagnosis of three common mechanical faults of industrial gears: surface wear (Fault I), broken teeth (Fault II), and missing teeth (Fault III). To verify the validity of the hybrid model proposed in this paper, a gear transmission platform and the gear faults are established in the laboratory, as shown in <xref rid="sensors-25-05230-f004" ref-type="fig">Figure 4</xref>.</p><p>The experimental platform comprises two primary systems, a mechanical transmission system and a signal acquisition system. The mechanical transmission system integrates a Siemens three-phase AC motor, programmable controller, frequency converter, gear transmission mechanism, and couplings. To obtain high-fidelity vibration data, the signal acquisition system employs two low-noise accelerometers (AC500-2P) with a &#177;80 g peak measurement range and 100 mV/g sensitivity. These sensors are strategically mounted on both the horizontal and vertical axes of the gear transmission mechanism&#8217;s support bearings. Vibration data acquisition is performed via a GX400 four-channel data recorder at a sampling frequency of 48 kHz. Four operational conditions are investigated: normal operation and three fault modes (missing tooth, broken tooth, and surface wear). Vibration signals under these conditions are systematically collected, resulting in four distinct datasets. As illustrated in <xref rid="sensors-25-05230-f005" ref-type="fig">Figure 5</xref>, the vibrations in the time domain are presented for a comparative analysis across the four operational states.</p><p>For the analysis, the frequency spectra of the four conditions are further given in <xref rid="sensors-25-05230-f006" ref-type="fig">Figure 6</xref>. In the normal state, the frequency spectrum is dominated by the fundamental frequencies related to the gear&#8217;s rotational speed and meshing frequency, with relatively low-amplitude harmonics. For Fault I, there are slight increases in the amplitudes of certain frequency components compared with those in the normal state, possibly due to the additional vibrations generated by surface wear. These increased amplitudes may be associated with the excitation of new resonant frequencies or the modulation of existing frequencies. Fault II results in more significant changes in the frequency spectrum. New frequency components appear, which are likely related to the impact forces caused by the broken tooth. These additional frequencies can be attributed to the transient vibrations generated when the broken tooth engages with other teeth during rotation. Fault III also shows distinct changes in the frequency spectrum. There are large-amplitude spikes at specific frequencies, which are a clear indication of the severe impact of the missing tooth on the gear&#8217;s vibration behavior. These spikes are likely associated with sudden changes in gear motion and the resulting dynamic forces. Overall, the frequency spectra provide valuable information about the different fault conditions, and the proposed fusion model can leverage these spectral features to accurately classify the gear faults, especially in scenarios with small sample sizes, as demonstrated in the experimental results.</p></sec><sec sec-type="results" id="sec4-sensors-25-05230"><title>4. Results and Analysis</title><p>To validate the effectiveness and diagnostic performance of the proposed FFT-CBAM-TCN-SVM methodology, four experimental datasets representing distinct operational states (the normal conditions and three fault modes: missing teeth, broken teeth, and surface wear) are utilized. Each operational state contains 300 experimental samples, with each sample comprising 6000 data points. The datasets are partitioned into training (70%) and validation (30%) subsets for systematic model development.</p><sec id="sec4dot1-sensors-25-05230"><title>4.1. Model Analysis</title><p>The TCN model incorporates the Adam optimizer to enable adaptive learning rate adjustments and parameter updates along the negative gradient direction, thereby accelerating network convergence. The leaky ReLU activation function is selected to enhance the nonlinear feature extraction capability. The maximum number of training iterations is set to 50. <xref rid="sensors-25-05230-t001" ref-type="table">Table 1</xref> and <xref rid="sensors-25-05230-t002" ref-type="table">Table 2</xref> provide detailed hyperparameter settings for the TCN model and the GS-SVM model, respectively. The initial value for the optimal penalty parameters of C is set to 1, and the initial value for the nuclear parameters of g is set to 0.1. The article sets up two CBAM-TCN modules, and the network structure is shown in <xref rid="sensors-25-05230-f007" ref-type="fig">Figure 7</xref>.</p></sec><sec id="sec4dot2-sensors-25-05230"><title>4.2. Experimental Results and Analysis</title><p>After the architecture of the CBAM-TCN model is finalized, the TCN is integrated with a support vector machine (SVM) classifier. To mitigate computational resource requirements, the SVM uses a radial basis function (RBF) kernel. For a comparative performance analysis of the different hybrid models and enhanced experimental reliability, each methodology undergoes 10 independent trials, with the mean values of repeated experiments serving as evaluation metrics. As shown in <xref rid="sensors-25-05230-t003" ref-type="table">Table 3</xref>, multiple comparative experiments with other common classifiers are conducted to verify the capability of the fusion model for gear fault diagnosis.</p><p>Among the traditional methods, radial basis function networks (RBFs), extreme learning machines (ELMs), random forests (RFs), and SVMs exhibit relatively low and stable accuracy levels, with values of &#8722;0.4. The introduction of deep learning methods represents a significant improvement. The CNN demonstrates a notable increase in accuracy, with the maximum accuracy reaching approximately 0.85. The hybrid models CNN-SVM and TCN-SVM also show promising results, suggesting that combining deep learning models with SVM can enhance the overall performance to some extent. The TCN stands out for its high accuracy, where the minimum, maximum, and average accuracies are relatively high, approaching 0.95; this highlights the TCN&#8217;s strong ability to handle the given data, which is likely due to its effectiveness in processing sequential or time series information. The proposed CBAM-TCN-SVM model achieves the best performance among all the methods. Both the minimum and maximum accuracy bars are the highest, and the average accuracy line approaches 1. This outstanding performance can be attributed to the integration of the convolutional block attention module (CBAM). The attention mechanism in CBAM enables the model to focus more on important features, thereby significantly improving the accuracy. In conclusion, the proposed CBAM-TCN-SVM model is superior to the other methods in terms of accuracy. <xref rid="sensors-25-05230-f008" ref-type="fig">Figure 8</xref> further reveals the training dynamics, showing gradual stabilization and corresponding accuracy improvements for all the TCN variants during the iterative optimization. This observation underscores the inherent stability of TCN-based frameworks for fault detection, thereby validating the scientific importance of enhancing this foundational architecture.</p><p>Increased fluctuations in early-stage classification accuracies following CBAM integration can be detected. This phenomenon stems from the attention mechanism&#8217;s design objective to mitigate the computational overhead associated with sliding-window-based exhaustive search strategies. During the initial training phases, insufficient feature knowledge accumulation may lead to signal misinterpretations in critical regions, potentially resulting in false negatives. However, as evidenced in the latter training stages, the stability of classification accuracy&#8212;particularly when attention-based training strategies are employed&#8212;demonstrates marked post-convergence enhancements.</p><p>In addition to classification accuracy comparisons, <xref rid="sensors-25-05230-t004" ref-type="table">Table 4</xref> provides a comprehensive evaluation of the four TCN architectures through metrics including training duration, F1 score, and recall rate, enabling multidimensional performance assessment.</p><p>As shown in <xref rid="sensors-25-05230-t002" ref-type="table">Table 2</xref>, the CBAM-TCN-SVM architecture demonstrates superior performance across multiple evaluation metrics. Specifically, accuracy improvements of 7.6%, 6.7%, and 1.7% are observed compared with those of the baseline models, indicating an optimal comprehensive performance. The recall rate reaches 0.984, reflecting enhancements of 6.8%, 6.3%, and 1.6%, respectively, which signifies an improved true positive recognition capability with reduced false-negative occurrences. The F1 score of 0.982 (representing 6.6%, 6.3%, and 1.9% improvements) demonstrates an effective balance between precision and recall, ensuring robust positive sample identification while minimizing false-positive errors.</p><p>However, the integration of the CBAM module into the TCN architecture resulted in a 37.31 s increase in training duration. This computational trade-off is attributable to the attention mechanism&#8217;s feature refinement process that makes use of channelwise nonlinear transformations. Considering the substantial performance gains achieved, the additional computational cost associated with CBAM implementation is deemed acceptable to obtain the enhanced diagnostic capabilities. Furthermore, the training duration of the CBAM-TCN-SVM architecture is shorter than that of the CBAM-TCN model. This discrepancy arises from the decoupled training paradigm, where the TCN component focuses on feature learning while the SVM handles classification decision-making, thereby reducing end-to-end parameter optimization complexity. In contrast, conventional TCN architectures require a simultaneous optimization of all the network parameters during backpropagation, leading to exponential computational growth with increased input sequence lengths or network depths.</p><p>Notably, the observed training time differences pertain specifically to model calibration rather than operational inference. For practical mechanical fault diagnosis applications, the processing time during real-time deployment is more important than the training duration, particularly given that fault events typically develop over extended periods. The 98.3% classification accuracy achieved by the proposed methodology indicates a state-of-the-art performance in AI-based fault recognition, demonstrating clear superiority over comparative architectures. To facilitate an intuitive interpretation of the model&#8217;s feature learning capabilities and classification decision boundaries, t-distributed stochastic neighbor embedding (t-SNE) dimensionality reduction is applied to visualize the fault classification process on the test dataset, as illustrated in <xref rid="sensors-25-05230-f009" ref-type="fig">Figure 9</xref>.</p><p>In <xref rid="sensors-25-05230-f009" ref-type="fig">Figure 9</xref>a, the data points of different states are somewhat clustered but with significant overlaps among them; this indicates that the TCN model alone has a certain ability to distinguish between different states, but the separation is not distinct enough, which may lead to relatively high misclassification rates. <xref rid="sensors-25-05230-f009" ref-type="fig">Figure 9</xref>b shows a slightly better separation than <xref rid="sensors-25-05230-f009" ref-type="fig">Figure 9</xref>a. The SVM component seems to enhance the model&#8217;s ability to define boundaries between the different state clusters. However, there are still some overlapping regions, especially between certain fault states, suggesting that while the combination improves performance, it is not yet optimal. <xref rid="sensors-25-05230-f009" ref-type="fig">Figure 9</xref>c shows a more refined clustering of data points. The addition of the CBAM helps the model focus on more relevant features, resulting in tighter and more distinct clusters for each state. The overlaps among the different state clusters are reduced compared with those of the previous two models, indicating an improvement in the model&#8217;s discriminative ability. <xref rid="sensors-25-05230-f009" ref-type="fig">Figure 9</xref>d shows the best performance among the four methods. The data points for each state form well-separated and compact clusters. The combination of CBAM, TCN, and SVM effectively leverages the strengths of each component. The attention mechanism in CBAM helps the model extract more informative features, the TCN processes the sequential information well, and the SVM establishes clear decision boundaries. This model has the greatest potential for accurately classifying different states with minimal misclassifications.</p><p>In summary, the aforementioned experimental evaluation substantiates the robust diagnostic capability of the developed CBAM-TCN-SVM methodology, demonstrating high-precision fault identification across various gear failure modes. These findings conclusively validate the practical feasibility of the proposed framework for industrial gearbox fault diagnosis applications.</p></sec><sec id="sec4dot3-sensors-25-05230"><title>4.3. Ablation Experiments</title><p>To systematically evaluate the contribution of TCN (temporal convolutional network), CBAM (convolutional block attention module), and SVM (support vector machine) in the hybrid model, we designed five groups of ablation experiments to verify the effectiveness of their integration. As shown in <xref rid="sensors-25-05230-t005" ref-type="table">Table 5</xref>, the experimental parameters remain consistent across all configurations. By adding or removing core components using the control variable method, we compare the classification performance of the models on the small-sample gear fault dataset.</p><p>In the exclusive implementation of SVM (Group 1), the conspicuously low accuracy and F1 score, attributable to the absence of temporal dependency and feature correlation exploration, underscore the inefficacy of conventional classifiers in small-sample temporal diagnostic paradigms. The integration of TCN (Group 2), which harnesses causal convolution to model temporal dependencies, elevates the accuracy to 0.908, thereby validating its pivotal role as a cornerstone for temporal fault information extraction. A comparative analysis between TCN alone (Group 2) and the TCN + SVM ensemble (Group 3) reveals a discernible performance improvement, stemming from SVM&#8217;s enhancement of fault boundary delineation. In contrast, the TCN + CBAM configuration (Group 4) demonstrates a substantial performance boost: CBAM suppresses extraneous features and accentuates fault-sensitive regions, thereby augmenting feature discriminability. The fully integrated CBAM-TCN-SVM architecture (Group 5) achieves optimal efficacy. Through the synergistic interplay of TCN&#8217;s temporal pattern mining, CBAM&#8217;s feature refinement, and SVM&#8217;s boundary reinforcement, the model effectively mitigates challenges intrinsic to small-sample scenarios, including feature noise, information sparsity, and overfitting proclivity. This culminates in a high-fidelity diagnostic framework, offering a robust solution for industrial fault diagnosis under data-constrained conditions.</p></sec></sec><sec sec-type="conclusions" id="sec5-sensors-25-05230"><title>5. Conclusions</title><p>In conclusion, this study introduces a novel CBAM-TCN-SVM fusion model for intelligent gear fault diagnosis with small sample sizes. Through comprehensive experiments, the model demonstrated its superiority, with a high classification accuracy of 98.3%. The integration of CBAM enhances feature extraction by focusing on critical information, whereas the SVM classifier improves nonlinear pattern recognition, especially under limited-data conditions. This model effectively addresses the limitations of both the traditional shallow and deep models, providing a practical and efficient solution for industrial gearbox fault diagnoses. While this study focuses on gear fault diagnoses under constant-speed operating conditions, real-world industrial scenarios often involve variable speed regimes. In the future, further investigations are warranted to validate the proposed model&#8217;s performance under speed-varying conditions. Moreover, incorporating data augmentation techniques to further enhance the robustness of small-sample diagnosis will be further explored, aiming to provide a more comprehensive solution reference for this field.</p></sec></body><back><fn-group><fn><p><bold>Disclaimer/Publisher&#8217;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><notes><title>Author Contributions</title><p>Conceptualization, J.H. (Jianing Huang); software, Z.L.; validation, J.H. (Jianggui Han); formal analysis, C.C.; funding acquisition, X.L. All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Institutional Review Board Statement</title><p>Not applicable.</p></notes><notes><title>Informed Consent Statement</title><p>Not applicable.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>The data that support the findings of this study are available from the corresponding author upon reasonable request.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflicts of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-25-05230"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yu</surname><given-names>R.</given-names></name><name name-style="western"><surname>He</surname><given-names>B.</given-names></name><name name-style="western"><surname>Qian</surname><given-names>S.</given-names></name></person-group><article-title>Prediction of gear degradation trend under failure modes based on accelerated life test</article-title><source>Eng. Fail. Anal.</source><year>2025</year><volume>170</volume><fpage>109290</fpage><pub-id pub-id-type="doi">10.1016/j.engfailanal.2025.109290</pub-id></element-citation></ref><ref id="B2-sensors-25-05230"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tang</surname><given-names>S.</given-names></name><name name-style="western"><surname>Ma</surname><given-names>J.</given-names></name><name name-style="western"><surname>Yan</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Zhu</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Khoo</surname><given-names>B.</given-names></name></person-group><article-title>Deep transfer learning strategy in intelligent fault diagnosis of rotating machinery</article-title><source>Eng. Appl. Artif. Intell.</source><year>2024</year><volume>134</volume><fpage>108678</fpage><pub-id pub-id-type="doi">10.1016/j.engappai.2024.108678</pub-id></element-citation></ref><ref id="B3-sensors-25-05230"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>Q.</given-names></name><name name-style="western"><surname>Huang</surname><given-names>R.</given-names></name><name name-style="western"><surname>Xiong</surname><given-names>J.</given-names></name><name name-style="western"><surname>Yang</surname><given-names>J.</given-names></name><name name-style="western"><surname>Dong</surname><given-names>X.</given-names></name><name name-style="western"><surname>Wu</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Wu</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Lu</surname><given-names>T.</given-names></name></person-group><article-title>A survey on fault diagnosis of rotating machinery based on machine learning</article-title><source>Meas. Sci. Technol.</source><year>2024</year><volume>35</volume><fpage>102001</fpage><pub-id pub-id-type="doi">10.1088/1361-6501/ad6203</pub-id></element-citation></ref><ref id="B4-sensors-25-05230"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shi</surname><given-names>J.</given-names></name><name name-style="western"><surname>Peng</surname><given-names>D.</given-names></name><name name-style="western"><surname>Peng</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Goebel</surname><given-names>K.</given-names></name><name name-style="western"><surname>Wu</surname><given-names>D.</given-names></name></person-group><article-title>Planetary gearbox fault diagnosis using bidirectional-convolutional LSTM networks</article-title><source>Mech. Syst. Signal Process.</source><year>2022</year><volume>162</volume><fpage>107996</fpage><pub-id pub-id-type="doi">10.1016/j.ymssp.2021.107996</pub-id></element-citation></ref><ref id="B5-sensors-25-05230"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Surucu</surname><given-names>O.</given-names></name><name name-style="western"><surname>Gadsden</surname><given-names>S.</given-names></name><name name-style="western"><surname>Yawney</surname><given-names>J.</given-names></name></person-group><article-title>Condition monitoring using machine learning: A review of theory, applications, and recent advances</article-title><source>Expert Syst. Appl.</source><year>2023</year><volume>221</volume><fpage>119738</fpage><pub-id pub-id-type="doi">10.1016/j.eswa.2023.119738</pub-id></element-citation></ref><ref id="B6-sensors-25-05230"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Cui</surname><given-names>X.</given-names></name></person-group><article-title>An ensemble model with convolutional neural network by DS evidence fusion for bearing fault diagnosis</article-title><source>J. Vibroengineering</source><year>2025</year><volume>27</volume><fpage>608</fpage><lpage>618</lpage><pub-id pub-id-type="doi">10.21595/jve.2025.24722</pub-id></element-citation></ref><ref id="B7-sensors-25-05230"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>X.</given-names></name><name name-style="western"><surname>Wu</surname><given-names>S.</given-names></name><name name-style="western"><surname>Li</surname><given-names>X.</given-names></name><name name-style="western"><surname>Yuan</surname><given-names>H.</given-names></name><name name-style="western"><surname>Zhao</surname><given-names>D.</given-names></name></person-group><article-title>Particle swarm optimization-support vector machine model for machinery fault diagnoses in high-voltage circuit breakers</article-title><source>Chin. J. Mech. Eng.</source><year>2020</year><volume>33</volume><fpage>6</fpage><pub-id pub-id-type="doi">10.1186/s10033-019-0428-5</pub-id></element-citation></ref><ref id="B8-sensors-25-05230"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Deng</surname><given-names>S.</given-names></name><name name-style="western"><surname>Hong</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Wei</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Cai</surname><given-names>L.</given-names></name></person-group><article-title>A novel hybrid CNN-SVM method for lithology identification in shale reservoirs based on logging measurements</article-title><source>J. Appl. Geophys.</source><year>2024</year><volume>223</volume><fpage>105346</fpage><pub-id pub-id-type="doi">10.1016/j.jappgeo.2024.105346</pub-id></element-citation></ref><ref id="B9-sensors-25-05230"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cheng</surname><given-names>X.</given-names></name><name name-style="western"><surname>Dou</surname><given-names>S.</given-names></name><name name-style="western"><surname>Du</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>Z.</given-names></name></person-group><article-title>Gearbox fault diagnosis method based on lightweight channel attention mechanism and transfer learning</article-title><source>Sci. Rep.</source><year>2024</year><volume>14</volume><elocation-id>743</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-023-50826-6</pub-id><pub-id pub-id-type="pmid">38185699</pub-id><pub-id pub-id-type="pmcid">PMC10772111</pub-id></element-citation></ref><ref id="B10-sensors-25-05230"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Moshrefzadeh</surname><given-names>A.</given-names></name></person-group><article-title>Condition monitoring and intelligent diagnosis of rolling element bearings under constant/variable load and speed conditions</article-title><source>Mech. Syst. Signal Process.</source><year>2021</year><volume>149</volume><fpage>107153</fpage><pub-id pub-id-type="doi">10.1016/j.ymssp.2020.107153</pub-id></element-citation></ref><ref id="B11-sensors-25-05230"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>X.</given-names></name><name name-style="western"><surname>Zheng</surname><given-names>X.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>T.</given-names></name><name name-style="western"><surname>Guo</surname><given-names>W.</given-names></name><name name-style="western"><surname>Wu</surname><given-names>Z.</given-names></name></person-group><article-title>Robust fault diagnosis of a high-voltage circuit breaker via an ensemble echo state network with evidence fusion</article-title><source>Complex Intell. Syst.</source><year>2023</year><volume>9</volume><fpage>5991</fpage><lpage>6007</lpage><pub-id pub-id-type="doi">10.1007/s40747-023-01025-3</pub-id></element-citation></ref><ref id="B12-sensors-25-05230"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dao</surname><given-names>F.</given-names></name><name name-style="western"><surname>Zeng</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Qian</surname><given-names>J.</given-names></name></person-group><article-title>Fault diagnosis of hydro-turbine via the incorporation of bayesian algorithm optimized CNN-LSTM neural network</article-title><source>Energy</source><year>2024</year><volume>290</volume><fpage>130326</fpage><pub-id pub-id-type="doi">10.1016/j.energy.2024.130326</pub-id><pub-id pub-id-type="pmcid">PMC11511977</pub-id><pub-id pub-id-type="pmid">39455870</pub-id></element-citation></ref><ref id="B13-sensors-25-05230"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>F.</given-names></name><name name-style="western"><surname>Dai</surname><given-names>Y.</given-names></name></person-group><article-title>Product quality prediction method in small sample data environment</article-title><source>Adv. Eng. Inform.</source><year>2023</year><volume>56</volume><fpage>101975</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2023.101975</pub-id></element-citation></ref><ref id="B14-sensors-25-05230"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>S.</given-names></name><name name-style="western"><surname>Xu</surname><given-names>T.</given-names></name><name name-style="western"><surname>Du</surname><given-names>X.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Wu</surname><given-names>J.</given-names></name></person-group><article-title>A hybrid deep learning model based on parallel architecture TCN-LSTM with Savitzky-Golay filter for wind power prediction</article-title><source>Energy Convers. Manag.</source><year>2024</year><volume>302</volume><fpage>118122</fpage><pub-id pub-id-type="doi">10.1016/j.enconman.2024.118122</pub-id></element-citation></ref><ref id="B15-sensors-25-05230"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yuan</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Ma</surname><given-names>G.</given-names></name><name name-style="western"><surname>Cheng</surname><given-names>C.</given-names></name><name name-style="western"><surname>Zhou</surname><given-names>B.</given-names></name><name name-style="western"><surname>Zhao</surname><given-names>H.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>H.-T.</given-names></name><name name-style="western"><surname>Ding</surname><given-names>H.</given-names></name></person-group><article-title>A general end-to-end diagnosis framework for manufacturing systems</article-title><source>Natl. Sci. Rev.</source><year>2020</year><volume>7</volume><fpage>418</fpage><lpage>429</lpage><pub-id pub-id-type="doi">10.1093/nsr/nwz190</pub-id><pub-id pub-id-type="pmid">34692057</pub-id><pub-id pub-id-type="pmcid">PMC8289032</pub-id></element-citation></ref><ref id="B16-sensors-25-05230"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yang</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Duan</surname><given-names>Y.</given-names></name><name name-style="western"><surname>She</surname><given-names>D.</given-names></name><name name-style="western"><surname>Pecht</surname><given-names>M.G.</given-names></name></person-group><article-title>A meta transfer learning fault diagnosis method for gearbox with few-shot data</article-title><source>Meas. Sci. Technol.</source><year>2025</year><volume>36</volume><fpage>025007</fpage><pub-id pub-id-type="doi">10.1088/1361-6501/ada39f</pub-id></element-citation></ref><ref id="B17-sensors-25-05230"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jiang</surname><given-names>F.</given-names></name><name name-style="western"><surname>Lin</surname><given-names>W.</given-names></name><name name-style="western"><surname>Wu</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>S.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Li</surname><given-names>W.</given-names></name></person-group><article-title>Fault diagnosis of gearbox driven by vibration response mechanism and enhanced unsupervised domain adaptation</article-title><source>Adv. Eng. Inform.</source><year>2024</year><volume>61</volume><fpage>102460</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2024.102460</pub-id></element-citation></ref><ref id="B18-sensors-25-05230"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>R.</given-names></name><name name-style="western"><surname>Li</surname><given-names>S.</given-names></name><name name-style="western"><surname>Xu</surname><given-names>K.</given-names></name><name name-style="western"><surname>Zeng</surname><given-names>M.</given-names></name><name name-style="western"><surname>Li</surname><given-names>X.</given-names></name><name name-style="western"><surname>Gu</surname><given-names>J.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>Y.</given-names></name></person-group><article-title>Auxiliary generative mutual adversarial networks for class-imbalanced fault diagnosis under small samples</article-title><source>Chin. J. Aeronaut.</source><year>2023</year><volume>36</volume><fpage>464</fpage><lpage>478</lpage><pub-id pub-id-type="doi">10.1016/j.cja.2022.12.015</pub-id></element-citation></ref><ref id="B19-sensors-25-05230"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>B.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>X.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Zhao</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>X.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>T.</given-names></name></person-group><article-title>Fault Prediction of Hydropower Station Based On CNN-LSTM-GAN with Biased</article-title><source>Data Energ.</source><year>2025</year><volume>18</volume><elocation-id>3772</elocation-id><pub-id pub-id-type="doi">10.3390/en18143772</pub-id></element-citation></ref><ref id="B20-sensors-25-05230"><label>20.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>S.</given-names></name><name name-style="western"><surname>Qiu</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Zhao</surname><given-names>L.</given-names></name><name name-style="western"><surname>Huang</surname><given-names>X.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>F.</given-names></name><name name-style="western"><surname>Kang</surname><given-names>Y.</given-names></name></person-group><article-title>Research on Few-Shot Sample Fault Prediction Method for Electric Drive Systems Based on Transfer Learning</article-title><source>Proceedings of the TEPEN International Workshop on Fault Diagnostic and Prognostic</source><conf-loc>Qingdao, China</conf-loc><conf-date>8&#8211;11 May 2024</conf-date><publisher-name>Springer Nature</publisher-name><publisher-loc>Cham, Switzerland</publisher-loc><year>2024</year><volume>Volume 4</volume><fpage>285</fpage><lpage>295</lpage><pub-id pub-id-type="doi">10.1007/978-3-031-69483-7_27</pub-id></element-citation></ref><ref id="B21-sensors-25-05230"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ma</surname><given-names>X.</given-names></name><name name-style="western"><surname>Zhai</surname><given-names>K.</given-names></name><name name-style="western"><surname>Luo</surname><given-names>N.</given-names></name><name name-style="western"><surname>Zhao</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>G.</given-names></name></person-group><article-title>Gearbox Fault Diagnosis Under Noise and Variable Operating Conditions Using Multiscale Depthwise Separable Convolution and Bidirectional Gated Recurrent Unit with a Squeeze-and-Excitation Attention Mechanism</article-title><source>Sensors</source><year>2025</year><volume>25</volume><elocation-id>2978</elocation-id><pub-id pub-id-type="doi">10.3390/s25102978</pub-id><pub-id pub-id-type="pmid">40431773</pub-id><pub-id pub-id-type="pmcid">PMC12115310</pub-id></element-citation></ref><ref id="B22-sensors-25-05230"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sun</surname><given-names>Q.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Chu</surname><given-names>L.</given-names></name><name name-style="western"><surname>Tang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Xu</surname><given-names>L.</given-names></name><name name-style="western"><surname>Li</surname><given-names>Q.</given-names></name></person-group><article-title>Fault diagnosis of gearbox based on cross-domain transfer learning with fine-tuning mechanism using unbalanced samples</article-title><source>IEEE. Trans. Instrum. Meas.</source><year>2024</year><volume>73</volume><fpage>24310</fpage><pub-id pub-id-type="doi">10.1109/TIM.2024.3415783</pub-id></element-citation></ref><ref id="B23-sensors-25-05230"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>X.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>H.</given-names></name><name name-style="western"><surname>Xie</surname><given-names>F.</given-names></name><name name-style="western"><surname>Cao</surname><given-names>C.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>S.</given-names></name><name name-style="western"><surname>Shuai</surname><given-names>C.</given-names></name></person-group><article-title>Hybrid model of multiple echo state network integrated by evidence fusion for fault diagnosis of a high-voltage circuit breaker</article-title><source>IEEE Trans. Consum. Electron.</source><year>2024</year><volume>70</volume><fpage>5269</fpage><lpage>5277</lpage><pub-id pub-id-type="doi">10.1109/TCE.2024.3424280</pub-id></element-citation></ref><ref id="B24-sensors-25-05230"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ding</surname><given-names>L.</given-names></name><name name-style="western"><surname>Li</surname><given-names>Q.</given-names></name></person-group><article-title>Fault diagnosis of rotating machinery using novel self-attention mechanism TCN with soft thresholding method</article-title><source>Meas. Sci. Technol.</source><year>2024</year><volume>35</volume><fpage>047001</fpage><pub-id pub-id-type="doi">10.1088/1361-6501/ad1eb3</pub-id></element-citation></ref><ref id="B25-sensors-25-05230"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Han</surname><given-names>X.</given-names></name><name name-style="western"><surname>Zhu</surname><given-names>X.</given-names></name><name name-style="western"><surname>Pedrycz</surname><given-names>W.</given-names></name><name name-style="western"><surname>Mostafa</surname><given-names>A.M.</given-names></name><name name-style="western"><surname>Li</surname><given-names>Z.</given-names></name></person-group><article-title>A design of fuzzy rule-based classifier optimized through softmax function and information entropy</article-title><source>Appl. Soft Comput.</source><year>2024</year><volume>156</volume><fpage>111498</fpage><pub-id pub-id-type="doi">10.1016/j.asoc.2024.111498</pub-id></element-citation></ref><ref id="B26-sensors-25-05230"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>L.</given-names></name><name name-style="western"><surname>Ren</surname><given-names>G.</given-names></name><name name-style="western"><surname>Li</surname><given-names>S.</given-names></name><name name-style="western"><surname>Du</surname><given-names>J.</given-names></name><name name-style="western"><surname>Xu</surname><given-names>D.</given-names></name><name name-style="western"><surname>Li</surname><given-names>Y.</given-names></name></person-group><article-title>A novel soft sensor approach for industrial quality prediction based TCN with spatial and temporal attention</article-title><source>Chemom. Intell. Lab. Syst.</source><year>2025</year><volume>257</volume><fpage>105272</fpage><pub-id pub-id-type="doi">10.1016/j.chemolab.2024.105272</pub-id></element-citation></ref><ref id="B27-sensors-25-05230"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lai</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Liang</surname><given-names>G.</given-names></name><name name-style="western"><surname>Zhou</surname><given-names>J.</given-names></name><name name-style="western"><surname>Kong</surname><given-names>H.</given-names></name><name name-style="western"><surname>Lu</surname><given-names>Y.</given-names></name></person-group><article-title>A joint learning framework for optimal feature extraction and multi-class SVM</article-title><source>Inf. Sci.</source><year>2024</year><volume>671</volume><fpage>120656</fpage><pub-id pub-id-type="doi">10.1016/j.ins.2024.120656</pub-id></element-citation></ref><ref id="B28-sensors-25-05230"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ke</surname><given-names>T.</given-names></name><name name-style="western"><surname>Ge</surname><given-names>X.</given-names></name><name name-style="western"><surname>Yin</surname><given-names>F.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>L.</given-names></name><name name-style="western"><surname>Zheng</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>C.</given-names></name><name name-style="western"><surname>Li</surname><given-names>J.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>B.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>W.</given-names></name></person-group><article-title>A general maximal margin hyper-sphere SVM for multi-class classification</article-title><source>Expert Syst. Appl.</source><year>2024</year><volume>237</volume><fpage>121647</fpage><pub-id pub-id-type="doi">10.1016/j.eswa.2023.121647</pub-id></element-citation></ref><ref id="B29-sensors-25-05230"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>An</surname><given-names>W.</given-names></name><name name-style="western"><surname>Gao</surname><given-names>B.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>J.</given-names></name><name name-style="western"><surname>Ni</surname><given-names>J.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>J.</given-names></name></person-group><article-title>Predicting hourly heating load in residential buildings using a hybrid SSA-CNN-SVM approach</article-title><source>Case Stud. Therm. Eng.</source><year>2024</year><volume>59</volume><fpage>110998</fpage><pub-id pub-id-type="doi">10.1016/j.csite.2024.104516</pub-id></element-citation></ref><ref id="B30-sensors-25-05230"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>H.</given-names></name><name name-style="western"><surname>Zhou</surname><given-names>W.</given-names></name><name name-style="western"><surname>Shao</surname><given-names>Y.</given-names></name></person-group><article-title>A new fast ADMM for kernelless SVM classifier with truncated fraction loss</article-title><source>Knowl. Based Syst.</source><year>2024</year><volume>283</volume><fpage>111214</fpage><pub-id pub-id-type="doi">10.1016/j.knosys.2023.111214</pub-id></element-citation></ref><ref id="B31-sensors-25-05230"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bai</surname><given-names>S.</given-names></name><name name-style="western"><surname>Kolter</surname><given-names>J.Z.</given-names></name><name name-style="western"><surname>Koltun</surname><given-names>V.</given-names></name></person-group><article-title>An empirical evaluation of generic convolutional and recurrent networks for sequence modeling</article-title><source>arXiv</source><year>2018</year><pub-id pub-id-type="doi">10.48550/arXiv.1803.01271</pub-id><pub-id pub-id-type="arxiv">1803.01271</pub-id></element-citation></ref><ref id="B32-sensors-25-05230"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Matania</surname><given-names>O.</given-names></name><name name-style="western"><surname>Bachar</surname><given-names>L.</given-names></name><name name-style="western"><surname>Khemani</surname><given-names>V.</given-names></name><name name-style="western"><surname>Das</surname><given-names>D.</given-names></name><name name-style="western"><surname>Azarian</surname><given-names>M.</given-names></name><name name-style="western"><surname>Bortman</surname><given-names>J.</given-names></name></person-group><article-title>One-fault-shot learning for fault severity estimation of gears that addresses differences between simulation and experimental signals and transfer function effects</article-title><source>Adv. Eng. Inform.</source><year>2023</year><volume>56</volume><fpage>101945</fpage><pub-id pub-id-type="doi">10.1016/j.aei.2023.101945</pub-id></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-05230-f001" orientation="portrait"><label>Figure 1</label><caption><p>Structures of residual blocks in the TCN.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05230-g001.jpg"/></fig><fig position="float" id="sensors-25-05230-f002" orientation="portrait"><label>Figure 2</label><caption><p>Overall architecture of CBAM.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05230-g002.jpg"/></fig><fig position="float" id="sensors-25-05230-f003" orientation="portrait"><label>Figure 3</label><caption><p>The hybrid model fault diagnosis process.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05230-g003.jpg"/></fig><fig position="float" id="sensors-25-05230-f004" orientation="portrait"><label>Figure 4</label><caption><p>Gear fault test rig with different fault conditions.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05230-g004.jpg"/></fig><fig position="float" id="sensors-25-05230-f005" orientation="portrait"><label>Figure 5</label><caption><p>Original vibration waveforms of the four conditions.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05230-g005.jpg"/></fig><fig position="float" id="sensors-25-05230-f006" orientation="portrait"><label>Figure 6</label><caption><p>Frequency spectra of the four conditions.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05230-g006.jpg"/></fig><fig position="float" id="sensors-25-05230-f007" orientation="portrait"><label>Figure 7</label><caption><p>Network structure diagram of CBAM-TCN.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05230-g007.jpg"/></fig><fig position="float" id="sensors-25-05230-f008" orientation="portrait"><label>Figure 8</label><caption><p>Model training loss curve.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05230-g008.jpg"/></fig><fig position="float" id="sensors-25-05230-f009" orientation="portrait"><label>Figure 9</label><caption><p>Fault characteristics before and after model recognition.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05230-g009.jpg"/></fig><table-wrap position="float" id="sensors-25-05230-t001" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05230-t001_Table 1</object-id><label>Table 1</label><caption><p>TCN model hyperparameter settings.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Model Hyperparameter</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Parameter Setting</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Model Hyperparameter</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Parameter Setting</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Optimization algorithm</td><td align="center" valign="middle" rowspan="1" colspan="1">Adam</td><td align="center" valign="middle" rowspan="1" colspan="1">Activation function</td><td align="center" valign="middle" rowspan="1" colspan="1">Leaky ReLU</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Loss function</td><td align="center" valign="middle" rowspan="1" colspan="1">Categorical entropy</td><td align="center" valign="middle" rowspan="1" colspan="1">Expansion factor</td><td align="center" valign="middle" rowspan="1" colspan="1">1, 1</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Convolution kernel</td><td align="center" valign="middle" rowspan="1" colspan="1">64</td><td align="center" valign="middle" rowspan="1" colspan="1">Convolution kernel size</td><td align="center" valign="middle" rowspan="1" colspan="1">10</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Random inactivation factor</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Learning rate</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.001</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05230-t002" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05230-t002_Table 2</object-id><label>Table 2</label><caption><p>GS-SVM model hyperparameter settings.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Parameter Setting</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Values/Range</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Optimization Result/Objective</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Penalty Factor C</td><td align="center" valign="middle" rowspan="1" colspan="1">C &#8712; [2<sup>&#8722;5</sup>, 2<sup>10</sup>]</td><td align="center" valign="middle" rowspan="1" colspan="1">Best c: 0.031</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Kernel Parameter g</td><td align="center" valign="middle" rowspan="1" colspan="1">g &#8712; [2<sup>&#8722;5</sup>, 2<sup>10</sup>]</td><td align="center" valign="middle" rowspan="1" colspan="1">Best g: 0.250</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Cross-Validation Folds</td><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">Evaluates generalization capability</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Kernel Function Type</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RBF </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Adapts to data linear separability</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05230-t003" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05230-t003_Table 3</object-id><label>Table 3</label><caption><p>Accuracy comparisons of different methods.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Model Name</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Accuracy</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Precision</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Recall</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">F1 Score</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">BP</td><td align="center" valign="middle" rowspan="1" colspan="1">33.2%</td><td align="center" valign="middle" rowspan="1" colspan="1">0.331</td><td align="center" valign="middle" rowspan="1" colspan="1">0.332</td><td align="center" valign="middle" rowspan="1" colspan="1">0.333</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">RBF</td><td align="center" valign="middle" rowspan="1" colspan="1">35.2%</td><td align="center" valign="middle" rowspan="1" colspan="1">0.351</td><td align="center" valign="middle" rowspan="1" colspan="1">0.353</td><td align="center" valign="middle" rowspan="1" colspan="1">0.352</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">ELM</td><td align="center" valign="middle" rowspan="1" colspan="1">36.4%</td><td align="center" valign="middle" rowspan="1" colspan="1">0.366</td><td align="center" valign="middle" rowspan="1" colspan="1">0.365</td><td align="center" valign="middle" rowspan="1" colspan="1">0.364</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">RF</td><td align="center" valign="middle" rowspan="1" colspan="1">32.8%</td><td align="center" valign="middle" rowspan="1" colspan="1">0.330</td><td align="center" valign="middle" rowspan="1" colspan="1">0.326</td><td align="center" valign="middle" rowspan="1" colspan="1">0.328</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">SVM</td><td align="center" valign="middle" rowspan="1" colspan="1">33.6%</td><td align="center" valign="middle" rowspan="1" colspan="1">0.329</td><td align="center" valign="middle" rowspan="1" colspan="1">0.336</td><td align="center" valign="middle" rowspan="1" colspan="1">0.332</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">CNN</td><td align="center" valign="middle" rowspan="1" colspan="1">83.3%</td><td align="center" valign="middle" rowspan="1" colspan="1">0.840</td><td align="center" valign="middle" rowspan="1" colspan="1">0.839</td><td align="center" valign="middle" rowspan="1" colspan="1">0.840</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">CNN-SVM</td><td align="center" valign="middle" rowspan="1" colspan="1">85.0%</td><td align="center" valign="middle" rowspan="1" colspan="1">0.868</td><td align="center" valign="middle" rowspan="1" colspan="1">0.855</td><td align="center" valign="middle" rowspan="1" colspan="1">0.861</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">CNN-LSTM</td><td align="center" valign="middle" rowspan="1" colspan="1">52.5%</td><td align="center" valign="middle" rowspan="1" colspan="1">0.518</td><td align="center" valign="middle" rowspan="1" colspan="1">0.525</td><td align="center" valign="middle" rowspan="1" colspan="1">0.521</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">MCNN-BiGRU-Attention</td><td align="center" valign="middle" rowspan="1" colspan="1">78.8%</td><td align="center" valign="middle" rowspan="1" colspan="1">0.823</td><td align="center" valign="middle" rowspan="1" colspan="1">0.788</td><td align="center" valign="middle" rowspan="1" colspan="1">0.805</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">TCN</td><td align="center" valign="middle" rowspan="1" colspan="1">90.8%</td><td align="center" valign="middle" rowspan="1" colspan="1">0.916</td><td align="center" valign="middle" rowspan="1" colspan="1">0.916</td><td align="center" valign="middle" rowspan="1" colspan="1">0.916</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">TCN-SVM</td><td align="center" valign="middle" rowspan="1" colspan="1">91.6%</td><td align="center" valign="middle" rowspan="1" colspan="1">0.917</td><td align="center" valign="middle" rowspan="1" colspan="1">0.921</td><td align="center" valign="middle" rowspan="1" colspan="1">0.919</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">CBAM-TCN</td><td align="center" valign="middle" rowspan="1" colspan="1">96.6%</td><td align="center" valign="middle" rowspan="1" colspan="1">0.958</td><td align="center" valign="middle" rowspan="1" colspan="1">0.968</td><td align="center" valign="middle" rowspan="1" colspan="1">0.963</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">CBAM-TCN-SVM</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">98.3%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.980</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.984</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.982</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05230-t004" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05230-t004_Table 4</object-id><label>Table 4</label><caption><p>Four model evaluation indicators.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Evaluation Index</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">TCN</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">TCN-SVM</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">CBAM-TCN</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">CBAM-TCN-SVM</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Training time</td><td align="center" valign="middle" rowspan="1" colspan="1">64.251</td><td align="center" valign="middle" rowspan="1" colspan="1">63.965</td><td align="center" valign="middle" rowspan="1" colspan="1">101.275</td><td align="center" valign="middle" rowspan="1" colspan="1">97.956</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">F1 score</td><td align="center" valign="middle" rowspan="1" colspan="1">0.916</td><td align="center" valign="middle" rowspan="1" colspan="1">0.919</td><td align="center" valign="middle" rowspan="1" colspan="1">0.963</td><td align="center" valign="middle" rowspan="1" colspan="1">0.982</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Recall</td><td align="center" valign="middle" rowspan="1" colspan="1">0.916</td><td align="center" valign="middle" rowspan="1" colspan="1">0.921</td><td align="center" valign="middle" rowspan="1" colspan="1">0.968</td><td align="center" valign="middle" rowspan="1" colspan="1">0.984</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Accuracy rate</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">90.8%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">91.6%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">96.6%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">98.3%</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05230-t005" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05230-t005_Table 5</object-id><label>Table 5</label><caption><p>Four model evaluation indicators.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Number</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">TCN</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">CBAM</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">SVM</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Accuracy</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Precision</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Recall</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">F1 Score</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">&#215;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#215;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8730;</td><td align="center" valign="middle" rowspan="1" colspan="1">0.336</td><td align="center" valign="middle" rowspan="1" colspan="1">0.332</td><td align="center" valign="middle" rowspan="1" colspan="1">0.338</td><td align="center" valign="middle" rowspan="1" colspan="1">0.335</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8730;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#215;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#215;</td><td align="center" valign="middle" rowspan="1" colspan="1">0.908</td><td align="center" valign="middle" rowspan="1" colspan="1">0.916</td><td align="center" valign="middle" rowspan="1" colspan="1">0.916</td><td align="center" valign="middle" rowspan="1" colspan="1">0.916</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8730;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#215;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8730;</td><td align="center" valign="middle" rowspan="1" colspan="1">0.916</td><td align="center" valign="middle" rowspan="1" colspan="1">0.917</td><td align="center" valign="middle" rowspan="1" colspan="1">0.921</td><td align="center" valign="middle" rowspan="1" colspan="1">0.919</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">4</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8730;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8730;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#215;</td><td align="center" valign="middle" rowspan="1" colspan="1">0.966</td><td align="center" valign="middle" rowspan="1" colspan="1">0.958</td><td align="center" valign="middle" rowspan="1" colspan="1">0.968</td><td align="center" valign="middle" rowspan="1" colspan="1">0.963</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8730;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8730;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8730;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.983</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.980</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.984</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.982</td></tr></tbody></table></table-wrap></floats-group></article></pmc-articleset>