<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xml:lang="en" article-type="research-article" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="pmc-domain-id">1660</journal-id><journal-id journal-id-type="pmc-domain">sensors</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>Multidisciplinary Digital Publishing Institute  (MDPI)</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12431087</article-id><article-id pub-id-type="pmcid-ver">PMC12431087.1</article-id><article-id pub-id-type="pmcaid">12431087</article-id><article-id pub-id-type="pmcaiid">12431087</article-id><article-id pub-id-type="doi">10.3390/s25175335</article-id><article-id pub-id-type="publisher-id">sensors-25-05335</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Analysis of Surface EMG Signals to Control of a Bionic Hand Prototype with Its Implementation <xref rid="fn1-sensors-25-05335" ref-type="author-notes">&#8224;</xref></article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-7059-2118</contrib-id><name name-style="western"><surname>Pieprzycki</surname><given-names initials="A">Adam</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Resources" vocab-term-identifier="https://credit.niso.org/contributor-roles/resources/">Resources</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project administration</role><xref rid="c1-sensors-25-05335" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-8611-0838</contrib-id><name name-style="western"><surname>Kr&#243;l</surname><given-names initials="D">Daniel</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-5345-7800</contrib-id><name name-style="western"><surname>Srebro</surname><given-names initials="B">Bartosz</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-0754-4356</contrib-id><name name-style="western"><surname>Skobel</surname><given-names initials="M">Marcin</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name name-style="western"><surname>Fischer</surname><given-names initials="G">Georg</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-05335">Department of Computer Science, University of Applied Sciences in Tarnow, ul. Mickiewicza 8, 33-100 Tarnow, Poland; <email>d_krol@atar.edu.pl</email> (D.K.); <email>b_srebro@atar.edu.pl</email> (B.S.); <email>m_skobel@atar.edu.pl</email> (M.S.)</aff><author-notes><corresp id="c1-sensors-25-05335"><label>*</label>Correspondence: <email>a_pieprzycki@atar.edu.pl</email></corresp><fn id="fn1-sensors-25-05335"><label>&#8224;</label><p>This paper is an extended version of our paper published in Pieprzycki, A.; Krol, D.; Wawryka, P.; &#321;achut, K.; Hamera, M.; Srebro, B. Analysis of Surface EMG Signals to Control of a Bionic Hand Prototype. In Proceedings of the PP-RAI 2023 Conference, Lodz, Poland, 24&#8211;26 April 2023.</p></fn></author-notes><pub-date pub-type="epub"><day>28</day><month>8</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>9</month><year>2025</year></pub-date><volume>25</volume><issue>17</issue><issue-id pub-id-type="pmc-issue-id">496815</issue-id><elocation-id>5335</elocation-id><history><date date-type="received"><day>06</day><month>7</month><year>2025</year></date><date date-type="rev-recd"><day>01</day><month>8</month><year>2025</year></date><date date-type="accepted"><day>11</day><month>8</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>28</day><month>08</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>13</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-13 17:25:36.317"><day>13</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="sensors-25-05335.pdf"/><abstract><p>The primary objective of the presented study is to develop a comprehensive system for the acquisition of surface electromyographic (sEMG) data and to perform time&#8211;frequency analysis aimed at extracting discriminative features for the classification of hand gestures intended for the control of a simplified bionic hand prosthesis. The proposed system is designed to facilitate precise finger gesture execution in both prosthetic and robotic hand applications. This article outlines the methodology for multi-channel sEMG signal acquisition and processing, as well as the extraction of relevant features for gesture recognition using artificial neural networks (ANNs) and other well-established machine learning (ML) algorithms. Electromyographic signals were acquired using a prototypical LPCXpresso LPC1347 ARM Cortex M3 (NXP, Eindhoven, Holland) development board in conjunction with surface EMG sensors of the Gravity OYMotion SEN0240 type (DFRobot, Shanghai, China). Signal processing and feature extraction were carried out in the MATLAB 2024b environment, utilizing both the Fourier transform and the Hilbert&#8211;Huang transform to extract selected time&#8211;frequency characteristics of the sEMG signals. An artificial neural network (ANN) was implemented and trained within the same computational framework. The experimental protocol involved 109 healthy volunteers, each performing five predefined gestures of the right hand. The first electrode was positioned on the brachioradialis (BR) muscle, with subsequent channels arranged laterally outward from the perspective of the participant. Comprehensive analyses were conducted in the time domain, frequency domain, and time&#8211;frequency domain to evaluate signal properties and identify features relevant to gesture classification. The bionic hand prototype was fabricated using 3D printing technology with a PETG filament (Spectrum, P&#281;cice, Poland). Actuation of the fingers was achieved using six MG996R servo motors (TowerPro, Shenzhen, China), each with an angular range of <inline-formula><mml:math id="mm1" overflow="scroll"><mml:mrow><mml:msup><mml:mn>180</mml:mn><mml:mo>&#8728;</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>, controlled via a PCA9685 driver board (Adafruit, New York, NY, USA) connected to the main control unit.</p></abstract><kwd-group><kwd>EMG</kwd><kwd>bionic hand</kwd><kwd>artificial neural network (ANN)</kwd></kwd-group><funding-group><award-group><funding-source>University of Applied Sciences in Tarnow, Poland</funding-source><award-id>BAD/09/2020 PWSZ/PRWRs/0700-209 8/PN-U/2020</award-id></award-group><funding-statement>This research was funded by the internal grant BAD/09/2020 PWSZ/PRWRs/0700-209 8/PN-U/2020 from the University of Applied Sciences in Tarnow. The publication was co-financed by the University of Applied Sciences in Tarnow, Poland.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-05335"><title>1. Introduction</title><sec id="sec1dot1-sensors-25-05335"><title>1.1. Surface Electromyography sEMG</title><p>Electromyographic (EMG) signals are electrophysiological signals generated by muscles in response to stimulation from the nervous system. Among the nineteen muscles located in the forearm, ten are primarily responsible for flexion and extension at the metacarpophalangeal and interphalangeal joints of the fingers and thumb. The most relevant muscles in this context appear to be the flexor digitorum superficialis (FDS), the flexor digitorum profundus (FDP), and the extensor digitorum communis (EDC), as illustrated in <xref rid="sensors-25-05335-f001" ref-type="fig">Figure 1</xref>. EMG signals were acquired in accordance with the SENIAM (Surface Electromyography for the Non-Invasive Assessment of Muscles) guidelines [<xref rid="B1-sensors-25-05335" ref-type="bibr">1</xref>].</p><p>Electromyographic (EMG) analysis enables the assessment of electrical activity in muscles engaged during different phases of movement. The characteristics of the recorded signal&#8212;both in the time and frequency domains&#8212;are influenced by several factors, including the number of motor units within the electrode detection range (<xref rid="sensors-25-05335-f002" ref-type="fig">Figure 2</xref>), the type and diameter of muscle fibers, and the frequency of neural excitation that triggers muscle contraction. It must be emphasized that, due to the complexity of neuromuscular physiology, a direct linear relationship cannot be assumed between the amplitude of the EMG signal recorded from a given muscle and the force generated by that muscle.</p></sec><sec id="sec1dot2-sensors-25-05335"><title>1.2. Principles of Surface Electromyography (sEMG)</title><p>Surface EMG (sEMG) is a non-invasive technique that allows for the measurement of muscle activity through electrodes placed on the skin surface. As described by Merletti and Farina [<xref rid="B2-sensors-25-05335" ref-type="bibr">2</xref>], sEMG signals are generated by the summation of motor unit action potentials and are influenced by anatomical, physiological, and technical factors. These include inter-electrode distance, electrode size, placement, skin impedance, and crosstalk from nearby muscles. Signal characteristics such as amplitude, frequency content, and duration vary depending on the intensity of contraction and the muscle type [<xref rid="B3-sensors-25-05335" ref-type="bibr">3</xref>].</p></sec><sec id="sec1dot3-sensors-25-05335"><title>1.3. Importance, Applications, and Evolution of sEMG</title><p>Since its inception as a needle-based technique, EMG has evolved into a surface-based modality better suited for clinical and engineering applications. While intramuscular EMG offers high spatial resolution, sEMG provides a safer and more comfortable alternative for long-term and mobile measurements [<xref rid="B2-sensors-25-05335" ref-type="bibr">2</xref>,<xref rid="B4-sensors-25-05335" ref-type="bibr">4</xref>].</p><p>sEMG is widely used in various fields, including neurophysiology, biomechanics, rehabilitation, and biomedical engineering. It plays a central role in gesture recognition systems, human&#8211;machine interfaces, robotic control, and the development of myoelectric prostheses [<xref rid="B5-sensors-25-05335" ref-type="bibr">5</xref>,<xref rid="B6-sensors-25-05335" ref-type="bibr">6</xref>]. In clinical settings, sEMG helps evaluate neuromuscular disorders, monitor therapy outcomes, and support biofeedback-based interventions. Despite its advantages, limitations such as electrode placement sensitivity and signal contamination must be carefully considered [<xref rid="B4-sensors-25-05335" ref-type="bibr">4</xref>].</p></sec><sec id="sec1dot4-sensors-25-05335"><title>1.4. Prior Work on Forearm EMG Signal Analysis</title><p>The forearm is a common region for sEMG-based control due to the presence of multiple muscles responsible for fine motor control. Previous research, such as the work by Atzori et al. [<xref rid="B7-sensors-25-05335" ref-type="bibr">7</xref>], evaluated a wide range of features in the time and frequency domain extracted from multichannel EMG signals of the forearm for the purpose of controlling prosthetic hands. Their study emphasized the importance of robust feature extraction techniques and the impact of factors such as electrode configuration and inter-subject variability on classification performance.</p></sec><sec id="sec1dot5-sensors-25-05335"><title>1.5. Signal Processing Techniques for sEMG</title><p>EMG signal processing typically involves denoising, feature extraction, and classification. Time domain features like root mean square (RMS), zero-crossings, mean absolute value (MAV), and waveform length provide intuitive representations of muscle activity [<xref rid="B8-sensors-25-05335" ref-type="bibr">8</xref>]. Frequency domain analysis, especially via Fast Fourier Transform (FFT), offers insight into muscle fatigue and motor unit behavior.</p><p>In recent years, time&#8211;frequency methods, such as wavelet transforms, have gained popularity due to their ability to analyze non-stationary and dynamic EMG signals. These approaches enable localized tracking of muscle activation patterns and are particularly effective in gesture recognition and motion segmentation [<xref rid="B5-sensors-25-05335" ref-type="bibr">5</xref>,<xref rid="B8-sensors-25-05335" ref-type="bibr">8</xref>].</p></sec><sec id="sec1dot6-sensors-25-05335"><title>1.6. Summary and Motivation</title><p>Given the broad applicability and richness of sEMG signals, this study focuses on analyzing forearm sEMG data to support gesture recognition tasks. Understanding the physiological basis of EMG, its historical development, and the standard processing techniques provides a strong foundation for the proposed methodology (<xref rid="sensors-25-05335-f003" ref-type="fig">Figure 3</xref>).</p></sec></sec><sec id="sec2-sensors-25-05335"><title>2. Materials and Methods</title><sec id="sec2dot1-sensors-25-05335"><title>2.1. Gesture Signals Collecting&#8212;Hardware</title><p>Electromyographic signals were acquired using a prototypical LPCXpresso LPC1347 ARM Cortex M3 (NXP, Eindhoven, Holland) development board. The system is based on a 32-bit ARM Cortex-M3 microprocessor operating at a clock frequency of 72 MHz. It features a 12-bit successive approximation register (SAR) analog-to-digital converter (ADC) equipped with an 8-channel input multiplexer and a hardware sequencer for automatic channel switching [<xref rid="B9-sensors-25-05335" ref-type="bibr">9</xref>].</p><p>Surface electromyographic (sEMG) signals were acquired using Gravity OYMotion SEN0240 (DFRobot, Shanghai, China) sensors (dimensions: 3.5 &#215; 2.2 cm) (<xref rid="sensors-25-05335-f002" ref-type="fig">Figure 2</xref>) connected to dedicated ports of the ADC multiplexer. Each sensor consists of a triple dry electrode module and a signal amplification unit with a fixed gain of 60 dB. The sensor integrates a signal conditioning circuit that includes both amplification and analog filtering. It amplifies low-amplitude sEMG signals within the range of &#177;1.5 mV by a factor of approximately 1000 and suppresses noise&#8212;particularly power line interference&#8212;via a differential input and analog filter design. The analog output is centered around a reference voltage of 1.5 V, with a total output voltage range of 0&#8211;3.0 V [<xref rid="B10-sensors-25-05335" ref-type="bibr">10</xref>].</p><p>The use of analog sEMG sensors is non-invasive and user-friendly, making them suitable for applications in human&#8211;computer interaction. The dry metal electrodes offer long-term usability and ease of application. Additionally, the sensors feature a differential input with a high common-mode rejection ratio (CMRR), enhancing signal quality in noisy environments.</p><p>To enable continuous acquisition, real-time visualization, and multi-channel recording of the EMG signals in WAVE format via a USB 2.0 interface, a dedicated application was developed in C++ using the Qt 5.12.12 framework.</p></sec><sec id="sec2dot2-sensors-25-05335"><title>2.2. Collecting sEMG Signal Selected Gestures</title><p>Eight surface electrodes for electromyographic (EMG) signal acquisition were positioned at the mid-forearm level, as illustrated in <xref rid="sensors-25-05335-f004" ref-type="fig">Figure 4</xref>.</p><p>The first (1) electrode <xref rid="sensors-25-05335-f004" ref-type="fig">Figure 4</xref> was carefully placed over the BR muscle (m. brachioradialis) <xref rid="sensors-25-05335-f001" ref-type="fig">Figure 1</xref>. The remaining electrodes (2&#8211;8) were placed on a prototype band, as shown in <xref rid="sensors-25-05335-f004" ref-type="fig">Figure 4</xref> and <xref rid="sensors-25-05335-f005" ref-type="fig">Figure 5</xref>, using eight sensors arranged in a circle. Positioning of sensors on the forearm (over selected muscles) is shown in <xref rid="sensors-25-05335-f001" ref-type="fig">Figure 1</xref>.</p><p>The electrode placement was carefully selected, as the spatial configuration significantly affects both the accuracy of signal processing and the performance of machine learning (ML) algorithms and artificial neural networks (ANNs) used for hand gesture recognition.</p><p>Prior to each measurement session, reference noise levels were recorded. Following electrode attachment, a stabilization period of approximately 5&#8211;20 s was required to ensure optimal electrical contact with the skin. It should be noted that electromagnetic interference (EMI) from power supply wiring within walls may affect the quality of the recorded EMG signals (<xref rid="sensors-25-05335-t001" ref-type="table">Table 1</xref>).</p><p>All sEMG sensors were placed in accordance with the SENIAM guidelines (Surface Electromyography for the Non-Invasive Assessment of Muscles) [<xref rid="B1-sensors-25-05335" ref-type="bibr">1</xref>], ensuring standardization and reliability of the measurements.</p><p>The following hand gestures were arbitrarily selected for analysis and utilized in the surface electromyography (sEMG) study:<list list-type="simple"><list-item><label>1.</label><p>Straight fingers&#8212;<xref rid="sensors-25-05335-f006" ref-type="fig">Figure 6</xref>a;</p></list-item><list-item><label>2.</label><p>Clenched hand&#8212;<xref rid="sensors-25-05335-f006" ref-type="fig">Figure 6</xref>b;</p></list-item><list-item><label>3.</label><p>Victory&#8212;<xref rid="sensors-25-05335-f006" ref-type="fig">Figure 6</xref>c;</p></list-item><list-item><label>4.</label><p>The middle fingers straight&#8212;<xref rid="sensors-25-05335-f006" ref-type="fig">Figure 6</xref>d;</p></list-item><list-item><label>5.</label><p>OK gesture&#8212;<xref rid="sensors-25-05335-f006" ref-type="fig">Figure 6</xref>e.</p></list-item></list></p><fig position="anchor" id="sensors-25-05335-f006" orientation="portrait"><label>Figure 6</label><caption><p>(<bold>a</bold>) Gesture straight fingers. (<bold>b</bold>) Gesture clenched hand. (<bold>c</bold>) Gesture victory. (<bold>d</bold>) Gesture middle fingers straight. (<bold>e</bold>) Gesture OK. Reproduced with permission from author P. Wawryka [<xref rid="B12-sensors-25-05335" ref-type="bibr">12</xref>].</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05335-g006a.jpg"/><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05335-g006b.jpg"/></fig></sec><sec id="sec2dot3-sensors-25-05335"><title>2.3. Software</title><p>A dedicated software application for data acquisition was developed using the C++ programming language within the Qt Creator 5.0.2 integrated development environment. This application enables real-time visualization of electromyographic (EMG) signals and their recording into a multi-channel WAVE file format [<xref rid="B13-sensors-25-05335" ref-type="bibr">13</xref>].</p><p>The Hilbert&#8211;Huang Transform (HHT) [<xref rid="B14-sensors-25-05335" ref-type="bibr">14</xref>,<xref rid="B15-sensors-25-05335" ref-type="bibr">15</xref>] was applied in the MATLAB 2024b environment to extract selected features of the EMG signals [<xref rid="B13-sensors-25-05335" ref-type="bibr">13</xref>]. Additional feature extraction procedures were also carried out using MATLAB 2024b software [<xref rid="B16-sensors-25-05335" ref-type="bibr">16</xref>].</p><p>Machine learning models, including regularized logistic regression and artificial neural networks (ANNs), were implemented using JMP Student Edition 18.2.0 [<xref rid="B17-sensors-25-05335" ref-type="bibr">17</xref>].</p><p>The study was conducted on a cohort of 109 healthy volunteers, with the objective of classifying four predefined gestures of the right hand. Electrode No. 1 was positioned on the brachioradialis (BR) muscle (<xref rid="sensors-25-05335-f001" ref-type="fig">Figure 1</xref>), with subsequent electrodes placed in sequence laterally outward from the participant&#8217;s perspective (<xref rid="sensors-25-05335-f004" ref-type="fig">Figure 4</xref>).</p></sec></sec><sec id="sec3-sensors-25-05335"><title>3. Processing EMG Signal Features</title><sec id="sec3dot1-sensors-25-05335"><title>3.1. Feature Extraction</title><p>In the initial phase of the analysis, electromyographic signals acquired from the bionic hand were subjected to a feature extraction process. The purpose of this step was to identify salient signal characteristics that could be utilized as input features for subsequent processing and analysis.</p><p>Depending on the computational methodology, the extracted features can be categorized into three distinct groups: features obtained directly from the raw signal, features derived from the signal envelope, and features extracted through signal decomposition techniques (<xref rid="sensors-25-05335-t002" ref-type="table">Table 2</xref>).</p><p>In this study, EMG signals were acquired using an eight-channel measurement system. Data acquisition was performed for 18 defined factors, each representing different states or tasks. Consequently, eight data channels were obtained for each of the 18 factors, resulting in a data set comprising 144 scalar features derived from unprocessed EMG signals.</p><p>Additionally, 16 additionalnal scalar features were incorporated into the set of features. These additional features represent the mean and standard deviation calculated from the upper-range envelope of the signal for each of the eight individual channels.</p><p>An additional set of features was derived from the decomposition (<xref rid="sensors-25-05335-f007" ref-type="fig">Figure 7</xref>) of the signal using Empirical Mode Decomposition (EMD) [<xref rid="B18-sensors-25-05335" ref-type="bibr">18</xref>] and Variational Mode Decomposition (VMD) [<xref rid="B19-sensors-25-05335" ref-type="bibr">19</xref>]. From the EMD decomposition, the seven fundamental intrinsic mode functions (IMFs) were selected, while five modes were chosen from the VMD decomposition for each of the eight electromyographic (EMG) signal channels. This resulted in a total of 96 components. Subsequently, the energy and approximate entropy were calculated for each of these components, resulting in a final set of 192 novel features.</p><p>The comprehensive feature set consisted of 352 distinct scalar features, encompassing a diverse range of information extracted from EMG signals. This set included 144 features derived from unprocessed EMG data, 16 features representing the mean and standard deviation of the upper-range signal envelope, and 192 features obtained through EMD and VMD analysis. These features collectively aimed to capture the multifaceted characteristics of muscle activity, providing a robust foundation for subsequent analytical and modeling procedures.</p></sec><sec id="sec3dot2-sensors-25-05335"><title>3.2. Data Preprocessing</title><p>The data set, containing 362 instances, was partitioned into training, validation, and test subsets with a distribution of 78% for training, 11% for validation, and 11% for testing. The subsets were randomly selected, maintaining the representation of all five gesture classes within each subset.</p><p>Due to the significant class imbalance observed within the gesture dataset, the Receiver Operating Characteristic Area Under the Curve (ROC AUC) was used as a primary evaluation metric for predictive models. This metric was selected to provide a robust assessment of model performance, where it is particularly useful in scenarios where traditional accuracy measures may be misleading due to uneven class distributions. The ROC AUC assesses the model&#8217;s ability to discriminate between classes across various threshold settings.</p></sec><sec id="sec3dot3-sensors-25-05335"><title>3.3. Building Models</title><p>Research has consistently shown that advanced machine learning algorithms can achieve high accuracy in classifying electromyographic (EMG) signals for the identification of specific hand movements [<xref rid="B20-sensors-25-05335" ref-type="bibr">20</xref>]. Building on this, investigations were conducted to evaluate various machine learning models, specifically emphasizing regularized and dimensionality-reduced logistic regression models, alongside neural network classifiers. While the classification performance of the selected methods was largely comparable, neural network classifiers demonstrated a marginal superiority. Nevertheless, logistic regression models present distinct advantages, including notable resistance to overfitting, simplicity of implementation, computational efficiency, and enhanced interpretability. Collectively, these attributes render logistic regression a highly appropriate solution for controlling bionic prostheses.</p><p>Among the logistic regression models, regularized variants employing L1 (LASSO&#8212;Least Absolute Shrinkage and Selection Operator [<xref rid="B21-sensors-25-05335" ref-type="bibr">21</xref>]), Ridge Regression (L2) [<xref rid="B22-sensors-25-05335" ref-type="bibr">22</xref>] and Elastic Net [<xref rid="B23-sensors-25-05335" ref-type="bibr">23</xref>] penalties were evaluated. These regularization techniques were implemented to mitigate the risk of overfitting, particularly in scenarios with a high number of input features relative to the sample size. By adding a penalty term to the loss function, these methods constrain the magnitude of the coefficient estimates. This helps in reducing the impact of multicollinearity.</p><p>The LASSO method modifies the standard cost function (typically the sum of squared residuals for linear regression or negative log-likelihood for logistic regression) by adding an L1 penalty (L1 norm) to the sum of the absolute values of the regression coefficients.<disp-formula id="FD1-sensors-25-05335"><label>(1)</label><mml:math id="mm2" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:munder><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:msub><mml:mi>&#946;</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>&#946;</mml:mi></mml:mrow></mml:munder><mml:mfenced separators="" open="{" close="}"><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#8722;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>&#946;</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mi>&#946;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>&#955;</mml:mi><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi>&#946;</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where</p><list list-type="bullet"><list-item><p><inline-formula><mml:math id="mm3" overflow="scroll"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the observed value of the dependent variable for the <italic toggle="yes">i</italic>-th observation;</p></list-item><list-item><p><inline-formula><mml:math id="mm4" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the vector of independent variables for the <italic toggle="yes">i</italic>-th observation;</p></list-item><list-item><p><inline-formula><mml:math id="mm5" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#946;</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is the intercept term;</p></list-item><list-item><p><inline-formula><mml:math id="mm6" overflow="scroll"><mml:mrow><mml:mi>&#946;</mml:mi></mml:mrow></mml:math></inline-formula> is the vector of regression coefficients for the predictors;</p></list-item><list-item><p><italic toggle="yes">n</italic> is the number of observations;</p></list-item><list-item><p><italic toggle="yes">p</italic> is the number of predictors;</p></list-item><list-item><p><inline-formula><mml:math id="mm7" overflow="scroll"><mml:mrow><mml:mi>&#955;</mml:mi></mml:mrow></mml:math></inline-formula> (lambda) is the regularization parameter (penalty strength), controlling the degree of coefficient shrinkage, where a larger <inline-formula><mml:math id="mm8" overflow="scroll"><mml:mrow><mml:mi>&#955;</mml:mi></mml:mrow></mml:math></inline-formula> indicates a stronger penalty;</p></list-item><list-item><p><inline-formula><mml:math id="mm9" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi>&#946;</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the L1 penalty, representing the sum of the absolute values of the coefficients.</p></list-item></list><p>This formula can be simplified to minimize a cost function (also known as a loss function). This cost function combines the prediction error with a regularization term as defined below:<disp-formula id="FD2-sensors-25-05335"><label>(2)</label><mml:math id="mm10" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>A</mml:mi><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>O</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mspace width="3.33333pt"/><mml:mi>E</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mi>&#955;</mml:mi><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi>&#946;</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula> For the LASSO regularization, a penalty fraction (<inline-formula><mml:math id="mm11" overflow="scroll"><mml:mrow><mml:mi>&#955;</mml:mi></mml:mrow></mml:math></inline-formula>) of 0.001 was applied.</p><p>Elastic Net combines the L1 penalty of LASSO with an L2 penalty (sum of squared coefficients, <inline-formula><mml:math id="mm12" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8721;</mml:mo><mml:msubsup><mml:mi>&#946;</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>), which is characteristic of Ridge Regression. Elastic Net offers a balance between feature selection and coefficient shrinkage, potentially outperforming either L1 or L2 alone in situations with groups of correlated variables.<disp-formula id="FD3-sensors-25-05335"><label>(3)</label><mml:math id="mm13" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:munder><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:msub><mml:mi>&#946;</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>&#946;</mml:mi></mml:mrow></mml:munder><mml:mfenced separators="" open="{" close="}"><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#8722;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>&#946;</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mi>&#946;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>&#955;</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mi>&#945;</mml:mi><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi>&#946;</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mi>&#945;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:msubsup><mml:mi>&#946;</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfenced></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where</p><list list-type="bullet"><list-item><p><inline-formula><mml:math id="mm14" overflow="scroll"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm15" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm16" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#946;</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm17" overflow="scroll"><mml:mrow><mml:mi>&#946;</mml:mi></mml:mrow></mml:math></inline-formula>, <italic toggle="yes">n</italic>, and <italic toggle="yes">p</italic> have the same meaning as in LASSO;</p></list-item><list-item><p><inline-formula><mml:math id="mm18" overflow="scroll"><mml:mrow><mml:mi>&#955;</mml:mi></mml:mrow></mml:math></inline-formula> (lambda) is the regularization parameter, controlling the overall penalty strength;</p></list-item><list-item><p><inline-formula><mml:math id="mm19" overflow="scroll"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow></mml:math></inline-formula> (alpha) is the mixing parameter, in the range of <inline-formula><mml:math id="mm20" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>;</p></list-item><list-item><p>If <inline-formula><mml:math id="mm21" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#945;</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, Elastic Net becomes LASSO (L1 penalty only);</p></list-item><list-item><p>If <inline-formula><mml:math id="mm22" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#945;</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, Elastic Net becomes Ridge (L2 penalty only);</p></list-item><list-item><p>For <inline-formula><mml:math id="mm23" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>&#945;</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, Elastic Net is a combination of both penalties;</p></list-item><list-item><p><inline-formula><mml:math id="mm24" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi>&#946;</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the L1 penalty;</p></list-item><list-item><p><inline-formula><mml:math id="mm25" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:msubsup><mml:mi>&#946;</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> is the L2 penalty (sum of squared coefficients).</p></list-item></list><p>Consistent with other regularization techniques, Elastic Net regularization also seeks to minimize a cost function, whose formulation can likewise be simplified as follows:<disp-formula id="FD4-sensors-25-05335"><label>(4)</label><mml:math id="mm26" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>N</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mspace width="3.33333pt"/><mml:mi>E</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mi>&#955;</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mi>&#945;</mml:mi><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi>&#946;</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mi>&#945;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:msubsup><mml:mi>&#946;</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula> Elastic Net regularization was performed with an <inline-formula><mml:math id="mm27" overflow="scroll"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow></mml:math></inline-formula> value of 0.99 and a penalty fraction (<inline-formula><mml:math id="mm28" overflow="scroll"><mml:mrow><mml:mi>&#955;</mml:mi></mml:mrow></mml:math></inline-formula>) of 0.001.</p><p>The performance of these regularized logistic regression models was compared to assess their suitability for the specific classification task, considering factors such as predictive accuracy, model complexity, and interpretability.</p><p>In addition to the regularization methods, a feature selection technique employing Recursive Feature Elimination (RFE [<xref rid="B24-sensors-25-05335" ref-type="bibr">24</xref>]) was also implemented. RFE is a wrapper-type feature selection algorithm that operates by iteratively fitting the model and removing the least important features based on the model&#8217;s coefficient magnitudes (in the case of linear models like logistic regression). This process is repeated until the desired number of features is reached. The rationale behind employing RFE was to identify the most informative subset of features for the classification task, potentially improving model parsimony, reducing computational cost, and enhancing generalization performance by removing noisy or redundant variables. A modification to the RFE method was introduced, wherein the selected feature subset maximized the minimum F1-score obtained for any category. Specifically, the objective was to find the subset of features that maximized the F1 score as follows:<disp-formula id="FD5-sensors-25-05335"><label>(5)</label><mml:math id="mm29" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mi>feature</mml:mi><mml:mi>subset</mml:mi></mml:mrow></mml:munder><mml:mfenced separators="" open="(" close=")"><mml:munder><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>&#8712;</mml:mo><mml:mi>categories</mml:mi></mml:mrow></mml:munder><mml:mi>F</mml:mi><mml:msub><mml:mn>1</mml:mn><mml:mi>c</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>
where F1c represents the F1-score for category c.</p><p>Within the experimental framework, neural network classifier models, in addition to regression models, exhibited significant performance. Therefore, a neural network classifier model was implemented, comprising 10 neurons employing the tanh activation function in the hidden layer and 5 neurons using the tanh activation function in the output layer (<xref rid="sensors-25-05335-f008" ref-type="fig">Figure 8</xref>).</p><p>In JMP, hyperparameters were primarily determined through internal validation mechanisms within the platform, such as cross-validation or validation set performance, which JMP automatically optimizes. This approach allows the software to iteratively search for and select the parameter values that yield the best model performance based on the chosen validation metric. JMP, like many advanced statistical and analytical software packages, typically does not disclose the specific fixed name of the optimization algorithm used &#8220;under the hood&#8221; for its artificial neural networks (ANN). Instead, it focuses on delivering optimized results and offers the user certain configuration options that influence the optimization process.</p><p>Although direct access to neural network hyperparameters was unavailable, a significant benefit emerged from the unified testing environment provided by JMP. This enabled a more robust and comparable evaluation of the machine learning algorithms.</p><p>Furthermore, an exploration of signal classification capabilities was conducted employing GRU and LSTM architectures applied to unprocessed signal data. However, the insufficient sample size within the data set limited the ability to establish the effectiveness of these network models.</p></sec></sec><sec id="sec4-sensors-25-05335"><title>4. Implementation Simple Bionic Hand</title><sec><title>Model of Bionic Hand&#8212;Hardware</title><p>The bionic hand model (<xref rid="sensors-25-05335-f009" ref-type="fig">Figure 9</xref> and <xref rid="sensors-25-05335-f010" ref-type="fig">Figure 10</xref>) was made using a 3D printer (Prusa i3 MK3S+, Prague, Czech Republic) equipped with the Multi Material 2 upgrade. All components of the model were designed by Gael Langevin [<xref rid="B25-sensors-25-05335" ref-type="bibr">25</xref>], who made them publicly available on the Thingiverse platform under a Creative Commons license.</p><p>Individual parts of the prototype were printed using Spectrum PETG filament (1.75 mm diameter, Silver Star color). This material was selected due to its favorable mechanical properties, including high durability, flexibility, and resistance to moisture-induced degradation. The assembled components were joined using appropriate fasteners and adhesive to ensure structural integrity.</p><p>The bionic hand is actuated by six Tower Pro MG996R servo motors, each with an angular range of 180&#176;, and controlled via a PCA9685 PWM driver board (Adafruit 815) connected to the main controller. The first servo is responsible for wrist articulation, while the remaining five control the individual fingers by tensioning or releasing braided fishing lines.</p><p>To ensure reliable actuation and minimize elastic deformation, high-strength braided fishing line (PowerPro Spectra, 0.76 mm diameter, tensile strength 90 kg) was used. Each line was routed through dedicated guide holes to prevent tangling. In order to maintain consistent tension in the tendons of each finger, return springs were incorporated into the tensioning mechanism.</p><p>The servo control system was integrated with the same LPC1347 microcontroller board that was used during the initial stages for surface electromyography (sEMG) signal acquisition, enabling a compact and unified hardware architecture.</p><p>Each servo motor was individually calibrated to define precise initial and terminal positions for each finger. Finger flexion is achieved by varying the servo positions, resulting in proportional joint articulation. When all servo motors are set to their zero-angle positions, the hand assumes a fully open posture, which serves as the system&#8217;s reference configuration.</p></sec></sec><sec sec-type="results" id="sec5-sensors-25-05335"><title>5. Results and Discussion</title><p>The experiment assessed the effectiveness of recognizing five distinct hand gestures using both regularized logistic regression models and artificial neural networks (ANNs). These two methods demonstrated superior classification performance compared to other initially evaluated algorithms, including k-Nearest Neighbors (k-NN), Support Vector Machines (SVMs), Random Forests, and Decision Trees.</p><p>The analysis was based on complete 5-second signal sequences, from which scalar features were subsequently extracted. The use of full-length sequences allowed for improved model fitting to representative patterns in the EMG signals, including potential artifacts that could arise during the real-world operation of the bionic hand.</p><p>The results indicate that both artificial neural networks (ANNs) employing sigmoidal activation functions and regularized logistic regression models achieved comparable performance (see <xref rid="sensors-25-05335-t003" ref-type="table">Table 3</xref> and <xref rid="sensors-25-05335-t004" ref-type="table">Table 4</xref>). Neural networks exhibited a slightly greater tendency to overfit the training data. Additionally, the ANNs utilized the full set of available features, whereas the regularized models selected a subset&#8212;103 features in the case of LASSO regression and 135 features with Elastic Net regularization.</p><p>Overall, the most favorable results were achieved through the application of logistic regression with Elastic Net regularization. Considering the lowest classification accuracies across gestures, LASSO and Elastic Net yielded the highest values. It is also pertinent to note that the performance of the ANNs varied depending on the local minimum of the loss function identified by the optimization algorithm. The table presents the optimal outcome attained across multiple experimental runs, which consequently positions the results obtained for the logistic regression methods in a more advantageous perspective.</p><p>The absence of a significant advantage of ANNs over regression methods on the test data suggests that Elastic Net or LASSO are the recommended models for practical application (see <xref rid="sensors-25-05335-f011" ref-type="fig">Figure 11</xref> and <xref rid="sensors-25-05335-f012" ref-type="fig">Figure 12</xref>). Furthermore, the high generalization capabilities inherent in regularized regression models, stemming from their propensity to avoid overfitting the data, further support their adoption. Moreover, regression models offer transparency, ease of interpretation, and straightforward implementation on the bionic hand&#8217;s control system. These models also possess a significantly smaller computational footprint, thereby enabling a more rapid response of the bionic hand to EMG signals.</p><p>A primary limitation of employing neural networks in this study lies in their substantial demand for diverse and extensive datasets, the acquisition of which necessitates considerable time and financial resources without providing an absolute guarantee of successful implementation.</p><p>The ElasticNet model, as demonstrated in the provided example, incorporated nearly all features enumerated in <xref rid="sensors-25-05335-t001" ref-type="table">Table 1</xref> during its construction. Notably, the features Kurtosis, Approximate Entropy, and Energy were entirely excluded from the model training process. All other features participated to a greater or lesser extent in the training process of the ElasticNet model.</p><p>This study employed numerous features for constructing the Elastic Net regression model, from which several statistically significant ones were identified. The assessment of statistical significance was based on rejecting the null hypothesis of a zero regression coefficient (with a <italic toggle="yes">p</italic>-value below 0.05).</p><p>The most significant predictors, exhibiting non-zero coefficients in the model, include the following:<list list-type="bullet"><list-item><p>Signal skewness in channel 3.</p></list-item><list-item><p>Mean signal value in channel 1.</p></list-item><list-item><p>Entropy of the first intrinsic mode function (IMF) from VMD decomposition in channel 8.</p></list-item><list-item><p>Mean signal value in channel 4.</p></list-item><list-item><p>Mean signal frequency in channel 6.</p></list-item><list-item><p>Energy of the fifth IMF from EMD decomposition in channel 4.</p></list-item><list-item><p>Correlation Dimension in channel 3.</p></list-item><list-item><p>Total Harmonic Distortion (THD) in channel 6.</p></list-item></list></p><p>These findings indicate that the most influential factors in the model were derived from data originating in channels 1, 3, 4, 6, and 8 (<xref rid="sensors-25-05335-f001" ref-type="fig">Figure 1</xref>). A detailed description of all utilized features is beyond the scope of this section. The diverse nature of the identified features&#8212;ranging from statistical moments (skewness, mean) to spectral (frequency, THD) and decomposition-based (IMF entropy, energy) as well as non-linear dynamics (Correlation Dimension) metrics&#8212;underscores the complexity of the underlying process and the necessity of a multi-faceted approach to feature extraction.</p><p>In the LASSO regression model, twelve predictors demonstrated statistical significance, with their <italic toggle="yes">p</italic>-values falling below the 0.05 threshold. The list of these significant predictors is as follows (those also identified in the Elastic Net model are italicized):<list list-type="bullet"><list-item><p>Mean upper envelope of the signal in channel 5.</p></list-item><list-item><p>Correlation Dimension in channel 2.</p></list-item><list-item><p>Signal skewness in channel 3.</p></list-item><list-item><p>Entropy of the first intrinsic mode function (IMF) from VMD decomposition in channel 8.</p></list-item><list-item><p>Mean signal value in channel 1.</p></list-item><list-item><p>Mean signal frequency in channel 6.</p></list-item><list-item><p>Shape Factor in channel 1.</p></list-item><list-item><p>Correlation Dimension in channel 3.</p></list-item><list-item><p>Mean signal value in channel 4.</p></list-item><list-item><p>Energy of the fifth IMF from EMD decomposition in channel 4.</p></list-item><list-item><p>Energy of the first IMF from VMD decomposition in channel 6.</p></list-item><list-item><p>Total Harmonic Distortion (THD) in channel 6.</p></list-item></list></p><p>The identification of these statistically significant predictors in the LASSO model highlights the most influential features contributing to the model&#8217;s predictive power. The substantial overlap with features selected by the Elastic Net model (8 out of 12) suggests a robust set of key indicators across both regularization techniques. This consistency underscores the reliability of these particular features in capturing the underlying patterns within the data. Furthermore, the inclusion of additional unique features by the LASSO model, such as the mean upper envelope in channel 5 and the form factor in channel 1, indicates that while core predictive elements are shared, each regularization method may prioritize slightly different aspects of the data&#8212;potentially due to their distinct penalty functions (L1 for LASSO&#8217;s sparsity vs. combined L1/L2 for Elastic Net&#8217;s grouping effect).</p></sec><sec sec-type="conclusions" id="sec6-sensors-25-05335"><title>6. Conclusions</title><p>In summary, although artificial neural networks (ANNs) exhibited comparable or, in certain cases, marginally superior performance in gesture classification, several considerations advocate for the use of regularized logistic regression models&#8212;specifically Elastic Net and LASSO&#8212;in the practical implementation of bionic hand control based on EMG signals. The absence of a definitive advantage of ANNs on the test dataset, combined with their intrinsic dependence on large and diverse training datasets&#8212;whose acquisition is both resource-intensive and does not ensure optimal performance&#8212;constitutes a significant practical limitation.</p><p>Conversely, regularized regression models constitute a compelling alternative due to their superior generalization capabilities, which reduce the risk of overfitting&#8212;an issue more prominently observed in the evaluated artificial neural networks. Moreover, the intrinsic transparency, interpretability, and ease of implementation of these models within the bionic hand control system represent significant advantages. Their lower computational demands enable more rapid processing, thereby facilitating a potentially critical real-time response of the prosthetic limb to the user&#8217;s intended gestures&#8212;an essential requirement for practical applications.</p><p>Conclusions drawn from a review of advancements in robotic upper-limb prostheses [<xref rid="B26-sensors-25-05335" ref-type="bibr">26</xref>] indicate that a major limitation of machine learning methods is their black-box nature coupled with high computational demands. The application of effective models based on regularized logistic regression addresses these fundamental challenges inherent to conventional ML approaches.</p><p>Considering these factors&#8212;particularly the trade-offs between performance, data requirements, interpretability, implementability, and real-time responsiveness&#8212;regularized logistic regression methods, notably Elastic Net and LASSO, emerge as a more pragmatic and potentially efficacious choice for controlling bionic hands in this context.</p><p>The classification accuracy of gestures was substantially improved compared to the initial study [<xref rid="B11-sensors-25-05335" ref-type="bibr">11</xref>], owing to an expanded feature set employed to characterize EMG signals. An additional advantage of this increased feature dimensionality was the feasibility of applying efficient logistic regression techniques that demonstrated competitive performance relative to artificial neural networks (ANNs). Furthermore, the evaluation methodology for gesture classification was revised from accuracy-based metrics [<xref rid="B11-sensors-25-05335" ref-type="bibr">11</xref>] to the Receiver Operating Characteristic (ROC) curve and Area Under the Curve (AUC). This shift to more robust model quality indicators provides a better representation of classification performance, especially when addressing imbalanced datasets.</p><p>A detailed analysis of feature extraction methods contributing to the development of controllable prosthetic hands has been conducted [<xref rid="B27-sensors-25-05335" ref-type="bibr">27</xref>]. Beyond applications in computer or mobile device gesture control, research in this domain holds potential for prostheses addressing hand hemimelia. Such prosthetic systems could be further enhanced by incorporating modules supported by Inertial Measurement Units (IMUs) to detect hand rotation.</p><p>All experiments were performed using MATLAB 2024b [<xref rid="B16-sensors-25-05335" ref-type="bibr">16</xref>], JMP Student Edition 18.2.0 [<xref rid="B17-sensors-25-05335" ref-type="bibr">17</xref>], and Python 3.13 software, with JMP Student Edition 18.2.0 additionally employed for ROC AUC visualization.</p></sec></body><back><ack><title>Acknowledgments</title><p>The authors are grateful to Marcin Krawczyk, Piotr Wawryka, Katarzyna Srebro, and Mateusz Hamera for their fruitful suggestions and assistance during signal collection.</p></ack><fn-group><fn><p><bold>Disclaimer/Publisher&#8217;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><notes><title>Author Contributions</title><p>Conceptualization, A.P. and D.K.; methodology, A.P.; software, A.P. and D.K.; validation, A.P. and M.S.; formal analysis, M.S.; investigation, A.P. and B.S.; resources, D.K. and B.S.; data curation, A.P. and M.S.; writing&#8212;original draft preparation, A.P., B.S., and M.S.; writing&#8212;review and editing, A.P., M.S., and B.S.; visualization, A.P.; supervision, M.S.; project administration, A.P.; funding acquisition, D.K. and A.P. All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Institutional Review Board Statement</title><p>The research protocol was approved of by the local Bioethics Committee pursuant to Resolution 6/0177/2019, and all research procedures were carried out in compliance with the Helsinki Declaration.</p></notes><notes><title>Informed Consent Statement</title><p>Informed consent was obtained from all subjects involved in the study.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>The datasets used and analysed during the current study available from the corresponding author on reasonable request.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflicts of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-25-05335"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hermens</surname><given-names>H.J.</given-names></name><name name-style="western"><surname>Freriks</surname><given-names>B.</given-names></name><name name-style="western"><surname>Disselhorst-Klug</surname><given-names>C.</given-names></name><name name-style="western"><surname>Rau</surname><given-names>G.</given-names></name></person-group><article-title>Development of recommendations for SEMG sensors and sensor placement procedures</article-title><source>J. Electromyogr. Kinesiol.</source><year>2000</year><volume>10</volume><fpage>361</fpage><lpage>374</lpage><pub-id pub-id-type="doi">10.1016/S1050-6411(00)00027-4</pub-id><pub-id pub-id-type="pmid">11018445</pub-id></element-citation></ref><ref id="B2-sensors-25-05335"><label>2.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Merletti</surname><given-names>R.</given-names></name><name name-style="western"><surname>Farina</surname><given-names>D.</given-names></name></person-group><source>Surface Electromyography: Physiology, Engineering and Applications</source><publisher-name>John Wiley &amp; Sons</publisher-name><publisher-loc>Hoboken, NJ, USA</publisher-loc><year>2016</year></element-citation></ref><ref id="B3-sensors-25-05335"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Farina</surname><given-names>D.</given-names></name><name name-style="western"><surname>Merletti</surname><given-names>R.</given-names></name></person-group><article-title>Principles of surface electromyography: Interpretation of the signal and applications</article-title><source>Exerc. Sport Sci. Rev.</source><year>2004</year><volume>32</volume><fpage>128</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1097/00003677-200407000-00006</pub-id></element-citation></ref><ref id="B4-sensors-25-05335"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vigotsky</surname><given-names>A.D.</given-names></name><name name-style="western"><surname>Halperin</surname><given-names>I.</given-names></name><name name-style="western"><surname>Lehman</surname><given-names>G.J.</given-names></name><name name-style="western"><surname>Trajano</surname><given-names>G.S.</given-names></name><name name-style="western"><surname>Vieira</surname><given-names>T.M.M.</given-names></name></person-group><article-title>Surface electromyography: What limits its use in exercise and sport physiology?</article-title><source>Front. Physiol.</source><year>2017</year><volume>8</volume><elocation-id>65</elocation-id><pub-id pub-id-type="doi">10.3389/fphys.2017.00065</pub-id><pub-id pub-id-type="pmid">29354060</pub-id><pub-id pub-id-type="pmcid">PMC5758546</pub-id></element-citation></ref><ref id="B5-sensors-25-05335"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Phinyomark</surname><given-names>A.</given-names></name><name name-style="western"><surname>Khushaba</surname><given-names>R.N.</given-names></name><name name-style="western"><surname>Scheme</surname><given-names>E.J.</given-names></name></person-group><article-title>Feature extraction and selection for myoelectric control based on wearable EMG sensors</article-title><source>Sensors</source><year>2018</year><volume>18</volume><elocation-id>1615</elocation-id><pub-id pub-id-type="doi">10.3390/s18051615</pub-id><pub-id pub-id-type="pmid">29783659</pub-id><pub-id pub-id-type="pmcid">PMC5982518</pub-id></element-citation></ref><ref id="B6-sensors-25-05335"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Farina</surname><given-names>D.</given-names></name><name name-style="western"><surname>Enoka</surname><given-names>R.M.</given-names></name></person-group><article-title>The extraction of neural strategies from the surface EMG: 2004&#8211;2024</article-title><source>J. Appl. Physiol.</source><year>2025</year><volume>138</volume><fpage>1081</fpage><lpage>1093</lpage><pub-id pub-id-type="doi">10.1152/japplphysiol.00453.2024</pub-id><pub-id pub-id-type="pmid">39576281</pub-id></element-citation></ref><ref id="B7-sensors-25-05335"><label>7.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Atzori</surname><given-names>M.</given-names></name><name name-style="western"><surname>Gijsberts</surname><given-names>A.</given-names></name><name name-style="western"><surname>Castellini</surname><given-names>C.</given-names></name><name name-style="western"><surname>Caputo</surname><given-names>B.</given-names></name><name name-style="western"><surname>Mougiakakou</surname><given-names>S.G.</given-names></name><name name-style="western"><surname>M&#252;ller</surname><given-names>H.</given-names></name></person-group><article-title>Evaluation of the forearm EMG signal features for the control of a prosthetic hand</article-title><source>Proceedings of the 2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)</source><conf-loc>San Diego, CA, USA</conf-loc><conf-date>5&#8211;8 October 2014</conf-date><fpage>2917</fpage><lpage>2921</lpage><pub-id pub-id-type="doi">10.1109/SMC.2014.6974415</pub-id></element-citation></ref><ref id="B8-sensors-25-05335"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Oskoei</surname><given-names>M.A.</given-names></name><name name-style="western"><surname>Hu</surname><given-names>H.</given-names></name></person-group><article-title>Techniques of EMG signal analysis: Detection, processing, classification and applications</article-title><source>Biol. Proced. Online</source><year>2007</year><volume>8</volume><fpage>11</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1251/bpo115</pub-id><pub-id pub-id-type="pmcid">PMC1455479</pub-id><pub-id pub-id-type="pmid">16799694</pub-id></element-citation></ref><ref id="B9-sensors-25-05335"><label>9.</label><element-citation publication-type="webpage"><article-title>Recommendations for Sensor Locations on Individual Muscles</article-title><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.nxp.com/design/microcontrollers-developer-resources/lpc-microcontroller-utilities/lpcxpresso-board-for-lpc1347:OM13045" ext-link-type="uri">https://www.nxp.com/design/microcontrollers-developer-resources/lpc-microcontroller-utilities/lpcxpresso-board-for-lpc1347:OM13045</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-06-08">(accessed on 8 June 2025)</date-in-citation></element-citation></ref><ref id="B10-sensors-25-05335"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pieprzycki</surname><given-names>A.</given-names></name><name name-style="western"><surname>Kr&#243;l</surname><given-names>D.</given-names></name></person-group><article-title>Concept of the EMG Controlled Bionic Hand</article-title><source>Sci. Technol. Innov.</source><year>2020</year><volume>8</volume><fpage>26</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.5604/01.3001.0014.1901</pub-id></element-citation></ref><ref id="B11-sensors-25-05335"><label>11.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Pieprzycki</surname><given-names>A.</given-names></name><name name-style="western"><surname>Krol</surname><given-names>D.</given-names></name><name name-style="western"><surname>Wawryka</surname><given-names>P.</given-names></name><name name-style="western"><surname>&#321;achut</surname><given-names>K.</given-names></name><name name-style="western"><surname>Hamera</surname><given-names>M.</given-names></name><name name-style="western"><surname>Srebro</surname><given-names>B.</given-names></name></person-group><article-title>Analysis of Surface EMG Signals to Control of a Bionic Hand Prototype</article-title><source>Progress in Polish Artificial Intelligence Research 4</source><publisher-name>Wydawnictwo Politechniki &#321;&#243;dzkiej/Lodz University of Technology Press</publisher-name><publisher-loc>&#321;&#243;d&#378;, Poland</publisher-loc><year>2023</year></element-citation></ref><ref id="B12-sensors-25-05335"><label>12.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Wawryka</surname><given-names>P.</given-names></name></person-group><article-title>Analiza sygan&#322;&#243;W Elektromiograficznych w Zastosowaniu Protetycznym</article-title><source>Bachelor&#8217;s Thesis</source><publisher-name>University of Applied Sciences in Tarnow, ul. Mickiewicza 8</publisher-name><publisher-loc>Tarnow, Poland</publisher-loc><year>2022</year></element-citation></ref><ref id="B13-sensors-25-05335"><label>13.</label><element-citation publication-type="webpage"><article-title>EMG</article-title><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/informacja/EMG" ext-link-type="uri">https://github.com/informacja/EMG</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-06-08">(accessed on 8 June 2025)</date-in-citation></element-citation></ref><ref id="B14-sensors-25-05335"><label>14.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Huang</surname><given-names>N.E.</given-names></name><name name-style="western"><surname>Shen</surname><given-names>S.S.P.</given-names></name></person-group><source>Hilbert-Huang Transform and Its Applications</source><edition>1st ed.</edition><publisher-name>World Scientific</publisher-name><publisher-loc>Singapore</publisher-loc><year>2005</year></element-citation></ref><ref id="B15-sensors-25-05335"><label>15.</label><element-citation publication-type="webpage"><article-title>Hilbert-Huang Transform</article-title><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.mathworks.com/matlabcentral/fileexchange/19681-hilbert-huang-transform" ext-link-type="uri">https://www.mathworks.com/matlabcentral/fileexchange/19681-hilbert-huang-transform</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-06-08">(accessed on 8 June 2025)</date-in-citation></element-citation></ref><ref id="B16-sensors-25-05335"><label>16.</label><element-citation publication-type="book"><person-group person-group-type="author"><collab>The MathWorks Inc</collab></person-group><source>Statistics and Machine Learning Toolbox Documentation, Natick</source><publisher-name>The MathWorks Inc.</publisher-name><publisher-loc>Natick, MA, USA</publisher-loc><year>2022</year><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.mathworks.com/help/stats/index.html" ext-link-type="uri">https://www.mathworks.com/help/stats/index.html</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-06-08">(accessed on 8 June 2025)</date-in-citation></element-citation></ref><ref id="B17-sensors-25-05335"><label>17.</label><element-citation publication-type="book"><source>JMP<sup>&#174;</sup></source><comment>Version 18.0.2.</comment><publisher-name>SAS Institute Inc.</publisher-name><publisher-loc>Cary, NC, USA</publisher-loc><year>2024</year></element-citation></ref><ref id="B18-sensors-25-05335"><label>18.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Huang</surname><given-names>N.E.</given-names></name><name name-style="western"><surname>Shen</surname><given-names>S.S.P.</given-names></name></person-group><source>Hilbert&#8212;Huang Transform and Its Applications</source><edition>2nd ed.</edition><comment>Interdisciplinary Mathematical Sciences</comment><publisher-name>World Scientific</publisher-name><publisher-loc>Singapore</publisher-loc><year>2014</year><volume>Volume 16</volume><pub-id pub-id-type="doi">10.1142/8804</pub-id></element-citation></ref><ref id="B19-sensors-25-05335"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dragomiretskiy</surname><given-names>K.</given-names></name><name name-style="western"><surname>Zosso</surname><given-names>D.</given-names></name></person-group><article-title>Variational Mode Decomposition</article-title><source>IEEE Trans. Signal Process.</source><year>2014</year><volume>62</volume><fpage>531</fpage><lpage>534</lpage><pub-id pub-id-type="doi">10.1109/TSP.2013.2288675</pub-id></element-citation></ref><ref id="B20-sensors-25-05335"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chun</surname><given-names>S.</given-names></name><name name-style="western"><surname>Kim</surname><given-names>S.</given-names></name><name name-style="western"><surname>Kim</surname><given-names>J.</given-names></name></person-group><article-title>Human Arm Workout Classification by Arm Sleeve Device Based on Machine Learning Algorithms</article-title><source>Sensors</source><year>2023</year><volume>23</volume><elocation-id>3106</elocation-id><pub-id pub-id-type="doi">10.3390/s23063106</pub-id><pub-id pub-id-type="pmid">36991817</pub-id><pub-id pub-id-type="pmcid">PMC10057383</pub-id></element-citation></ref><ref id="B21-sensors-25-05335"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tibshirani</surname><given-names>R.</given-names></name></person-group><article-title>Regression Shrinkage and Selection via the lasso</article-title><source>J. R. Stat. Soc. Ser. B (Methodol.)</source><year>1996</year><volume>58</volume><fpage>267</fpage><lpage>288</lpage><pub-id pub-id-type="doi">10.1111/j.2517-6161.1996.tb02080.x</pub-id></element-citation></ref><ref id="B22-sensors-25-05335"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hoerl</surname><given-names>A.E.</given-names></name><name name-style="western"><surname>Kennard</surname><given-names>R.W.</given-names></name></person-group><article-title>Ridge Regression: Applications to Nonorthogonal Problems</article-title><source>Technometrics</source><year>1970</year><volume>12</volume><fpage>69</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1080/00401706.1970.10488635</pub-id></element-citation></ref><ref id="B23-sensors-25-05335"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zou</surname><given-names>H.</given-names></name><name name-style="western"><surname>Hastie</surname><given-names>T.</given-names></name></person-group><article-title>Regularization and Variable Selection Via the Elastic Net</article-title><source>J. R. Stat. Soc. Ser. B Stat. Methodol.</source><year>2005</year><volume>67</volume><fpage>301</fpage><lpage>320</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9868.2005.00503.x</pub-id></element-citation></ref><ref id="B24-sensors-25-05335"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Guyon</surname><given-names>I.</given-names></name><name name-style="western"><surname>Weston</surname><given-names>J.</given-names></name><name name-style="western"><surname>Barnhill</surname><given-names>S.</given-names></name><name name-style="western"><surname>Vapnik</surname><given-names>V.</given-names></name></person-group><article-title>Gene Selection for Cancer Classification using Support Vector Machines</article-title><source>Mach. Learn.</source><year>2002</year><volume>46</volume><fpage>389</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.1023/A:1012487302797</pub-id></element-citation></ref><ref id="B25-sensors-25-05335"><label>25.</label><element-citation publication-type="webpage"><article-title>Hand Robot InMoovs</article-title><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.thingiverse.com/thing:17773" ext-link-type="uri">https://www.thingiverse.com/thing:17773</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-06-08">(accessed on 8 June 2025)</date-in-citation></element-citation></ref><ref id="B26-sensors-25-05335"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Abdikenov</surname><given-names>B.</given-names></name><name name-style="western"><surname>Zholtayev</surname><given-names>D.</given-names></name><name name-style="western"><surname>Suleimenov</surname><given-names>K.</given-names></name><name name-style="western"><surname>Assan</surname><given-names>N.</given-names></name><name name-style="western"><surname>Ozhikenov</surname><given-names>K.</given-names></name><name name-style="western"><surname>Ozhikenova</surname><given-names>A.</given-names></name><name name-style="western"><surname>Nadirov</surname><given-names>N.</given-names></name><name name-style="western"><surname>Kapsalyamov</surname><given-names>A.</given-names></name></person-group><article-title>Emerging Frontiers in Robotic Upper-Limb Prostheses: Mechanisms, Materials, Tactile Sensors and Machine Learning-Based EMG Control: A Comprehensive Review</article-title><source>Sensors</source><year>2025</year><volume>25</volume><elocation-id>3892</elocation-id><pub-id pub-id-type="doi">10.3390/s25133892</pub-id><pub-id pub-id-type="pmid">40648148</pub-id><pub-id pub-id-type="pmcid">PMC12251605</pub-id></element-citation></ref><ref id="B27-sensors-25-05335"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yoo</surname><given-names>H.-J.</given-names></name><name name-style="western"><surname>Park</surname><given-names>H.-j.</given-names></name><name name-style="western"><surname>Lee</surname><given-names>B.</given-names></name></person-group><article-title>Boreom Myoelectric Signal Classification of Targeted Muscles Using Dictionary Learning</article-title><source>Sensors</source><year>2019</year><volume>19</volume><elocation-id>2370</elocation-id><pub-id pub-id-type="doi">10.3390/s19102370</pub-id><pub-id pub-id-type="pmid">31126025</pub-id><pub-id pub-id-type="pmcid">PMC6567142</pub-id></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-05335-f001" orientation="portrait"><label>Figure 1</label><caption><p>Visualization cross-section forearm with location and numbering of surface EMG electrode.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05335-g001.jpg"/></fig><fig position="float" id="sensors-25-05335-f002" orientation="portrait"><label>Figure 2</label><caption><p>One surface EMG sensor OYMotion SEN0240 (DFRobot, Shanghai, China) with a differential electrode pair and reference electrode DLR (Driven Right Leg).</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05335-g002.jpg"/></fig><fig position="float" id="sensors-25-05335-f003" orientation="portrait"><label>Figure 3</label><caption><p>Workflow for sEMG signal acquisition and bionic hand control.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05335-g003.jpg"/></fig><fig position="float" id="sensors-25-05335-f004" orientation="portrait"><label>Figure 4</label><caption><p>Prototype installation and positioning of the first electrode [<xref rid="B11-sensors-25-05335" ref-type="bibr">11</xref>], reproduced with permission from author P. Wawryka [<xref rid="B12-sensors-25-05335" ref-type="bibr">12</xref>].</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05335-g004.jpg"/></fig><fig position="float" id="sensors-25-05335-f005" orientation="portrait"><label>Figure 5</label><caption><p>Prototype board and band for the analysis of EMG signals [<xref rid="B11-sensors-25-05335" ref-type="bibr">11</xref>], reproduced with permission from author P. Wawryka [<xref rid="B12-sensors-25-05335" ref-type="bibr">12</xref>].</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05335-g005.jpg"/></fig><fig position="float" id="sensors-25-05335-f007" orientation="portrait"><label>Figure 7</label><caption><p>An example of the intrinsic mode functions (IMFs) and Variational Mode Decomposition (VMD) modes, derived from a single channel of surface electromyography (sEMG), illustrating the decomposition of a 5&#8722;s gesture.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05335-g007.jpg"/></fig><fig position="float" id="sensors-25-05335-f008" orientation="portrait"><label>Figure 8</label><caption><p>Neural network classification: data preprocessing and transformation pipeline.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05335-g008.jpg"/></fig><fig position="float" id="sensors-25-05335-f009" orientation="portrait"><label>Figure 9</label><caption><p>Inner side of 3D printed bionic hand.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05335-g009.jpg"/></fig><fig position="float" id="sensors-25-05335-f010" orientation="portrait"><label>Figure 10</label><caption><p>The outside of the 3D printed bionic hand.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05335-g010.jpg"/></fig><fig position="float" id="sensors-25-05335-f011" orientation="portrait"><label>Figure 11</label><caption><p>ROC curves for ANN performance on training, validation, and test sets.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05335-g011.jpg"/></fig><fig position="float" id="sensors-25-05335-f012" orientation="portrait"><label>Figure 12</label><caption><p>ROC curves for elastic performance on training, validation, and test sets.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05335-g012.jpg"/></fig><table-wrap position="float" id="sensors-25-05335-t001" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05335-t001_Table 1</object-id><label>Table 1</label><caption><p>Parameters of the sEMG signal acquisition module.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Settings</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Values</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Number of sEMG channels (sensors)</td><td align="center" valign="middle" rowspan="1" colspan="1">8</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Analyzed frequency range</td><td align="center" valign="middle" rowspan="1" colspan="1">1&#8211;1024 Hz</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Signal amplification</td><td align="center" valign="middle" rowspan="1" colspan="1">1000</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Sampling frequency</td><td align="center" valign="middle" rowspan="1" colspan="1">2048 Hz</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Signal acquisition time</td><td align="center" valign="middle" rowspan="1" colspan="1">5 s</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Smooth signal</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5 samples</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05335-t002" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05335-t002_Table 2</object-id><label>Table 2</label><caption><p>EMG signal features for bionic hand movement classification.</p></caption><table frame="hsides" rules="groups"><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Unprocessed signal</td><td align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">1. Mean, 2. RMS, 3. Shape Factor, 4. SNR, 5. THD, 6. SINAD,<break/>7. Peak Value, 8. Crest Factor, 9. Clearance Factor,<break/>10. Impulse Factor, 11. Kurtosis, 12. Skewness,<break/>13. Approximate Entropy, 14. Energy, 15. Mean Frequency,<break/>16. Mean Peaks, 17. Std Peaks, 18. Correlation Dimension</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Envelopes</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1. Mean of upper envelope, 2. Std of upper envelope</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Decomposition</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1. Entropy of imf, 2. Enegry of imf</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05335-t003" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05335-t003_Table 3</object-id><label>Table 3</label><caption><p>Gesture classification performance (regularized logistic regression).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">
</th><th colspan="3" align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1">Ridge Regression</th><th colspan="3" align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1">Lasso Regression</th><th colspan="3" align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1">Elastic Net Regression</th></tr><tr><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Gesture
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Train
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Val
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Test
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Train
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Val
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Test
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Train
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Val
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Test
</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">1</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">2</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9930</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9028</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9914</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9060</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9875</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9930</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9122</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9937</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">3</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9983</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9561</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9969</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9990</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9592</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9937</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9987</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9655</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9969</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">4</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9946</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9143</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9653</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9874</td><td align="left" valign="middle" rowspan="1" colspan="1">0.8857</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9792</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9896</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9029</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9861</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9873</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9369</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9375</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9821</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9369</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9722</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9845</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9369</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9722</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05335-t004" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05335-t004_Table 4</object-id><label>Table 4</label><caption><p>Gesture classification performance (RFE and ANNs).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">
</th><th colspan="3" align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1">RFE Regression</th><th colspan="3" align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1">ANN (Linear Function)</th><th colspan="3" align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1">ANN (Tanh Function)</th></tr><tr><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Gesture
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Train
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Val
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Test
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Train
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Val
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Test
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Train
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Val
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Test
</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">1</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9967</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">2</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">0.7962</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9263</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9360</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9655</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9185</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9998</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9687</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9875</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">3</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">0.7241</td><td align="left" valign="middle" rowspan="1" colspan="1">0.8777</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9871</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9655</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9028</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9999</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9875</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9781</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">4</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">0.8443</td><td align="left" valign="middle" rowspan="1" colspan="1">0.7917</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9593</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9600</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9097</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9371</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9792</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.0000</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9369</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.8819</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9100</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9459</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9236</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9997</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9369</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.9514</td></tr></tbody></table></table-wrap></floats-group></article></pmc-articleset>