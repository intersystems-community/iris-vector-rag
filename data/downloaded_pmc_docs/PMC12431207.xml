<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xml:lang="en" article-type="research-article" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="pmc-domain-id">1660</journal-id><journal-id journal-id-type="pmc-domain">sensors</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>Multidisciplinary Digital Publishing Institute  (MDPI)</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12431207</article-id><article-id pub-id-type="pmcid-ver">PMC12431207.1</article-id><article-id pub-id-type="pmcaid">12431207</article-id><article-id pub-id-type="pmcaiid">12431207</article-id><article-id pub-id-type="doi">10.3390/s25175526</article-id><article-id pub-id-type="publisher-id">sensors-25-05526</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Anomaly Detection and Segmentation in Measurement Signals on Edge Devices Using Artificial Neural Networks</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-6011-1955</contrib-id><name name-style="western"><surname>Dembski</surname><given-names initials="J">Jerzy</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><xref rid="fn1-sensors-25-05526" ref-type="author-notes">&#8224;</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-5798-0252</contrib-id><name name-style="western"><surname>Wiszniewski</surname><given-names initials="B">Bogdan</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#8211; original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><xref rid="fn1-sensors-25-05526" ref-type="author-notes">&#8224;</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-5916-8391</contrib-id><name name-style="western"><surname>Ko&#322;akowska</surname><given-names initials="A">Agata</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><xref rid="c1-sensors-25-05526" ref-type="corresp">*</xref><xref rid="fn1-sensors-25-05526" ref-type="author-notes">&#8224;</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name name-style="western"><surname>Dabbous</surname><given-names initials="A">Ali</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name name-style="western"><surname>Pasini</surname><given-names initials="P">Paolo</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name name-style="western"><surname>Bellotti</surname><given-names initials="F">Francesco</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-05526">Faculty of Electronics, Telecommunications and Informatics, Gda&#324;sk University of Technology, Narutowicza 11/12, 80-233 Gda&#324;sk, Poland; <email>jerzy.dembski@pg.edu.pl</email> (J.D.); <email>bogdan.wiszniewski@pg.edu.pl</email> (B.W.)</aff><author-notes><corresp id="c1-sensors-25-05526"><label>*</label>Correspondence: <email>agata.kolakowska@pg.edu.pl</email>; Tel.: +48-58-347-2761</corresp><fn id="fn1-sensors-25-05526"><label>&#8224;</label><p>These authors contributed equally to this work.</p></fn></author-notes><pub-date pub-type="epub"><day>05</day><month>9</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>9</month><year>2025</year></pub-date><volume>25</volume><issue>17</issue><issue-id pub-id-type="pmc-issue-id">496815</issue-id><elocation-id>5526</elocation-id><history><date date-type="received"><day>12</day><month>7</month><year>2025</year></date><date date-type="rev-recd"><day>21</day><month>8</month><year>2025</year></date><date date-type="accepted"><day>29</day><month>8</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>05</day><month>09</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>13</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-13 11:25:14.803"><day>13</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="sensors-25-05526.pdf"/><abstract><p>In this paper, three alternative solutions to the problem of detecting and cleaning anomalies in soil signal time series, involving the use of artificial neural networks deployed on in situ data measurement end devices, are proposed and investigated. These models are designed to perform calculations on MCUs, characterized by significantly limited computing capabilities and a limited supply of electrical power. Training of neural network models is carried out based on data from multiple sensors in the supporting computing cloud instance, while detection and removal of anomalies with a trained model takes place on the constrained end devices. With such a distribution of work, it is necessary to achieve a sound compromise between prediction accuracy and the computational complexity of the detection process. In this study, neural-primed heuristic (NPH), autoencoder-based (AEB), and U-Net-based (UNB) approaches were tested, which were found to vary regarding both prediction accuracy and computational complexity. Labeled data were used to train the models, transforming the detection task into an anomaly segmentation task. The obtained results reveal that the UNB approach presents certain advantages; however, it requires a significant volume of training data and has a relatively high time complexity which, in turn, translates into increased power consumption by the end device. For this reason, the other two approaches&#8212;NPH and AEB&#8212;may be worth considering as reasonable alternatives when developing in situ data cleaning solutions for IoT measurement systems.</p></abstract><kwd-group><kwd>time-series data cleaning</kwd><kwd>intelligent IoT sensors</kwd><kwd>constrained end devices</kwd></kwd-group><funding-group><award-group><funding-source>National Centre for Research and Development (NCBR)</funding-source><award-id>WPN/4/68/Rural IoT/2022</award-id></award-group><funding-statement>This research was funded by National Centre for Research and Development (NCBR), Poland, German&#8211;Polish Bilateral R&amp;D Cooperation Programme in the Field of Digitization of the Economy, 2021&#8211;2023, grant number WPN/4/68/Rural IoT/2022 (Smart Rural IoT data acquisition and fusion).</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-05526"><title>1. Introduction</title><p>Monitoring of environmental conditions, such as the risk of forest fires, the&#160;condition of flood embankments along rivers, and&#160;soil parameters in precision agriculture, requires the collection of data from vast and often hard to access areas; for this purpose, in&#160;situ measurement sensors can be utilized. Such areas usually lack an efficient telecommunications infrastructure enabling the continuous transmission of the acquired measurement data for the purpose of delivering them to a processing center (e.g., a cloud computing center). Due to the excessive costs of establishing such infrastructure, the&#160;collection of data from sensors scattered throughout an extended area currently requires the use of an unmanned aerial vehicle (UAV), acting as a mobile go-between serving both sensors and the cloud, which is piloted from the ground or operates autonomously. In such a nomadic scheme, a&#160;gateway onboard the UAV receives chunks of data from the sensors it flies over, which are then stored in its local memory and, after&#160;landing, uploaded to the cloud via the nearest available access&#160;point.</p><p>The development of such a measurement ecosystem poses a number of serious challenges. First, each sensor on the ground has a limited time window to send measurement data to the UAV. Wireless communication protocols used in IoT use relatively small packet sizes to conserve energy and maximize battery life. Moreover, as&#160;more devices can transmit data independently within the same time frame, congestion/collisions are reduced by decreasing data rate managed by the protocol&#8217;s underlying airtime allowance mechanism&#160;[<xref rid="B1-sensors-25-05526" ref-type="bibr">1</xref>]. As&#160;a result, the&#160;transmission of large amounts of data from a sensor may not fit within the available time window of a passing UAV. To reduce the volume of data to be sent, they must be cleaned of erroneous, misleading, and&#160;otherwise redundant data, all of which must be performed by a constrained end device with limited computing, memory, and&#160;power resources. Measurement data of soil signals are stored in the sensor&#8217;s memory as time series of values reflecting consecutive samples. The&#160;literature lacks generic solution patterns which can be readily used for the automatic detection and localization (i.e., segmentation) of sample fragments in signals, which is necessary to implement the above-mentioned operations. The&#160;main reason for this shortcoming is that sufficiently large training datasets are required to effectively train ML models for such tasks. For instance, in&#160;[<xref rid="B2-sensors-25-05526" ref-type="bibr">2</xref>] a combined LSTM&#8211;Autoencoder was proposed, which can detect anomalies in indoor air quality data by learning long-term dependencies and reconstructing sequences to identify deviations. In&#160;turn, solutions using 1D U-Net models described in the literature (e.g.,&#160;[<xref rid="B3-sensors-25-05526" ref-type="bibr">3</xref>]) are especially effective for training on small datasets thanks to their symmetric and compact design. However, when compared with autoencoders, their memory footprint is higher due to deeper layers and skip connections, are more energy-intensive due to more layers and operations, and&#160;require more capable CPUs. Thus, although&#160;more powerful for segmentation tasks, they are better suited for more capable cloud&#160;instances.</p><p>The inspiration for this study is the belief that, when there is insufficient data for automatic analysis using state-of-the-art deep learning methods, plain visual interpretation of signal plots to determine any common-sense abnormal change-points and patterns may be misleading&#160;[<xref rid="B4-sensors-25-05526" ref-type="bibr">4</xref>]. Intuition tells us that, similarly to the synoptic interpretation of weather maps, only in-depth knowledge of the ongoing processes whose parameters we measure will allow us to correctly interpret their recorded values. One example could be the problem of detecting power gaps (as described later in <xref rid="sensors-25-05526-t001" ref-type="table">Table 1</xref>), resulting in misplaced samples. Based on this knowledge, augmentation of real data may be performed by mimicking the relevant physical processes in the sensor&#8217;s operational environment. A&#160;key novel component in such automation that is that explainable anomalies can be represented, in&#160;a meaningful way, using instances from just a handful of their parameterized generic classes. For sets of realistic data generated in such a manner, four alternative models for detecting and segmenting fragments of anomalous samples in soil signal time series, with different dynamics and physics, were evaluated, from&#160;unoptimized and optimized heuristic detectors, through to combined neural&#8211;heuristic ones and up to two variants of autoencoders. Each of these models can be implemented on an Arduino-based constrained&#160;device.</p><p>The results of our study are significant for the IoT research community and practitioners for two reasons. The&#160;first is that we can effectively cope with the problem of insufficient volumes of training data by augmenting them based on the comprehensive physics-informed ML (PIML) approach&#160;[<xref rid="B5-sensors-25-05526" ref-type="bibr">5</xref>]. The&#160;anomalies present in time-series of measurement data generated in this way are not merely injected perturbations, and&#160;can provide a sound basis for ensuring the ecological validity of the tested models&#8217; performance under unpredictable, real-world conditions. The&#160;second is showing how cheap smart sensors can significantly reduce the costs of implementing measurement ecosystems over large areas without the need to invest into associated telecommunications infrastructure. Our field tests in real farmland and forest environments show that with an appropriate wireless telecommunication technology (e.g., LoRaWAN), constrained battery-powered IoT end devices can maintain operational readiness for long periods due to only the sporadic transmission of minimal byte loads for short distances between the ground and the UAVs flying by being&#160;required.</p><p>The remainder of this paper is structured as follows: In <xref rid="sec2-sensors-25-05526" ref-type="sec">Section 2</xref>, we set the scene for the rest of the paper from the perspective of a nomadic in&#160;situ soil data acquisition scheme using UAVs and constrained end devices, which we implemented as a Rural IoT system. In <xref rid="sec3-sensors-25-05526" ref-type="sec">Section 3</xref>, three basic neural network architecture models and their implementations investigated in the study are described. In <xref rid="sec4-sensors-25-05526" ref-type="sec">Section 4</xref>, the&#160;results of our experimental evaluation of their suitability and effectiveness in detecting various classes of anomalies in the time series comprising measurement signals of several key soil parameters are presented and discussed. Finally, in&#160;<xref rid="sec5-sensors-25-05526" ref-type="sec">Section 5</xref>, our results regarding the use of neural network models for the intelligent segmentation of time-series data are summarized and directions for future work are detailed, with&#160;the goal of increasing the technological readiness level of our soil measurement sensors in their final (production) version.</p></sec><sec id="sec2-sensors-25-05526"><title>2. Detection and Segmentation&#160;Problem</title><p>The traditional method for detecting anomalies in measurement signals involves detecting atypical signal fragments in relation to the typical waveform. Furthermore, the&#160;segmentation problem involves precisely locating the signal fragment where the anomaly occurs; it can therefore be said that segmentation is a more general and more difficult problem than detection&#160;itself.</p><p>There is a wide spectrum of causes for this type of phenomenon, which have been analyzed in the literature for years. These include natural factors such as varying weather conditions, radiation, lightning, or&#160;chemical activity of the monitored environment, as&#160;well as human-caused disruptions, which can be unintentional (by other devices or machinery) or intentional (e.g., jamming, spoofing). Examples include the following:<list list-type="bullet"><list-item><p>Environmental disturbances such as sudden weather changes, large fluctuations in pressure, temperature, radiation, fires, or&#160;pollution temporarily disrupting normal readings; such disturbances are the major source of anomalies [<xref rid="B6-sensors-25-05526" ref-type="bibr">6</xref>,<xref rid="B7-sensors-25-05526" ref-type="bibr">7</xref>].</p></list-item><list-item><p>Hardware-related issues, including sensor aging and battery depletion [<xref rid="B8-sensors-25-05526" ref-type="bibr">8</xref>,<xref rid="B9-sensors-25-05526" ref-type="bibr">9</xref>] or physical damage to nodes. Moreover, the&#160;sensing capabilities of the sensors used in common low-cost configurations are limited, making the measurement values more sensitive to external factors&#160;[<xref rid="B6-sensors-25-05526" ref-type="bibr">6</xref>,<xref rid="B8-sensors-25-05526" ref-type="bibr">8</xref>].</p></list-item><list-item><p>Communication errors [<xref rid="B6-sensors-25-05526" ref-type="bibr">6</xref>,<xref rid="B7-sensors-25-05526" ref-type="bibr">7</xref>,<xref rid="B8-sensors-25-05526" ref-type="bibr">8</xref>,<xref rid="B10-sensors-25-05526" ref-type="bibr">10</xref>] such as packet loss, data corruption, or&#160;network congestion compromising data integrity, particularly in a multi-sensor distributed setting. These errors may be caused by interference from other wireless-based technologies, electromagnetic noise, narrow bandwidth degrading communication speed, or&#160;physical barriers such as high buildings.</p></list-item><list-item><p>Software failures stemming from firmware bugs, misconfigurations, or&#160;calibration drift over time affecting the accuracy of sensor output. Furthermore, human factors such as incorrect sensor deployment, inadequate measurement techniques, or&#160;other operational misuse may contribute to such failures [<xref rid="B8-sensors-25-05526" ref-type="bibr">8</xref>,<xref rid="B10-sensors-25-05526" ref-type="bibr">10</xref>]; e.g., the&#160;interpretation of data might be wrong if seasonal or environmental factors are not considered during the calibration process [<xref rid="B10-sensors-25-05526" ref-type="bibr">10</xref>].</p></list-item><list-item><p>Various types of cyberattacks, including jamming attacks causing communication delays or packet loss [<xref rid="B11-sensors-25-05526" ref-type="bibr">11</xref>], as well as spoofing (i.e., the&#160;injection of false data) [<xref rid="B12-sensors-25-05526" ref-type="bibr">12</xref>].</p></list-item></list></p><p>In rural IoT measurement ecosystems such as those considered in this study, not all of the abovementioned causes of anomalies in the time-series data collected by the nomadic UAV gateway will require equal attention. Certain environmental disturbances or hardware issues, including sensor aging and battery depletion, are undoubtedly more difficult to control than the others, for&#160;which we can either deploy appropriate technologies or design sensor usage scenarios which make them practically non-existent. This is particularly true for communication errors when using a properly configured technology that is specifically designed to wirelessly connect battery-powered IoT devices to the Internet (e.g., LoRaWAN) [<xref rid="B13-sensors-25-05526" ref-type="bibr">13</xref>]. On&#160;the other hand, software errors due to calibration drift over time and measurement inaccuracy practically did not occur during our experiments using sensors with an assumed lifetime spanning over one vegetation period; typically from March to October in European latitudes. Therefore, our sensors were designed as single-use, disposable devices. Finally, when monitoring soil parameters for agricultural purposes, especially with multiple sensors spread over very large areas of arable land, the&#160;likelihood of human intrusion is negligible. In&#160;this scenario, the&#160;UAV itself seems to be at greater risk, especially when its navigation unit uses GNSS signals that can be jammed or spoofed in the event of an attack.</p><p>To find unusual patterns in time-series data (e.g., signal samples) that deviate significantly from the typical signal waveforms, it is crucial to understand their underlying physical processes&#8212;especially when no analytical model of a given process exists or the amount of measurement data is too small to identify it. To&#160;cope with this issue, we utilize the physics-informed ML (PIML) approach&#160;[<xref rid="B5-sensors-25-05526" ref-type="bibr">5</xref>], which comprised a comprehensive interpretation of the recorded soil signal samples and the development of explainable anomaly classes. Moreover, understanding the phenomena occurring in the soil allowed us to parameterize these anomaly classes as generic classes, allowing us to generate extensive synthetic datasets that included anomalies found in real measurement signals, not just random perturbations injected&#160;arbitrarily.</p><sec id="sec2dot1-sensors-25-05526"><title>2.1. Generic Anomaly&#160;Classes</title><p>We started by analyzing four soil signals, namely, temperature (T), moisture (M), acidity (pH), and&#160;solar radiation (PV), in&#160;a volume of over 175,000 samples collected using 7 autonomous measurement sensors at different locations scattered within an area of approximately 35 km during one full growing season (i.e., from&#160;April to October)&#160;[<xref rid="B14-sensors-25-05526" ref-type="bibr">14</xref>]. We have previously detailed the characteristics of their underlying physical processes in [<xref rid="B15-sensors-25-05526" ref-type="bibr">15</xref>,<xref rid="B16-sensors-25-05526" ref-type="bibr">16</xref>]. For&#160;sake of brevity, we reiterate only their essential features below:<list list-type="simple"><list-item><label>T</label><p>exhibits a strong (regular) daily trend, as&#160;solar heat is gradually accumulated in the soil from sunrise and radiated out after sunset;</p></list-item><list-item><label>M</label><p>has periodicity that is hard to capture, as&#160;rainfalls combined with soil/terrain conditions and the location of the sensor may result in flooding of the measurement&#160;probe;</p></list-item><list-item><label>pH</label><p>normally has no trend, as&#160;minerals contained in the soil can dissolve only in the water contained therein up to a certain concentration limit (saturated solution);</p></list-item><list-item><label>PV</label><p>has regular (every 24 h) leading edges of the voltage signal corresponding to two consecutive sunrises, and&#160; rapid fluctuations in between these time points depending on the actual external load (open circuit voltage).</p></list-item></list></p><p>Based on the above understanding, we carried out comprehensive visual interpretation of each signal plot to find and explain signal fragments that deviated from the underlying physical processes. Samples collected from all sensors were stored in the InfluxDB time-series database, from&#160;which subsequent portions of data were visualized using a visualization package, Grafana, integrated in our cloud-based CLaaS technology stack&#160;[<xref rid="B16-sensors-25-05526" ref-type="bibr">16</xref>]. The&#160;identified deviations are explained in <xref rid="sensors-25-05526-t001" ref-type="table">Table 1</xref>.</p><p>By understanding the physical basis of individual types of anomalies, it is possible to search for methods (both heuristic and neural) for their detection, thus answering whether a given fragment of signal samples contains a sequence of samples that can be classified into one of the types identified in <xref rid="sensors-25-05526-t001" ref-type="table">Table 1</xref>. Subsequently, we can look for methods for their segmentation, which allow for determination of their most probable positions in the analyzed sequence. Of&#160;course, a&#160;straightforward solution would be to use an autoencoder that is trained to process the input signal into the same output signal, where the objective function is to minimize the output signal reconstruction error. When processing an unknown signal in this way, an&#160;excessive reconstruction error would indicate an anomaly that is either known (explainable) or unknown beforehand. However, a&#160;disadvantage of this approach when dealing with a small volume of training data is that a valid signal that was not in the training set may also be considered an anomaly. A false positive error, i.e.,&#160;detecting an anomaly where there is none, may result in the removal of an important fragment of the signal during its cleaning. Therefore, a&#160;more reasonable approach in our case was to study the similarity of a signal fragment to previously established patterns. In this line, we parameterized four types of pattern explained in <xref rid="sensors-25-05526-t001" ref-type="table">Table 1</xref>; namely, <italic toggle="yes">peaks</italic>, <italic toggle="yes">jumps</italic>, <italic toggle="yes">bumps</italic>, and&#160;<italic toggle="yes">instabilities</italic>&#160;[<xref rid="B15-sensors-25-05526" ref-type="bibr">15</xref>]. These patterns are outlined schematically in <xref rid="sensors-25-05526-f001" ref-type="fig">Figure 1</xref>.</p><p>In this paper, we denote each potentially anomalous signal fragment by <inline-formula><mml:math id="mm1" overflow="scroll"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mo>&#8727;</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm2" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8727;</mml:mo><mml:mo>&#8712;</mml:mo><mml:mo>{</mml:mo><mml:mi>P</mml:mi><mml:mo>,</mml:mo><mml:mi>J</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which is referred to as the anomaly center, with&#160;left and right neighbors <inline-formula><mml:math id="mm3" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>N</mml:mi><mml:mo>&#8727;</mml:mo><mml:mi>L</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm4" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>N</mml:mi><mml:mo>&#8727;</mml:mo><mml:mi>R</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>, respectively. Samples delimiting the anomaly neighbors from the associated center are termed the left and right edges of the anomaly, respectively. This parameterization is necessary, as&#160;simply detecting the existence of an anomaly is not sufficient in&#160;situations where anomalous signal fragments must be cleaned (i.e., either removed or corrected)&#160;[<xref rid="B15-sensors-25-05526" ref-type="bibr">15</xref>]. In&#160;such cases, segmentation of the anomaly requires determining its&#160;boundaries.</p><p>Detection, segmentation, and&#160;cleaning of anomalies in time series of measured signals should be performed locally in the sensor&#8217;s processing environment, due to the previously mentioned need to minimize the byte payload transmitted from the sensor to the UAV in the time- and energy-constrained data transmission window&#160;[<xref rid="B13-sensors-25-05526" ref-type="bibr">13</xref>]. Hence, in&#160;this paper, we analyze alternative models for the detection and segmentation of the four anomaly classes specified in <xref rid="sensors-25-05526-f001" ref-type="fig">Figure 1</xref>, which must be deployed on constrained end devices. It is worth noting that sensors in rural IoT ecosystems should be able to deal with anomalies that cannot be cleaned locally, as&#160;well as anomalies that can be cleaned with simple filtration; the former are power gaps, whereas the latter are absolute&#160;errors.</p><p>In the case of power gaps, as&#160;explained in <xref rid="sensors-25-05526-t001" ref-type="table">Table 1</xref>, each sensor can only detect the fact that some samples have been time-shifted. It can do this by counting samples of the T, M, and&#160;pH signals between two consecutive PV instant voltage drop-ups, corresponding to two sunrises. With&#160;a known sampling period, the&#160;number of signal samples should fall within some fixed interval. When the calculated actual number of samples is much lower or higher, it means that the sensor was down for some period. Then, all samples in that time frame should be marked as misplaced and, when uploaded to the cloud instance, can be correctly shifted on the timeline by combining samples from other sensors. One possible way to fix this anomaly is a heuristic time-series data fusion method we have previously developed, which combines the Dynamic Time Warping (DTW) and Derivative DTW (DDTW) methods&#160;[<xref rid="B17-sensors-25-05526" ref-type="bibr">17</xref>].</p><p>In turn, eliminating absolute errors from measurement data requires setting the appropriate limit values for the variability ranges of individual signals in the sensor&#8217;s software. For European latitudes, these ranges can be set as pH&#160;<inline-formula><mml:math id="mm5" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8712;</mml:mo><mml:mo>{</mml:mo><mml:mn>3.0</mml:mn><mml:mo>,</mml:mo><mml:mn>9.0</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, M&#160;<inline-formula><mml:math id="mm6" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8712;</mml:mo><mml:mo>{</mml:mo><mml:mn>10</mml:mn><mml:mo>%</mml:mo><mml:mo>,</mml:mo><mml:mn>80</mml:mn><mml:mo>%</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and&#160; T&#160;<inline-formula><mml:math id="mm7" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8712;</mml:mo><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>&#160;</mml:mo><mml:mo>&#176;</mml:mo><mml:mi mathvariant="normal">C</mml:mi><mml:mo>,</mml:mo><mml:mn>40</mml:mn><mml:mo>&#160;</mml:mo><mml:mo>&#176;</mml:mo><mml:mi mathvariant="normal">C</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. When implementing a rural IoT ecosystem at other geographical latitudes, it is sufficient to shift these ranges according to the normative documents of the relevant agricultural authorities (ministries). Moreover, depending on the manufacturer of the cell used, its catalog provides the nominal value of its output voltage (e.g., PV <inline-formula><mml:math id="mm8" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8712;</mml:mo><mml:mo>{</mml:mo><mml:mn>0.0</mml:mn><mml:mo>&#160;</mml:mo><mml:mi mathvariant="normal">V</mml:mi><mml:mo>,</mml:mo><mml:mn>6.6</mml:mn><mml:mo>&#160;</mml:mo><mml:mi mathvariant="normal">V</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>). When reading the values of subsequent samples that fall outside the allowed ranges, the&#160;samples are saved as <italic toggle="yes">empty</italic>. Their values can then be locally calculated as an average of the left and right sample values from the correct range, determined from the signal trend, or&#160;simply forwarded to the cloud instance where it can be repaired through fusion with data from other sensors. The&#160;sensors in our Rural IoT ecosystem implement the first of these&#160;solutions.</p></sec><sec id="sec2dot2-sensors-25-05526"><title>2.2. Training and Testing&#160;Datasets</title><p>Measurements carried out in a real operational environment, characterized by highly variable weather conditions for approximately 215 days spanning the three seasons from spring to autumn, provided us with real and representative soil data. However, developing an effective mechanism for automatic detection and segmentation posed a fundamental &#8220;chicken and egg&#8221; dilemma: should we first collect a significant amount of data and then discover patterns, or&#160;determine the meaningful patterns first and then look for them in the analyzed data? The main problem was the high cost of deploying a sufficient number of sensors to collect the initial data, as&#160;too small a dataset may not enable the proper training of neural models for anomaly detection and segmentation. Therefore, it was necessary to develop a workaround through the generation of synthetic but realistic data, taking advantage of the explainable physics of phenomena occurring in the&#160;soil.</p><p>With the generic anomaly models described earlier and, according to the previously discussed daily periodicity of the pH, M, and&#160;T signals, we generated sufficiently large training and testing datasets. First, for&#160;the original time-series data (raw signals) recorded by each of the seven sensors over the entire growing season, we created seven corresponding reference (ideal) signals by manually removing all pre-determined anomalies. Then, for&#160;each reference signal, we generated synthetic signals by injecting different fragments of anomalous samples into the ideal signal time-series data; these were not simple random perturbations injected into reference signals, but&#160;entire fragments corresponding to particular types of anomalies. The&#160;individual parameters of the anomalies specified in <xref rid="sensors-25-05526-f001" ref-type="fig">Figure 1</xref> changed within the ranges implied by the physical attributes of the measurement process, and&#160;the logic of the reference signals of individual soil parameters, according to an algorithm specifically developed for this purpose (the details of which were presented earlier in&#160;[<xref rid="B15-sensors-25-05526" ref-type="bibr">15</xref>]). The aforementioned approach has two advantages. First, injecting faults into a dataset gave us an accurate ground truth that helped to better understand the performance of anomaly detection and segmentation methods. Second, we were able to control intensity of each anomaly and, thereby, could explore the limits of performance of each such method and comparatively assess different schemes at low anomaly intensities&#160;[<xref rid="B9-sensors-25-05526" ref-type="bibr">9</xref>].</p><p>The data obtained from three sensors <inline-formula><mml:math id="mm9" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mi>s</mml:mi><mml:mn>01</mml:mn><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mn>02</mml:mn><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mn>23</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and processed as described above were used for training, while data from the remaining four <inline-formula><mml:math id="mm10" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mi>s</mml:mi><mml:mn>03</mml:mn><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mn>21</mml:mn><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mn>22</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> were used for testing. Within both groups <inline-formula><mml:math id="mm11" overflow="scroll"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm12" overflow="scroll"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, sensors were distributed in different locations to ensure that the data obtained were as representative as possible, ensuring the good generalization ability of the resulting models. All data represented time series for three measured physical soil parameters: pH, M, and&#160;T.</p></sec><sec id="sec2dot3-sensors-25-05526"><title>2.3. Segmentation Quality&#160;Assessment</title><p>To compare the segmentation algorithm&#8217;s output with respect to the known ground truth, we used the intersection over union (IOU) metric given by Formula&#160;(<xref rid="FD1-sensors-25-05526" ref-type="disp-formula">1</xref>):<disp-formula id="FD1-sensors-25-05526"><label>(1)</label><mml:math id="mm13" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>O</mml:mi><mml:mi>U</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:mi>t</mml:mi><mml:mo>&#8745;</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>t</mml:mi><mml:mo>&#8746;</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">t</italic> denotes a sequence of bits containing true anomaly labels, <italic toggle="yes">y</italic> denotes an analogous sequence output by the segmentation algorithm, <inline-formula><mml:math id="mm14" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#8745;</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is the intersection over individual bits, <inline-formula><mml:math id="mm15" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#8746;</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is the union over individual bits, and&#160;<inline-formula><mml:math id="mm16" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mo>.</mml:mo><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a sum of bits. In equivalent notation, it is calculated as the number of true positive samples (TP) divided by the sum of all ground truth samples (P) and false positive samples (FP). All results presented in <xref rid="sec4dot2-sensors-25-05526" ref-type="sec">Section 4.2</xref> were calculated for test signals concatenated into one long vector, which allowed us to avoid averaging as, in&#160;the case of unevenly distributed anomalies in different signals, it can lead to unreliable&#160;results.</p><p>Another popular metric used in this context is the F1 metric, which can be represented as an IOU-dependent value obtained from Formula (<xref rid="FD2-sensors-25-05526" ref-type="disp-formula">2</xref>):<disp-formula id="FD2-sensors-25-05526"><label>(2)</label><mml:math id="mm17" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>I</mml:mi><mml:mi>O</mml:mi><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>I</mml:mi><mml:mi>O</mml:mi><mml:mi>U</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>If the output of the segmentation system is the probabilities of anomaly classes, it is necessary to adopt a probability threshold above which one may consider that a sample belongs to the anomaly class. Depending on the adopted threshold, different TP and FP values will be obtained, as&#160;well as the true positive rate <inline-formula><mml:math id="mm18" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>/</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic toggle="yes">P</italic> is the number of positive samples, and&#160;the false positive rate <inline-formula><mml:math id="mm19" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic toggle="yes">N</italic> is the number of negative samples. In this case, a&#160;reliable approach for evaluation of the segmentation system is using the receiver operating characteristic (ROC) parametric curve, the&#160;parameter of which is a threshold value and the related area under curve (AUC) measure can be obtained, which is independent of the selected threshold.</p></sec><sec id="sec2dot4-sensors-25-05526"><title>2.4. Edge&#8211;Cloud Work&#160;Distribution</title><p>An important issue to be addressed when developing a measurement IoT system is the distribution of work between end devices and their supporting cloud. While the end device (sensor) could detect anomalies in data and send them to the cloud for processing, this would increase its energy consumption due to excess computations. Cloud feedback could optimize such a process by combining data from multiple end devices in a collaborative learning scheme; however, this would require additional bandwidth and energy reserve for the latter to receive local model updates. Balancing this scheme, in&#160;fact, requires prior experimentation for each specific&#160;application.</p><p>Due to the limited computing resources of the end device (e.g., a&#160;measurement sensor), development of its software requires support from an external entity, such as a computing cloud. This is particularly important when ML models used by anomaly detectors require the ability to continuously evolve, enabling increasingly better cleaning of measurement data time series as knowledge about the monitored phenomena is gradually accumulated across the entire measurement ecosystem. This knowledge should be periodically redistributed, starting from the initial configuration of the detector parameters used by the sensors in the process of cleaning raw measurement data based on previously acquired knowledge about the monitored phenomena, and&#160;then updating them regularly during the fusion of data from multiple sensors in subsequent cycles. The&#160;updated detector parameters can then be transmitted back to the previously installed measurement sensors (when their communication module enables the receiving of data from the UAV nomadic gateway) or used in the software of the next-generation (improved) sensors.</p><sec id="sec2dot4dot1-sensors-25-05526"><title>2.4.1. Initial Version of the Anomaly Detector&#160;Software</title><p>Development of the initial version of the anomaly detector software requires knowledge of the design of the measuring end device, methods of measuring selected soil parameters and, as&#160;argued earlier, the&#160;physical properties of the monitored processes. When we can formally characterize individual anomalies by a set of measurable parameters, for&#160;example, as&#160;shown earlier in <xref rid="sensors-25-05526-f001" ref-type="fig">Figure 1</xref>, the&#160;first step of software development for the detector should be determining the optimal values of these parameters. This, in&#160;turn, requires a sufficiently large volume of raw measurement data. If&#160;we do not have such a set, it may be helpful to use the Data Free scheme presented in <xref rid="sensors-25-05526-f002" ref-type="fig">Figure 2</xref>, which uses the synthetic data mentioned&#160;earlier.</p><p>We implemented this scheme in our CLaaS technology stack on the TASKcloud&#160;[<xref rid="B16-sensors-25-05526" ref-type="bibr">16</xref>] computing cloud by adapting it from a portfolio of federated learning models&#160;[<xref rid="B18-sensors-25-05526" ref-type="bibr">18</xref>]. The&#160;computationally advanced &#8220;teacher&#8221; module searches for optimal parameter values for individual anomalies, while the &#8220;student&#8221; module is the actual anomaly detector software to be installed on the end device. Both modules&#8212;the &#8220;teacher&#8221; and the &#8220;student&#8221;&#8212;are fed with data containing anomalies, and&#160;the entire process continues until the &#8220;student&#8221; reaches the desired level of detection quality. The&#160;result of this operation is a set of detector parameters <inline-formula><mml:math id="mm20" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>&#8727;</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, which is the same for each sensor <inline-formula><mml:math id="mm21" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>&#8727;</mml:mo></mml:msup><mml:mo>&#8712;</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. The&#160;&#8220;teacher&#8221; module can use various models: in [<xref rid="B15-sensors-25-05526" ref-type="bibr">15</xref>], we described the solution we implemented using <italic toggle="yes">simulated annealing</italic> (SA) to optimize the detector parameters, whereas three alternative solutions using neural models are further detailed in <xref rid="sec3-sensors-25-05526" ref-type="sec">Section 3</xref>.</p></sec><sec id="sec2dot4dot2-sensors-25-05526"><title>2.4.2. Continuous Development of the Anomaly Detector&#160;Software</title><p>During regular exploitation of the Rural IoT ecosystem sensors over a long time period, the&#160;volume of cleaned data <inline-formula><mml:math id="mm22" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>&#8727;</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> collected from sensors <inline-formula><mml:math id="mm23" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> systematically increases. These data can then be used for continuous evaluation of the quality of the current version of the <inline-formula><mml:math id="mm24" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>&#8727;</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> detector software installed in the sensors, through comparison with the respective raw data <inline-formula><mml:math id="mm25" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm26" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. The&#160;Life-Long Learning federated learning scheme&#160;[<xref rid="B18-sensors-25-05526" ref-type="bibr">18</xref>] is suitable for this purpose, which we also adapted to our CLaaS technology stack, as&#160;presented in <xref rid="sensors-25-05526-f003" ref-type="fig">Figure 3</xref>.</p><p>All measurement data collected to date in our TASK cloud instance are delivered to the input of the module that implements a selected ML model, which is systematically fine-tuned with the <inline-formula><mml:math id="mm27" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>&#8727;</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> data. As&#160;a result of this process, a&#160;set of new detector parameter values (e.g., neural network weights), <inline-formula><mml:math id="mm28" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>&#8727;</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, is determined. If the results of anomaly detection obtained for the newer version are better than the results obtained so far, the&#160;new set of parameters <inline-formula><mml:math id="mm29" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>&#8727;</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is, if&#160;possible, sent back to the existing sensors <inline-formula><mml:math id="mm30" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> of the ecosystem as an update to their software, or&#160;is set in the software of all newly installed sensors. In&#160;both cases, involving the Data Free and Life-Long Learning schemes, the&#160;quality of anomaly detection is assessed with respect to reference signals, as&#160;described later in <xref rid="sec4-sensors-25-05526" ref-type="sec">Section 4</xref>.</p></sec></sec></sec><sec id="sec3-sensors-25-05526"><title>3. Neural Networks for Time-Series&#160;Segmentation</title><p>Anomaly detection in measurement data time-series using neural networks provides a number of advantages that have been repeatedly confirmed in the literature&#160;[<xref rid="B19-sensors-25-05526" ref-type="bibr">19</xref>]. Neural networks are powerful tools that can learn relevant features from data, adapt to the different characteristics of time-series, and&#160;learn optimal segmentation points, making them more robust than traditional methods for handling noisy or incomplete data. These models, however, come at a cost. First, in&#160;order for neural networks to learn efficiently, they generally require a lot of training data. Second, they can be computationally costly to train and deploy, particularly on end devices with limited resources. Finally, it can be difficult to comprehend how they make decisions regarding specific types of anomalies. While the latter task appears to be relatively straightforward once there is a comprehensive model explaining the physics of the process producing the data to be analyzed, the&#160;first two need a more thorough investigation. For this purpose, we build upon the approach we adopted earlier in&#160;[<xref rid="B15-sensors-25-05526" ref-type="bibr">15</xref>].</p><p>With the limited set of real measurement data that we had at our disposal, we first constructed reference signals based on our understanding of the originally recorded time-series data. All explainable anomalies shown in <xref rid="sensors-25-05526-f001" ref-type="fig">Figure 1</xref> were corrected by smoothing them out automatically or replacing them with sequences of samples from the nearest preceding or following days, clearly marked by PV jumps between two consecutive sunrises. We then generated hundreds of mutated time-series by injecting various anomalies that had been previously identified into the reference series, with&#160;the values of individual parameters varying randomly. Anomalies were introduced realistically, namely, for&#160;each anomaly and signal type, a&#160;randomly selected week was subject to local mutations during one of its days. The data obtained in this way, although&#160;synthetic, contained anomalies that were suitably related to the physical properties of the measurement&#160;processes.</p><p>In turn, to&#160;address the limitations of constrained measurement devices at the edge, we took a closer look at alternative types of neural networks for anomaly detection to find a reasonable compromise between the time complexity of the underlying process and the accuracy of signal segmentation. We conducted comparative experiments based on the following three approaches:<list list-type="bullet"><list-item><p><italic toggle="yes">Neural-primed heuristic (NPH)</italic> using two pre-trained neural models to detect the center and edges of anomalies and heuristics to determine the extent of anomalies.</p></list-item><list-item><p><italic toggle="yes">Autoencoder-based (AEB)</italic> comprising a simple 5-layer autoencoder architecture without skip connections but, instead of reproducing the input, it outputs the anomaly probabilities for each signal sample.</p></list-item><list-item><p><italic toggle="yes">U-Net-based (UNB)</italic> using the original U-Net with a 2D input&#160;[<xref rid="B20-sensors-25-05526" ref-type="bibr">20</xref>] reduced to a number of time steps corresponding to the length of a 1D signal, and&#160;with 1D convolutions maintaining the concept of skip connections, i.e.,&#160;connecting the outputs of the encoder layer to the inputs of the decoder layer at the corresponding resolutions.</p></list-item></list></p><p>The reason for considering three different anomaly detector variants with different complexities and different structures was the need to achieve a compromise between accuracy and processing time, which is important when using constrained end devices. Therefore, it is worth investigating which variant offers the best compromise between detection accuracy and processing time, or, at&#160;least, to&#160;be certain of the choice in the case that one of the variants dominates over the&#160;others.</p><sec id="sec3dot1-sensors-25-05526"><title>3.1. Signal&#160;Normalization</title><p>Normalization can be understood as a simple transformation of a signal to reduce some of its variance and make the task of detecting anomalies easier. The lack of normalization would result in the need to use much more data for training to make them more representative. Two types of normalization of signal samples were tested:<list list-type="bullet"><list-item><p>Dividing by the mean, i.e.,&#160;<inline-formula><mml:math id="mm31" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi mathvariant="bold">N</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>&#956;</mml:mi><mml:mi mathvariant="bold">N</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="mm32" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi mathvariant="bold">N</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the normalized value of a signal sample and <inline-formula><mml:math id="mm33" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#956;</mml:mi><mml:mi mathvariant="bold">N</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the mean value of samples in some fragment <italic toggle="yes">N</italic> of the signal&#160;sample.</p></list-item><list-item><p>Normalizing by the average and standard deviation, i.e.,&#160; <inline-formula><mml:math id="mm34" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi mathvariant="bold">N</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>&#956;</mml:mi><mml:mi mathvariant="bold">N</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>&#963;</mml:mi><mml:mi mathvariant="bold">N</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="mm35" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#963;</mml:mi><mml:mi mathvariant="bold">N</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is a standard deviation of a signal sample&#8217;s values in some range <italic toggle="yes">N</italic> of the signal&#160;sample.</p></list-item></list></p><p>Both types of normalization were tested for a global variant (i.e., the&#160;entire signal <inline-formula><mml:math id="mm36" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>) and a local one (i.e., the&#160;signal portion <inline-formula><mml:math id="mm37" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>), and&#160;fed to the neural networks as input. All nine combinations of normalization or its absence were checked. The best solution was to adopt only local normalization by the&#160;mean.</p><p>If an anomaly has a constant amplitude, global normalization introduces additional variance, thus making it more difficult to detect. Normalizing by the mean and standard deviation can flatten out some anomalies, such as instabilities, which are characterized by an increased standard deviation relative to the rest of the&#160;signal.</p></sec><sec id="sec3dot2-sensors-25-05526"><title>3.2. Neural-Primed Heuristic (NPH) Approach</title><p>The neural-primed heuristic approach combines heuristic rules with neural networks, for&#160;example, by&#160;integrating statistical thresholds with deep representations to improve precision and adaptability. This hybrid idea underlies notable systems such as AlphaGo&#160;[<xref rid="B21-sensors-25-05526" ref-type="bibr">21</xref>], which merges neural evaluation with Monte Carlo Tree Search, and&#160;IBM&#8217;s Neuro-Symbolic Concept Learner&#160;[<xref rid="B22-sensors-25-05526" ref-type="bibr">22</xref>], which couples neural perception with symbolic&#160;reasoning.</p><p>In our application, the&#160;approach comprises two stages. First, neural models are trained to detect the center and edges of individual anomalies. In&#160;the second stage, based on the probabilities of occurrence of anomaly centers and edges obtained in the first stage, the&#160;anomalies are segmented using a heuristic method. For both stages, the&#160;same signals from training subset are&#160;used.</p><sec id="sec3dot2dot1-sensors-25-05526"><title>3.2.1. Training Stage of&#160;NPH</title><p>The neural network models were trained based on training examples containing input vectors in the form of fixed-length signal fragments. These examples can be positive (i.e., containing an anomaly) or negative (i.e., without&#160;any anomaly).</p><p>Two types of model were trained with respect to the locations of anomalies within the input&#160;vectors:<list list-type="bullet"><list-item><p>ANN-Center uses vectors with an anomaly located in the middle of the input vector as positive examples;</p></list-item><list-item><p>ANN-Edge uses vectors with left anomaly boundary in the middle of the input vector as positive examples.</p></list-item></list></p><p>In this way, eight models were trained: two for each of the four anomaly types shown in <xref rid="sensors-25-05526-f001" ref-type="fig">Figure 1</xref>. Each model returns the probability of the anomaly center or its left edge occurring in a given signal fragment. The probability of the right edge occurring is determined by applying the input signal with samples in reversed order to the ANN-Edge&#160; model.</p><p>In our experiments, the&#160;structure of the neural network was the same for the ANN-Center and ANN-Edge models except for the number of inputs, which slightly differed for each of the models and also depended on the anomaly type. Several structures with different numbers of Conv1D convolutional layers and fully connected layers were&#160;tested.</p><p>Ultimately, a&#160;four-layer structure consisting of two convolutional layers and two fully connected layers was selected. The&#160;convolutional layers contained 16 filters with a mask width of 5 and 8 filters with a mask width of 3, respectively. The&#160;fully connected layers consisted of 20 and 2 neurons, respectively. The&#160;first three layers used the ReLU activation function, while the last layer used the softmax activation function to obtain a measure of the probability of anomaly occurrence for a given signal&#160;sample. The loss function was cross-entropy and the optimization algorithm was the adaptive moment method ADAM&#160;[<xref rid="B23-sensors-25-05526" ref-type="bibr">23</xref>].</p><p>One of the key problems we faced was selection of the length of the signal fragment <italic toggle="yes">N</italic>, constituting the length of the input vector fed to the network. Longer signal fragments allow for better highlighting of anomaly features against the background of the correct signal but are associated with a longer data processing time by the neural network, which is roughly proportional to the length of the input vector; this is crucial to take into consideration when processing signal data using an MCU. Longer signal fragments can also result in over-fitting to the training data. Therefore, a&#160;reasonable compromise between the measure of segmentation correctness and data processing time is&#160;necessary.</p><p>Based on the results presented in <xref rid="sensors-25-05526-t002" ref-type="table">Table 2</xref>, the&#160;signal length <italic toggle="yes">N</italic> for detecting the center of the anomaly was chosen to be equal to three average anomaly widths, and&#160;that for detecting the edge was equal to two average anomaly&#160;widths.</p><p>The numbers in the Input Vector Length row indicate the mean anomaly length multipliers that provide input lengths for ANN-Center and ANN-Edge models; e.g.,&#160;<inline-formula><mml:math id="mm38" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> for anomaly peak with <inline-formula><mml:math id="mm39" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>2.89</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> mean length gives a <inline-formula><mml:math id="mm40" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mo>&#183;</mml:mo><mml:mn>2.89</mml:mn><mml:mo>&#8773;</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> sample vector as the ANN-Center model input length and <inline-formula><mml:math id="mm41" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#183;</mml:mo><mml:mn>2.89</mml:mn><mml:mo>&#8773;</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> as the ANN-Edge model input&#160;length.</p><p>After analyzing the results presented in <xref rid="sensors-25-05526-t002" ref-type="table">Table 2</xref>, we decided to use <inline-formula><mml:math id="mm42" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>3</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> multipliers due to their much better results compared with <inline-formula><mml:math id="mm43" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>/</mml:mo><mml:mn>1.5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> multipliers. When longer input vectors were used, the&#160;results were slightly better for some anomalies, but&#160;at a much higher computational cost. The&#160;input vector lengths for particular anomalies are presented in <xref rid="sensors-25-05526-t003" ref-type="table">Table 3</xref>.</p><p>The number of multiplications needed to classify a single sample results from the network architecture and is equal to <inline-formula><mml:math id="mm44" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mo>&#183;</mml:mo><mml:mn>16</mml:mn><mml:mo>&#183;</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>3</mml:mn><mml:mo>&#183;</mml:mo><mml:mn>16</mml:mn><mml:mo>&#183;</mml:mo><mml:mn>8</mml:mn><mml:mo>&#183;</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>8</mml:mn><mml:mo>&#183;</mml:mo><mml:mn>20</mml:mn><mml:mo>&#183;</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>20</mml:mn><mml:mo>&#183;</mml:mo><mml:mn>2</mml:mn><mml:mo>=</mml:mo><mml:mn>624</mml:mn><mml:mo>&#183;</mml:mo><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mn>40</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic toggle="yes">N</italic> is the number of samples of the input vector, which depends on the model type and anomaly type, as&#160;presented in <xref rid="sensors-25-05526-t003" ref-type="table">Table 3</xref>. The total number of multiplications to compute probability vectors for heuristic anomaly detection per signal sample can thus be calculated using<disp-formula id="FD3-sensors-25-05526"><label>(3)</label><mml:math id="mm45" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>P</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mspace width="3.33333pt"/><mml:munder><mml:mo>&#8721;</mml:mo><mml:mo>&#8727;</mml:mo></mml:munder><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8727;</mml:mo><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo>&#183;</mml:mo><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8727;</mml:mo><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>632800</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm46" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8727;</mml:mo><mml:mo>&#8712;</mml:mo><mml:mo>{</mml:mo><mml:mi>P</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>J</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm47" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8727;</mml:mo><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> denotes the number of multiplications to classify the center of anomaly &#8220;&#8727;&#8221; for a single sample, and&#160;<inline-formula><mml:math id="mm48" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8727;</mml:mo><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> is the number of multiplications needed to classify an edge of anomaly &#8220;&#8727;&#8221;, respectively.</p></sec><sec id="sec3dot2dot2-sensors-25-05526"><title>3.2.2. Heuristic Segmentation of&#160;Anomalies</title><p>In the second stage of NPH, the&#160;neural network models are used to detect anomalies in the signal by feeding a signal window of fixed length to the input of each model. The anomaly center and left edge probabilities are obtained directly from the ANN-Center and ANN-Edge models, while the right edge is obtained by inverting the input vector to the ANN-Edge model. The overall NPH anomaly segmentation process is described in Algorithm&#160;1.
<array orientation="portrait"><tbody><tr><td align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1"><bold>Algorithm 1</bold> Anomaly segmentation via the NPH&#160;method.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>1:</label><p><bold>function</bold>&#160;<sc>AnomSegmentationByNPH</sc> (<inline-formula><mml:math id="mm49" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>)</p></list-item><list-item><label>2:</label><p>&#160;&#160;&#160;&#160;&#9657; <bold>Input parameters:</bold></p></list-item><list-item><label>3:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#9657;<inline-formula><mml:math id="mm50" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>&#8212;time series</p></list-item><list-item><label>4:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#9657;<inline-formula><mml:math id="mm51" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>&#8212;neural models for center and edge of anomaly detection</p></list-item><list-item><label>5:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#9657;<inline-formula><mml:math id="mm52" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>&#8212;threshold for a region of maximum</p></list-item><list-item><label>6:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#9657;<inline-formula><mml:math id="mm53" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>&#8212;threshold for center or edge maximum value acceptation</p></list-item><list-item><label>7:</label><p>&#160;&#160;&#160;&#160;&#9657; <bold>Output:</bold></p></list-item><list-item><label>8:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#9657;<inline-formula><mml:math id="mm54" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>&#8212;a set of anomaly regions</p><p><bold>&#160;</bold></p></list-item><list-item><label>9:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;<inline-formula><mml:math id="mm55" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>&#8592;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula><sc>CalcProbs</sc>(<inline-formula><mml:math id="mm56" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm57" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>) &#8195;&#8195;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#9657; anomaly probabilty calculation</p></list-item><list-item><label>10:</label><p><bold>&#160;&#160;&#160;&#160;</bold><inline-formula><mml:math id="mm58" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>&#8592;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula><sc>CalcProbs</sc>(<inline-formula><mml:math id="mm59" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm60" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>)</p></list-item><list-item><label>11:</label><p><bold>&#160;&#160;&#160;&#160;</bold><inline-formula><mml:math id="mm61" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>&#8592;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula><sc>CalcProbsRevers</sc>(<inline-formula><mml:math id="mm62" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm63" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#8195;&#9657; using signal in reverse order</p></list-item><list-item><label>12:</label><p>&#160;&#160;&#160;&#160;<bold>for all</bold>&#160;<inline-formula><mml:math id="mm64" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>y</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>&#8712;</mml:mo><mml:mo>{</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>&#160;<bold>do</bold>&#160;&#160;&#160;&#8195;&#160;&#160;&#160;&#8195;&#9657; center and left and right edges of anomaly region</p></list-item><list-item><label>13:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<inline-formula><mml:math id="mm65" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>y</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&#8592;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula><sc>MaximaDeterm</sc>(<inline-formula><mml:math id="mm66" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>y</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>,<inline-formula><mml:math id="mm67" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>)</p></list-item><list-item><label>14:</label><p>&#160;&#160;&#160;&#160;<bold>end for</bold></p></list-item><list-item><label>15:</label><p>&#160;&#160;&#160;&#160;<inline-formula><mml:math id="mm68" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>s</mml:mi><mml:mo>&#8592;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula><sc>PotentialAnomDetermination</sc>(<inline-formula><mml:math id="mm69" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>)</p></list-item><list-item><label>16:</label><p>&#160;&#160;&#160;&#160;<inline-formula><mml:math id="mm70" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mo>&#8592;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula><sc>GradesCalculation</sc>(<inline-formula><mml:math id="mm71" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>) &#160;&#160;&#160;&#160;&#160;&#160;&#8195;&#160;&#160;&#160;&#8195;&#9657; grade calculation using Formula (<xref rid="FD4-sensors-25-05526" ref-type="disp-formula">4</xref>)</p></list-item><list-item><label>17:</label><p>&#160;&#160;&#160;&#160;<inline-formula><mml:math id="mm72" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>s</mml:mi><mml:mo>&#8592;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula><sc>OverlappedAnomRemoval</sc>(<inline-formula><mml:math id="mm73" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>)</p></list-item><list-item><label>18:</label><p>&#160;&#160;&#160;&#160;<bold>return</bold>&#160;<inline-formula><mml:math id="mm74" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>19:</label><p><bold>end function</bold></p></list-item></list></td></tr></tbody></array></p><p>The NPH processing scheme is shown in <xref rid="sensors-25-05526-f004" ref-type="fig">Figure 4</xref>. Blue arrows indicate the direction of data&#160;flow.</p><p>A signal fragment <inline-formula><mml:math id="mm75" overflow="scroll"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mo>&#8727;</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> is considered a potential anomaly when it has a sufficiently high maximum probability for the left edge of an anomaly on its left side <inline-formula><mml:math id="mm76" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>N</mml:mi><mml:mo>&#8727;</mml:mo><mml:mi>L</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>, a&#160;sufficiently high maximum probability of the right edge of an anomaly on its right side <inline-formula><mml:math id="mm77" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>N</mml:mi><mml:mo>&#8727;</mml:mo><mml:mi>R</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>, and&#160;a sufficiently high maximum probability of a center anomaly near its center. For simplicity, a&#160;single threshold <inline-formula><mml:math id="mm78" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> value is assumed for all three maxima, after&#160;which the given maximum is taken into account for segmentation. The allowable ranges for the widths of individual anomalies were also assumed to be equal to the minimum and maximum widths of anomalies of a given type determined from the training data. Determining values of the local maximum probability involves adopting a threshold <inline-formula><mml:math id="mm79" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> for the height of the maximum region, which may contain only one maximum (analogous to the peak prominence as a feature of mountain peaks, which is the elevation of the lowest contour within which there is no higher peak).</p><p>The regions and chosen maxima are shown in <xref rid="sensors-25-05526-f005" ref-type="fig">Figure 5</xref> as an exemplary anomaly probability chart.</p><p>Given maxima for all key points of the anomaly region, using the PotentialAnomDetermination procedure, we can generate potential anomalies from triplets of maxima occurring in the appropriate order, with&#160;the width of the potential anomaly limited to the maximum anomaly width in the training set. It is assumed that anomalies of the same type cannot overlap within one measurement signal. Therefore, to&#160;assess the significance of a potential anomaly, the&#160;following metric was defined: <disp-formula id="FD4-sensors-25-05526"><label>(4)</label><mml:math id="mm80" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:msub><mml:mi>f</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm81" overflow="scroll"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm82" overflow="scroll"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and&#160;<inline-formula><mml:math id="mm83" overflow="scroll"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> denote the values of the respective probability maxima in <xref rid="sensors-25-05526-f006" ref-type="fig">Figure 6</xref>, whereas <inline-formula><mml:math id="mm84" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is a measure of the centrality of the maximum probability of the anomaly center relative to the maxima of the probabilities of the left and right anomaly edges. If potential anomalies overlap, those with lower grade are discarded, as specified in Algorithm&#160;2.
<array orientation="portrait"><tbody><tr><td align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1"><bold>Algorithm 2</bold> Overlapped anomaly removal for NPH&#160;detection.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>1:</label><p>&#160;<bold>function</bold>&#160;<sc>OverlappedAnomRemoval</sc>(<inline-formula><mml:math id="mm85" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>)</p></list-item><list-item><label>2:</label><p>&#160;&#160;&#160;&#160;&#9657; <bold>Input parameters:</bold></p></list-item><list-item><label>3:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#9657;<inline-formula><mml:math id="mm86" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>&#8212;set of potential anomalies represented of regions of signal</p></list-item><list-item><label>4:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#9657;<inline-formula><mml:math id="mm87" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>&#8212;grades for all potential anomalies calculated by Formula (<xref rid="FD4-sensors-25-05526" ref-type="disp-formula">4</xref>)</p></list-item><list-item><label>5:</label><p>&#160;&#160;&#160;&#160;&#9657; <bold>Output:</bold></p></list-item><list-item><label>6:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#9657;<inline-formula><mml:math id="mm88" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>&#8212;a set of the most reliable and not overlapped anomalies</p><p><bold>&#160;&#160;</bold></p></list-item><list-item><label>7:</label><p>&#160;&#160;&#160;&#160;<bold>for</bold>&#160;<inline-formula><mml:math id="mm89" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>&#160;<bold>do</bold>&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#160;&#160;&#160;&#160;&#160;&#9657;<italic toggle="yes">K</italic>&#8212;the number of potential anomalies</p></list-item><list-item><label>8:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<bold>for</bold>&#160;<inline-formula><mml:math id="mm90" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>&#8800;</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>&#160;<bold>do</bold></p></list-item><list-item><label>9:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<bold>if</bold>&#160;<sc>Overlapped</sc>(<inline-formula><mml:math id="mm91" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>s</mml:mi><mml:mo>[</mml:mo><mml:mi>n</mml:mi><mml:mo>]</mml:mo><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>s</mml:mi><mml:mo>[</mml:mo><mml:mi>m</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>)&#160; <bold>and</bold><inline-formula><mml:math id="mm92" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>[</mml:mo><mml:mi>n</mml:mi><mml:mo>]</mml:mo><mml:mo>&#8804;</mml:mo><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo>[</mml:mo><mml:mi>m</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>&#160;<bold>then</bold></p></list-item><list-item><label>10:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<sc>MarkForRemove</sc>(<inline-formula><mml:math id="mm93" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mo>[</mml:mo><mml:mi>n</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>)</p></list-item><list-item><label>11:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<bold>end if</bold></p></list-item><list-item><label>12:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<bold>end for</bold></p></list-item><list-item><label>13:</label><p>&#160;&#160;&#160;&#160;<bold>end for</bold></p></list-item><list-item><label>14:</label><p>&#160;&#160;&#160;&#160;<inline-formula><mml:math id="mm94" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>s</mml:mi><mml:mo>&#8592;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula><sc>RemoveAllMarkedAnoms</sc>(<inline-formula><mml:math id="mm95" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>)</p></list-item><list-item><label>15:</label><p>&#160;&#160;&#160;&#160;<bold>return</bold>&#160;<inline-formula><mml:math id="mm96" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>16:</label><p><bold>end function</bold></p></list-item></list></td></tr></tbody></array></p><p>An example signal waveform, along with the associated detection results, is shown in <xref rid="sensors-25-05526-f006" ref-type="fig">Figure 6</xref>. In a situation where there is a possibility of anomalies overlapping, some of them are rejected based on evaluation of the <inline-formula><mml:math id="mm97" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> measure defined in Equation&#160;(<xref rid="FD4-sensors-25-05526" ref-type="disp-formula">4</xref>), which depends on the product of the heights of the maxima and the degree to which the center lies in the middle of the interval between the left and right&#160;edges.</p><p>The entire heuristic stage of NPH, after&#160;determining the probability vectors of the anomaly center and edges, is repeated for different values of the threshold <inline-formula><mml:math id="mm98" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> using the training data to determine its optimal&#160;value.</p></sec><sec id="sec3dot2dot3-sensors-25-05526"><title>3.2.3. Cyclic Training and Generation of Negative&#160;Examples</title><p>For each anomaly type, the&#160;learning and detection processes in either stage of NPH are performed repeatedly. In the first round, positive examples with anomalies and randomly selected negative examples without anomalies are extracted from the training data and used to train the models. Then, after&#160;each round, difficult negative examples are selected based on the detection results. These are signal fragments falsely classified as positive with a high probability of containing anomalies, as&#160;illustrated in <xref rid="sensors-25-05526-f007" ref-type="fig">Figure 7</xref>.</p><p>Using these false positive (FP) examples to train models in the next round allows for a significant reduction in the false positive rate (FPR). A motivation for this process is the inability to check before the first cycle, in&#160;which correct parts of the signal may be confused with anomalies. From cycle to cycle, increasingly difficult false positive examples are extracted, making it increasingly possible to distinguish true anomalies from apparent&#160;ones.</p></sec></sec><sec id="sec3dot3-sensors-25-05526"><title>3.3. Autoencoder-Based (AEB) Approach</title><p>There are numerous examples in the literature of successful applications using autoencoders to detect anomalies in time series, particularly in approaches that treat anomaly detection as a sequence labeling task. For&#160;example, in&#160;[<xref rid="B24-sensors-25-05526" ref-type="bibr">24</xref>], attention mechanisms and autoencoders were combined to capture both local and long-term relationships in time-series data. Other approaches take advantage of regularizing autoencoders; for example, through the use of wavelet transforms&#160;[<xref rid="B25-sensors-25-05526" ref-type="bibr">25</xref>]. However, few studies have focused on pinpointing the exact time steps in which anomalies occur&#160;[<xref rid="B2-sensors-25-05526" ref-type="bibr">2</xref>].</p><p>An alternative approach, which was applied in our project for delimitation of the anomalies shown in <xref rid="sensors-25-05526-f001" ref-type="fig">Figure 1</xref>, is to use an autoencoder that outputs an anomaly probability value for each input signal sample. The most important feature of such a neural network is that it has the same number of outputs as&#160;inputs.</p><p>To achieve this, one can use many one-dimensional convolutional layers of the <italic toggle="yes">Conv1D</italic> type, which do not cause shortening of the signal at the output of each layer. Another possibility may be the use of layers with padding parameter set to same and the strides parameter set to 1. Another is shortening the output signal in the initial network structure (e.g., using <inline-formula><mml:math id="mm99" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), and&#160;then extending the signal using transposed convolutional Conv1DTranspose layers in the final part of the network; this latter solution was adopted in this study, as&#160;outlined in <xref rid="sensors-25-05526-f008" ref-type="fig">Figure 8</xref>.</p><p>By compressing information in the central part of the structure, this type of network allows for overall analysis of the entire input signal fragment with a small number of layers, which is important when considering segmentation problems. More details regarding this type of layer may be found in&#160;[<xref rid="B26-sensors-25-05526" ref-type="bibr">26</xref>].</p><p>The number of channels obtained after filtering is indicated at the bottom of <xref rid="sensors-25-05526-f008" ref-type="fig">Figure 8</xref>. Each filter corresponds to one output channel, and&#160;we used filters with a mask of length 7. The sample value in the output channel is calculated using the ReLU activation function on the weighted sums of seven-sample neighborhoods of samples from individual input channels. The exception is the last layer, which contains only one filter and a linear activation function. Values below zero are converted to zero and values above 1 are converted to 1, such that each output value corresponds to the probability of an anomaly occurring. When using AEB, similarly to NPH, a&#160;separate model was created for each pair (i.e., an&#160;anomaly and a physical parameter), resulting in a total of 12 models that were trained and tested independently. The number of multiplications per sample for one model is equal to 5679. Taking into account that four models are needed to detect all anomalies, the&#160;number of multiplications per sample is thus <inline-formula><mml:math id="mm100" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>E</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>22,716</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. The&#160;number of additions is almost the&#160;same.</p><sec id="sec3dot3dot1-sensors-25-05526"><title>3.3.1. AEB&#160;Training</title><p>The network was trained with signal fragments of a fixed length equal to 30 times the average anomaly length; each randomly selected fragment contained several labeled anomalies at random locations. Such a signal fragment length guarantees an appropriate amount of background signal for anomaly isolation. The input length for an autoencoder network increases the training time but has no effect on the detection time, provided that the network structure contains only convolutional layers. However, for&#160;longer signal fragments, no improvement in results was observed. An additional problem in the case of using convolutional layers in the encoder is the reduction of the signal resolution in individual layers (usually twice) due to subsampling (e.g., <italic toggle="yes">stride</italic> = 2, or&#160;using the <italic toggle="yes">MaxPool1D</italic> operation in the case of UNB, as&#160;discussed below). As it may be a good idea to set the input length as a power of 2, in&#160;this study, we rounded this value up to the nearest power of 2. In <xref rid="sensors-25-05526-t004" ref-type="table">Table 4</xref>, the&#160;average lengths of anomalies of the respective types and the determined lengths of signal fragments fed to the autoencoder as input are&#160;presented.</p><p>For each anomaly that occurred in the training data signals, 50 randomly selected fragments containing the anomaly were generated to train the autoencoder in a way that is invariant with respect to the position of the anomaly in the analyzed signal fragment. The training set was supplemented with 500 randomly selected signal fragments containing mainly the background, thus being ten times greater than the number of fragments that definitely included&#160;anomalies.</p><p>For each pair (an anomaly and a physical parameter), the&#160;loss function was the mean squared error (MSE), calculated as the squared difference between the probabilities output by the network and the ground truth labels. Training was performed for 100 epochs, with&#160;modification of the network weights using the ADAM method mentioned above. In each epoch, all training examples were grouped into&#160;minibatches.</p></sec><sec id="sec3dot3dot2-sensors-25-05526"><title>3.3.2. Detection of Anomaly by&#160;AEB</title><p>Segmentation of anomalies into T, M and pH signals required feeding the model subsequent signal fragments with lengths depending on the type of detected anomaly specified in <xref rid="sensors-25-05526-t004" ref-type="table">Table 4</xref> as the input. Each subsequent fragment overlapped the previous one by about 30%, as&#160;shown in <xref rid="sensors-25-05526-f009" ref-type="fig">Figure 9</xref>.</p><p>The model output represents the probability of an anomaly occurring in each sample of the selected signal fragment. In overlapping areas, when a given sample belongs to two independently processed signal fragments, the&#160;anomaly probability is calculated as the maximum value of the two obtained values. A 30% overlap allows the anomaly context to be included if one of the fragments contains only a part of it, as&#160;illustrated in <xref rid="sensors-25-05526-f009" ref-type="fig">Figure 9</xref>. Higher overlap values increase the time complexity of the detection process, but&#160;do not significantly improve the&#160;results.</p><p>The final binary anomaly labels are determined by thresholding the probability values. The standard threshold is <inline-formula><mml:math id="mm101" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>0.5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, above&#160;which the sample value is considered anomalous. However, these results can be improved by determining an optimal threshold for the selected criterion (e.g., intersection over union (IOU), as&#160;defined in Equation&#160;(<xref rid="FD1-sensors-25-05526" ref-type="disp-formula">1</xref>)) for each neural network model. Such a threshold can be determined using the aggregated probabilities of anomaly occurrence in individual samples for all signals in the training set, as&#160;shown in <xref rid="sensors-25-05526-f009" ref-type="fig">Figure 9</xref>. Computational efficiency may be ensured by concatenating probability vectors into one long vector, then using Algorithm&#160;3 to sort it in ascending order, and&#160;finally calculating the IOU for each subsequent probability value by counting the true positive&#160;labels.
<array orientation="portrait"><tbody><tr><td align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1"><bold>Algorithm 3</bold> Probability threshold selection for IOU&#160;maximization.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>1:</label><p><bold>function</bold>&#160;<sc>OptimalThresholdSelection</sc>(<inline-formula><mml:math id="mm102" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>)</p></list-item><list-item><label>2:</label><p>&#160;&#160;&#160;&#160;&#9657; <bold>Input parameters:</bold></p></list-item><list-item><label>3:</label><p>&#8195;&#8195;&#160;&#160;&#160;&#160;&#160;&#9657;<inline-formula><mml:math id="mm103" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>&#8212;aggregated vector of anomaly probablities for all training signals</p></list-item><list-item><label>4:</label><p>&#8195;&#8195;&#160;&#160;&#160;&#160;&#160;&#9657;<italic toggle="yes">t</italic>&#8212;aggregated vector of true labels for all training signals</p></list-item><list-item><label>5:</label><p>&#160;&#160;&#160;&#160;&#9657; <bold>Output:</bold></p></list-item><list-item><label>6:</label><p>&#8195;&#8195;&#160;&#160;&#160;&#160;&#160;&#9657;<inline-formula><mml:math id="mm104" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mi>O</mml:mi><mml:mi>U</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>&#8212;optimal threshold for IOU measure</p><p><bold>&#160;&#160;</bold></p></list-item><list-item><label>7:</label><p>&#160;&#160;&#160;&#160;<inline-formula><mml:math id="mm105" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>&#8592;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula><sc>length</sc>(<italic toggle="yes">t</italic>)</p></list-item><list-item><label>8:</label><p>&#160;&#160;&#160;&#160;<inline-formula><mml:math id="mm106" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>&#8592;</mml:mo><mml:mo>|</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>&#8195;&#8195;&#8195;&#8195;&#8195;&#160;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#9657; number of anomaly (positive) samples</p></list-item><list-item><label>9:</label><p>&#160;&#160;&#160;&#160;<inline-formula><mml:math id="mm107" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>O</mml:mi><mml:mi>U</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mo>/</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>10:</label><p>&#160;&#160;<inline-formula><mml:math id="mm108" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mo>&#8592;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula><sc>sort</sc>(<inline-formula><mml:math id="mm109" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>)</p></list-item><list-item><label>11:</label><p>&#160;&#160;<inline-formula><mml:math id="mm110" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#8592;</mml:mo><mml:mi>t</mml:mi><mml:mo>[</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula><sc>argsort</sc>(<inline-formula><mml:math id="mm111" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>)]&#8195;&#8195;&#160;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#9657;<italic toggle="yes">t</italic> is sorted in the same order as <inline-formula><mml:math id="mm112" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>12:</label><p>&#160;&#160;<inline-formula><mml:math id="mm113" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>&#8592;</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>&#160;&#160;&#8195;&#8195;&#8195;&#8195;&#160;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#9657; initial number of true positive samples</p></list-item><list-item><label>13:</label><p>&#8201;&#160;<inline-formula><mml:math id="mm114" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>&#8592;</mml:mo><mml:mi>L</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>&#160;&#160;&#160;&#160;&#160;&#8195;&#8195;&#8195;&#8195;&#160;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#9657; initial number of false positive samples</p></list-item><list-item><label>14:</label><p>&#160;&#160;<bold>for</bold>&#160;<inline-formula><mml:math id="mm115" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>&#160;<bold>do</bold></p></list-item><list-item><label>15:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<inline-formula><mml:math id="mm116" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>&#8592;</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>t</mml:mi><mml:mo>[</mml:mo><mml:mi>n</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>16:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<inline-formula><mml:math id="mm117" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>&#8592;</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>&#8722;</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mi>t</mml:mi><mml:mo>[</mml:mo><mml:mi>n</mml:mi><mml:mo>]</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>17:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<inline-formula><mml:math id="mm118" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>O</mml:mi><mml:mi>U</mml:mi><mml:mo>&#8592;</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>18:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<bold>if</bold>&#160;<inline-formula><mml:math id="mm119" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>O</mml:mi><mml:mi>U</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>I</mml:mi><mml:mi>O</mml:mi><mml:mi>U</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>&#160;<bold>then</bold></p></list-item><list-item><label>19:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<inline-formula><mml:math id="mm120" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>O</mml:mi><mml:mi>U</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo>&#8592;</mml:mo><mml:mi>I</mml:mi><mml:mi>O</mml:mi><mml:mi>U</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>20:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<inline-formula><mml:math id="mm121" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mi>O</mml:mi><mml:mi>U</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>&#8592;</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi>n</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>21:</label><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<bold>end if</bold></p></list-item><list-item><label>22:</label><p>&#160;&#160;&#160;&#160;<bold>end for</bold></p></list-item><list-item><label>23:</label><p>&#160;&#160;&#160;&#160;<bold>return</bold>&#160;<inline-formula><mml:math id="mm122" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mi>O</mml:mi><mml:mi>U</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula></p></list-item><list-item><label>24:</label><p><bold>end function</bold></p></list-item></list></td></tr></tbody></array></p></sec></sec><sec id="sec3dot4-sensors-25-05526"><title>3.4. U-Net-Based (UNB) Approach</title><p>Originally developed for 2D biomedical segmentation [<xref rid="B20-sensors-25-05526" ref-type="bibr">20</xref>], U-Nets can be adapted to 1D time series, enabling the segmentation of anomalies or events in temporal fragments. Such models have shown versatility across domains such as sleep staging [<xref rid="B27-sensors-25-05526" ref-type="bibr">27</xref>], activity recognition [<xref rid="B28-sensors-25-05526" ref-type="bibr">28</xref>], and anomaly detection [<xref rid="B3-sensors-25-05526" ref-type="bibr">3</xref>]. Their compact design yields benefits on small datasets; however, compared with autoencoders, they demand more memory and energy due to deeper layers and skip connections, making them better suited for cloud deployment.</p><p>This approach differs from AEB only in the structure of the network used. All other aspects of training and detection were the same. Details of the UNB structure are shown in <xref rid="sensors-25-05526-f010" ref-type="fig">Figure 10</xref>.</p><p>As in AEB, the network consists only of convolutional layers&#8212;in this case, a total of 23 layers&#8212;that are considered to be parts of the structure that process data using weight parameters. In <xref rid="sensors-25-05526-f010" ref-type="fig">Figure 10</xref>, the layers are indicated by blue and white arrows. Blue arrows indicate filtering of the signal by the convolution function <italic toggle="yes">Conv1D</italic> to an output signal with the same resolution. The width of all <italic toggle="yes">Conv1D</italic> filters is equal to 3. In the encoder part, the signal resolution is reduced using the <italic toggle="yes">MaxPool1D</italic> operation every few layers, as indicated by the yellow arrows. This resolution reduction is compensated for by an increase in the number of filters and, therefore, channels. In the decoder part, the resolution is increased using the <italic toggle="yes">Conv1DTranspose</italic> function with filter width equal to 2. Unlike AEB, UNB has additional connections, namely, skip connections, as indicated by grey arrows. These allow for the addition of signals obtained in much earlier stages of processing (i.e., in the encoder part) to the decoder part.</p><p>The number of multiplications per sample for one model is equal to <inline-formula><mml:math id="mm123" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>1,302,413</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. Taking into account that four models are needed to detect all anomalies, the number of multiplications per sample is <inline-formula><mml:math id="mm124" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>E</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>5,209,632</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>; this is about 230 times more than that required for the AEB model.</p></sec></sec><sec id="sec4-sensors-25-05526"><title>4. Experiment</title><p>In this section we provide the details of the performed experiment, including the environment setup, performance metrics, analysis of results, and discussion.</p><sec id="sec4dot1-sensors-25-05526"><title>4.1. Environment Setup and&#160;Data</title><p>For training and testing the NPH, AEB, and UNB methods, the same data were used as in the case of evaluation of the heuristic method with simulated annealing optimization described in the work [<xref rid="B15-sensors-25-05526" ref-type="bibr">15</xref>]. The data consisted of real signals obtained from sensors placed in the soil with different variants of trends and with added artificially generated anomalies, namely, peaks <italic toggle="yes">P</italic>, bumps <italic toggle="yes">B</italic>, jumps <italic toggle="yes">J</italic>, and instabilities <italic toggle="yes">I</italic> of different widths and amplitudes inserted in random places. Details regarding the generated data can be found in [<xref rid="B15-sensors-25-05526" ref-type="bibr">15</xref>]. Experiments focused on the NPH, AEB, and UNB methods were performed independently for each anomaly type <inline-formula><mml:math id="mm125" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mi>P</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>J</mml:mi><mml:mo>,</mml:mo><mml:mi>I</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and each physical parameter T, M and pH, with <inline-formula><mml:math id="mm126" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mo>&#183;</mml:mo><mml:mn>3</mml:mn><mml:mo>=</mml:mo><mml:mn>12</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> model training and testing experiments in total. Neural network models were trained using our cloud computing facility and one <italic toggle="yes">Nvidia H100</italic> card. Training was performed using the Python 3.11.7 interpreter and the Tensorflow 2.18.0 library. The source code for training and testing all described methods is available from <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://ieee-dataport.org/documents/rural-iot-soil-data">https://ieee-dataport.org/documents/rural-iot-soil-data</uri> (accessed on 21 August 2025).</p><p>Details on the neural network structure, optimization method, and loss function are described in <xref rid="sec3dot2-sensors-25-05526" ref-type="sec">Section 3.2</xref> for the NPH method, <xref rid="sec3dot3-sensors-25-05526" ref-type="sec">Section 3.3</xref> for the AEB method, and <xref rid="sec3dot4-sensors-25-05526" ref-type="sec">Section 3.4</xref> for the UNB method.</p><p><xref rid="sensors-25-05526-f011" ref-type="fig">Figure 11</xref> shows the MSE loss function plots obtained during training for the AEB and UNB models. In the case of NPH, for each pair (anomaly, physical parameter), two models are required to detect the center and edge of the anomaly.</p></sec><sec sec-type="results" id="sec4dot2-sensors-25-05526"><title>4.2. Results</title><p>The test error values obtained for the NPH method described in <xref rid="sec3dot2-sensors-25-05526" ref-type="sec">Section 3.2</xref> are presented in <xref rid="sensors-25-05526-t005" ref-type="table">Table 5</xref>. They were calculated for the test data not used in the detector construction process, as described in <xref rid="sec2dot2-sensors-25-05526" ref-type="sec">Section 2.2</xref>.</p><p>These results were obtained for specific threshold values, based on which detectors decided whether a given signal fragment was, in fact, an anomaly. By manipulating the values of these thresholds, we can obtain a trade-off between the FPR and FNR errors described in <xref rid="sec2dot3-sensors-25-05526" ref-type="sec">Section 2.3</xref>. Lower threshold values result in reduced FNR and increased FPS values, and vice versa. In this case, the quality measure of the detection system, regardless of the adopted detection threshold, can be considered as the area under the ROC curve (AUC), when the coordinate axes are FPR and FNR, and the tolerance threshold (or a combination thereof) is the parameter.</p><p>The values of the test error obtained for the AEB method described in <xref rid="sec3dot3-sensors-25-05526" ref-type="sec">Section 3.3</xref> are presented in <xref rid="sensors-25-05526-t006" ref-type="table">Table 6</xref>, and those for the UNB method described in <xref rid="sec3dot4-sensors-25-05526" ref-type="sec">Section 3.4</xref> are presented in <xref rid="sensors-25-05526-t007" ref-type="table">Table 7</xref>.</p><p>Comparing the test FPR and FNR error values and the IOU rates for the NPH, AEB, and UNB models presented in <xref rid="sensors-25-05526-t005" ref-type="table">Table 5</xref>, <xref rid="sensors-25-05526-t006" ref-type="table">Table 6</xref> and <xref rid="sensors-25-05526-t007" ref-type="table">Table 7</xref>, respectively, it can be seen that the error values were significantly smaller for the AEB and UNB methods, whereas the IOU rates were higher; however, this does not necessarily mean that these methods are better than the NPH for anomaly detection on end devices. It is equally important to consider the processing power demand of the end device, the amount of data available for training, and the level of support from the cloud instance for continuous improvement of the model parameters. The weaker results obtained for the NPH method compared with the AEB and UNB methods are probably due to the quality of the heuristics, which were not optimized. On the other hand, heuristics based on human knowledge of the problem may allow for dealing with the problem of small datasets, with which training autoencoders can be difficult. Nevertheless, the results of anomaly segmentation alone with the NPH method were significantly better than those with the SA method. The average IOU value for the test data for the SA method was <inline-formula><mml:math id="mm127" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>0.25</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, which was almost twice as bad than the value obtained with the NPH method (<inline-formula><mml:math id="mm128" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>0.48</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), as presented in <xref rid="sensors-25-05526-t008" ref-type="table">Table 8</xref>. The AEB and UNB methods both present certain advantages and disadvantages. For example, one advantage of the latter is its higher prediction accuracy, as confirmed by our test results, while its disadvantage is a higher power demand due to its more extensive computational structure in comparison with the AEB, which may be a crucial consideration for a constrained device. <xref rid="sensors-25-05526-t009" ref-type="table">Table 9</xref> presents the AUC values obtained for both AEB and UNB methods. These values are presented only for these two methods as, in the case of NPH, the anomaly probabilities were not determined for individual samples due to the heuristic nature of this method.</p><p>ROC curves for anomaly segmentation in temperature (T) signals are presented in <xref rid="sensors-25-05526-f012" ref-type="fig">Figure 12</xref>, in moisture (M) signals in <xref rid="sensors-25-05526-f013" ref-type="fig">Figure 13</xref>, and in pH signals in <xref rid="sensors-25-05526-f014" ref-type="fig">Figure 14</xref>.</p><p>The parameter of each curve is the anomaly probability threshold, the values of which start at <inline-formula><mml:math id="mm129" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>0.0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> in the upper right corner and end at <inline-formula><mml:math id="mm130" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>1.0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> in the lower-left corner. The red color indicates the curve for the training data (sensors <inline-formula><mml:math id="mm131" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mi>s</mml:mi><mml:mn>01</mml:mn><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mn>02</mml:mn><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mn>23</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>), and blue for the test data (sensors <inline-formula><mml:math id="mm132" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mi>s</mml:mi><mml:mn>03</mml:mn><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mn>21</mml:mn><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mn>22</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>). The circle indicates the place on the curve corresponding to the threshold <inline-formula><mml:math id="mm133" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mi>O</mml:mi><mml:mi>U</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, giving the maximum IOU value for training data obtained by Algorithm 3. <xref rid="sensors-25-05526-f015" ref-type="fig">Figure 15</xref>, <xref rid="sensors-25-05526-f016" ref-type="fig">Figure 16</xref> and <xref rid="sensors-25-05526-f017" ref-type="fig">Figure 17</xref> show plots of T, M, and pH signals from sensor <inline-formula><mml:math id="mm134" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>22</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and the regions of true and detected anomalies determined by the three methods used in this work. Signals from this sensor were used only for testing, and thus, the results indicate the generalization ability of the models. The results and graphs for the signals used for training of models are better and more accurate.</p></sec><sec sec-type="discussion" id="sec4dot3-sensors-25-05526"><title>4.3. Discussion</title><p>All of the previously discussed models for detecting and segmenting anomalies in the analyzed signal fragments, after appropriate optimization/tuning on the cloud instance (performed according to the schemes depicted in <xref rid="sensors-25-05526-f002" ref-type="fig">Figure 2</xref> and <xref rid="sensors-25-05526-f003" ref-type="fig">Figure 3</xref>) and their conversion from Python to C, were integrated with the sensor&#8217;s software to implement a daily (every 24 h) cleaning cycle, determined according to two consecutive leading edges of the PV signal. Measurements of the values of individual T, M, and pH signals are carried out with different sampling periods, depending on the dynamics of each individual signal. In the current implementation of our sensors, this period is approx. 10 min for all signals. After the cleaning process, the sample values of individual signals can be aggregated over longer time intervals without losing information, to a maximum of 70 min for M, 90 min for T and PV, and 220 min for pH. This aggregation is necessary to maintain the byte payload of data to be sent to the UAV at an appropriately low level, resulting from the specifications of the LoRaWAN technology (up to 250 bytes per single packet in Europe) [<xref rid="B13-sensors-25-05526" ref-type="bibr">13</xref>].</p><p>The following steps briefly summarize our daily cleaning cycle, as previously specified in detail in [<xref rid="B15-sensors-25-05526" ref-type="bibr">15</xref>]:<list list-type="order"><list-item><p>Samples delayed due to a power gap may have valid values, so they are preserved but marked as &#8220;misplaced&#8221; for further processing in the cloud.</p></list-item><list-item><p>All &#8220;absolute error&#8221; samples are set to the &#8220;empty&#8221; value.</p></list-item><list-item><p>Values of samples labeled by the anomaly detector as &#8220;peak&#8221; and &#8220;jump&#8221; are interpolated with respect to their neighbors.</p></list-item><list-item><p>Samples labeled as &#8220;bump&#8221; are smoothed relative to the values of their adjacent fragments.</p></list-item><list-item><p>Finally, samples labeled as &#8220;instabilities&#8221; are replaced with the signal trend samples, calculated as a daily moving average.</p></list-item></list></p><p>The rationale behind these steps is to first eliminate samples which may affect signal smoothing (steps 1 and 2), before correcting outliers and the most abrupt change points (step 3), followed by less abrupt ones (step 4). Smoothing of values is necessary to eliminate bias that could be introduced during calculation over the values neighboring more gentle changes, such as bumps and instabilities (steps 4 and 5).</p><p>We evaluated the effectiveness of each of the previously analyzed anomaly detection methods defined in <xref rid="sensors-25-05526-f001" ref-type="fig">Figure 1</xref> in the same way as in [<xref rid="B15-sensors-25-05526" ref-type="bibr">15</xref>], that is, by measuring the average distances between each reference signal (ground truth) and the signals cleaned via the operations specified above. The polar charts shown in <xref rid="sensors-25-05526-f018" ref-type="fig">Figure 18</xref> present the results we obtained for all seven (s01&#8211;s03, s10, s21&#8211;s23) devices, with distances averaged across 10 cleaned signals for every week of the lifetime of each sensor.</p><p>As a reference for assessing the effectiveness of time-series cleaning using detectors exploiting the neural network models NPH, AEB, and UNB, we used a heuristic method with simulated annealing-optimized (SA) detector parameters for each anomaly class specified in <xref rid="sensors-25-05526-f001" ref-type="fig">Figure 1</xref>. At least two time series were used for each signal (M, T, and pH): one with truly labeled anomalous samples, and another with samples labeled by the detector being optimized. Several independent optimization tasks were created in this way and were executed in parallel in the computing cloud, each targeting a specific combination of anomaly signal types. As a result, the best possible values of the parameters for individual anomalies were determined, such that each detected anomaly corresponded as closely as possible to the true anomalies [<xref rid="B15-sensors-25-05526" ref-type="bibr">15</xref>].</p><p>The graph shows a relatively small improvement in signal quality with NPH over SA, whereas the improvements of AEB and UNB over SA are more significant. However, in the case of detection alone (without taking into account the effects of the cleaning algorithm), the NPH method was clearly better than the SA method, yielding almost twice the IOU value, evidence of which may be found in [<xref rid="B14-sensors-25-05526" ref-type="bibr">14</xref>]. It also performed better than the AEB method in some cases (e.g., in segmenting bump anomalies in the moisture signal, as can be seen from <xref rid="sensors-25-05526-t005" ref-type="table">Table 5</xref> and <xref rid="sensors-25-05526-t006" ref-type="table">Table 6</xref>).</p><p>The worst segmentation quality was observed for jump anomalies, as indicated by both the IOU values presented in <xref rid="sensors-25-05526-t005" ref-type="table">Table 5</xref>, <xref rid="sensors-25-05526-t006" ref-type="table">Table 6</xref> and <xref rid="sensors-25-05526-t007" ref-type="table">Table 7</xref>, as well as the AUC values presented in <xref rid="sensors-25-05526-t009" ref-type="table">Table 9</xref>. The reason for this is likely that a jump anomaly involves a momentary change in the trend in the time series, while the trends in the signal outside of the jump appear normal, which can make the detection of such an anomaly difficult.</p><p>The best segmentation quality was achieved for the temperature signal. This is likely due to the greater predictability of the trend and its daily periodicity, which makes it easier to distinguish anomalies from random noise.</p><p>As shown in <xref rid="sensors-25-05526-t009" ref-type="table">Table 9</xref> and <xref rid="sensors-25-05526-f012" ref-type="fig">Figure 12</xref>, <xref rid="sensors-25-05526-f013" ref-type="fig">Figure 13</xref> and <xref rid="sensors-25-05526-f014" ref-type="fig">Figure 14</xref>, the segmentation results for the training data were clearly better than those for the test data. This indicates that the test results can be improved through the use of larger amounts of training data.</p><p>The comparison of anomaly detection performance against processing time for the three methods is presented in <xref rid="sensors-25-05526-t008" ref-type="table">Table 8</xref>. The intersection over union (IOU) measure was averaged across 12 detectors for combinations of four anomaly types and three measured physical parameters. It is also considered as a measure of generalization ability, as it was calculated only for the test sensors <inline-formula><mml:math id="mm135" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mi>s</mml:mi><mml:mn>03</mml:mn><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mn>21</mml:mn><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mn>22</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. The number of addition operations in neural network model processing is approximately the same as the number of multiplications in each method and the same as the number of model parameters. Therefore, the total number of arithmetic operations can be approximately calculated by multiplying the number of multiplications by 2. Memory usage is also roughly proportional to the number of parameters of the neural model.</p><p>The last row of <xref rid="sensors-25-05526-t008" ref-type="table">Table 8</xref> provides the average time complexity, expressed as processing time (excluding the time required to load neural models from disk to working memory). These values are not directly proportional to the number of multiplications (neural network model parameters) due to other operations, such as input vector normalization, output vector summation, or heuristic segmentation in the case of the NPH method. Individual times were determined using one CPU and one GPU of an Nvidia H100 computer for segmentation scripts written in Python. However, in the target microcomputer environment equipped with measurement devices, C code is expected to be used. Given the hardware capabilities and different implementation languages, the processing times may be much longer and in different proportions for the individual methods. The best method for anomaly detection accuracy appears to be the U-Net-based (UNB) model. However, the large number of arithmetic operations required per signal sample can be problematic on a constrained device running an MCU. Therefore, the AEB method seems to be a reasonable choice, as it offers only slightly lower accuracy but at the cost of nearly 230 times lower processing time. On the other hand, while the NPH method appears to be dominated by the other two methods, it has potential for improvement (especially regarding the heuristic component).</p><p>Anomaly detection in sensor-generated time series is highly application-specific, and there is no universal method that is suitable for every scenario. In IoT and industrial contexts, models such as ARIMA, machine learning classifiers, clustering, and deep learning require tailored selection and tuning depending on the nature of the sensor data and the anomaly type [<xref rid="B29-sensors-25-05526" ref-type="bibr">29</xref>]. For example, statistical and forecasting models turn out to be appropriate when time-series data exhibit clear trend and seasonal structures. An Isolation Forest scales well to high-dimensional, sparse, or unbalanced datasets. In environmental monitoring, such as high-frequency water quality sensors, researchers have found that combining regression-based methods, feature-based detection, and rule-based techniques improves performance, as each method excels at capturing different types of anomalies such as spikes, drift, or missing values [<xref rid="B30-sensors-25-05526" ref-type="bibr">30</xref>].</p><p>Similarly, when comparing various deep learning frameworks, it has been highlighted that even state-of-the-art models (e.g., autoencoders, graph-based networks, LSTM encoder&#8211;decoders) cannot be universally applied across systems, as their effectiveness depends on many factors such as cross-sensor relations, temporal dependencies, and system-specific characteristics [<xref rid="B31-sensors-25-05526" ref-type="bibr">31</xref>]. Autoencoders effectively adapt to complex, non-linear patterns [<xref rid="B32-sensors-25-05526" ref-type="bibr">32</xref>]. Advanced multivariate deep models (e.g., InterFusion) are ideal for multi-sensor systems where both temporal patterns and cross-sensor dependencies matter [<xref rid="B33-sensors-25-05526" ref-type="bibr">33</xref>]. GAN-based approaches such as TAD-GAN are powerful for anomaly detection, as they can jointly perform realistic time-series generation and discrimination, enabling subtle deviations from normal behavior to be effectively identified [<xref rid="B34-sensors-25-05526" ref-type="bibr">34</xref>].</p><p>Consequently, the design of anomaly detection systems must be adapted to the specific application context, data characteristics, anomaly types, and operational requirements.</p></sec></sec><sec sec-type="conclusions" id="sec5-sensors-25-05526"><title>5. Conclusions</title><p>In this paper, we report the results of a three-year R&amp;D project during which we developed and deployed a demonstration Rural IoT measurement ecosystem in a real operation environment. The proposed system enables the monitoring of soil parameters in vast areas, such as farmland, forests, or river banks, where there is no telecommunications infrastructure enabling the transmission of data from measurement sensors planted in the ground to a cloud instance for further processing. A key component of this ecosystem is a nomadic gateway carried by a UAV. While such a UAV may possess sufficient lifting capacity and operational range, the working conditions of the mobile gateway do not differ much from its stationary counterpart on the ground. As such, a number of problems relating to the use of ground sensors arise due to the moderate computational capabilities of their MCUs, battery capacity, and limited byte payload that can be sent from the sensor to a nearby UAV. The volume of data to be sent varies due to the timing of UAV flights, depending on the weather conditions and the availability of airspace over the monitored area. Hence, each sensor may be tasked to clean incorrect, redundant, or irrelevant samples in the collected raw data time-series, such that the ultimately transmitted packet is as small as possible and falls within the available limitations.</p><p>The cleaning of time-series data first requires detecting and locating anomalous samples which the sensor software can correct or remove to obtain cleaned data that are ready for sending. To address the problem of determining which specific signal samples the sensor software should classify as anomalous, we developed a method based on comprehensive interpretation of the physical characteristics of soil signal measurement processes, enabling us to distinguish four generic classes of anomalies. These classes can be parameterized, making it possible to explain and adjust the anomaly detection and segmentation processes to specific soil types, climates, or sensor modalities at any geographical latitude where agricultural activities are carried out. We tested four alternative solutions for anomaly detection: a solution with heuristically selected anomaly parameters and their SA-optimized variants [<xref rid="B15-sensors-25-05526" ref-type="bibr">15</xref>]; NPH, which involves fully heuristic anomaly detection; and the more computationally expensive AEB and UNB models. We carried out a comparative assessment of these methods regarding their detection performance and computational complexity. We also validated their performance limits using sensors based on Arduino and LoRaWAN technology in realistic operational environments, including farms (54&#176;07&#8242;12.0&#8243; N 18&#176;46&#8242;48.0&#8243; E) and forests (54&#176;0&#8242;50.0&#8243; N 17&#176;49&#8242;45.0&#8243; E). It should be noted that, by &#8221;realistic&#8221; we mean solutions that can be implemented using Arduino-compatible MCUs. Analysis of the time and memory complexity of the four tested models presented in this paper confirmed their satisfactory effectiveness in cleaning the anomalies defined in <xref rid="sensors-25-05526-f001" ref-type="fig">Figure 1</xref> from the collected real-world time-series data.</p><p>Our experience from three growing seasons starting from 2023 indicates that sporadic power outages of individual sensors developed for the project, which were observed during irregular UAV operations caused by weather conditions (thus preventing UAVs from collecting data regularly on a 1- to 3-day basis), do not really pose a serious problem, and thus, the measured data can be quite effectively cleaned by the sensor and processed further in our TASKcloud instance [<xref rid="B17-sensors-25-05526" ref-type="bibr">17</xref>]. However, further research is needed to determine operational limits for the production version of the measurement sensors, with further reduced battery capacity, PV cell, and box dimensions, compared with our current experimental version. The latter utilizes an Arduino-compatible 32-bit 64 MHz MCU with 256 KB of flash memory to store the executable code and 32 KB of RAM to store data, powered by a 350 mAh LiPo battery and a 135 &#215; 165 mm PV cell with a nominal voltage of 6.0 V, all housed in a weather-resistant 175 &#215; 225 &#215; 80 mm box. At present, we are conducting a series of electrical measurement experiments to determine the sensor&#8217;s energy reserve limits, to make it more compact and sufficient for continuous operation over extended (weekly or monthly) periods. A detailed description of this experiment, however, is beyond the scope of the current paper. The ultimate goal of this research is to develop disposable sensors that can be dropped over large areas by UAVs, to further reduce the cost of deploying rural IoT networks.</p></sec></body><back><ack><title>Acknowledgments</title><p>Thanks are due to many people who are directly and indirectly involved in the Rural IoT project: Dariusz Klimowicz and ukasz Wiszniewski for designing and programming the measurement sensors and the mobile gateway, Krzysztof Drypczewski and Piotr Orzechowski for deploying cloud services on the Gdansk Tech cloud for the acquistion and collection of data from the sensors, Avatar Technologies firm for providing us with a VTOL UAV monoplane capable of performing long-term measurement missions (in particular, Dariusz Czajka and his team of pilots performing flights in various weather conditions), Tadeusz Dumi&#324;ski for providing his farmland for conducting year-round measurements of soil parameters, and finally Bogumi&#322; Bierawski for granting us access to his landing airstrip with an adjacent forest complex for the testing of alternative UAV platforms.</p></ack><fn-group><fn><p><bold>Disclaimer/Publisher&#8217;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><notes><title>Author Contributions</title><p>Conceptualization, J.D., A.K. and B.W.; methodology, J.D. and A.K.; software, J.D. and A.K.; validation, B.W.; investigation, J.D., A.K. and B.W.; writing&#8212;original draft preparation, B.W.; writing&#8212;review and editing, J.D., A.K. and B.W.; visualization, J.D. and A.K.; supervision, B.W.; funding acquisition, B.W. All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Institutional Review Board Statement</title><p>Not applicable.</p></notes><notes><title>Informed Consent Statement</title><p>Not applicable.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>The original data presented in the study are openly available from IEEE DataPort at <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://doi.org/10.21227/0j1h-ew11">https://doi.org/10.21227/0j1h-ew11</uri> (accessed on 21 August 2025).</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflicts of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-25-05526"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>H.</given-names></name><name name-style="western"><surname>Song</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Yang</surname><given-names>M.</given-names></name><name name-style="western"><surname>Jia</surname><given-names>Q.</given-names></name></person-group><article-title>Modeling and Optimization of LoRa Networks under Multiple Constraints</article-title><source>Sensors</source><year>2023</year><volume>23</volume><elocation-id>7783</elocation-id><pub-id pub-id-type="doi">10.3390/s23187783</pub-id><pub-id pub-id-type="pmid">37765840</pub-id><pub-id pub-id-type="pmcid">PMC10537289</pub-id></element-citation></ref><ref id="B2-sensors-25-05526"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wei</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Jang-Jaccard</surname><given-names>J.</given-names></name><name name-style="western"><surname>Xu</surname><given-names>W.</given-names></name><name name-style="western"><surname>Sabrina</surname><given-names>F.</given-names></name><name name-style="western"><surname>Camtepe</surname><given-names>S.</given-names></name><name name-style="western"><surname>Boulic</surname><given-names>M.</given-names></name></person-group><article-title>LSTM-Autoencoder-Based Anomaly Detection for Indoor Air Quality Time-Series Data</article-title><source>IEEE Sensors J.</source><year>2023</year><volume>23</volume><fpage>3787</fpage><lpage>3800</lpage><pub-id pub-id-type="doi">10.1109/JSEN.2022.3230361</pub-id></element-citation></ref><ref id="B3-sensors-25-05526"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wen</surname><given-names>T.</given-names></name><name name-style="western"><surname>Keyes</surname><given-names>R.</given-names></name></person-group><article-title>Time Series Anomaly Detection Using Convolutional Neural Networks and Transfer Learning</article-title><source>arXiv</source><year>2019</year><pub-id pub-id-type="doi">10.48550/arXiv.1905.13628</pub-id><pub-id pub-id-type="arxiv">1905.13628</pub-id></element-citation></ref><ref id="B4-sensors-25-05526"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cook</surname><given-names>A.A.</given-names></name><name name-style="western"><surname>Misirli</surname><given-names>G.</given-names></name><name name-style="western"><surname>Fan</surname><given-names>Z.</given-names></name></person-group><article-title>Anomaly Detection for IoT Time-Series Data: A Survey</article-title><source>IEEE Internet Things J.</source><year>2020</year><volume>7</volume><fpage>6481</fpage><lpage>6494</lpage><pub-id pub-id-type="doi">10.1109/JIOT.2019.2958185</pub-id></element-citation></ref><ref id="B5-sensors-25-05526"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pateras</surname><given-names>J.</given-names></name><name name-style="western"><surname>Rana</surname><given-names>P.</given-names></name><name name-style="western"><surname>Ghosh</surname><given-names>P.</given-names></name></person-group><article-title>A Taxonomic Survey of Physics-Informed Machine Learning</article-title><source>Appl. Sci.</source><year>2023</year><volume>13</volume><elocation-id>6892</elocation-id><pub-id pub-id-type="doi">10.3390/app13126892</pub-id></element-citation></ref><ref id="B6-sensors-25-05526"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Ye</surname><given-names>M.</given-names></name><name name-style="western"><surname>Cheng</surname><given-names>J.</given-names></name><name name-style="western"><surname>Zhu</surname><given-names>C.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>Y.</given-names></name></person-group><article-title>An Anomaly Node Detection Method for Wireless Sensor Networks Based on Deep Metric Learning with Fusion of Spatial&#8211;Temporal Features</article-title><source>Sensors</source><year>2025</year><volume>25</volume><elocation-id>3033</elocation-id><pub-id pub-id-type="doi">10.3390/s25103033</pub-id><pub-id pub-id-type="pmid">40431828</pub-id><pub-id pub-id-type="pmcid">PMC12114998</pub-id></element-citation></ref><ref id="B7-sensors-25-05526"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Izadi</surname><given-names>D.</given-names></name><name name-style="western"><surname>Abawajy</surname><given-names>J.H.</given-names></name><name name-style="western"><surname>Ghanavati</surname><given-names>S.</given-names></name><name name-style="western"><surname>Herawan</surname><given-names>T.</given-names></name></person-group><article-title>A Data Fusion Method in Wireless Sensor Networks</article-title><source>Sensors</source><year>2015</year><volume>15</volume><fpage>2964</fpage><lpage>2979</lpage><pub-id pub-id-type="doi">10.3390/s150202964</pub-id><pub-id pub-id-type="pmid">25635417</pub-id><pub-id pub-id-type="pmcid">PMC4367343</pub-id></element-citation></ref><ref id="B8-sensors-25-05526"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kenyeres</surname><given-names>M.</given-names></name><name name-style="western"><surname>Kenyeres</surname><given-names>J.</given-names></name><name name-style="western"><surname>Hassankhani Dolatabadi</surname><given-names>S.</given-names></name></person-group><article-title>Distributed Consensus Gossip-Based Data Fusion for Suppressing Incorrect Sensor Readings in Wireless Sensor Networks</article-title><source>J. Low Power Electron. Appl.</source><year>2025</year><volume>15</volume><elocation-id>6</elocation-id><pub-id pub-id-type="doi">10.3390/jlpea15010006</pub-id></element-citation></ref><ref id="B9-sensors-25-05526"><label>9.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Sharma</surname><given-names>A.</given-names></name><name name-style="western"><surname>Golubchik</surname><given-names>L.</given-names></name><name name-style="western"><surname>Govindan</surname><given-names>R.</given-names></name></person-group><article-title>On the Prevalence of Sensor Faults in Real-World Deployments</article-title><source>Proceedings of the 2007 4th Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks</source><conf-loc>San Diego, CA, USA</conf-loc><conf-date>18&#8211;21 June 2007</conf-date><fpage>213</fpage><lpage>222</lpage><pub-id pub-id-type="doi">10.1109/SAHCN.2007.4292833</pub-id></element-citation></ref><ref id="B10-sensors-25-05526"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vladov</surname><given-names>S.</given-names></name><name name-style="western"><surname>Vysotska</surname><given-names>V.</given-names></name><name name-style="western"><surname>Sokurenko</surname><given-names>V.</given-names></name><name name-style="western"><surname>Muzychuk</surname><given-names>O.</given-names></name><name name-style="western"><surname>Nazarkevych</surname><given-names>M.</given-names></name><name name-style="western"><surname>Lytvyn</surname><given-names>V.</given-names></name></person-group><article-title>Neural Network System for Predicting Anomalous Data in Applied Sensor Systems</article-title><source>Appl. Syst. Innov.</source><year>2024</year><volume>7</volume><elocation-id>88</elocation-id><pub-id pub-id-type="doi">10.3390/asi7050088</pub-id></element-citation></ref><ref id="B11-sensors-25-05526"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pirayesh</surname><given-names>H.</given-names></name><name name-style="western"><surname>Zeng</surname><given-names>H.</given-names></name></person-group><article-title>Jamming Attacks and Anti-Jamming Strategies in Wireless Networks: A Comprehensive Survey</article-title><source>IEEE Commun. Surv. Tutor.</source><year>2022</year><volume>24</volume><fpage>767</fpage><lpage>809</lpage><pub-id pub-id-type="doi">10.1109/COMST.2022.3159185</pub-id></element-citation></ref><ref id="B12-sensors-25-05526"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hu</surname><given-names>J.</given-names></name><name name-style="western"><surname>Yang</surname><given-names>X.</given-names></name><name name-style="western"><surname>Yang</surname><given-names>L.X.</given-names></name></person-group><article-title>A Framework for Detecting False Data Injection Attacks in Large-Scale Wireless Sensor Networks</article-title><source>Sensors</source><year>2024</year><volume>24</volume><elocation-id>1643</elocation-id><pub-id pub-id-type="doi">10.3390/s24051643</pub-id><pub-id pub-id-type="pmid">38475179</pub-id><pub-id pub-id-type="pmcid">PMC10935136</pub-id></element-citation></ref><ref id="B13-sensors-25-05526"><label>13.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Vaghalandari</surname><given-names>N.G.</given-names></name><name name-style="western"><surname>Ko&#322;akowska</surname><given-names>A.</given-names></name><name name-style="western"><surname>Grundig</surname><given-names>C.</given-names></name><name name-style="western"><surname>Dongchen</surname><given-names>L.</given-names></name><name name-style="western"><surname>Wiszniewski</surname><given-names>B.</given-names></name><name name-style="western"><surname>Daniel</surname><given-names>K.</given-names></name><name name-style="western"><surname>Obermaisser</surname><given-names>R.</given-names></name></person-group><article-title>Performance Evaluation of Nomadic Data Collection with a UAV-LoRa System</article-title><source>Proceedings of the 2025 21st International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT)</source><conf-loc>Lucca, Italy</conf-loc><conf-date>9&#8211;11 June 2025</conf-date><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1109/DCOSS-IoT65416.2025.00143</pub-id></element-citation></ref><ref id="B14-sensors-25-05526"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dembski</surname><given-names>J.</given-names></name><name name-style="western"><surname>Ko&#322;akowska</surname><given-names>A.</given-names></name><name name-style="western"><surname>Wiszniewski</surname><given-names>B.</given-names></name></person-group><article-title>Rural IoT Soil Data</article-title><source>IEEE DataPort</source><year>2024</year><pub-id pub-id-type="doi">10.21227/0j1h-ew11</pub-id></element-citation></ref><ref id="B15-sensors-25-05526"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dembski</surname><given-names>J.</given-names></name><name name-style="western"><surname>Ko&#322;akowska</surname><given-names>A.</given-names></name><name name-style="western"><surname>Wiszniewski</surname><given-names>B.</given-names></name></person-group><article-title>Automatic Cleaning of Time Series Data in Rural Internet of Things Ecosystems That Use Nomadic Gateways</article-title><source>Sensors</source><year>2025</year><volume>25</volume><elocation-id>189</elocation-id><pub-id pub-id-type="doi">10.3390/s25010189</pub-id><pub-id pub-id-type="pmid">39796980</pub-id><pub-id pub-id-type="pmcid">PMC11723292</pub-id></element-citation></ref><ref id="B16-sensors-25-05526"><label>16.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Krawczyk</surname><given-names>H.</given-names></name><name name-style="western"><surname>Wiszniewski</surname><given-names>B.</given-names></name></person-group><source>Collaborative Learning as a Service&#8212;A Blueprint for a Cloud Based Rural IoTs Deployment Facility, Proceedings of the Parallel Processing and Applied Mathematics, Ostrava, Czech Republic, 8&#8211;11 September 2024</source><person-group person-group-type="editor"><name name-style="western"><surname>Wyrzykowski</surname><given-names>R.</given-names></name><name name-style="western"><surname>Dongarra</surname><given-names>J.</given-names></name><name name-style="western"><surname>Deelman</surname><given-names>E.</given-names></name><name name-style="western"><surname>Karczewski</surname><given-names>K.</given-names></name></person-group><publisher-name>Springer</publisher-name><publisher-loc>Cham, Switzerland</publisher-loc><year>2025</year><comment>LNCS 15579</comment><fpage>328</fpage><lpage>342</lpage></element-citation></ref><ref id="B17-sensors-25-05526"><label>17.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Ko&#322;akowska</surname><given-names>A.</given-names></name><name name-style="western"><surname>Wiszniewski</surname><given-names>B.</given-names></name><name name-style="western"><surname>Dembski</surname><given-names>J.</given-names></name></person-group><source>Hierarchical Alignment of Multiple Time Series with Missing Timestamps, Proceedings of the 23rd ACM Conference on Embedded Networked Sensor Systems, Irvine, CA, USA, 6&#8211;9 May 2025</source><publisher-name>Association for Computing Machinery</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>2025</year><fpage>616</fpage><lpage>617</lpage></element-citation></ref><ref id="B18-sensors-25-05526"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wahab</surname><given-names>O.A.</given-names></name><name name-style="western"><surname>Mourad</surname><given-names>A.</given-names></name><name name-style="western"><surname>Otrok</surname><given-names>H.</given-names></name><name name-style="western"><surname>Taleb</surname><given-names>T.</given-names></name></person-group><article-title>Federated Machine Learning: Survey, Multi-Level Classification, Desirable Criteria and Future Directions in Communication and Networking Systems</article-title><source>IEEE Commun. Surv. Tutor.</source><year>2021</year><volume>23</volume><fpage>1342</fpage><lpage>1397</lpage><pub-id pub-id-type="doi">10.1109/COMST.2021.3058573</pub-id></element-citation></ref><ref id="B19-sensors-25-05526"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Schmidl</surname><given-names>S.</given-names></name><name name-style="western"><surname>Wenig</surname><given-names>P.</given-names></name><name name-style="western"><surname>Papenbrock</surname><given-names>T.</given-names></name></person-group><article-title>Anomaly detection in time series: A comprehensive evaluation</article-title><source>Proc. VLDB Endow.</source><year>2022</year><volume>15</volume><fpage>1779</fpage><lpage>1797</lpage><pub-id pub-id-type="doi">10.14778/3538598.3538602</pub-id></element-citation></ref><ref id="B20-sensors-25-05526"><label>20.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Ronneberger</surname><given-names>O.</given-names></name><name name-style="western"><surname>Fischer</surname><given-names>P.</given-names></name><name name-style="western"><surname>Brox</surname><given-names>T.</given-names></name></person-group><article-title>U-Net: Convolutional Networks for Biomedical Image Segmentation</article-title><source>Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention</source><conf-loc>Munich, Germany</conf-loc><conf-date>5&#8211;9 October 2015</conf-date></element-citation></ref><ref id="B21-sensors-25-05526"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Silver</surname><given-names>D.</given-names></name><name name-style="western"><surname>Huang</surname><given-names>A.</given-names></name><name name-style="western"><surname>Maddison</surname><given-names>C.J.</given-names></name><name name-style="western"><surname>Guez</surname><given-names>A.</given-names></name><name name-style="western"><surname>Sifre</surname><given-names>L.</given-names></name><name name-style="western"><surname>van den Driessche</surname><given-names>G.</given-names></name><name name-style="western"><surname>Schrittwieser</surname><given-names>J.</given-names></name><name name-style="western"><surname>Antonoglou</surname><given-names>I.</given-names></name><name name-style="western"><surname>Panneershelvam</surname><given-names>V.</given-names></name><name name-style="western"><surname>Lanctot</surname><given-names>M.</given-names></name><etal/></person-group><article-title>Mastering the game of Go with deep neural networks and tree search</article-title><source>Nature</source><year>2016</year><volume>529</volume><fpage>484</fpage><lpage>489</lpage><pub-id pub-id-type="doi">10.1038/nature16961</pub-id><pub-id pub-id-type="pmid">26819042</pub-id></element-citation></ref><ref id="B22-sensors-25-05526"><label>22.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Mao</surname><given-names>J.</given-names></name><name name-style="western"><surname>Gan</surname><given-names>C.</given-names></name><name name-style="western"><surname>Kohli</surname><given-names>P.</given-names></name><name name-style="western"><surname>Tenenbaum</surname><given-names>J.B.</given-names></name><name name-style="western"><surname>Wu</surname><given-names>J.</given-names></name></person-group><article-title>The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision</article-title><source>Proceedings of the 7th International Conference on Learning Representations, ICLR 2019</source><conf-loc>New Orleans, LA, USA</conf-loc><conf-date>6&#8211;9 May 2019</conf-date></element-citation></ref><ref id="B23-sensors-25-05526"><label>23.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Kingma</surname><given-names>D.P.</given-names></name><name name-style="western"><surname>Ba</surname><given-names>J.</given-names></name></person-group><article-title>Adam: A Method for Stochastic Optimization</article-title><source>Proceedings of the 3rd International Conference on Learning Representations, ICLR 2015</source><conf-loc>San Diego, CA, USA</conf-loc><conf-date>7&#8211;9 May 2015</conf-date></element-citation></ref><ref id="B24-sensors-25-05526"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Najafi</surname><given-names>S.A.</given-names></name><name name-style="western"><surname>Asemani</surname><given-names>M.H.</given-names></name><name name-style="western"><surname>Setoodeh</surname><given-names>P.</given-names></name></person-group><article-title>Attention and Autoencoder Hybrid Model for Unsupervised Online Anomaly Detection</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type="doi">10.48550/arXiv.2401.03322</pub-id><pub-id pub-id-type="arxiv">2401.03322</pub-id></element-citation></ref><ref id="B25-sensors-25-05526"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yao</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Ma</surname><given-names>J.</given-names></name><name name-style="western"><surname>Ye</surname><given-names>Y.</given-names></name></person-group><article-title>Regularizing autoencoders with wavelet transform for sequence anomaly detection</article-title><source>Pattern Recognit.</source><year>2023</year><volume>134</volume><fpage>109084</fpage><pub-id pub-id-type="doi">10.1016/j.patcog.2022.109084</pub-id></element-citation></ref><ref id="B26-sensors-25-05526"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dumoulin</surname><given-names>V.</given-names></name><name name-style="western"><surname>Visin</surname><given-names>F.</given-names></name></person-group><article-title>A guide to convolution arithmetic for deep learning</article-title><source>arXiv</source><year>2018</year><pub-id pub-id-type="doi">10.48550/arXiv.1603.07285</pub-id><pub-id pub-id-type="arxiv">1603.07285</pub-id></element-citation></ref><ref id="B27-sensors-25-05526"><label>27.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Perslev</surname><given-names>M.</given-names></name><name name-style="western"><surname>Jensen</surname><given-names>M.H.</given-names></name><name name-style="western"><surname>Darkner</surname><given-names>S.</given-names></name><name name-style="western"><surname>Jennum</surname><given-names>P.J.</given-names></name><name name-style="western"><surname>Igel</surname><given-names>C.</given-names></name></person-group><article-title>U-Time: A fully convolutional network for time series segmentation applied to sleep staging</article-title><source>Proceedings of the 33rd International Conference on Neural Information Processing Systems</source><conf-loc>Red Hook, NY, USA</conf-loc><conf-date>8&#8211;14 December 2019</conf-date></element-citation></ref><ref id="B28-sensors-25-05526"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Bao</surname><given-names>J.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Deng</surname><given-names>H.</given-names></name></person-group><article-title>Human Activity Recognition Based on Motion Sensor Using U-Net</article-title><source>IEEE Access</source><year>2019</year><volume>7</volume><fpage>75213</fpage><lpage>75226</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2019.2920969</pub-id></element-citation></ref><ref id="B29-sensors-25-05526"><label>29.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Mohamudally</surname><given-names>N.</given-names></name></person-group><article-title>Introductory Chapter: Time Series Analysis (TSA) for Anomaly Detection in IoT</article-title><source>Time Series Analysis and Applications</source><person-group person-group-type="editor"><name name-style="western"><surname>Mohamudally</surname><given-names>N.</given-names></name></person-group><publisher-name>IntechOpen</publisher-name><publisher-loc>Rijeka, Croatia</publisher-loc><year>2018</year><comment>Chapter 1</comment><pub-id pub-id-type="doi">10.5772/intechopen.72669</pub-id></element-citation></ref><ref id="B30-sensors-25-05526"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Leigh</surname><given-names>C.</given-names></name><name name-style="western"><surname>Alsibai</surname><given-names>O.</given-names></name><name name-style="western"><surname>Hyndman</surname><given-names>R.J.</given-names></name><name name-style="western"><surname>Kandanaarachchi</surname><given-names>S.</given-names></name><name name-style="western"><surname>King</surname><given-names>O.C.</given-names></name><name name-style="western"><surname>McGree</surname><given-names>J.M.</given-names></name><name name-style="western"><surname>Neelamraju</surname><given-names>C.</given-names></name><name name-style="western"><surname>Strauss</surname><given-names>J.</given-names></name><name name-style="western"><surname>Talagala</surname><given-names>P.D.</given-names></name><name name-style="western"><surname>Turner</surname><given-names>R.S.</given-names></name><etal/></person-group><article-title>A framework for automated anomaly detection in high frequency water-quality data from in situ sensors</article-title><source>Sci. Total. Environ.</source><year>2019</year><volume>664</volume><fpage>885</fpage><lpage>898</lpage><pub-id pub-id-type="doi">10.1016/j.scitotenv.2019.02.085</pub-id><pub-id pub-id-type="pmid">30769312</pub-id></element-citation></ref><ref id="B31-sensors-25-05526"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kim</surname><given-names>B.</given-names></name><name name-style="western"><surname>Alawami</surname><given-names>M.A.</given-names></name><name name-style="western"><surname>Kim</surname><given-names>E.</given-names></name><name name-style="western"><surname>Oh</surname><given-names>S.</given-names></name><name name-style="western"><surname>Park</surname><given-names>J.</given-names></name><name name-style="western"><surname>Kim</surname><given-names>H.</given-names></name></person-group><article-title>A Comparative Study of Time Series Anomaly Detection Models for Industrial Control Systems</article-title><source>Sensors</source><year>2023</year><volume>23</volume><elocation-id>1310</elocation-id><pub-id pub-id-type="doi">10.3390/s23031310</pub-id><pub-id pub-id-type="pmid">36772349</pub-id><pub-id pub-id-type="pmcid">PMC9921147</pub-id></element-citation></ref><ref id="B32-sensors-25-05526"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pota</surname><given-names>M.</given-names></name><name name-style="western"><surname>De Pietro</surname><given-names>G.</given-names></name><name name-style="western"><surname>Esposito</surname><given-names>M.</given-names></name></person-group><article-title>Real-time anomaly detection on time series of industrial furnaces: A comparison of autoencoder architectures</article-title><source>Eng. Appl. Artif. Intell.</source><year>2023</year><volume>124</volume><fpage>106597</fpage><pub-id pub-id-type="doi">10.1016/j.engappai.2023.106597</pub-id></element-citation></ref><ref id="B33-sensors-25-05526"><label>33.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Zhao</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Han</surname><given-names>J.</given-names></name><name name-style="western"><surname>Su</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Jiao</surname><given-names>R.</given-names></name><name name-style="western"><surname>Wen</surname><given-names>X.</given-names></name><name name-style="western"><surname>Pei</surname><given-names>D.</given-names></name></person-group><article-title>Multivariate Time Series Anomaly Detection and Interpretation using Hierarchical Inter-Metric and Temporal Embedding</article-title><source>Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</source><conf-loc>New York, NY, USA</conf-loc><conf-date>14&#8211;18 August 2021</conf-date><comment>KDD &#8217;21</comment><fpage>3220</fpage><lpage>3230</lpage><pub-id pub-id-type="doi">10.1145/3447548.3467075</pub-id></element-citation></ref><ref id="B34-sensors-25-05526"><label>34.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Geiger</surname><given-names>A.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>D.</given-names></name><name name-style="western"><surname>Alnegheimish</surname><given-names>S.</given-names></name><name name-style="western"><surname>Cuesta-Infante</surname><given-names>A.</given-names></name><name name-style="western"><surname>Veeramachaneni</surname><given-names>K.</given-names></name></person-group><article-title>TadGAN: Time Series Anomaly Detection Using Generative Adversarial Networks</article-title><source>Proceedings of the 2020 IEEE International Conference on Big Data (Big Data)</source><conf-loc>Atlanta, GA, USA</conf-loc><conf-date>10&#8211;13 December 2020</conf-date></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-05526-f001" orientation="portrait"><label>Figure 1</label><caption><p>Classes of anomalies in soil signals.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05526-g001.jpg"/></fig><fig position="float" id="sensors-25-05526-f002" orientation="portrait"><label>Figure 2</label><caption><p>Data-free scheme for development of the anomaly detection software.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05526-g002.jpg"/></fig><fig position="float" id="sensors-25-05526-f003" orientation="portrait"><label>Figure 3</label><caption><p>Life-Long Learning scheme for development of the anomaly detection software.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05526-g003.jpg"/></fig><fig position="float" id="sensors-25-05526-f004" orientation="portrait"><label>Figure 4</label><caption><p>NPH processing scheme.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05526-g004.jpg"/></fig><fig position="float" id="sensors-25-05526-f005" orientation="portrait"><label>Figure 5</label><caption><p>A sample anomaly probability chart with maxima and regions determined via procedure MaximaDeterm.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05526-g005.jpg"/></fig><fig position="float" id="sensors-25-05526-f006" orientation="portrait"><label>Figure 6</label><caption><p>A sample waveform of a signal containing a bump, along with the anomaly probabilities for the center and edges.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05526-g006.jpg"/></fig><fig position="float" id="sensors-25-05526-f007" orientation="portrait"><label>Figure 7</label><caption><p>Training and detection cycle with the addition of difficult negative examples.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05526-g007.jpg"/></fig><fig position="float" id="sensors-25-05526-f008" orientation="portrait"><label>Figure 8</label><caption><p>AEB model structure.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05526-g008.jpg"/></fig><fig position="float" id="sensors-25-05526-f009" orientation="portrait"><label>Figure 9</label><caption><p>Sliding window scheme for AEB and UNB anomaly segmentation.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05526-g009.jpg"/></fig><fig position="float" id="sensors-25-05526-f010" orientation="portrait"><label>Figure 10</label><caption><p>U-Net structure.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05526-g010.jpg"/></fig><fig position="float" id="sensors-25-05526-f011" orientation="portrait"><label>Figure 11</label><caption><p>Loss diagrams for AEB and UNB model training.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05526-g011.jpg"/></fig><fig position="float" id="sensors-25-05526-f012" orientation="portrait"><label>Figure 12</label><caption><p>ROC curves for anomaly segmentation in temperature signals for the AEB and UNB methods.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05526-g012.jpg"/></fig><fig position="float" id="sensors-25-05526-f013" orientation="portrait"><label>Figure 13</label><caption><p>ROC curves for anomaly segmentation in moisture signals for the AEB and UNB methods.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05526-g013.jpg"/></fig><fig position="float" id="sensors-25-05526-f014" orientation="portrait"><label>Figure 14</label><caption><p>ROC curves for anomaly segmentation in pH signals for the AEB and UNB methods.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05526-g014.jpg"/></fig><fig position="float" id="sensors-25-05526-f015" orientation="portrait"><label>Figure 15</label><caption><p>True and detected anomalies in temperature signal from sensor <inline-formula><mml:math id="mm140" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>22</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05526-g015.jpg"/></fig><fig position="float" id="sensors-25-05526-f016" orientation="portrait"><label>Figure 16</label><caption><p>True and detected anomalies in moisture signal from sensor <inline-formula><mml:math id="mm141" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>22</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05526-g016.jpg"/></fig><fig position="float" id="sensors-25-05526-f017" orientation="portrait"><label>Figure 17</label><caption><p>True and detected anomalies in pH signal from sensor <inline-formula><mml:math id="mm142" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>22</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05526-g017.jpg"/></fig><fig position="float" id="sensors-25-05526-f018" orientation="portrait"><label>Figure 18</label><caption><p>Comparison of effectiveness of time-series data cleaning using alternative detector models.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05526-g018.jpg"/></fig><table-wrap position="float" id="sensors-25-05526-t001" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05526-t001_Table 1</object-id><label>Table 1</label><caption><p>Explainable deviations in soil&#160;signals.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Interpretation</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Explanation</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Type</th></tr></thead><tbody><tr><td align="left" valign="top" rowspan="1" colspan="1">Samples (values) stored in the sensor memory are shifted (delayed) in time relative to the original signal waveform.</td><td align="left" valign="top" rowspan="1" colspan="1">When reading subsequent samples from probes placed in the soil by MCU, the&#160;system time counter stops due to a complete lack of power (e.g., after&#160;the battery has been discharged during night). Our constrained end devices do not have an autonomously powered system clock.</td><td align="left" valign="top" rowspan="1" colspan="1">Power&#160;gaps</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">The value of a single signal sample falls outside the allowable range of its variability.</td><td align="left" valign="top" rowspan="1" colspan="1">A short-term event occurred in the probe&#8217;s immediate vicinity, causing an erroneous reading of a given value.</td><td align="left" valign="top" rowspan="1" colspan="1">Absolute&#160;error</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">The values of several adjacent signal samples remain within the correct range of signal variation, but&#160;significantly exceed the average values of the samples in both of their neighborhoods (left and right).</td><td align="left" valign="top" rowspan="1" colspan="1">An event occurred in the probe&#8217;s immediate vicinity, which temporarily interfered with the read signal.</td><td align="left" valign="top" rowspan="1" colspan="1">Peak</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">The values of several adjacent signal samples remain within the correct range of signal variation, but&#160;significantly exceed the average value of samples only in their left or right neighborhood.</td><td align="left" valign="top" rowspan="1" colspan="1">During data reading, the&#160;state of the probe placed in the soil was permanently changed; e.g.,&#160;by switching its power supply on or off (analog sensor) or resetting its reading register (digital sensor).</td><td align="left" valign="top" rowspan="1" colspan="1">Jump</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">The values of signal samples in some sequence remain within a normal range of signal variability, but&#160;show a gentle and reversible deflection from its overall trend over a longer observation period (e.g., daily).</td><td align="left" valign="top" rowspan="1" colspan="1">While reading subsequent samples, an&#160;event occurred that caused an observable, long-lasting change in the value of the measured parameter (e.g., flooding of the soil moisture probe).</td><td align="left" valign="top" rowspan="1" colspan="1">Bump</td></tr><tr><td align="left" valign="top" style="border-bottom:solid thin" rowspan="1" colspan="1">The values of a certain sequence of samples oscillate with a small deviation from each other along the signal trend line.</td><td align="left" valign="top" style="border-bottom:solid thin" rowspan="1" colspan="1">When reading subsequent samples, the&#160;sensor power supply is unstable (e.g., when the battery is not sufficiently charged, the&#160;additional load imposed by MCU computations temporarily affects the PV cell output voltage).</td><td align="left" valign="top" style="border-bottom:solid thin" rowspan="1" colspan="1">Instabilities</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05526-t002" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05526-t002_Table 2</object-id><label>Table 2</label><caption><p>IOU rates for input vectors of different length when using&#160;NPH.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">Input Vector Length</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin" rowspan="1">2/1.5</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin" rowspan="1">3/2</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin" rowspan="1">6/4</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin" rowspan="1">9/6</th></tr></thead><tbody><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Training</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Test</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Training</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Test</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Training</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Test</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Training</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Test</bold>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Peaks</td><td align="left" valign="middle" rowspan="1" colspan="1">0.16</td><td align="left" valign="middle" rowspan="1" colspan="1">0.04</td><td align="left" valign="middle" rowspan="1" colspan="1">0.39</td><td align="left" valign="middle" rowspan="1" colspan="1">0.33</td><td align="left" valign="middle" rowspan="1" colspan="1">0.56</td><td align="left" valign="middle" rowspan="1" colspan="1">0.43</td><td align="left" valign="middle" rowspan="1" colspan="1">0.55</td><td align="left" valign="middle" rowspan="1" colspan="1">0.54</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Bumps</td><td align="left" valign="middle" rowspan="1" colspan="1">0.89</td><td align="left" valign="middle" rowspan="1" colspan="1">0.63</td><td align="left" valign="middle" rowspan="1" colspan="1">0.9</td><td align="left" valign="middle" rowspan="1" colspan="1">0.63</td><td align="left" valign="middle" rowspan="1" colspan="1">0.8</td><td align="left" valign="middle" rowspan="1" colspan="1">0.59</td><td align="left" valign="middle" rowspan="1" colspan="1">0.74</td><td align="left" valign="middle" rowspan="1" colspan="1">0.55</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Jumps</td><td align="left" valign="middle" rowspan="1" colspan="1">0.77</td><td align="left" valign="middle" rowspan="1" colspan="1">0.17</td><td align="left" valign="middle" rowspan="1" colspan="1">0.74</td><td align="left" valign="middle" rowspan="1" colspan="1">0.17</td><td align="left" valign="middle" rowspan="1" colspan="1">0.77</td><td align="left" valign="middle" rowspan="1" colspan="1">0.24</td><td align="left" valign="middle" rowspan="1" colspan="1">0.68</td><td align="left" valign="middle" rowspan="1" colspan="1">0.38</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Instabilities</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.8</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.79</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.68</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.72</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.65</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.67</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.6</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.71</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Average</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.66</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.4</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.68</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.46</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.7</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.48</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.64</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.54</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05526-t003" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05526-t003_Table 3</object-id><label>Table 3</label><caption><p>Lengths of the input vectors used for NPH depending on the anomaly&#160;type.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">
</th><th colspan="4" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Anomaly Type</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Peaks
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Bumps
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Jumps
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Instabilities
</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">Average anomaly length</td><td align="center" valign="middle" rowspan="1" colspan="1">2.89</td><td align="center" valign="middle" rowspan="1" colspan="1">52.54</td><td align="center" valign="middle" rowspan="1" colspan="1">74.03</td><td align="center" valign="middle" rowspan="1" colspan="1">11.61</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Input vector length for ANN-Center</td><td align="center" valign="middle" rowspan="1" colspan="1">9</td><td align="center" valign="middle" rowspan="1" colspan="1">158</td><td align="center" valign="middle" rowspan="1" colspan="1">222</td><td align="center" valign="middle" rowspan="1" colspan="1">35</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Input vector length for ANN-Edge</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">105</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">148</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">23</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05526-t004" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05526-t004_Table 4</object-id><label>Table 4</label><caption><p>Lengths of the input vectors used for AEB and UNB depending on the anomaly&#160;type.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">
</th><th colspan="4" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Anomaly Type</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Peaks
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Bumps
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Jumps
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Instabilities
</th></tr></thead><tbody><tr><td colspan="2" align="left" valign="middle" rowspan="1">Average anomaly length</td><td align="center" valign="middle" rowspan="1" colspan="1">2.89</td><td align="center" valign="middle" rowspan="1" colspan="1">52.54</td><td align="center" valign="middle" rowspan="1" colspan="1">74.03</td><td align="center" valign="middle" rowspan="1" colspan="1">11.61</td></tr><tr><td colspan="2" align="left" valign="middle" style="border-bottom:solid thin" rowspan="1">Input vector length</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">128</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2048</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4096</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">512</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05526-t005" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05526-t005_Table 5</object-id><label>Table 5</label><caption><p>Test results for the NPH method.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">
</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Peak</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Bump</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Jump</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Instabilities</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Error Type&#160;&#8594;
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
IoU
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FPR
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FNR
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
IoU
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FPR
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FNR
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
IoU
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FPR
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FNR
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
IoU
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FPR
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FNR
</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">T</td><td align="left" valign="middle" rowspan="1" colspan="1">0.42</td><td align="left" valign="middle" rowspan="1" colspan="1">0.0012</td><td align="left" valign="middle" rowspan="1" colspan="1">0.41</td><td align="left" valign="middle" rowspan="1" colspan="1">0.75</td><td align="left" valign="middle" rowspan="1" colspan="1">0.0007</td><td align="left" valign="middle" rowspan="1" colspan="1">0.24</td><td align="left" valign="middle" rowspan="1" colspan="1">0.39</td><td align="left" valign="middle" rowspan="1" colspan="1">0.0016</td><td align="left" valign="middle" rowspan="1" colspan="1">0.6</td><td align="left" valign="middle" rowspan="1" colspan="1">0.78</td><td align="left" valign="middle" rowspan="1" colspan="1">0.0008</td><td align="left" valign="middle" rowspan="1" colspan="1">0.17</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">M</td><td align="left" valign="middle" rowspan="1" colspan="1">0.3</td><td align="left" valign="middle" rowspan="1" colspan="1">0.002</td><td align="left" valign="middle" rowspan="1" colspan="1">0.5</td><td align="left" valign="middle" rowspan="1" colspan="1">0.6</td><td align="left" valign="middle" rowspan="1" colspan="1">0.0131</td><td align="left" valign="middle" rowspan="1" colspan="1">0.22</td><td align="left" valign="middle" rowspan="1" colspan="1">0.0</td><td align="left" valign="middle" rowspan="1" colspan="1">0.0017</td><td align="left" valign="middle" rowspan="1" colspan="1">1.0</td><td align="left" valign="middle" rowspan="1" colspan="1">0.49</td><td align="left" valign="middle" rowspan="1" colspan="1">0.005</td><td align="left" valign="middle" rowspan="1" colspan="1">0.3</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">pH</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.44</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0012</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.38</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.48</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.002</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.5</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.34</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0042</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.64</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.72</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0007</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.24</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Average</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.39</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0015</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.43</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.61</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0053</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.32</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.24</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0025</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.75</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.66</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0022</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.24</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05526-t006" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05526-t006_Table 6</object-id><label>Table 6</label><caption><p>Test results for the AEB method.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">
</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Peak</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Bump</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Jump</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Instabilities</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Error Type&#160;&#8594;
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
IoU
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FPR
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FNR
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
IoU
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FPR
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FNR
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
IoU
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FPR
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FNR
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
IoU
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FPR
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FNR
</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">T</td><td align="center" valign="middle" rowspan="1" colspan="1">0.9</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0001</td><td align="center" valign="middle" rowspan="1" colspan="1">0.07</td><td align="center" valign="middle" rowspan="1" colspan="1">0.76</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0052</td><td align="center" valign="middle" rowspan="1" colspan="1">0.17</td><td align="center" valign="middle" rowspan="1" colspan="1">0.43</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0008</td><td align="center" valign="middle" rowspan="1" colspan="1">0.57</td><td align="center" valign="middle" rowspan="1" colspan="1">0.91</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0006</td><td align="center" valign="middle" rowspan="1" colspan="1">0.04</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">M</td><td align="center" valign="middle" rowspan="1" colspan="1">0.71</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0003</td><td align="center" valign="middle" rowspan="1" colspan="1">0.22</td><td align="center" valign="middle" rowspan="1" colspan="1">0.46</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0321</td><td align="center" valign="middle" rowspan="1" colspan="1">0.21</td><td align="center" valign="middle" rowspan="1" colspan="1">0.02</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0492</td><td align="center" valign="middle" rowspan="1" colspan="1">0.86</td><td align="center" valign="middle" rowspan="1" colspan="1">0.69</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0021</td><td align="center" valign="middle" rowspan="1" colspan="1">0.19</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">pH</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.86</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0001</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.09</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.48</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0015</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.51</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.26</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0008</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.74</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.85</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0005</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.11</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Average</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.82</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0002</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.13</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.56</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0129</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.23</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0169</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.72</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.82</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0011</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.12</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05526-t007" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05526-t007_Table 7</object-id><label>Table 7</label><caption><p>Test results for the UNB method.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">
</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Peak</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Bump</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Jump</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Instabilities</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Error Type&#160;&#8594;
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
IoU
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FPR
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FNR
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
IoU
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FPR
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FNR
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
IoU
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FPR
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FNR
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
IoU
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FPR
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
FNR
</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">T</td><td align="center" valign="middle" rowspan="1" colspan="1">0.89</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0001</td><td align="center" valign="middle" rowspan="1" colspan="1">0.07</td><td align="center" valign="middle" rowspan="1" colspan="1">0.94</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0006</td><td align="center" valign="middle" rowspan="1" colspan="1">0.05</td><td align="center" valign="middle" rowspan="1" colspan="1">0.48</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0048</td><td align="center" valign="middle" rowspan="1" colspan="1">0.47</td><td align="center" valign="middle" rowspan="1" colspan="1">0.93</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0003</td><td align="center" valign="middle" rowspan="1" colspan="1">0.04</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">M</td><td align="center" valign="middle" rowspan="1" colspan="1">0.67</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0002</td><td align="center" valign="middle" rowspan="1" colspan="1">0.28</td><td align="center" valign="middle" rowspan="1" colspan="1">0.62</td><td align="center" valign="middle" rowspan="1" colspan="1">0.012</td><td align="center" valign="middle" rowspan="1" colspan="1">0.21</td><td align="center" valign="middle" rowspan="1" colspan="1">0.15</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0104</td><td align="center" valign="middle" rowspan="1" colspan="1">0.63</td><td align="center" valign="middle" rowspan="1" colspan="1">0.72</td><td align="center" valign="middle" rowspan="1" colspan="1">0.0014</td><td align="center" valign="middle" rowspan="1" colspan="1">0.2</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">pH</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.85</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0001</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.13</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.71</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0011</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.28</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.51</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0011</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.49</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.86</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0004</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.11</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Average</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.8</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0001</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.16</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.76</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0045</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.18</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.38</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0054</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.53</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.84</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0007</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.12</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05526-t008" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05526-t008_Table 8</object-id><label>Table 8</label><caption><p>Comparison of anomaly detection accuracy and processing time for the three considered methods.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Method &#8594;</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">NPH</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">AEB</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">UNB</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">Average IOU for test sensors</td><td align="center" valign="middle" rowspan="1" colspan="1">0.48</td><td align="center" valign="middle" rowspan="1" colspan="1">0.61</td><td align="center" valign="middle" rowspan="1" colspan="1">0.69</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Number of multiplications per sample</td><td align="center" valign="middle" rowspan="1" colspan="1">632,800</td><td align="center" valign="middle" rowspan="1" colspan="1">22,716</td><td align="center" valign="middle" rowspan="1" colspan="1">5,209,632</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Time complexity per sample (in sec.)</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm143" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>4.1</mml:mn><mml:mo>&#183;</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm144" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>1.17</mml:mn><mml:mo>&#183;</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm145" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>1.17</mml:mn><mml:mo>&#183;</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05526-t009" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05526-t009_Table 9</object-id><label>Table 9</label><caption><p>Comparison of AUC values between the AEB and UNB methods, calculated for anomaly detection ROC curves of test sensors.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">
</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Peak</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Bump</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Jump</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin" rowspan="1">Instabilities</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Time Series&#160;&#8594;
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
T
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
M
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
pH
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
T
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
M
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
pH
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
T
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
M
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
pH
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
T
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
M
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
pH
</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">AEB</td><td align="center" valign="middle" rowspan="1" colspan="1">1.0</td><td align="center" valign="middle" rowspan="1" colspan="1">0.96</td><td align="center" valign="middle" rowspan="1" colspan="1">0.99</td><td align="center" valign="middle" rowspan="1" colspan="1">0.95</td><td align="center" valign="middle" rowspan="1" colspan="1">0.92</td><td align="center" valign="middle" rowspan="1" colspan="1">0.89</td><td align="center" valign="middle" rowspan="1" colspan="1">0.75</td><td align="center" valign="middle" rowspan="1" colspan="1">0.72</td><td align="center" valign="middle" rowspan="1" colspan="1">0.74</td><td align="center" valign="middle" rowspan="1" colspan="1">0.99</td><td align="center" valign="middle" rowspan="1" colspan="1">0.97</td><td align="center" valign="middle" rowspan="1" colspan="1">0.98</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">UNB</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.98</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.92</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.96</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.95</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.88</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.87</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.82</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.86</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.77</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.99</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.94</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.97</td></tr></tbody></table></table-wrap></floats-group></article></pmc-articleset>