<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xml:lang="en" article-type="research-article" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="pmc-domain-id">1660</journal-id><journal-id journal-id-type="pmc-domain">sensors</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>Multidisciplinary Digital Publishing Institute  (MDPI)</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12431339</article-id><article-id pub-id-type="pmcid-ver">PMC12431339.1</article-id><article-id pub-id-type="pmcaid">12431339</article-id><article-id pub-id-type="pmcaiid">12431339</article-id><article-id pub-id-type="doi">10.3390/s25175515</article-id><article-id pub-id-type="publisher-id">sensors-25-05515</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Machine Learning-Based Alexithymia Assessment Using Resting-State Default Mode Network Functional Connectivity</article-title></title-group><contrib-group><contrib contrib-type="author"><name name-style="western"><surname>Suzuki</surname><given-names initials="K">Kei</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Resources" vocab-term-identifier="https://credit.niso.org/contributor-roles/resources/">Resources</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#8211; original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><xref rid="c1-sensors-25-05515" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-3297-5913</contrib-id><name name-style="western"><surname>Sugaya</surname><given-names initials="M">Midori</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Resources" vocab-term-identifier="https://credit.niso.org/contributor-roles/resources/">Resources</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project administration</role></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name name-style="western"><surname>Vanello</surname><given-names initials="N">Nicola</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name name-style="western"><surname>Positano</surname><given-names initials="V">Vincenzo</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name name-style="western"><surname>Santarelli</surname><given-names initials="MF">Maria Filomena</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-05515">Functional Control Systems, Graduate School of Engineering and Science, TOYOSU Campus, Shibaura Institute of Technology, Research Building #14A32, 3-7-5 Toyosu, Koto-ku, Tokyo 135-8548, Japan; <email>doly@shibaura-it.ac.jp</email></aff><author-notes><corresp id="c1-sensors-25-05515"><label>*</label>Correspondence: <email>nb23108@shibaura-it.ac.jp</email></corresp></author-notes><pub-date pub-type="epub"><day>04</day><month>9</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>9</month><year>2025</year></pub-date><volume>25</volume><issue>17</issue><issue-id pub-id-type="pmc-issue-id">496815</issue-id><elocation-id>5515</elocation-id><history><date date-type="received"><day>26</day><month>7</month><year>2025</year></date><date date-type="rev-recd"><day>29</day><month>8</month><year>2025</year></date><date date-type="accepted"><day>30</day><month>8</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>04</day><month>09</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>13</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-13 17:25:36.317"><day>13</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="sensors-25-05515.pdf"/><abstract><p>Alexithymia is regarded as one of the risk factors for several prevalent mental disorders, and there is a growing need for convenient and objective methods to assess alexithymia. Therefore, this study proposes a method for constructing models to assess alexithymia using machine learning and electroencephalogram (EEG) signals. The explanatory variables for the models were functional connectivity calculated from resting-state EEG data, reflecting the default mode network (DMN). The functional connectivity was computed for each frequency band in brain regions estimated by source localization. The objective variable was defined as either low or high alexithymia severity. Explainable artificial intelligence (XAI) was used to analyze which features the models relied on for their assessments. The results indicated that the classification model suggested effective assessment depending on the threshold used to define low and high alexithymia. The maximum receiver operating characteristic area under the curve (ROC-AUC) score was 0.70. Furthermore, analysis of the classification model indicated that functional connectivity in the theta and gamma frequency bands, and specifically in the Left Hippocampus, was effective for alexithymia assessment. This study demonstrates the potential applicability of EEG signals and machine learning in alexithymia assessment.</p></abstract><kwd-group><kwd>alexithymia</kwd><kwd>source localization</kwd><kwd>default mode network</kwd><kwd>electroencephalogram</kwd><kwd>machine learning</kwd></kwd-group><funding-group><award-group><funding-source>JSPS KAKENHI</funding-source><award-id>JP23KJ1924</award-id></award-group><funding-statement>This research was funded by JSPS KAKENHI Grant Number JP23KJ1924.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-05515"><title>1. Introduction</title><p>In recent years, there has been increasing interest in the treatment and prevention of mental disorders. According to a report by the World Health Organization (WHO), approximately 1 billion people out of the global population of 7.5 billion suffer from some form of mental disorder [<xref rid="B1-sensors-25-05515" ref-type="bibr">1</xref>]. Another report indicated that approximately 30% of individuals are affected by mental disorders at some point in their lives [<xref rid="B2-sensors-25-05515" ref-type="bibr">2</xref>]. Mental disorders are increasingly recognized as one of the leading causes of the global burden of disease (GBD) [<xref rid="B3-sensors-25-05515" ref-type="bibr">3</xref>], which is used to quantify the impact on human life expectancy and mortality [<xref rid="B4-sensors-25-05515" ref-type="bibr">4</xref>], and the economic and human costs arising from ill health [<xref rid="B2-sensors-25-05515" ref-type="bibr">2</xref>,<xref rid="B4-sensors-25-05515" ref-type="bibr">4</xref>]. Given the significant impact of mental disorders on human life and associated healthcare costs, early detection, timely intervention, and preventive measures are of critical importance.</p><p>Notably, treatment resistance in a subset of mental disorders poses a critical problem for healthcare costs. Treatment resistance is defined as the failure to achieve a therapeutic response despite adequate treatment, and affects 20&#8211;60% of patients with mental disorders [<xref rid="B5-sensors-25-05515" ref-type="bibr">5</xref>,<xref rid="B6-sensors-25-05515" ref-type="bibr">6</xref>]. This also leads to a tenfold increase in healthcare burden and costs compared to general patients [<xref rid="B6-sensors-25-05515" ref-type="bibr">6</xref>]. To alleviate the treatment burden and economic costs on patients with numerous mental disorders, there is growing interest in the treatment and prevention of mental disorders. Therefore, addressing the causes and risk factors of mental disorders is considered important for their treatment and prevention.</p><p>In addressing the causes and risk factors of mental disorders, alexithymia has received attention. Alexithymia is a personality trait [<xref rid="B7-sensors-25-05515" ref-type="bibr">7</xref>] characterized by difficulties in identifying and describing emotions, and it is considered one of the risk factors for mental disorders [<xref rid="B8-sensors-25-05515" ref-type="bibr">8</xref>]. Individuals experiencing difficulties in identifying emotions, a core characteristic of alexithymia, often struggle to recognize negative emotions such as stress. This impaired emotional recognition can subsequently lead to inadequate emotion regulation [<xref rid="B9-sensors-25-05515" ref-type="bibr">9</xref>], potentially contributing to mental disorders. For instance, delayed emotional processing with negative emotions [<xref rid="B9-sensors-25-05515" ref-type="bibr">9</xref>,<xref rid="B10-sensors-25-05515" ref-type="bibr">10</xref>] can lead to unintentionally prolonged exposure to negative emotions. Consequently, alexithymia can lead to the development of mental disorders such as depression and anxiety disorders. Furthermore, it has been suggested that alexithymia influences the outcomes of mental disorder treatment [<xref rid="B11-sensors-25-05515" ref-type="bibr">11</xref>]. Given these considerations, alexithymia has garnered interest due to its role as a risk factor for mental disorders and its contribution to predicting treatment outcomes.</p><p>While alexithymia has received considerable attention, its assessment has limitations in terms of objectivity and convenience. Current assessment methods involve self-report questionnaires completed by individuals and interviews conducted by clinicians [<xref rid="B7-sensors-25-05515" ref-type="bibr">7</xref>]. These methods have demonstrated a certain degree of validity. In particular, self-report questionnaires are the most widely used assessment methods [<xref rid="B7-sensors-25-05515" ref-type="bibr">7</xref>]. However, the validity of these questionnaires for assessing one of alexithymia&#8217;s core components has been questioned [<xref rid="B7-sensors-25-05515" ref-type="bibr">7</xref>]. Furthermore, these self-report questionnaires tend to lead to subjective assessments; thus, objectivity is restricted. In addition, the interviews tend to consume time [<xref rid="B12-sensors-25-05515" ref-type="bibr">12</xref>], so their convenience is restricted. Therefore, we aimed to improve the objectivity and convenience of alexithymia assessment.</p><p>To improve the objectivity and convenience of assessment, evaluation using electroencephalogram (EEG) signals with machine learning has been proposed in mental disorders related to alexithymia [<xref rid="B13-sensors-25-05515" ref-type="bibr">13</xref>,<xref rid="B14-sensors-25-05515" ref-type="bibr">14</xref>]. EEG signals are quantitative recordings of brain activity, reflecting the brain&#8217;s processes that give rise to human thoughts and personality. Additionally, as EEG signals are quantitatively recorded, they are more objective than qualitative human assessments. Moreover, compared to other brain activity recording methods such as positron emission tomography (PET) and functional magnetic resonance imaging (fMRI) [<xref rid="B15-sensors-25-05515" ref-type="bibr">15</xref>], EEG signals can be measured more conveniently [<xref rid="B16-sensors-25-05515" ref-type="bibr">16</xref>]. As these EEG signals are learned by machine learning models, the models can then objectively assess alexithymia according to their algorithms. If machine learning models could extract and leverage beneficial information from complex data that human analysis struggles to grasp, it could facilitate more convenient and more objective diagnostic support [<xref rid="B14-sensors-25-05515" ref-type="bibr">14</xref>]. This approach, which leverages the convenience and objectivity of EEG signals and machine learning, has achieved notable success in the evaluation of mental disorders [<xref rid="B13-sensors-25-05515" ref-type="bibr">13</xref>,<xref rid="B14-sensors-25-05515" ref-type="bibr">14</xref>]. In addition, employing explainable artificial intelligence (XAI) techniques, which have advanced significantly in recent years, allows for the analysis of factors a model uses for its evaluations [<xref rid="B17-sensors-25-05515" ref-type="bibr">17</xref>]. This analysis can yield new insights and deepen understanding. Thus, an approach that evaluates alexithymia using machine learning and EEG signals could offer both objectivity and convenience in its assessment.</p><p>In related work, approaches other than EEG have been explored to estimate alexithymia. Farhoumandi et al. attempted to estimate alexithymia from the scores of facial emotion recognition tasks. Their approach was based on reports of reduced activity in brain regions involved in extracting emotional information from facial expressions in individuals with alexithymia. Their results demonstrated that facial expression scores contribute to the estimation of alexithymia [<xref rid="B12-sensors-25-05515" ref-type="bibr">12</xref>]. Filippou et al. reported a high-performance model using a multimodal approach that included heart rate, skin conductance, and facial electromyography [<xref rid="B18-sensors-25-05515" ref-type="bibr">18</xref>,<xref rid="B19-sensors-25-05515" ref-type="bibr">19</xref>]. Edwards et al. attempted estimation using multiple questionnaires that measured the degree of positive and negative emotions, emotion regulation ability, and self-as-context, among other factors. They suggested that the relationship between emotion regulation and alexithymia is mediated by the degree of self-as-context [<xref rid="B20-sensors-25-05515" ref-type="bibr">20</xref>]. Wen et al. attempted to estimate the degree of alexithymia from the levels of social support and resilience, which is the ability to adapt and recover from adversity, as assessed by questionnaires. They suggested that these factors could be protective against alexithymia [<xref rid="B21-sensors-25-05515" ref-type="bibr">21</xref>]. These studies have implications for the robust estimation of alexithymia and for providing support to individuals with alexithymia. On the other hand, estimation using EEG signals, which reflect brain activity responsible for human thought and mind, may enable a more biologically plausible assessment. Moreover, applying XAI to these EEG-based models could provide new biological insights.</p><p>Therefore, this study aims to construct a model predicting alexithymia using machine learning and EEG signals. Previously, there were some obstacles to constructing a model. For example, recruiting individuals with alexithymia and acquiring EEG data were time-consuming and laborious. However, the recent availability of public datasets has alleviated these difficulties, enhancing the feasibility of constructing a model.</p><p>When constructing a model using EEG signals, it is essential to utilize EEG signals that reflect the characteristics of alexithymia. This is because the machine learning estimation is performed based on these signals, and if they do not reflect the characteristics of alexithymia, the model&#8217;s performance will be degraded. To this end, this study focuses on functional connectivity within the resting-state default mode network (DMN). Resting-state EEG signals reflect the activity of several brain regions within the DMN, a network that becomes active when individuals are at rest [<xref rid="B21-sensors-25-05515" ref-type="bibr">21</xref>,<xref rid="B22-sensors-25-05515" ref-type="bibr">22</xref>]. Functional connectivity is a quantitative index that measures the degree of synchrony among multiple EEG signals [<xref rid="B23-sensors-25-05515" ref-type="bibr">23</xref>]. This resting-state functional connectivity reflecting the DMN has been reported to correlate with alexithymia severity in relevant studies [<xref rid="B22-sensors-25-05515" ref-type="bibr">22</xref>]. Therefore, it is considered that if a machine learning model learns this correlation, it could become effective for assessment. However, it remains incompletely understood whether this resting-state functional connectivity is effective for alexithymia assessment using machine learning.</p><p>To summarize this study, we propose and validate a method for constructing models to evaluate alexithymia using EEG signals and machine learning. When developing the dataset for model construction, functional connectivity was calculated from resting-state EEG data reflecting the DMN. To compute these features, signals from DMN-related brain regions were derived via source localization. Subsequently, the functional connectivity was calculated from these localized signals.</p><p>As our contributions and the results of this study, the classification model predicting low/high alexithymia achieved a maximum receiver operating characteristic area under the curve (ROC-AUC) of 0.70. This indicated that binary classification of low/high alexithymia is feasible using resting-state functional connectivity. Furthermore, analysis of the constructed model using XAI suggested that functional connectivity in the theta and gamma frequency bands and the Left Hippocampus is effective for alexithymia evaluation. These results revealed the effective frequency bands, brain regions, and models for alexithymia evaluation. To the best of our knowledge, these findings are unique contributions of this study.</p><p>The subsequent sections are organized as follows. <xref rid="sec2-sensors-25-05515" ref-type="sec">Section 2</xref> describes the methodology, including the proposed method and the dataset used for its validation. <xref rid="sec3-sensors-25-05515" ref-type="sec">Section 3</xref> describes the results and discussion of the model validation and the XAI analysis. <xref rid="sec4-sensors-25-05515" ref-type="sec">Section 4</xref> concludes this study.</p></sec><sec sec-type="methods" id="sec2-sensors-25-05515"><title>2. Methodology</title><sec id="sec2dot1-sensors-25-05515"><title>2.1. Publicly Available Dataset Used in This Study</title><p>For data analysis, we utilized the publicly available Leipzig Study for Mind&#8211;Body&#8211;Emotion Interactions (LEMON) dataset [<xref rid="B24-sensors-25-05515" ref-type="bibr">24</xref>]. This dataset comprises data from a total of 227 participants [<xref rid="B24-sensors-25-05515" ref-type="bibr">24</xref>], consisting of a younger group (<italic toggle="yes">N</italic> = 153, 25.1 &#177; 3.1 years old, range 20&#8211;35 years, 45 females) and an older group (<italic toggle="yes">N</italic> = 74, 67.6 &#177; 4.7 years old, range 59&#8211;77 years, 37 females). Data collection for this dataset adhered to the Declaration of Helsinki, and the research protocol was approved by the Ethics Committee of the Medical Faculty, University of Leipzig. Exclusion criteria were applied to the participants. The representative criteria are as follows [<xref rid="B24-sensors-25-05515" ref-type="bibr">24</xref>].
<list list-type="bullet"><list-item><p>History of psychiatric diseases that required inpatient treatment for over 2 weeks in the last 10 years;</p></list-item><list-item><p>History of neurological disorders;</p></list-item><list-item><p>Use of any chemotherapeutic or psychopharmacological medication;</p></list-item><list-item><p>Positive drug history.</p></list-item></list></p><p>This dataset contains EEG signals and alexithymia questionnaire results relevant for this study. Data from 203 participants, for whom no missing information was observed, were analyzed. For the EEG signal analysis, the preprocessed EEG signals in the LEMON dataset were used. These data were recorded for a total of 8 min during eyes-closed resting state. For alexithymia evaluation, the results of the German version [<xref rid="B25-sensors-25-05515" ref-type="bibr">25</xref>] of the 26-item Toronto Alexithymia Scale (TAS) [<xref rid="B26-sensors-25-05515" ref-type="bibr">26</xref>] were used.</p></sec><sec id="sec2dot2-sensors-25-05515"><title>2.2. EEG Signal Recording Method in the Publicly Available Dataset</title><p>This section describes the EEG signals recording method, which is important for understanding the characteristics of the LEMON dataset. For EEG signal recording, a BrainAmp MR plus amplifier was used. A 62-channel active ActiCAP electrode system, adhering to the international 10-10 system, was utilized for electrode placement. The amplifiers and electrodes were from Brain Products GmbH (Gilching, Germany). FCz was referenced, grounding was at the sternum, and skin electrode impedance was kept below 5 k&#937;. The sessions for recording EEG signals consisted of a total of 16 blocks. Each block was 60 s long. Eight blocks were in an eyes-closed (EC) state, and the remaining eight blocks were in an eyes-open (EO) state. EC and EO states were measured alternately and repeatedly [<xref rid="B24-sensors-25-05515" ref-type="bibr">24</xref>].</p><p>Note that only EEG signals from the EC state were analyzed in this study. This is because EEG signals during the EC state are less susceptible to noise contamination from eye movements and blinks, thereby allowing for a reduction in noise-induced effects.</p></sec><sec id="sec2dot3-sensors-25-05515"><title>2.3. Preprocessing of EEG Signals in the Publicly Available Dataset</title><p>The recorded EEG signals were downsampled from 2500 Hz to 250 Hz and band-pass filtered within 1&#8211;45 Hz using an 8th-order Butterworth filter. Channels exhibiting frequent voltage jumps/shifts or poor signal quality were rejected as outliers after visual inspection. Similarly, data segments containing extreme peak-to-peak deflections or large bursts of high-frequency activity were identified and removed via visual inspection. After EEG signals were decomposed into components using independent component analysis (ICA), components reflecting noise related to eye movements, blinks, or cardiac activity were removed [<xref rid="B24-sensors-25-05515" ref-type="bibr">24</xref>].</p></sec><sec id="sec2dot4-sensors-25-05515"><title>2.4. Source Localization of EEG Signals</title><p>In this study, source localization was performed to extract brain region signals from the preprocessed EEG signals in the LEMON dataset, which were obtained using the recording method described in <xref rid="sec2dot2-sensors-25-05515" ref-type="sec">Section 2.2</xref> and preprocessed as detailed in <xref rid="sec2dot3-sensors-25-05515" ref-type="sec">Section 2.3</xref>.</p><p>To perform source localization of EEG signals, we used exact low-resolution brain electromagnetic tomography (eLORETA) [<xref rid="B27-sensors-25-05515" ref-type="bibr">27</xref>]. eLORETA has been reported to have lower localization error and a higher ability to suppress less significant sources compared to other methods [<xref rid="B28-sensors-25-05515" ref-type="bibr">28</xref>]. We utilized Python (version 3.10.0) and MNE-Python (version 1.9.0) [<xref rid="B29-sensors-25-05515" ref-type="bibr">29</xref>] as the software for implementing eLORETA. For the magnetic resonance imaging (MRI) data required for eLORETA execution, we used the fsaverage template. Referring to a related study [<xref rid="B22-sensors-25-05515" ref-type="bibr">22</xref>], we defined Regions of Interest (ROIs) as brain regions associated with the DMN (<xref rid="sensors-25-05515-t001" ref-type="table">Table 1</xref>). Then, to represent the signal of each ROI, we extracted the signal from the single vertex closest to each ROI&#8217;s coordinates, again referencing the related study [<xref rid="B22-sensors-25-05515" ref-type="bibr">22</xref>].</p></sec><sec id="sec2dot5-sensors-25-05515"><title>2.5. Calculation of Functional Connectivity</title><p>After source estimation, functional connectivity was calculated from the signals of each ROI. This calculation was performed because this index has been reported to correlate with alexithymia scores [<xref rid="B22-sensors-25-05515" ref-type="bibr">22</xref>], suggesting its potential effectiveness in assessing alexithymia. Functional connectivity quantifies the statistical interdependence of physiological time series recorded from different brain regions [<xref rid="B23-sensors-25-05515" ref-type="bibr">23</xref>]. We employed the weighted phase lag index (wPLI) [<xref rid="B30-sensors-25-05515" ref-type="bibr">30</xref>], which has been reported to be robust to noise, as a measure of functional connectivity. For wPLI calculation, mne-connectivity (version 0.7.0) [<xref rid="B31-sensors-25-05515" ref-type="bibr">31</xref>] was used as the software. For the calculation of wPLI, EEG signals were epoched into 6-s windows with a 6-s slide, and wPLI was calculated from these epochs. wPLI was calculated for several frequency bands, as shown in <xref rid="sensors-25-05515-t002" ref-type="table">Table 2</xref>. In this study, functional connectivity was calculated for all possible combinations of signals from two ROIs in each frequency band.</p><p>Using the methods described above, we calculated (number of frequency bands) &#215; (number of all possible combinations of signals from two ROIs) = 6 &#215; <inline-formula><mml:math id="mm1" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mmultiscripts><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mn>2</mml:mn><mml:none/><mml:mprescripts/><mml:mn>12</mml:mn><mml:none/></mml:mmultiscripts></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> = 396 values per participant. These indices were then used as explanatory variables.</p></sec><sec id="sec2dot6-sensors-25-05515"><title>2.6. Method for Assessing Alexithymia in Public Dataset</title><p>The 26-item German version of the Toronto Alexithymia Scale (TAS)&#8212;26 [<xref rid="B25-sensors-25-05515" ref-type="bibr">25</xref>,<xref rid="B26-sensors-25-05515" ref-type="bibr">26</xref>] was utilized to assess alexithymia in a public dataset. This questionnaire comprises items evaluated on a 5-point Likert scale, ranging from 1 (&#8220;does not apply at all&#8221;) to 5 (&#8220;applies completely&#8221;) [<xref rid="B24-sensors-25-05515" ref-type="bibr">24</xref>]. The responses are aggregated to assess the following four components: (1) difficulty identifying feelings, (2) difficulty expressing and describing feelings, (3) externally oriented thinking, and (4) a total score encompassing these aspects. In this study, the total score from component (4) was used to construct the objective variable.</p><p>The TAS is recognized as a psychometrically valid instrument [<xref rid="B7-sensors-25-05515" ref-type="bibr">7</xref>]. Furthermore, its reliability was evaluated using Cronbach&#8217;s alpha [<xref rid="B24-sensors-25-05515" ref-type="bibr">24</xref>,<xref rid="B25-sensors-25-05515" ref-type="bibr">25</xref>], and the values for each subscale were 0.79, 0.76, and 0.63 [<xref rid="B24-sensors-25-05515" ref-type="bibr">24</xref>]. The 0.63 is close to the lower limit of the acceptable range, but it seems to be acceptable in the context of evaluating alexithymia [<xref rid="B32-sensors-25-05515" ref-type="bibr">32</xref>].</p></sec><sec id="sec2dot7-sensors-25-05515"><title>2.7. Dataset Construction</title><p>For each participant, 396 explanatory variables were extracted using the methods described in <xref rid="sec2dot4-sensors-25-05515" ref-type="sec">Section 2.4</xref> and <xref rid="sec2dot5-sensors-25-05515" ref-type="sec">Section 2.5</xref>. Similarly, one objective variable was created for each participant from the scores of a questionnaire used to assess alexithymia, as detailed in <xref rid="sec2dot6-sensors-25-05515" ref-type="sec">Section 2.6</xref>. Since the analysis involved 203 participants, a table dataset of 203 &#215; (396 + 1) was constructed.</p><p>For the classification model, thresholds were set to create binary labels indicating low or high levels of alexithymia. Scores at or below the threshold were labeled as &#8220;low,&#8221; while scores above the threshold were labeled as &#8220;high.&#8221; Since the optimal threshold for accurate classification was unknown, the threshold was varied for determining &#8220;low&#8221; and &#8220;high&#8221; in 10-percentile increments, ranging from the 20th to the 80th percentile. This resulted in seven distinct thresholds, and a binary classification model was constructed for each of them.</p></sec><sec id="sec2dot8-sensors-25-05515"><title>2.8. Cross-Validation</title><p>In this study, to evaluate the machine learning models, we repeatedly divided the dataset into three types: training data, validation data, and test data. Training data are the data from which the model learns. Validation data are used to tune the machine learning model&#8217;s hyperparameters. Test data are used to assess a machine learning model&#8217;s performance.</p><p>To divide the data, StratifiedGroupKFold was implemented, which splits the data K times. The primary reason for adopting this method is to maintain the independence between the training and test datasets, thereby preventing overestimation of the model&#8217;s performance. &#8220;Stratified&#8221; means that the proportion of data for each class in the overall dataset is preserved as much as possible in the divided datasets. &#8220;Group&#8221; means that data belonging to the same group will not be distributed across both divided datasets. In this study, &#8220;the same group&#8221; refers to data from the same participant. This ensures data independence by preventing data from the same participant from being included in both the training and test data, which in turn prevents overestimation of the model&#8217;s performance. In this study, we set K = 5. For the implementation of StratifiedGroupKFold, Scikit-learn (version 1.6.1)&#8217;s [<xref rid="B33-sensors-25-05515" ref-type="bibr">33</xref>] StratifiedGroupKFold was utilized.</p></sec><sec id="sec2dot9-sensors-25-05515"><title>2.9. Dataset Preprocessing</title><p>To robustly standardize the scale of the explanatory variables, scaling was performed using the median and interquartile range. Additionally, for learning, feature selection was conducted to identify and remove redundant explanatory variables based on their correlations. The threshold for the correlation coefficient was set at 0.95. For scaling, Scikit-learn (version 1.6.1)&#8217;s RobustScaler [<xref rid="B33-sensors-25-05515" ref-type="bibr">33</xref>] was used. For feature selection, Feature-engine (version 1.8.3)&#8217;s SmartCorrelatedSelection [<xref rid="B34-sensors-25-05515" ref-type="bibr">34</xref>] was used.</p></sec><sec id="sec2dot10-sensors-25-05515"><title>2.10. Model Construction</title><p>When constructing the classification model, we recognized the potential for imbalanced data across different classes. To address this, a combined approach of undersampling with bagging was employed to integrate multiple models. Undersampling is a technique [<xref rid="B35-sensors-25-05515" ref-type="bibr">35</xref>] that balances class data by randomly removing samples from the majority class in the training dataset. Bagging involves the following steps: (1) creating new datasets by randomly sampling data with replacement from the original dataset; (2) training a model on each new dataset; (3) repeating steps 1 and 2 multiple times to construct multiple models [<xref rid="B35-sensors-25-05515" ref-type="bibr">35</xref>]; (4) constructing an integrated model that estimates classes based on majority voting or weighted voting using multiple models. This combined approach, integrating undersampling and bagging [<xref rid="B36-sensors-25-05515" ref-type="bibr">36</xref>], is widely used for imbalanced datasets where class distributions are imbalanced [<xref rid="B37-sensors-25-05515" ref-type="bibr">37</xref>]. Hereafter, we refer to this method as UB. For the implementation of UB, BalancedBaggingClassifier from Imbalanced-learn (version 0.13.0) [<xref rid="B38-sensors-25-05515" ref-type="bibr">38</xref>] was used.</p><p>We considered other well-known techniques for imbalanced data, such as the synthetic minority over-sampling technique (SMOTE) and its numerous variants [<xref rid="B39-sensors-25-05515" ref-type="bibr">39</xref>]. However, we deliberately chose not to employ these methods in this study. Our research planned to use XAI to identify the actual physiological features used by the model for evaluation. Using SMOTE introduces synthetic data points that may not correspond to actual physiological measurements, which may impair the interpretability of XAI results.</p><p>For our classification models, six representative machine learning algorithms were employed: (1) logistic regression (LR); (2) a model that integrates multiple LR models using UB (hereafter referred to as LR UB); (3) a support vector machine (SVM) for classification with a linear kernel (hereafter referred to as SVM C(linear)); (4) a model that integrates multiple SVM C(linear) models using UB (hereafter referred to as SVM C(linear) UB); (5) an SVM for classification with a radial basis function (RBF) kernel (hereafter referred to as SVM C(RBF)); and (6) an RF for classification (hereafter referred to as RF C). These models were implemented using Scikit-learn (version 1.6.1) [<xref rid="B33-sensors-25-05515" ref-type="bibr">33</xref>] and Imbalanced-learn (version 0.13.0) [<xref rid="B38-sensors-25-05515" ref-type="bibr">38</xref>].</p><p>To briefly describe the characteristics of the primary models used in this study, the LR model incorporates both L1 regularization, as in Lasso regression, and L2 regularization, as in Ridge regression. The L1 regularization is expected to enable feature selection, while the L2 regularization is expected to improve stability and performance [<xref rid="B40-sensors-25-05515" ref-type="bibr">40</xref>]. The SVM is widely recognized for its high generalization performance [<xref rid="B41-sensors-25-05515" ref-type="bibr">41</xref>]. A linear kernel enables the model to learn linear patterns, whereas an RBF kernel allows it to capture non-linear relationships. The RF model is known to prevent overfitting, thereby achieving high generalization performance [<xref rid="B42-sensors-25-05515" ref-type="bibr">42</xref>].</p><p>The hyperparameters for both the regression and classification models were tuned using Bayesian optimization, which was implemented with Optuna (version 3.5.0) [<xref rid="B43-sensors-25-05515" ref-type="bibr">43</xref>]. During this optimization process, the hyperparameters were adjusted to achieve optimal performance on the validation data, ensuring it remained independent from the test data. The classification models were tuned to maximize the ROC-AUC. <xref rid="sensors-25-05515-t003" ref-type="table">Table 3</xref> displays the tuned hyperparameters for each model.</p></sec><sec id="sec2dot11-sensors-25-05515"><title>2.11. Model Performance Metrics</title><p>The ROC-AUC represents the area under the ROC curve. The ROC curve is plotted on a graph with the false positive rate (FPR) on the <italic toggle="yes">x</italic>-axis and the true positive rate (TPR) on the <italic toggle="yes">y</italic>-axis. This curve is generated by varying the classification threshold applied to the probabilities estimated by the classification model. The ROC-AUC ranges from 0 to 1. A value of 0 indicates that all classifications are incorrect, 0.5 indicates performance equivalent to random chance, and 1 indicates all classifications are correct [<xref rid="B44-sensors-25-05515" ref-type="bibr">44</xref>].</p></sec><sec id="sec2dot12-sensors-25-05515"><title>2.12. Statistical Significance Evaluation of Machine Learning Model Performance</title><p>To statistically assess whether the performance of our trained machine learning models was higher than what could occur by chance, a permutation test [<xref rid="B45-sensors-25-05515" ref-type="bibr">45</xref>,<xref rid="B46-sensors-25-05515" ref-type="bibr">46</xref>] was conducted. In this study, we performed the permutation test as follows:<list list-type="order"><list-item><p>Train the machine learning model using the training data.</p></list-item><list-item><p>Evaluate the performance of the trained machine learning model on the test data.</p></list-item><list-item><p>Randomly permute the objective variables in both the training and test data.</p></list-item><list-item><p>Train the machine learning model using the permuted training data.</p></list-item><list-item><p>Evaluate the performance of the machine learning model using the permuted test data.</p></list-item><list-item><p>Repeat steps 3&#8211;5 an arbitrary number of times.</p></list-item><list-item><p>Obtain the empirical null distribution by aggregating the accuracies calculated repeatedly in step 6.</p></list-item><list-item><p>Evaluate the statistical significance of the performance calculated in step 2, based on the empirical null distribution obtained in step 7.</p></list-item></list></p><p>In this study, the number of repetitions for step 6 of the permutation test was set to 100 for regression models and 1000 for classification models.</p><p>Inspired by [<xref rid="B46-sensors-25-05515" ref-type="bibr">46</xref>], an intuitive explanation of the permutation test is as follows: if the performance calculated in step 2 is higher than the 95th percentile of the accuracies that could occur by chance (obtained in step 7), then the original classification is considered statistically significant with <italic toggle="yes">p</italic> &lt; 0.05.</p></sec><sec id="sec2dot13-sensors-25-05515"><title>2.13. Interpreting Machine Learning Models with Permutation Feature Importance</title><p>We analyzed which features contributed to the evaluation using permutation feature importance (PFI). PFI quantifies the degree of each feature&#8217;s contribution to a model&#8217;s performance. This value for each feature is calculated by assessing the impact on model performance after permuting that feature. If the model&#8217;s performance decreases after shuffling a feature&#8217;s values (a column in tabular data), that feature is considered important. Conversely, if shuffling a feature&#8217;s values does not change the model&#8217;s performance, the feature is considered unimportant. In this study, we calculated PFI using the following steps:<list list-type="order"><list-item><p>Train the machine learning model using the training data.</p></list-item><list-item><p>Evaluate the performance of the trained machine learning model on the test data.</p></list-item><list-item><p>Permute the data for one feature within the test dataset.</p></list-item><list-item><p>Evaluate the performance of the trained machine learning model using the permuted data.</p></list-item><list-item><p>Calculate the difference between the performance before permutation and the performance after permutation.</p></list-item><list-item><p>Repeat steps 3&#8211;5 ten times.</p></list-item><list-item><p>Average the differences in performance calculated in step 6.</p></list-item><list-item><p>Perform steps 3&#8211;6 for each feature.</p></list-item></list></p><p>We implemented PFI using Scikit-learn (version 1.6.1) [<xref rid="B33-sensors-25-05515" ref-type="bibr">33</xref>].</p><p>Based on the calculated PFI, we analyzed which ROIs and frequency bands contributed to the evaluation. For ROIs, their importances were quantified by aggregating the PFI of the features derived from them. Specifically, we aggregated the data using the following steps:<list list-type="order"><list-item><p>Calculate PFI for each feature.</p></list-item><list-item><p>Exclude from the analysis any features with a PFI of 0 or less, as these are considered not to contribute to the evaluation.</p></list-item><list-item><p>Select the top <inline-formula><mml:math id="mm2" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>% of features based on their PFI values.</p></list-item><list-item><p>Count one point for the importance of the ROI from which the selected feature was derived.</p></list-item><list-item><p>Repeat steps 3&#8211;4, varying <inline-formula><mml:math id="mm3" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> at 10, 30, and 50.</p></list-item></list></p><p>ROIs that accumulate higher counts through steps 1&#8211;5 are considered to contribute more significantly to the evaluation. We quantified the importance of frequency bands using the same aggregation procedure as for the ROIs.</p><p>For example, if the wPLI of the alpha frequency band in the Left Frontal Lobe and Right Parietal Lobe contributes to the evaluation, the importance for &#8220;Frontal Lobe,&#8221; &#8220;Right Parietal Lobe,&#8221; and &#8220;alpha&#8221; would each be incremented by one. This analysis was conducted exclusively on models that demonstrated statistical significance using the method described in <xref rid="sec2dot12-sensors-25-05515" ref-type="sec">Section 2.12</xref>.</p><p>Although local interpretable model-agnostic explanations (LIME) and shapley additive explanations (SHAP) were considered as alternative XAI methods, this study employed PFI. The rationale for this selection is twofold: PFI can be computed within a practical timeframe, and it is capable of providing a global interpretation of the model. In contrast, while LIME is effective for local interpretations&#8212;offering explanations for individual predictions&#8212;it is not well-suited for global analysis. Furthermore, SHAP can be more computationally intensive than PFI, which raised concerns about its feasibility for the iterative calculations required in our research.</p></sec></sec><sec sec-type="results" id="sec3-sensors-25-05515"><title>3. Results and Discussions</title><sec id="sec3dot1-sensors-25-05515"><title>3.1. Classification Model Performance</title><p>Cross-validation was repeatedly performed, involving the optimization of hyperparameters using validation data, the training of the model with training data, and the evaluation of performance using test data. <xref rid="sensors-25-05515-t004" ref-type="table">Table 4</xref> presents the average performance calculated through this cross-validation. The classification model evaluated two values indicating low and high degrees of alexithymia. The thresholds defining these two values were set at every 10th percentile from the 20th to the 80th percentile. The average performance was calculated for each of these thresholds. The performance metric used was ROC-AUC.</p><p>As shown in <xref rid="sensors-25-05515-t004" ref-type="table">Table 4</xref>, the classification model LR UB achieved the highest performance of 0.70 with a threshold of 20%. Additionally, the SVM C(linear) UB classification model achieved a performance of 0.67, also with a threshold of 20%. This threshold may suggest a boundary that can effectively distinguish between groups with low and high alexithymia based on resting-state functional connectivity.</p></sec><sec id="sec3dot2-sensors-25-05515"><title>3.2. Permutation Tests in the Classification Model</title><p>Permutation tests were performed for each of the multiple models constructed as part of the cross-validation. <xref rid="sensors-25-05515-t005" ref-type="table">Table 5</xref> presents the number of times a significant difference was observed through the permutation tests. Since the models were constructed five times through cross-validation, the maximum value for each cell in <xref rid="sensors-25-05515-t005" ref-type="table">Table 5</xref>, excluding cells that represent a total sum, is 5.</p><p><xref rid="sensors-25-05515-t005" ref-type="table">Table 5</xref> indicates that it is often challenging to classify with a performance higher than chance because the count is frequently zero. However, in cases such as the threshold of 20% that achieved the highest performance, or thresholds of 30% and 70%, some cells exhibit counts of two or three. This suggests that if the dependent variable is set with these thresholds, classification with higher performance than chance is possible. The high performance suggests that the functional connectivity of the DMN, used as a feature, contains information capable of discriminating the degree of alexithymia. Consequently, a classification into three categories using two thresholds derived from this high performance may also be a useful approach that reflects underlying biological characteristics. This could inform the development of biologically plausible models.</p><p>Furthermore, summing the counts for each classification model in <xref rid="sensors-25-05515-t005" ref-type="table">Table 5</xref> reveals relatively high counts for SVM C(linear) UB, and LR UB. These higher counts suggest that these models can achieve higher performance than by chance. These models incorporated UB, which is a countermeasure for imbalanced data, thereby suggesting the effectiveness of UB in handling imbalanced datasets.</p></sec><sec id="sec3dot3-sensors-25-05515"><title>3.3. Permutation Feature Importance in the Classification Model</title><p>In this study, we analyzed which ROIs and frequency bands are important for alexithymia assessment, based on PFI, which quantifies the degree of feature importance. Specifically, the analysis was conducted for classification at a 30% threshold and a 70% threshold, as the performance of the trained models often showed a statistically significant improvement in permutation tests at these thresholds.</p><sec id="sec3dot3dot1-sensors-25-05515"><title>3.3.1. Important ROIs in Classification at a 30% Threshold</title><p><xref rid="sensors-25-05515-t006" ref-type="table">Table 6</xref> presents the calculated importance of ROIs.</p><p>As shown in <xref rid="sensors-25-05515-t006" ref-type="table">Table 6</xref>, the Left Frontal Lobe and Left Hippocampus exhibited higher counts in the top 10% of feature importance. Similarly, the Left Parietal Lobe and Right Parietal Lobe showed higher counts in the top 30% and 50%. These results suggest that these ROIs contribute more to the evaluation than other ROIs.</p><p>Regarding the Left Frontal Lobe, Left Parietal Lobe, and Right Parietal Lobe, it has been reported that these ROIs in individuals with alexithymia may reflect disruptions in functional connectivity and difficulties in cognitive processing and emotional labeling [<xref rid="B47-sensors-25-05515" ref-type="bibr">47</xref>]. Therefore, it is expected that disruptions in functional connectivity within these ROIs could contribute to the assessment of alexithymia. These ROIs were suggested to contribute more to the assessment than other ROIs. Therefore, the results of this study were consistent with this expectation.</p><p>For the Left Hippocampus, there are few reports on its association with alexithymia, even when referring to a review paper [<xref rid="B47-sensors-25-05515" ref-type="bibr">47</xref>]. Therefore, this study newly suggested that the Left Hippocampus could be useful for the assessment of alexithymia. Additionally, a related study [<xref rid="B48-sensors-25-05515" ref-type="bibr">48</xref>] has reported a reduction in hippocampal volume in a subset of alexithymia subtypes. While a reduction in volume does not necessarily affect functional connectivity, it may suggest that the hippocampus has some influence on the assessment of alexithymia.</p></sec><sec id="sec3dot3dot2-sensors-25-05515"><title>3.3.2. Important Frequency Bands in Classification at a 30% Threshold</title><p><xref rid="sensors-25-05515-t007" ref-type="table">Table 7</xref> presents the calculated importance of frequency bands.</p><p>As shown in <xref rid="sensors-25-05515-t007" ref-type="table">Table 7</xref>, gamma band activity appeared more frequently in the top 10%, 30%, and 50% of feature importance. This suggests that gamma contributes more to the assessment than other frequency bands.</p><p>Regarding gamma band activity, a related study [<xref rid="B49-sensors-25-05515" ref-type="bibr">49</xref>] reported that when negative emotions were presented, individuals with alexithymia did not show an increase in gamma-band functional connectivity. This finding has been reported to suggest an impairment in the processing of negative emotions by brain networks [<xref rid="B47-sensors-25-05515" ref-type="bibr">47</xref>,<xref rid="B49-sensors-25-05515" ref-type="bibr">49</xref>]. In contrast to this previous study [<xref rid="B49-sensors-25-05515" ref-type="bibr">49</xref>], our study analyzed resting-state EEG signals without presenting emotion-inducing stimuli. Therefore, our findings newly suggested that gamma band activity in the resting-state, not only during stimulation, could be beneficial for the assessment of alexithymia.</p></sec><sec id="sec3dot3dot3-sensors-25-05515"><title>3.3.3. Important ROIs in Classification at a 70% Threshold</title><p><xref rid="sensors-25-05515-t008" ref-type="table">Table 8</xref> presents the calculated importance of ROIs.</p><p>As shown in <xref rid="sensors-25-05515-t008" ref-type="table">Table 8</xref>, the Right Posterior Cingulate Cortex exhibited higher counts in the top 10% of feature importance. The Left Frontal Lobe and Left Hippocampus showed higher counts in the top 30% and 50%. The Right Posterior Cingulate Cortex had higher counts in the top 50%. These results suggest that these ROIs contribute more to the evaluation than other ROIs.</p><p>Regarding the Right Posterior Cingulate Cortex, it has been reported that its functional connectivity in individuals with alexithymia is decreasing [<xref rid="B22-sensors-25-05515" ref-type="bibr">22</xref>]. This decrease is expected to contribute to the evaluation. The results of this study suggest that this ROI contributes more to the evaluation than other ROIs. Therefore, the results of this study were consistent with this expectation.</p><p>Concerning the Left Frontal Lobe and Left Hippocampus, these ROIs were suggested to be effective for alexithymia assessment, consistent with the results in <xref rid="sec3dot3dot1-sensors-25-05515" ref-type="sec">Section 3.3.1</xref>.</p><p>In contrast to <xref rid="sec3dot3dot1-sensors-25-05515" ref-type="sec">Section 3.3.1</xref>, which used alternative thresholds, the Left Parietal Lobe and Right Parietal Lobe ROIs were found to be effective for alexithymia assessment. This difference suggests that the effective features for classifying alexithymia into low and high categories may vary depending on the threshold used to define these levels. This finding is considered a valuable insight when selecting an index for constructing highly accurate models. This is because if features are selected without understanding that effective indices can vary, there is a risk of decreased performance.</p></sec><sec id="sec3dot3dot4-sensors-25-05515"><title>3.3.4. Important Frequency Bands in Classification at a 70% Threshold</title><p><xref rid="sensors-25-05515-t009" ref-type="table">Table 9</xref> presents the calculated importance of frequency bands.</p><p>As shown in <xref rid="sensors-25-05515-t009" ref-type="table">Table 9</xref>, delta and theta band activity exhibited higher counts in the top 10%. Theta and alpha band activity showed higher counts in the top 30%. Alpha band activity appeared in higher counts in the top 50%. These results suggest that these frequency bands contribute more to alexithymia assessment than other frequency bands.</p><p>Regarding delta band activity, there are few reports on its association with alexithymia in the literature [<xref rid="B47-sensors-25-05515" ref-type="bibr">47</xref>]. Therefore, this study newly suggests its potential utility for alexithymia assessment. Furthermore, a related study [<xref rid="B50-sensors-25-05515" ref-type="bibr">50</xref>] reported differences in DMN delta band activity and functional connectivity among patients with mental disorders. The delta band activity differences reported in mental disorders may be relevant for alexithymia assessment, as alexithymia is considered one of the risk factors for mental disorders [<xref rid="B8-sensors-25-05515" ref-type="bibr">8</xref>].</p><p>Concerning the theta band, related studies [<xref rid="B47-sensors-25-05515" ref-type="bibr">47</xref>,<xref rid="B51-sensors-25-05515" ref-type="bibr">51</xref>,<xref rid="B52-sensors-25-05515" ref-type="bibr">52</xref>] have reported that individuals with alexithymia exhibit increased functional connectivity within this theta band when exposed to emotion-eliciting stimuli. This increase is considered to indicate that emotional expression and interpretation are disturbed [<xref rid="B47-sensors-25-05515" ref-type="bibr">47</xref>]. In contrast to these related studies, our study analyzed resting-state EEG signals, which were not affected by emotion-eliciting stimuli. Therefore, the present study newly suggests the potential utility of resting-state EEG signals within the theta band for alexithymia assessment.</p><p>Regarding the alpha band, a decrease in functional connectivity among individuals with alexithymia has been reported [<xref rid="B22-sensors-25-05515" ref-type="bibr">22</xref>]. Consequently, this decrease is expected to contribute to alexithymia assessment. As shown in <xref rid="sensors-25-05515-t009" ref-type="table">Table 9</xref>, the alpha band has been suggested to contribute more to the alexithymia assessment than other frequency bands. Therefore, the results of this study were consistent with this expectation.</p><p>This study has several limitations. First, the observed associations may be influenced by confounding variables such as age and gender. Although methods such as matching can contribute to controlling for such factors, we opted to include all available data to maximize the dataset size for our machine learning model. Therefore, our results do not imply strict causal inferences and should be interpreted with caution. Second, there are concerns about the generalizability of our findings. To improve generalizability, analyzing data from multiple sources is preferable to using a single dataset, which can be susceptible to unknown biases. To enhance the generalizability within our study, we evaluated the model&#8217;s performance using a rigorous cross-validation procedure. Crucially, to avoid overly optimistic performance estimates, we ensured that data from the same participant were not shared between the training and test data, thereby avoiding the common pitfall of data leakage, which impairs model generalizability. Nevertheless, future research is required to validate these findings across diverse datasets from multiple sources.</p></sec></sec></sec><sec sec-type="conclusions" id="sec4-sensors-25-05515"><title>4. Conclusions</title><p>The present study constructed regression and classification models to evaluate alexithymia using functional connectivity extracted from resting-state EEG signals. While the regression model aimed to assess alexithymia with finer granularity than the classification model, its construction proved challenging. The classification model was developed to assess low and high degrees of alexithymia. Its results indicated that it could effectively assess these degrees, defined by established low and high thresholds. The model achieved a maximum ROC-AUC score of 0.70. Analysis of the classification models newly suggested that the theta band, gamma band, and Left Hippocampus could be useful for alexithymia assessment.</p></sec></body><back><ack><title>Acknowledgments</title><p>During the preparation of this manuscript/study, the authors used Gemini 2.5 Pro for the purposes of improving this manuscript. The authors have reviewed and edited the output and take full responsibility for the content of this publication.</p></ack><fn-group><fn><p><bold>Disclaimer/Publisher&#8217;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><notes><title>Author Contributions</title><p>Conceptualization, K.S. and M.S.; methodology, K.S.; software, K.S.; validation, K.S.; formal analysis, K.S.; investigation, K.S.; resources, K.S. and M.S.; data curation, K.S.; writing&#8212;original draft preparation, K.S.; writing&#8212;review and editing, K.S. and M.S.; visualization, K.S.; supervision, M.S.; project administration, K.S. and M.S.; funding acquisition, K.S. All authors have read and agreed to the published version of the manuscript.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>In this study, the public dataset LEMON was analyzed.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The funders had no role in the design of the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript; or in the decision to publish the results.</p></notes><ref-list><title>References</title><ref id="B1-sensors-25-05515"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fusar-Poli</surname><given-names>P.</given-names></name><name name-style="western"><surname>Correll</surname><given-names>C.U.</given-names></name><name name-style="western"><surname>Arango</surname><given-names>C.</given-names></name><name name-style="western"><surname>Berk</surname><given-names>M.</given-names></name><name name-style="western"><surname>Patel</surname><given-names>V.</given-names></name><name name-style="western"><surname>Ioannidis</surname><given-names>J.P.A.</given-names></name></person-group><article-title>Preventive Psychiatry: A Blueprint for Improving the Mental Health of Young People</article-title><source>World Psychiatry</source><year>2021</year><volume>20</volume><fpage>200</fpage><lpage>221</lpage><pub-id pub-id-type="doi">10.1002/wps.20869</pub-id><pub-id pub-id-type="pmid">34002494</pub-id><pub-id pub-id-type="pmcid">PMC8129854</pub-id></element-citation></ref><ref id="B2-sensors-25-05515"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Firth</surname><given-names>J.</given-names></name><name name-style="western"><surname>Solmi</surname><given-names>M.</given-names></name><name name-style="western"><surname>Wootton</surname><given-names>R.E.</given-names></name><name name-style="western"><surname>Vancampfort</surname><given-names>D.</given-names></name><name name-style="western"><surname>Schuch</surname><given-names>F.B.</given-names></name><name name-style="western"><surname>Hoare</surname><given-names>E.</given-names></name><name name-style="western"><surname>Gilbody</surname><given-names>S.</given-names></name><name name-style="western"><surname>Torous</surname><given-names>J.</given-names></name><name name-style="western"><surname>Teasdale</surname><given-names>S.B.</given-names></name><name name-style="western"><surname>Jackson</surname><given-names>S.E.</given-names></name><etal/></person-group><article-title>A Meta-Review of &#8220;Lifestyle Psychiatry&#8221;: The Role of Exercise, Smoking, Diet and Sleep in the Prevention and Treatment of Mental Disorders</article-title><source>World Psychiatry</source><year>2020</year><volume>19</volume><fpage>360</fpage><lpage>380</lpage><pub-id pub-id-type="doi">10.1002/wps.20773</pub-id><pub-id pub-id-type="pmid">32931092</pub-id><pub-id pub-id-type="pmcid">PMC7491615</pub-id></element-citation></ref><ref id="B3-sensors-25-05515"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Schwend</surname><given-names>R.M.</given-names></name></person-group><article-title>The Burden of Pediatric Musculoskeletal Diseases Worldwide</article-title><source>Orthop. Clin. N. Am.</source><year>2020</year><volume>51</volume><fpage>207</fpage><lpage>217</lpage><pub-id pub-id-type="doi">10.1016/j.ocl.2019.11.005</pub-id><pub-id pub-id-type="pmid">32138858</pub-id></element-citation></ref><ref id="B4-sensors-25-05515"><label>4.</label><element-citation publication-type="journal"><article-title>GBD 2019 Mental Disorders Collaborators Global, Regional, and National Burden of 12 Mental Disorders in 204 Countries and Territories, 1990-2019: A Systematic Analysis for the Global Burden of Disease Study 2019</article-title><source>Lancet Psychiatry</source><year>2022</year><volume>9</volume><fpage>137</fpage><lpage>150</lpage><pub-id pub-id-type="doi">10.1016/S2215-0366(21)00395-3</pub-id><pub-id pub-id-type="pmid">35026139</pub-id><pub-id pub-id-type="pmcid">PMC8776563</pub-id></element-citation></ref><ref id="B5-sensors-25-05515"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kirkbride</surname><given-names>J.B.</given-names></name><name name-style="western"><surname>Anglin</surname><given-names>D.M.</given-names></name><name name-style="western"><surname>Colman</surname><given-names>I.</given-names></name><name name-style="western"><surname>Dykxhoorn</surname><given-names>J.</given-names></name><name name-style="western"><surname>Jones</surname><given-names>P.B.</given-names></name><name name-style="western"><surname>Patalay</surname><given-names>P.</given-names></name><name name-style="western"><surname>Pitman</surname><given-names>A.</given-names></name><name name-style="western"><surname>Soneson</surname><given-names>E.</given-names></name><name name-style="western"><surname>Steare</surname><given-names>T.</given-names></name><name name-style="western"><surname>Wright</surname><given-names>T.</given-names></name><etal/></person-group><article-title>The Social Determinants of Mental Health and Disorder: Evidence, Prevention and Recommendations</article-title><source>World Psychiatry</source><year>2024</year><volume>23</volume><fpage>58</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1002/wps.21160</pub-id><pub-id pub-id-type="pmid">38214615</pub-id><pub-id pub-id-type="pmcid">PMC10786006</pub-id></element-citation></ref><ref id="B6-sensors-25-05515"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Howes</surname><given-names>O.D.</given-names></name><name name-style="western"><surname>Thase</surname><given-names>M.E.</given-names></name><name name-style="western"><surname>Pillinger</surname><given-names>T.</given-names></name></person-group><article-title>Treatment Resistance in Psychiatry: State of the Art and New Directions</article-title><source>Mol. Psychiatry</source><year>2022</year><volume>27</volume><fpage>58</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1038/s41380-021-01200-3</pub-id><pub-id pub-id-type="pmid">34257409</pub-id><pub-id pub-id-type="pmcid">PMC8960394</pub-id></element-citation></ref><ref id="B7-sensors-25-05515"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Luminet</surname><given-names>O.</given-names></name><name name-style="western"><surname>Nielson</surname><given-names>K.A.</given-names></name></person-group><article-title>Alexithymia: Towards an Experimental, Processual Affective Science with Effective Interventions</article-title><source>Annu. Rev. Psychol.</source><year>2024</year><volume>76</volume><fpage>741</fpage><lpage>769</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-021424-030718</pub-id><pub-id pub-id-type="pmid">39322432</pub-id></element-citation></ref><ref id="B8-sensors-25-05515"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Preece</surname><given-names>D.A.</given-names></name><name name-style="western"><surname>Mehta</surname><given-names>A.</given-names></name><name name-style="western"><surname>Becerra</surname><given-names>R.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>W.</given-names></name><name name-style="western"><surname>Allan</surname><given-names>A.</given-names></name><name name-style="western"><surname>Robinson</surname><given-names>K.</given-names></name><name name-style="western"><surname>Boyes</surname><given-names>M.</given-names></name><name name-style="western"><surname>Hasking</surname><given-names>P.</given-names></name><name name-style="western"><surname>Gross</surname><given-names>J.J.</given-names></name></person-group><article-title>Why Is Alexithymia a Risk Factor for Affective Disorder Symptoms? The Role of Emotion Regulation</article-title><source>J. Affect. Disord.</source><year>2022</year><volume>296</volume><fpage>337</fpage><lpage>341</lpage><pub-id pub-id-type="doi">10.1016/j.jad.2021.09.085</pub-id><pub-id pub-id-type="pmid">34606815</pub-id></element-citation></ref><ref id="B9-sensors-25-05515"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sheppes</surname><given-names>G.</given-names></name><name name-style="western"><surname>Suri</surname><given-names>G.</given-names></name><name name-style="western"><surname>Gross</surname><given-names>J.J.</given-names></name></person-group><article-title>Emotion Regulation and Psychopathology</article-title><source>Annu. Rev. Clin. Psychol.</source><year>2015</year><volume>11</volume><fpage>379</fpage><lpage>405</lpage><pub-id pub-id-type="doi">10.1146/annurev-clinpsy-032814-112739</pub-id><pub-id pub-id-type="pmid">25581242</pub-id></element-citation></ref><ref id="B10-sensors-25-05515"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Quinto</surname><given-names>R.M.</given-names></name><name name-style="western"><surname>De Vincenzo</surname><given-names>F.</given-names></name><name name-style="western"><surname>Graceffa</surname><given-names>D.</given-names></name><name name-style="western"><surname>Bonifati</surname><given-names>C.</given-names></name><name name-style="western"><surname>Innamorati</surname><given-names>M.</given-names></name><name name-style="western"><surname>Iani</surname><given-names>L.</given-names></name></person-group><article-title>The Relationship between Alexithymia and Mental Health Is Fully Mediated by Anxiety and Depression in Patients with Psoriasis</article-title><source>Int. J. Environ. Res. Public Health</source><year>2022</year><volume>19</volume><elocation-id>3649</elocation-id><pub-id pub-id-type="doi">10.3390/ijerph19063649</pub-id><pub-id pub-id-type="pmid">35329336</pub-id><pub-id pub-id-type="pmcid">PMC8950845</pub-id></element-citation></ref><ref id="B11-sensors-25-05515"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pinna</surname><given-names>F.</given-names></name><name name-style="western"><surname>Manchia</surname><given-names>M.</given-names></name><name name-style="western"><surname>Paribello</surname><given-names>P.</given-names></name><name name-style="western"><surname>Carpiniello</surname><given-names>B.</given-names></name></person-group><article-title>The Impact of Alexithymia on Treatment Response in Psychiatric Disorders: A Systematic Review</article-title><source>Front. Psychiatry</source><year>2020</year><volume>11</volume><elocation-id>311</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyt.2020.00311</pub-id><pub-id pub-id-type="pmid">32372987</pub-id><pub-id pub-id-type="pmcid">PMC7177022</pub-id></element-citation></ref><ref id="B12-sensors-25-05515"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Farhoumandi</surname><given-names>N.</given-names></name><name name-style="western"><surname>Mollaey</surname><given-names>S.</given-names></name><name name-style="western"><surname>Heysieattalab</surname><given-names>S.</given-names></name><name name-style="western"><surname>Zarean</surname><given-names>M.</given-names></name><name name-style="western"><surname>Eyvazpour</surname><given-names>R.</given-names></name></person-group><article-title>Facial Emotion Recognition Predicts Alexithymia Using Machine Learning</article-title><source>Comput. Intell. Neurosci.</source><year>2021</year><volume>2021</volume><fpage>2053795</fpage><pub-id pub-id-type="doi">10.1155/2021/2053795</pub-id><pub-id pub-id-type="pmid">34621306</pub-id><pub-id pub-id-type="pmcid">PMC8492233</pub-id></element-citation></ref><ref id="B13-sensors-25-05515"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rivera</surname><given-names>M.J.</given-names></name><name name-style="western"><surname>Teruel</surname><given-names>M.A.</given-names></name><name name-style="western"><surname>Mat&#233;</surname><given-names>A.</given-names></name><name name-style="western"><surname>Trujillo</surname><given-names>J.</given-names></name></person-group><article-title>Diagnosis and Prognosis of Mental Disorders by Means of EEG and Deep Learning: A Systematic Mapping Study</article-title><source>Artif. Intell. Rev.</source><year>2021</year><volume>55</volume><fpage>1209</fpage><lpage>1251</lpage><pub-id pub-id-type="doi">10.1007/s10462-021-09986-y</pub-id></element-citation></ref><ref id="B14-sensors-25-05515"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>de Bardeci</surname><given-names>M.</given-names></name><name name-style="western"><surname>Ip</surname><given-names>C.T.</given-names></name><name name-style="western"><surname>Olbrich</surname><given-names>S.</given-names></name></person-group><article-title>Deep Learning Applied to Electroencephalogram Data in Mental Disorders: A Systematic Review</article-title><source>Biol. Psychol.</source><year>2021</year><volume>162</volume><elocation-id>108117</elocation-id><pub-id pub-id-type="doi">10.1016/j.biopsycho.2021.108117</pub-id><pub-id pub-id-type="pmid">33991592</pub-id></element-citation></ref><ref id="B15-sensors-25-05515"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lai</surname><given-names>C.-H.</given-names></name></person-group><article-title>Promising Neuroimaging Biomarkers in Depression</article-title><source>Psychiatry Investig.</source><year>2019</year><volume>16</volume><fpage>662</fpage><lpage>670</lpage><pub-id pub-id-type="doi">10.30773/pi.2019.07.25.2</pub-id><pub-id pub-id-type="pmcid">PMC6761793</pub-id><pub-id pub-id-type="pmid">31550875</pub-id></element-citation></ref><ref id="B16-sensors-25-05515"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dev</surname><given-names>A.</given-names></name><name name-style="western"><surname>Roy</surname><given-names>N.</given-names></name><name name-style="western"><surname>Islam</surname><given-names>M.K.</given-names></name><name name-style="western"><surname>Biswas</surname><given-names>C.</given-names></name><name name-style="western"><surname>Ahmed</surname><given-names>H.U.</given-names></name><name name-style="western"><surname>Amin</surname><given-names>M.A.</given-names></name><name name-style="western"><surname>Sarker</surname><given-names>F.</given-names></name><name name-style="western"><surname>Vaidyanathan</surname><given-names>R.</given-names></name><name name-style="western"><surname>Mamun</surname><given-names>K.A.</given-names></name></person-group><article-title>Exploration of EEG-Based Depression Biomarkers Identification Techniques and Their Applications: A Systematic Review</article-title><source>IEEE Access</source><year>2022</year><volume>10</volume><fpage>16756</fpage><lpage>16781</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2022.3146711</pub-id></element-citation></ref><ref id="B17-sensors-25-05515"><label>17.</label><element-citation publication-type="webpage"><person-group person-group-type="author"><name name-style="western"><surname>Molnar</surname><given-names>C.</given-names></name></person-group><article-title>Interpretable Machine Learning: A Guide for Making Black Box Models Explainable</article-title><year>2019</year><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://christophm.github.io/interpretable-ml-book/" ext-link-type="uri">https://christophm.github.io/interpretable-ml-book/</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-07-25">(accessed on 25 July 2025)</date-in-citation></element-citation></ref><ref id="B18-sensors-25-05515"><label>18.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Filippou</surname><given-names>V.</given-names></name><name name-style="western"><surname>Nicolaou</surname><given-names>M.A.</given-names></name><name name-style="western"><surname>Theodosiou</surname><given-names>N.</given-names></name><name name-style="western"><surname>Panayiotou</surname><given-names>G.</given-names></name><name name-style="western"><surname>Contantinou</surname><given-names>E.</given-names></name><name name-style="western"><surname>Theodorou</surname><given-names>M.</given-names></name><name name-style="western"><surname>Panteli</surname><given-names>M.</given-names></name></person-group><article-title>Multimodal Prediction of Alexithymia from Physiological and Audio Signals</article-title><source>Proceedings of the 2023 11th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)</source><conf-loc>Cambridge, MA, USA</conf-loc><conf-date>10 September 2023</conf-date><publisher-name>IEEE</publisher-name><publisher-loc>New York City, NY, USA</publisher-loc><year>2023</year><fpage>1</fpage><lpage>8</lpage></element-citation></ref><ref id="B19-sensors-25-05515"><label>19.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Filippou</surname><given-names>V.</given-names></name><name name-style="western"><surname>Theodosiou</surname><given-names>N.</given-names></name><name name-style="western"><surname>Nicolaou</surname><given-names>M.</given-names></name><name name-style="western"><surname>Constantinou</surname><given-names>E.</given-names></name><name name-style="western"><surname>Panayiotou</surname><given-names>G.</given-names></name><name name-style="western"><surname>Theodorou</surname><given-names>M.</given-names></name></person-group><article-title>A Wavelet-Based Approach for Multimodal Prediction of Alexithymia from Physiological Signals</article-title><source>Proceedings of the Companion Publication of the 2022 International Conference on Multimodal Interaction</source><conf-loc>Bengaluru, India</conf-loc><conf-date>7 November 2022</conf-date><publisher-name>Association for Computing Machinery</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><fpage>177</fpage><lpage>184</lpage></element-citation></ref><ref id="B20-sensors-25-05515"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Edwards</surname><given-names>D.J.</given-names></name><name name-style="western"><surname>Lowe</surname><given-names>R.</given-names></name></person-group><article-title>Associations between Mental Health, Interoception, Psychological Flexibility, and Self-as-Context, as Predictors for Alexithymia: A Deep Artificial Neural Network Approach</article-title><source>Front. Psychol.</source><year>2021</year><volume>12</volume><elocation-id>637802</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2021.637802</pub-id><pub-id pub-id-type="pmid">33868110</pub-id><pub-id pub-id-type="pmcid">PMC8044902</pub-id></element-citation></ref><ref id="B21-sensors-25-05515"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Callard</surname><given-names>F.</given-names></name><name name-style="western"><surname>Margulies</surname><given-names>D.S.</given-names></name></person-group><article-title>What We Talk about When We Talk about the Default Mode Network</article-title><source>Front. Hum. Neurosci.</source><year>2014</year><volume>8</volume><elocation-id>619</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2014.00619</pub-id><pub-id pub-id-type="pmid">25202250</pub-id><pub-id pub-id-type="pmcid">PMC4142807</pub-id></element-citation></ref><ref id="B22-sensors-25-05515"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Imperatori</surname><given-names>C.</given-names></name><name name-style="western"><surname>Della Marca</surname><given-names>G.</given-names></name><name name-style="western"><surname>Brunetti</surname><given-names>R.</given-names></name><name name-style="western"><surname>Carbone</surname><given-names>G.A.</given-names></name><name name-style="western"><surname>Massullo</surname><given-names>C.</given-names></name><name name-style="western"><surname>Valenti</surname><given-names>E.M.</given-names></name><name name-style="western"><surname>Amoroso</surname><given-names>N.</given-names></name><name name-style="western"><surname>Maestoso</surname><given-names>G.</given-names></name><name name-style="western"><surname>Contardi</surname><given-names>A.</given-names></name><name name-style="western"><surname>Farina</surname><given-names>B.</given-names></name></person-group><article-title>Default Mode Network Alterations in Alexithymia: An EEG Power Spectra and Connectivity Study</article-title><source>Sci. Rep.</source><year>2016</year><volume>6</volume><elocation-id>36653</elocation-id><pub-id pub-id-type="doi">10.1038/srep36653</pub-id><pub-id pub-id-type="pmid">27845326</pub-id><pub-id pub-id-type="pmcid">PMC5109184</pub-id></element-citation></ref><ref id="B23-sensors-25-05515"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ismail</surname><given-names>L.E.</given-names></name><name name-style="western"><surname>Karwowski</surname><given-names>W.</given-names></name></person-group><article-title>A Graph Theory-Based Modeling of Functional Brain Connectivity Based on EEG: A Systematic Review in the Context of Neuroergonomics</article-title><source>IEEE Access</source><year>2020</year><volume>8</volume><fpage>155103</fpage><lpage>155135</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2020.3018995</pub-id></element-citation></ref><ref id="B24-sensors-25-05515"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Babayan</surname><given-names>A.</given-names></name><name name-style="western"><surname>Erbey</surname><given-names>M.</given-names></name><name name-style="western"><surname>Kumral</surname><given-names>D.</given-names></name><name name-style="western"><surname>Reinelt</surname><given-names>J.D.</given-names></name><name name-style="western"><surname>Reiter</surname><given-names>A.M.F.</given-names></name><name name-style="western"><surname>R&#246;bbig</surname><given-names>J.</given-names></name><name name-style="western"><surname>Schaare</surname><given-names>H.L.</given-names></name><name name-style="western"><surname>Uhlig</surname><given-names>M.</given-names></name><name name-style="western"><surname>Anwander</surname><given-names>A.</given-names></name><name name-style="western"><surname>Bazin</surname><given-names>P.-L.</given-names></name><etal/></person-group><article-title>A Mind-Brain-Body Dataset of MRI, EEG, Cognition, Emotion, and Peripheral Physiology in Young and Old Adults</article-title><source>Sci. Data</source><year>2019</year><volume>6</volume><fpage>180308</fpage><pub-id pub-id-type="doi">10.1038/sdata.2018.308</pub-id><pub-id pub-id-type="pmid">30747911</pub-id><pub-id pub-id-type="pmcid">PMC6371893</pub-id></element-citation></ref><ref id="B25-sensors-25-05515"><label>25.</label><element-citation publication-type="webpage"><article-title>Toronto-Alexithymie-Skala-26</article-title><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.hogrefe.com/at/shop/toronto-alexithymie-skala-26.html" ext-link-type="uri">https://www.hogrefe.com/at/shop/toronto-alexithymie-skala-26.html</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-02-27">(accessed on 27 February 2025)</date-in-citation></element-citation></ref><ref id="B26-sensors-25-05515"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bagby</surname><given-names>R.M.</given-names></name><name name-style="western"><surname>Parker</surname><given-names>J.D.</given-names></name><name name-style="western"><surname>Taylor</surname><given-names>G.J.</given-names></name></person-group><article-title>The Twenty-Item Toronto Alexithymia Scale--I. Item Selection and Cross-Validation of the Factor Structure</article-title><source>J. Psychosom. Res.</source><year>1994</year><volume>38</volume><fpage>23</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1016/0022-3999(94)90005-1</pub-id><pub-id pub-id-type="pmid">8126686</pub-id></element-citation></ref><ref id="B27-sensors-25-05515"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pascual-Marqui</surname><given-names>R.D.</given-names></name><name name-style="western"><surname>Lehmann</surname><given-names>D.</given-names></name><name name-style="western"><surname>Koukkou</surname><given-names>M.</given-names></name><name name-style="western"><surname>Kochi</surname><given-names>K.</given-names></name><name name-style="western"><surname>Anderer</surname><given-names>P.</given-names></name><name name-style="western"><surname>Saletu</surname><given-names>B.</given-names></name><name name-style="western"><surname>Tanaka</surname><given-names>H.</given-names></name><name name-style="western"><surname>Hirata</surname><given-names>K.</given-names></name><name name-style="western"><surname>John</surname><given-names>E.R.</given-names></name><name name-style="western"><surname>Prichep</surname><given-names>L.</given-names></name><etal/></person-group><article-title>Assessing Interactions in the Brain with Exact Low-Resolution Electromagnetic Tomography</article-title><source>Philos. Transactions. Ser. A Math. Phys. Eng. Sci.</source><year>2011</year><volume>369</volume><fpage>3768</fpage><lpage>3784</lpage><pub-id pub-id-type="doi">10.1098/rsta.2011.0081</pub-id><pub-id pub-id-type="pmid">21893527</pub-id></element-citation></ref><ref id="B28-sensors-25-05515"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jatoi</surname><given-names>M.A.</given-names></name><name name-style="western"><surname>Kamel</surname><given-names>N.</given-names></name><name name-style="western"><surname>Malik</surname><given-names>A.S.</given-names></name><name name-style="western"><surname>Faye</surname><given-names>I.</given-names></name></person-group><article-title>EEG Based Brain Source Localization Comparison of SLORETA and ELORETA</article-title><source>Australas. Phys. Eng. Sci. Med.</source><year>2014</year><volume>37</volume><fpage>713</fpage><lpage>721</lpage><pub-id pub-id-type="doi">10.1007/s13246-014-0308-3</pub-id><pub-id pub-id-type="pmid">25359588</pub-id></element-citation></ref><ref id="B29-sensors-25-05515"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gramfort</surname><given-names>A.</given-names></name><name name-style="western"><surname>Luessi</surname><given-names>M.</given-names></name><name name-style="western"><surname>Larson</surname><given-names>E.</given-names></name><name name-style="western"><surname>Engemann</surname><given-names>D.A.</given-names></name><name name-style="western"><surname>Strohmeier</surname><given-names>D.</given-names></name><name name-style="western"><surname>Brodbeck</surname><given-names>C.</given-names></name><name name-style="western"><surname>Goj</surname><given-names>R.</given-names></name><name name-style="western"><surname>Jas</surname><given-names>M.</given-names></name><name name-style="western"><surname>Brooks</surname><given-names>T.</given-names></name><name name-style="western"><surname>Parkkonen</surname><given-names>L.</given-names></name><etal/></person-group><article-title>MEG and EEG Data Analysis with MNE-Python</article-title><source>Front. Neurosci.</source><year>2013</year><volume>7</volume><elocation-id>267</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2013.00267</pub-id><pub-id pub-id-type="pmid">24431986</pub-id><pub-id pub-id-type="pmcid">PMC3872725</pub-id></element-citation></ref><ref id="B30-sensors-25-05515"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vinck</surname><given-names>M.</given-names></name><name name-style="western"><surname>Oostenveld</surname><given-names>R.</given-names></name><name name-style="western"><surname>van Wingerden</surname><given-names>M.</given-names></name><name name-style="western"><surname>Battaglia</surname><given-names>F.</given-names></name><name name-style="western"><surname>Pennartz</surname><given-names>C.M.A.</given-names></name></person-group><article-title>An Improved Index of Phase-Synchronization for Electrophysiological Data in the Presence of Volume-Conduction, Noise and Sample-Size Bias</article-title><source>Neuroimage</source><year>2011</year><volume>55</volume><fpage>1548</fpage><lpage>1565</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.01.055</pub-id><pub-id pub-id-type="pmid">21276857</pub-id></element-citation></ref><ref id="B31-sensors-25-05515"><label>31.</label><element-citation publication-type="webpage"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>A.</given-names></name><name name-style="western"><surname>McCloy</surname><given-names>D.</given-names></name><name name-style="western"><surname>Larson</surname><given-names>E.</given-names></name><name name-style="western"><surname>Westner</surname><given-names>B.</given-names></name><name name-style="western"><surname>Kroner</surname><given-names>A.</given-names></name><name name-style="western"><surname>Gramfort</surname><given-names>A.</given-names></name><name name-style="western"><surname>Binns</surname><given-names>T.S.</given-names></name><name name-style="western"><surname>Orabe</surname><given-names>M.</given-names></name></person-group><article-title>Mne-Connectivity</article-title><year>2024</year><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/mne-tools/mne-connectivity" ext-link-type="uri">https://github.com/mne-tools/mne-connectivity</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-07-25">(accessed on 25 July 2025)</date-in-citation></element-citation></ref><ref id="B32-sensors-25-05515"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bagby</surname><given-names>R.M.</given-names></name><name name-style="western"><surname>Parker</surname><given-names>J.D.A.</given-names></name><name name-style="western"><surname>Taylor</surname><given-names>G.J.</given-names></name></person-group><article-title>Twenty-Five Years with the 20-Item Toronto Alexithymia Scale</article-title><source>J. Psychosom. Res.</source><year>2020</year><volume>131</volume><fpage>109940</fpage><pub-id pub-id-type="doi">10.1016/j.jpsychores.2020.109940</pub-id><pub-id pub-id-type="pmid">32007790</pub-id></element-citation></ref><ref id="B33-sensors-25-05515"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pedregosa</surname><given-names>F.</given-names></name><name name-style="western"><surname>Varoquaux</surname><given-names>G.</given-names></name><name name-style="western"><surname>Gramfort</surname><given-names>A.</given-names></name><name name-style="western"><surname>Michel</surname><given-names>V.</given-names></name><name name-style="western"><surname>Thirion</surname><given-names>B.</given-names></name><name name-style="western"><surname>Grisel</surname><given-names>O.</given-names></name><name name-style="western"><surname>Blondel</surname><given-names>M.</given-names></name><name name-style="western"><surname>Prettenhofer</surname><given-names>P.</given-names></name><name name-style="western"><surname>Weiss</surname><given-names>R.</given-names></name><name name-style="western"><surname>Dubourg</surname><given-names>V.</given-names></name><etal/></person-group><article-title>Scikit-Learn: Machine Learning in PYthon</article-title><source>J. Mach. Learn. Res.</source><year>2011</year><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="B34-sensors-25-05515"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Galli</surname><given-names>S.</given-names></name></person-group><article-title>Feature-Engine: A Python Package for Feature Engineering for Machine Learning</article-title><source>J. Open Source Softw.</source><year>2021</year><volume>6</volume><fpage>3642</fpage><pub-id pub-id-type="doi">10.21105/joss.03642</pub-id></element-citation></ref><ref id="B35-sensors-25-05515"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Galar</surname><given-names>M.</given-names></name><name name-style="western"><surname>Fernandez</surname><given-names>A.</given-names></name><name name-style="western"><surname>Barrenechea</surname><given-names>E.</given-names></name><name name-style="western"><surname>Bustince</surname><given-names>H.</given-names></name><name name-style="western"><surname>Herrera</surname><given-names>F.</given-names></name></person-group><article-title>A Review on Ensembles for the Class Imbalance Problem: Bagging-, Boosting-, and Hybrid-Based Approaches</article-title><source>IEEE Trans. Syst. Man Cybern. C Appl. Rev.</source><year>2012</year><volume>42</volume><fpage>463</fpage><lpage>484</lpage><pub-id pub-id-type="doi">10.1109/TSMCC.2011.2161285</pub-id></element-citation></ref><ref id="B36-sensors-25-05515"><label>36.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Wallace</surname><given-names>B.C.</given-names></name><name name-style="western"><surname>Small</surname><given-names>K.</given-names></name><name name-style="western"><surname>Brodley</surname><given-names>C.E.</given-names></name><name name-style="western"><surname>Trikalinos</surname><given-names>T.A.</given-names></name></person-group><article-title>Class Imbalance, Redux</article-title><source>Proceedings of the 2011 IEEE 11th International Conference on Data Mining</source><conf-loc>Vancouver, BC, Canada</conf-loc><conf-date>11&#8211;14 December 2011</conf-date><fpage>754</fpage><lpage>763</lpage></element-citation></ref><ref id="B37-sensors-25-05515"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vuttipittayamongkol</surname><given-names>P.</given-names></name><name name-style="western"><surname>Elyan</surname><given-names>E.</given-names></name><name name-style="western"><surname>Petrovski</surname><given-names>A.</given-names></name></person-group><article-title>On the Class Overlap Problem in Imbalanced Data Classification</article-title><source>Knowl. Based Syst.</source><year>2021</year><volume>212</volume><fpage>106631</fpage><pub-id pub-id-type="doi">10.1016/j.knosys.2020.106631</pub-id></element-citation></ref><ref id="B38-sensors-25-05515"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lema&#238;tre</surname><given-names>G.</given-names></name><name name-style="western"><surname>Nogueira</surname><given-names>F.</given-names></name><name name-style="western"><surname>Aridas</surname><given-names>C.K.</given-names></name></person-group><article-title>Imbalanced-Learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning</article-title><source>J. Mach. Learn. Res.</source><year>2016</year><volume>18</volume><fpage>1</fpage><lpage>5</lpage></element-citation></ref><ref id="B39-sensors-25-05515"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fernandez</surname><given-names>A.</given-names></name><name name-style="western"><surname>Garcia</surname><given-names>S.</given-names></name><name name-style="western"><surname>Herrera</surname><given-names>F.</given-names></name><name name-style="western"><surname>Chawla</surname><given-names>N.V.</given-names></name></person-group><article-title>SMOTE for Learning from Imbalanced Data: Progress and Challenges, Marking the 15-Year Anniversary</article-title><source>J. Artif. Intell. Res.</source><year>2018</year><volume>61</volume><fpage>863</fpage><lpage>905</lpage><pub-id pub-id-type="doi">10.1613/jair.1.11192</pub-id></element-citation></ref><ref id="B40-sensors-25-05515"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zou</surname><given-names>H.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>H.H.</given-names></name></person-group><article-title>On the adaptive elastic-net with a diverging number of parameters</article-title><source>Ann. Stat.</source><year>2009</year><volume>37</volume><fpage>1733</fpage><lpage>1751</lpage><pub-id pub-id-type="doi">10.1214/08-AOS625</pub-id><pub-id pub-id-type="pmid">20445770</pub-id><pub-id pub-id-type="pmcid">PMC2864037</pub-id></element-citation></ref><ref id="B41-sensors-25-05515"><label>41.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hosseini</surname><given-names>M.-P.</given-names></name><name name-style="western"><surname>Hosseini</surname><given-names>A.</given-names></name><name name-style="western"><surname>Ahi</surname><given-names>K.</given-names></name></person-group><article-title>A Review on Machine Learning for EEG Signal Processing in Bioengineering</article-title><source>IEEE Rev. Biomed. Eng.</source><year>2021</year><volume>14</volume><fpage>204</fpage><lpage>218</lpage><pub-id pub-id-type="doi">10.1109/RBME.2020.2969915</pub-id><pub-id pub-id-type="pmid">32011262</pub-id></element-citation></ref><ref id="B42-sensors-25-05515"><label>42.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sarker</surname><given-names>I.H.</given-names></name></person-group><article-title>Machine Learning: Algorithms, Real-World Applications and Research Directions</article-title><source>SN Comput. Sci.</source><year>2021</year><volume>2</volume><fpage>160</fpage><pub-id pub-id-type="doi">10.1007/s42979-021-00592-x</pub-id><pub-id pub-id-type="pmid">33778771</pub-id><pub-id pub-id-type="pmcid">PMC7983091</pub-id></element-citation></ref><ref id="B43-sensors-25-05515"><label>43.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Akiba</surname><given-names>T.</given-names></name><name name-style="western"><surname>Sano</surname><given-names>S.</given-names></name><name name-style="western"><surname>Yanase</surname><given-names>T.</given-names></name><name name-style="western"><surname>Ohta</surname><given-names>T.</given-names></name><name name-style="western"><surname>Koyama</surname><given-names>M.</given-names></name></person-group><article-title>Optuna: A Next-Generation Hyperparameter Optimization Framework</article-title><source>Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</source><conf-loc>Anchorage, AK, USA</conf-loc><conf-date>4&#8211;8 August 2019</conf-date><publisher-name>Association for Computing Machinery</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>2019</year><fpage>2623</fpage><lpage>2631</lpage></element-citation></ref><ref id="B44-sensors-25-05515"><label>44.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hajian-Tilaki</surname><given-names>K.</given-names></name></person-group><article-title>Receiver Operating Characteristic (ROC) Curve Analysis for Medical Diagnostic Test Evaluation</article-title><source>Caspian J. Intern. Med.</source><year>2013</year><volume>4</volume><fpage>627</fpage><lpage>635</lpage><pub-id pub-id-type="pmid">24009950</pub-id><pub-id pub-id-type="pmcid">PMC3755824</pub-id></element-citation></ref><ref id="B45-sensors-25-05515"><label>45.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Ojala</surname><given-names>M.</given-names></name><name name-style="western"><surname>Garriga</surname><given-names>G.C.</given-names></name></person-group><article-title>Permutation Tests for Studying Classifier Performance</article-title><source>Proceedings of the 2009 Ninth IEEE International Conference on Data Mining</source><conf-loc>Miami Beach, FL, USA</conf-loc><conf-date>6&#8211;9 December 2009</conf-date><publisher-name>IEEE</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>2009</year><fpage>908</fpage><lpage>913</lpage></element-citation></ref><ref id="B46-sensors-25-05515"><label>46.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Combrisson</surname><given-names>E.</given-names></name><name name-style="western"><surname>Jerbi</surname><given-names>K.</given-names></name></person-group><article-title>Exceeding Chance Level by Chance: The Caveat of Theoretical Chance Levels in Brain Signal Classification and Statistical Assessment of Decoding Accuracy</article-title><source>J. Neurosci. Methods</source><year>2015</year><volume>250</volume><fpage>126</fpage><lpage>136</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2015.01.010</pub-id><pub-id pub-id-type="pmid">25596422</pub-id></element-citation></ref><ref id="B47-sensors-25-05515"><label>47.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chmiel</surname><given-names>J.</given-names></name><name name-style="western"><surname>Wia&#380;ewicz-W&#243;jtowicz</surname><given-names>P.</given-names></name><name name-style="western"><surname>St&#281;pie&#324;-S&#322;odkowska</surname><given-names>M.</given-names></name></person-group><article-title>Neural Correlates of Alexithymia Based on Electroencephalogram (EEG)&#8212;A Mechanistic Review</article-title><source>J. Clin. Med.</source><year>2025</year><volume>14</volume><elocation-id>1895</elocation-id><pub-id pub-id-type="doi">10.3390/jcm14061895</pub-id><pub-id pub-id-type="pmid">40142703</pub-id><pub-id pub-id-type="pmcid">PMC11943194</pub-id></element-citation></ref><ref id="B48-sensors-25-05515"><label>48.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Goerlich-Dobre</surname><given-names>K.S.</given-names></name><name name-style="western"><surname>Votinov</surname><given-names>M.</given-names></name><name name-style="western"><surname>Habel</surname><given-names>U.</given-names></name><name name-style="western"><surname>Pripfl</surname><given-names>J.</given-names></name><name name-style="western"><surname>Lamm</surname><given-names>C.</given-names></name></person-group><article-title>Neuroanatomical Profiles of Alexithymia Dimensions and Subtypes: Structural Correlates of Alexithymia Subtypes</article-title><source>Hum. Brain Mapp.</source><year>2015</year><volume>36</volume><fpage>3805</fpage><lpage>3818</lpage><pub-id pub-id-type="doi">10.1002/hbm.22879</pub-id><pub-id pub-id-type="pmid">26094609</pub-id><pub-id pub-id-type="pmcid">PMC6869665</pub-id></element-citation></ref><ref id="B49-sensors-25-05515"><label>49.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Matsumoto</surname><given-names>A.</given-names></name><name name-style="western"><surname>Ichikawa</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Kanayama</surname><given-names>N.</given-names></name><name name-style="western"><surname>Ohira</surname><given-names>H.</given-names></name><name name-style="western"><surname>Iidaka</surname><given-names>T.</given-names></name></person-group><article-title>Gamma Band Activity and Its Synchronization Reflect the Dysfunctional Emotional Processing in Alexithymic Persons</article-title><source>Psychophysiology</source><year>2006</year><volume>43</volume><fpage>533</fpage><lpage>540</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2006.00461.x</pub-id><pub-id pub-id-type="pmid">17076809</pub-id></element-citation></ref><ref id="B50-sensors-25-05515"><label>50.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Baenninger</surname><given-names>A.</given-names></name><name name-style="western"><surname>Palzes</surname><given-names>V.A.</given-names></name><name name-style="western"><surname>Roach</surname><given-names>B.J.</given-names></name><name name-style="western"><surname>Mathalon</surname><given-names>D.H.</given-names></name><name name-style="western"><surname>Ford</surname><given-names>J.M.</given-names></name><name name-style="western"><surname>Koenig</surname><given-names>T.</given-names></name></person-group><article-title>Abnormal Coupling between Default Mode Network and Delta and Beta Band Brain Electric Activity in Psychotic Patients</article-title><source>Brain Connect.</source><year>2017</year><volume>7</volume><fpage>34</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.1089/brain.2016.0456</pub-id><pub-id pub-id-type="pmid">27897031</pub-id><pub-id pub-id-type="pmcid">PMC5312599</pub-id></element-citation></ref><ref id="B51-sensors-25-05515"><label>51.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Aftanas</surname><given-names>L.I.</given-names></name><name name-style="western"><surname>Varlamov</surname><given-names>A.A.</given-names></name><name name-style="western"><surname>Reva</surname><given-names>N.V.</given-names></name><name name-style="western"><surname>Pavlov</surname><given-names>S.V.</given-names></name></person-group><article-title>Disruption of Early Event-Related Theta Synchronization of Human EEG in Alexithymics Viewing Affective Pictures</article-title><source>Neurosci. Lett.</source><year>2003</year><volume>340</volume><fpage>57</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1016/S0304-3940(03)00070-3</pub-id><pub-id pub-id-type="pmid">12648758</pub-id></element-citation></ref><ref id="B52-sensors-25-05515"><label>52.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Aftanas</surname><given-names>L.I.</given-names></name><name name-style="western"><surname>Varlamov</surname><given-names>A.A.</given-names></name></person-group><article-title>Effects of Alexithymia on the Activity of the Anterior and Posterior Areas of the Cortex of the Right Hemisphere in Positive and Negative Emotional Activation</article-title><source>Neurosci. Behav. Physiol.</source><year>2007</year><volume>37</volume><fpage>67</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1007/s11055-007-0151-z</pub-id><pub-id pub-id-type="pmid">17180321</pub-id></element-citation></ref></ref-list></back><floats-group><table-wrap position="float" id="sensors-25-05515-t001" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05515-t001_Table 1</object-id><label>Table 1</label><caption><p>ROI.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Index</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">MNI Coordinates</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Anatomical Region</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">x</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">y</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">z</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;30</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">40</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">25</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Left Frontal Lobe</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">20</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">35</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">30</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Right Frontal Lobe</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;45</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;15</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;25</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Left Temporal Lobe</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">55</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;15</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;20</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Right Temporal Lobe</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">35</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Left Posterior Cingulate Cortex</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;10</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">30</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Right Posterior Cingulate Cortex</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">30</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">20</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Left Anterior Cingulate Cortex</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">30</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">20</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Right Anterior Cingulate Cortex</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;55</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">25</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Left Hippocampus</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;50</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">25</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Right Hippocampus</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;45</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;50</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">40</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Left Parietal Lobe</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">45</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;50</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">35</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Right Parietal Lobe</td></tr></tbody></table><table-wrap-foot><fn><p>MNI = Montreal Neurological Institute. Note: The MNI coordinates and anatomical region are based on [<xref rid="B22-sensors-25-05515" ref-type="bibr">22</xref>].</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-05515-t002" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05515-t002_Table 2</object-id><label>Table 2</label><caption><p>Frequency bands.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Names of Frequency Bands</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Frequency Bands (Hz)</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Delta</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1&#8211;3</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Theta</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4&#8211;7</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Alpha</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8&#8211;12</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Beta</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13&#8211;30</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Gamma</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">31&#8211;45</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1&#8211;30 Hz <sup>1</sup></td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1&#8211;30</td></tr></tbody></table><table-wrap-foot><fn><p><sup>1</sup> The 1&#8211;30 Hz range represents a broad frequency band, distinct from other subdivided bands such as delta, theta, alpha, and beta.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-05515-t003" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05515-t003_Table 3</object-id><label>Table 3</label><caption><p>Tuned parameters.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Models</th><th align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Hyperparameters <sup>1</sup></th></tr></thead><tbody><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">LR</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">C, l1_ratio</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">LR UB</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">C, l1_ratio, n_estimators</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SVM C (linear)</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">C</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SVM C (linear) UB</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">C, n_estimators</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SVM C (RBF)</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">C, gamma</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RF C</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features</td></tr></tbody></table><table-wrap-foot><fn><p>LR = logistic regression; LR UB = logistic regression models applied under sampling and bagging; SVM C (linear) = support vector machine for classification with a linear kernel; SVM C (linear) UB = support vector machine for classification models with liner a linear kernel applied under sampling and bagging; SVM C (RBF) = support vector machine for classification with a radial basis function kernel; RF C = random forest for classification. <sup>1</sup> Hyperparameters column represents parameter names in Scikit-learn [<xref rid="B33-sensors-25-05515" ref-type="bibr">33</xref>].</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-05515-t004" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05515-t004_Table 4</object-id><label>Table 4</label><caption><p>Performance of the classification models.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Threshold <sup>1</sup></th><th colspan="6" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Classification Model <sup>2</sup></th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">LR</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">LR <break/>UB</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SVM C<break/>(Linear)</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SVM C<break/>(Linear) <break/>UB</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SVM C<break/>(RBF)</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RF C</th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">20%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.64</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.70</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.63</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.67</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.60</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.59</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">30%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.60</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.65</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.54</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.64</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.61</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.65</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">40%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.48</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.52</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.44</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.54</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.48</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.49</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">50%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.53</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.54</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.52</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.55</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.49</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.54</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">60%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.61</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.54</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.58</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.57</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.42</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.50</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">70%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.56</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.62</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.66</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.66</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.56</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.43</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">80%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.56</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.49</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.52</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.55</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.50</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.55</td></tr></tbody></table><table-wrap-foot><fn><p>LR = logistic regression; LR UB = logistic regression models applied under sampling and bagging; SVM C (linear) = support vector machine for classification with a linear kernel; SVM C (linear) UB = support vector machine for classification models with liner a linear kernel applied under sampling and bagging; SVM C (RBF) = support vector machine for classification with a radial basis function kernel; RF C = random forest for classification. <sup>1</sup> The values in this column represent the percentile thresholds used to define low and high levels of alexithymia, as detailed in <xref rid="sec2dot7-sensors-25-05515" ref-type="sec">Section 2.7</xref>. <sup>2</sup> The values in these columns represent the ROC-AUC scores for the corresponding model and threshold. The ROC-AUC score ranges from 0 to 1. A value of 0 indicates that all classifications are incorrect, 0.5 indicates performance equivalent to random chance, and 1 indicates all classifications are correct [<xref rid="B44-sensors-25-05515" ref-type="bibr">44</xref>].</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-05515-t005" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05515-t005_Table 5</object-id><label>Table 5</label><caption><p>Results of permutation test.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Threshold&#160;<sup>1</sup></th><th colspan="6" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Classification Model <sup>2</sup></th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">LR</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">LR <break/>UB</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SVM C<break/>(Linear)</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SVM C<break/>(Linear)<break/>UB</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">SVM C<break/>(RBF)</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">RF C</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sum <sup>3</sup></th></tr></thead><tbody><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">20%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">30%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">40%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">50%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">60%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">70%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">80%</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Sum <sup>3</sup></td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">30</td></tr></tbody></table><table-wrap-foot><fn><p>LR = logistic regression; LR UB = logistic regression models applied under sampling and bagging; SVM C (linear) = support vector machine for classification with a linear kernel; SVM C (linear) UB = support vector machine for classification models with liner a linear kernel applied under sampling and bagging; SVM C (RBF) = support vector machine for classification with a radial basis function kernel; RF C = random forest for classification. <sup>1</sup> The values in this column represent the percentile thresholds used to define low and high levels of alexithymia, as detailed in <xref rid="sec2dot7-sensors-25-05515" ref-type="sec">Section 2.7</xref>. <sup>2</sup> The values in these columns represent the number of times the model performance was found to be significantly higher than the chance level. Statistical significance was determined by a permutation test with a significance level of 0.05. This performance was evaluated five times using cross-validation. Therefore, the values range from 0 to 5. A higher value indicates that models with statistically significant performance were more consistently constructed. The detail of the methodology is described in <xref rid="sec2dot12-sensors-25-05515" ref-type="sec">Section 2.12</xref>. <sup>3</sup> The values in this column or row represent the corresponding total.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-05515-t006" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05515-t006_Table 6</object-id><label>Table 6</label><caption><p>ROI importance in classification at a 30% threshold.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">ROI</th><th colspan="3" align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Counts of Top <italic toggle="yes">n</italic>% of Feature (<italic toggle="yes">n</italic> = 10, 30, 50) <sup>1</sup></th></tr><tr><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10%</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">30% </th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">50%</th></tr></thead><tbody><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Left Frontal Lobe</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Right Frontal Lobe</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Left Temporal Lobe</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Right Temporal Lobe</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Left Posterior Cingulate Cortex</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Right Posterior Cingulate Cortex</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Left Anterior Cingulate Cortex</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Right Anterior Cingulate Cortex</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Left Hippocampus</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Right Hippocampus</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Left Parietal Lobe</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">13</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Right Parietal Lobe</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14</td></tr></tbody></table><table-wrap-foot><fn><p>ROI = Regions of Interest. <sup>1</sup> The values in these columns represent the importance of each ROI, where a higher value indicates a more influential ROI. These importance values were calculated through the following procedure: (1) Evaluate the contribution of each feature using permutation feature importance. (2) Select the top <inline-formula><mml:math id="mm4" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>% of features based on their permutation feature importance. (3) Count the number of ROI corresponding to these selected features. (4) Repeat steps 3&#8211;4, varying <italic toggle="yes">n</italic> at 10, 30, and 50. The methodology is described in detail in <xref rid="sec2dot13-sensors-25-05515" ref-type="sec">Section 2.13</xref>.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-05515-t007" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05515-t007_Table 7</object-id><label>Table 7</label><caption><p>Frequency band importance in classification at a 30% threshold.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Frequency Band</th><th colspan="3" align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Counts of Top <italic toggle="yes">n</italic>% of Feature (<italic toggle="yes">n</italic> = 10, 30, 50) 1</th></tr><tr><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10%</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">30%</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">50%</th></tr></thead><tbody><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">delta</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">16</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">20</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">theta</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">alpha</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">18</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">20</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">beta</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">16</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">18</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">gamma</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">24</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">32</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1&#8211;30 Hz <sup>2</sup></td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">16</td></tr></tbody></table><table-wrap-foot><fn><p><sup>1</sup> The values in these columns represent the importance of each frequency band, where a higher value indicates a more influential frequency band. These importance values were calculated through the following procedure: (1) Evaluate the contribution of each feature using permutation feature importance. (2) Select the top <inline-formula><mml:math id="mm5" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>% of features based on their permutation feature importance. (3) Count the number of frequency bands corresponding to these selected features. (4) Repeat steps 3&#8211;4, varying <italic toggle="yes">n</italic> at 10, 30, and 50. The methodology is described in detail in <xref rid="sec2dot13-sensors-25-05515" ref-type="sec">Section 2.13</xref>. <sup>2</sup> The 1&#8211;30 Hz range represents a broad frequency band, distinct from other subdivided bands such as delta, theta, alpha, and beta.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-05515-t008" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05515-t008_Table 8</object-id><label>Table 8</label><caption><p>ROI importance in classification at a 70% threshold.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">ROI</th><th colspan="3" align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Counts of Top <italic toggle="yes">n</italic>% of Feature (<italic toggle="yes">n</italic> = 10, 30, 50) <sup>1</sup></th></tr><tr><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10%</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">30%</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">50%</th></tr></thead><tbody><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Left Frontal Lobe</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Right Frontal Lobe</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Left Temporal Lobe</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Right Temporal Lobe</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Left Posterior Cingulate Cortex</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Right Posterior Cingulate Cortex</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Left Anterior Cingulate Cortex</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Right Anterior Cingulate Cortex</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Left Hippocampus</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Right Hippocampus</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Left Parietal Lobe</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Right Parietal Lobe</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</td></tr></tbody></table><table-wrap-foot><fn><p>ROI = Regions of Interest. <sup>1</sup> The values in these columns represent the importance of each ROI, where a higher value indicates a more influential ROI. These importance values were calculated through the following procedure: (1) Evaluate the contribution of each feature using permutation feature importance. (2) Select the top <inline-formula><mml:math id="mm6" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>% of features based on their permutation feature importance. (3) Count the number of ROI corresponding to these selected features. (4) Repeat steps 3&#8211;4, varying <italic toggle="yes">n</italic> at 10, 30, and 50. The methodology is described in detail in <xref rid="sec2dot13-sensors-25-05515" ref-type="sec">Section 2.13</xref>.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-05515-t009" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05515-t009_Table 9</object-id><label>Table 9</label><caption><p>Frequency band importance in classification at a 70% threshold.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Frequency Band</th><th colspan="3" align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Counts of Top <italic toggle="yes">n</italic>% of Feature (<italic toggle="yes">n</italic> = 10, 30, 50) <sup>1</sup></th></tr><tr><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10%</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">30%</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">50%</th></tr></thead><tbody><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">delta</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">theta</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">18</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">22</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">alpha</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">18</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">28</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">beta</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">16</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">gamma</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">16</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1&#8211;30 Hz <sup>2</sup></td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td></tr></tbody></table><table-wrap-foot><fn><p><sup>1</sup> The values in these columns represent the importance of each frequency band, where a higher value indicates a more influential frequency band. These importance values were calculated through the following procedure: (1) Evaluate the contribution of each feature using permutation feature importance. (2) Select the top <inline-formula><mml:math id="mm7" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>% of features based on their permutation feature importance. (3) Count the number of frequency bands corresponding to these selected features. (4) Repeat steps 3&#8211;4, varying <italic toggle="yes">n</italic> at 10, 30, and 50. The methodology is described in detail in <xref rid="sec2dot13-sensors-25-05515" ref-type="sec">Section 2.13</xref>. <sup>2</sup> The 1&#8211;30 Hz range represents a broad frequency band, distinct from other subdivided bands such as delta, theta, alpha, and beta.</p></fn></table-wrap-foot></table-wrap></floats-group></article></pmc-articleset>