<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xml:lang="en" article-type="research-article" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Int J Surg</journal-id><journal-id journal-id-type="iso-abbrev">Int J Surg</journal-id><journal-id journal-id-type="pmc-domain-id">2035</journal-id><journal-id journal-id-type="pmc-domain">lwwopen</journal-id><journal-id journal-id-type="publisher-id">JS9</journal-id><journal-title-group><journal-title>International Journal of Surgery (London, England)</journal-title></journal-title-group><issn pub-type="ppub">1743-9191</issn><issn pub-type="epub">1743-9159</issn><custom-meta-group><custom-meta><meta-name>pmc-is-collection-domain</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-collection-title</meta-name><meta-value>Lippincott Open Access</meta-value></custom-meta></custom-meta-group></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12430758</article-id><article-id pub-id-type="pmcid-ver">PMC12430758.1</article-id><article-id pub-id-type="pmcaid">12430758</article-id><article-id pub-id-type="pmcaiid">12430758</article-id><article-id pub-id-type="pmid">40540436</article-id><article-id pub-id-type="doi">10.1097/JS9.0000000000002694</article-id><article-id pub-id-type="publisher-id">IJS-D-25-02209</article-id><article-version-alternatives><article-version article-version-type="pmc-version">1</article-version><article-version vocab="JAV" vocab-identifier="http://www.niso.org/publications/rp/RP-8-2008.pdf" article-version-type="Version of Record">3</article-version></article-version-alternatives><article-categories><subj-group subj-group-type="heading"><subject>Correspondence</subject></subj-group></article-categories><title-group><article-title>Large language models (LLMs) might be the future research language of nucleic acid</article-title></title-group><contrib-group><contrib contrib-type="author"><name name-style="western"><surname>Chakraborty</surname><given-names initials="C">Chiranjib</given-names></name><degrees>MSc, PhD</degrees><email>drchiranjib@yahoo.com</email><xref rid="aff1" ref-type="aff">
<sup>a</sup>
</xref><xref rid="COR0001" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Bhattacharya</surname><given-names initials="M">Manojit</given-names></name><degrees>MSc, PhD</degrees><email>mbhattacharya09@gmail.com</email><xref rid="aff2" ref-type="aff">
<sup>b</sup>
</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Das</surname><given-names initials="A">Arpita</given-names></name><degrees>MSc, PhD</degrees><email>arpita-84das@yahoo.co.in</email><xref rid="aff1" ref-type="aff">
<sup>a</sup>
</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-1091-9726</contrib-id><name name-style="western"><surname>Islam</surname><given-names initials="MA">Md. Aminul</given-names></name><degrees>MSc</degrees><email>aminulmbg@gmail.com</email><xref rid="aff3" ref-type="aff">
<sup>c</sup>
</xref><xref rid="aff4" ref-type="aff">
<sup>d</sup>
</xref><xref rid="COR0001" ref-type="corresp">*</xref></contrib><aff id="aff1"><label>a</label>Department of Biotechnology, School of Life Science and Biotechnology, Adamas University, Kolkata, West Bengal, India</aff><aff id="aff2"><label>b</label>Department of Zoology, Fakir Mohan University, Vyasa Vihar, Balasore, Odisha, India</aff><aff id="aff3"><label>c</label>COVID-19 Diagnostic Lab, Department of Microbiology, Noakhali Science and Technology University, Noakhali, Bangladesh</aff><aff id="aff4"><label>d</label>Advanced Molecular Lab, Department of Microbiology, President Abdul Hamid Medical College, Karimganj, Kishoreganj, Bangladesh</aff></contrib-group><author-notes><corresp id="COR0001"><label>*</label>Corresponding authors. Address: COVID-19 Diagnostic Lab, Department of Microbiology, Noakhali Science and Technology University, Noakhali 3814, Bangladesh. E-mail: <email>aminulmbg@gmail.com</email> (M. A. Islam); Department of Biotechnology, School of Life Science and Biotechnology, Adamas University, Kolkata, West Bengal 700126, India. Tel.: +91-9871608125. E-mail: <email>drchiranjib@yahoo.com</email> (C. Chakraborty).</corresp></author-notes><pub-date pub-type="collection"><month>9</month><year>2025</year></pub-date><pub-date pub-type="epub"><day>20</day><month>6</month><year>2025</year></pub-date><volume>111</volume><issue>9</issue><issue-id pub-id-type="pmc-issue-id">496813</issue-id><fpage>6534</fpage><lpage>6536</lpage><history><date date-type="received"><day>07</day><month>5</month><year>2025</year></date><date date-type="accepted"><day>29</day><month>5</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>12</day><month>09</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>13</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-13 17:25:36.317"><day>13</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>Copyright &#169; 2025 The Author(s). Published by Wolters Kluwer Health, Inc.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License 4.0</ext-link> (CCBY), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="js9-111-6534.pdf"/><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="js9-111-6534.pdf"/><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>OPEN-ACCESS</meta-name><meta-value>TRUE</meta-value></custom-meta></custom-meta-group></article-meta></front><body><p><italic toggle="yes">Dear Editor</italic>,</p><p>Artificial intelligence (AI) presents immense opportunities for solving the complex problems of different fields, including the biological sciences. Different complex tasks can be performed using the amalgamation of automation and AI, and it can even exceed human performance. That is why the use of AI is increasing steadily. On the other hand, when working with AI, transparency is essential during reporting. In this direction, a recent article published by Agha <italic toggle="yes">et al</italic> illustrated the transparency benchmarks for reporting AI and listed those benchmarks<sup>[<xref rid="R1" ref-type="bibr">1</xref>]</sup>. Similarly, Haibe-Kains <italic toggle="yes">et al</italic> discussed the reproducibility and transparency of AI<sup>[<xref rid="R2" ref-type="bibr">2</xref>]</sup>. However, both articles highlighted two vital topics: transparent and reproducible AI research. Therefore, both articles are significant and timely.</p><p>Large language models (LLMs), a subset of AI, have recently gained massive attention worldwide following the release of ChatGPT on 30 November 2022, in San Francisco, USA. This model is a free online version 3.5 of the GPT-3 (Generative Pretrained Transformer 3) series. The model has emerged as the fastest-growing tool globally. Within 2 months after its launch, the number of users reached about 100 million<sup>[<xref rid="R3" ref-type="bibr">3</xref>]</sup>. The model is immensely used in different medical science spheres<sup>[<xref rid="R4" ref-type="bibr">4</xref>,<xref rid="R5" ref-type="bibr">5</xref>]</sup>. At the same time, it is also utilized in other fields, including drug discovery<sup>[<xref rid="R6" ref-type="bibr">6</xref>,<xref rid="R7" ref-type="bibr">7</xref>]</sup>, nucleic acid research<sup>[<xref rid="R8" ref-type="bibr">8</xref>]</sup>, biomedical engineering<sup>[<xref rid="R9" ref-type="bibr">9</xref>]</sup>, and law<sup>[<xref rid="R10" ref-type="bibr">10</xref>]</sup>. Due to the excessive use of LLMs, researchers anticipate that research in various fields, ranging from medical science to chemistry to law, will attain a new dimension. LLMs, such as GPT-4, specifically the series 4 model, can generate images and human-like text from any prompt<sup>[<xref rid="R11" ref-type="bibr">11</xref>]</sup>. LLMs can solve complex problems related to nucleic acids, and scientists have started exploring the use of LLMs in this area. CodonBERT, an LLM platform, can help to design and optimize mRNA. Recently, mRNA-based vaccines and therapeutics have emerged as highly effective molecules. Therefore, to design and optimize a stable mRNA, sequence optimization is necessary to produce low-cost, high-potency, and safe vaccines and therapeutics. CodonBERT helps develop an optimized mRNA sequence for mRNA-based vaccines and therapeutics<sup>[<xref rid="R12" ref-type="bibr">12</xref>]</sup>. Recently, another LLM platform, entitled LitSumm, was developed to help summarize the literature on ncRNAs (non-coding RNAs)<sup>[<xref rid="R13" ref-type="bibr">13</xref>]</sup>. Furthermore, Jorapur <italic toggle="yes">et al</italic> stated that LLMs can design primers for diagnostic PCR (polymerase chain reaction)<sup>[<xref rid="R14" ref-type="bibr">14</xref>]</sup>. LLMs are capable of answering questions and making accurate decisions. However, LLMs apply neural network architectures to function.</p><p>LLMs can take the text and image inputs. Subsequently, it provides the text outputs. It shows human-level performance in the academic arena and various other professional fields. GPT-4 can solve a broader range of problems compared to its predecessor. Therefore, scientists are excited to use the GPT-4 model. This LLM, specifically GPT-4, has created a next-generation platform for researchers known as the multimodal large language model (MLLM). OpenAI&#8217;s effort created a new milestone in the Chatbot landscape when it released GPT-4. Following its release, GPT-4 marks the beginning of a new era for AI-powered LLMs. For medical applications, Lee <italic toggle="yes">et al</italic> found that GPT-4 may be a powerful tool, providing valuable responses<sup>[<xref rid="R15" ref-type="bibr">15</xref>]</sup>. This powerful GPT-4 model generates marker gene-related material from the typical single-cell RNA-seq study<sup>[<xref rid="R16" ref-type="bibr">16</xref>]</sup>. It is an automated cell-type annotation method, which is cost-effective.</p><p>The traditional transformer model utilizes attention and self-attention mechanisms, enabling the model to capture information from preceding tokens. The GPT models use a transformer framework. However, these possess a remarkable generative pretraining method. Compared to traditional transformers, which rely on labeled datasets for training, GPTs utilize an enormous corpus of unlabeled data and possess task-specific fine-tuning features<sup>[<xref rid="R17" ref-type="bibr">17</xref>]</sup>. Different versions of the GPT models were introduced, and the third generation, i.e., GPT-3, utilizes a remarkably high number of tokens (0.3 trillion) and parameters (0.175 trillion) for training. Due to this magnitude of large numbers, fine-tuning is often not essential in various tasks. The advanced version, recently launched, is the fourth generation, specifically GPT-4. Brynjolfsson <italic toggle="yes">et al</italic> noted in their study that the GPT-4 utilizes around 13 trillion tokens and 1.8 trillion parameters for training<sup>[<xref rid="R18" ref-type="bibr">18</xref>]</sup>. A novel feature of GPT-4 compared to GPT-3 is that GPT-4 can generate images from input datasets. Other significant LLMs are Gemini 2.0, developed by Google DeepMind<sup>[<xref rid="R19" ref-type="bibr">19</xref>]</sup>, and DeepSeek<sup>[<xref rid="R20" ref-type="bibr">20</xref>]</sup>, developed by the Chinese-based company High-Flyer. These LLMs are now GenAI-based, significant analytical models in the domains of biological science and medical research, including nucleic acid analysis.</p><p>LLMs are now at the forefront of providing effective solutions in medical science, especially in education, clinical, and research-related solutions<sup>[<xref rid="R4" ref-type="bibr">4</xref>,<xref rid="R21" ref-type="bibr">21</xref>]</sup>. LLMs can provide solutions in different fields besides the medical domain. White has informed us that LLMs can provide solutions to different areas of chemistry. He described LLMs as potentially the future of chemistry, which will help initiate a new era of developments in the field<sup>[<xref rid="R22" ref-type="bibr">22</xref>]</sup>. Recently, Chatterjee <italic toggle="yes">et al</italic> demonstrated that LLMs aid in solving various nucleic acid research problems. They informed us that LLMs will revolutionize nucleic acid research<sup>[<xref rid="R8" ref-type="bibr">8</xref>]</sup>. LLMs are capable of transforming different areas of nucleic acid research. Genomic research has also been explored using LLMs. DNABERT, a nucleic acid domain-specific LLM, can aid in evaluating global and transferable genomic DNA sequences, considering the altered environments of upstream and downstream nucleotides. It has the potential to predict genome-wide regulatory elements and reveal their usage frequency<sup>[<xref rid="R23" ref-type="bibr">23</xref>]</sup>. Additionally, the DNABERT platform helps identify lncRNA from the assemblies of the plant genome. Using DNABERT, Danilevicz <italic toggle="yes">et al</italic> accurately predicted lncRNAs from genomic sequences, with the highest accuracy noted in <italic toggle="yes">Zea mays</italic> at 83.4%. Similarly, the lowest accuracy was noted in the <italic toggle="yes">Brassica rapa</italic> as 57.9%<sup>[<xref rid="R24" ref-type="bibr">24</xref>]</sup>. In another LLM study, Sultan <italic toggle="yes">et al</italic> analyzed the genes associated with cancer predisposition. They used a study involving 53 patients with pathogenic mutations (CPG mutations) and noted that Rb1 was the most commonly mutated gene in the cohort. Other predicted genes were VHL, NF1, and TP53. In this analysis, the predicted genes were 93% correct. However, they noted that LLM shows promise in predicting CPG mutations<sup>[<xref rid="R25" ref-type="bibr">25</xref>]</sup>. Recently, Elsborg and Salvatore analyzed biomarkers at the single-cell level to gain a deeper understanding of the disease landscape using LLMs and explainable machine learning (ML). They found the symbolic and straightforward nature of fetched gene signatures. It may enable researchers to elucidate the underlying molecular causes of diseases<sup>[<xref rid="R26" ref-type="bibr">26</xref>]</sup>. Similarly, a large-scale pre-trained deep language model tool has been developed to annotate the cell type of single-cell RNA-seq data. This model, named scBERT, can be fine-tuned to utilize supervised user-specific single-cell RNA-seq (scRNA-seq) data. The model validated its performance in terms of robustness to batch effects, novel cell type discovery, and cell type annotation, among others<sup>[<xref rid="R27" ref-type="bibr">27</xref>]</sup>. Yamada and Hamada developed a nucleotide language model using tokens similar to those employed in GPT models. Here, tokens are referred to as sequences of words or their particular nucleotide positions inside a sequence. Here, they also consider the k-mers of the sequence, which are the 3-mers and the 4-mer sequences. The following 3-mers were used: TAC, GTA, and CGT. Similarly, the 4-mers were used as GTAC, CGTA, and ACGT. Their nucleotide language model was used to predict RNA&#8211;protein interactions<sup>[<xref rid="R10" ref-type="bibr">10</xref>]</sup>. Zhang <italic toggle="yes">et al</italic> have developed an RNA language model that performs multiple sequence alignment, which is an unsupervised RNA-MSM (Multiple Sequence Alignment-Associated RNA Language Model). It can map direct base pairing information and also provide solvent accessibility knowledge<sup>[<xref rid="R28" ref-type="bibr">28</xref>]</sup>. Another significant problem in this research domain. Recently, Song <italic toggle="yes">et al</italic> developed GLMSite, which accurately identifies DNA- and RNA-binding sites using a geometric graph learning (GGL) model<sup>[<xref rid="R29" ref-type="bibr">29</xref>]</sup>. GGL is an ML-based method that uses graphs to analyze and represent data. On the other hand, protein language models (pLMs), a type of LLM, are among the significant deep learning (DL)-based models that utilize natural language processing (NLP) techniques to analyze and comprehend protein sequences. Similarly, using pLMs, Roche <italic toggle="yes">et al</italic> developed the EquiPNAS model for improved prediction of protein-nucleic acid binding sites. The model combines the strengths of symmetry-aware deep graph learning and pre-trained language models (PLMs)<sup>[<xref rid="R30" ref-type="bibr">30</xref>]</sup>. Therefore, nucleic acid research is progressing quickly to solve the diverse problems in this area. Recently, different DNA language models have been developed to comprehend the sequence context in the human genome. In this direction, a DNA language model, GROVER, has been developed to learn the context of the human genome sequence using next-k-mer prediction with Byte-Pair Encoding (BPE) and a tokenization-based model architecture. This model illustrates the DNA&#8217;s coding for proteins and transcripts<sup>[<xref rid="R31" ref-type="bibr">31</xref>]</sup>.</p><p>Recently, scientists have utilized LLMs to develop nucleic acid language models (NALMs), which can be trained using nucleic acid sequences, such as RNA or DNA. The NALMs are capable of comprehending and predicting the behavior of these biological molecules. In these NALMs, sequences are described as text and employ tokenization to split them down into smaller units, known as tokens. NALM is also referred to as a genomic language model (gLM)<sup>[<xref rid="R32" ref-type="bibr">32</xref>]</sup>.</p><p>Just like LLMs, NALMs aim to comprehend the meaning of sequences in terms of their structure and function. It will offer new possibilities for investigating problems in biological science and developing solutions to them, thereby bridging the gap between medical science and biological science<sup>[<xref rid="R32" ref-type="bibr">32</xref>]</sup>.</p><p>Different scientists are attempting to understand various aspects of nucleic acids through LLMs, NALMs, or gLMs. Most importantly, we understand the various crucial aspects of nucleic acids, including evaluation metrics, species specificity, nucleotide sequence interpretation, and the complexities of LLMs. However, the proper tokenization process in converting to DNA/RNA sequences is essential.</p><p>The state-of-the-art LLMs, such as GPT-4, Google DeepMind, and DeepSeek, have emerged as leaders in AI innovation in nucleic acid research. Conversely, several LLM-derived models are assisting in solving the critical problem of nucleic acid research by handling a massive amount of data in this domain. Overall, LLMs can potentially revolutionize nucleic acid research by training on large datasets that incorporate texts, images, and videos. It indicates that it will open up a promising avenue for nucleic acid research. However, the potential replacement of humans and pressing ethical issues are considerable concerns. At the same time, progress in scientific development must continue. In the future, LLMs are expected to continue improving and will be introduced as next-generation, upgraded models. The future research language of nucleic acids may depend on MLLMs. Therefore, it is time for researchers to rethink nucleic acid-related research experiments, tools, and experimental design. They should utilize advanced next-generation technologies and tools, such as LLM or MLLM, to make rapid progress in nucleic acid research.</p></body><back><fn-group><fn fn-type="other"><p>Sponsorships or competing interests that may be relevant to content are disclosed at the end of this article.</p></fn><fn fn-type="equal"><p>Published online 20 June 2025</p></fn></fn-group><sec><title>Ethical approval</title><p>None.</p></sec><sec><title>Consent</title><p>None.</p></sec><sec><title>Sources of funding</title><p>None.</p></sec><sec><title>Author contributions</title><p>C.C.: conceptualization, data curation, investigation, writing &#8211; original draft, writing &#8211; review &amp; editing; M.B., A.D., and A.I.: validation, formal analysis. All authors critically reviewed and approved the final version of the manuscript.</p></sec><sec sec-type="COI-statement"><title>Conflicts of interest disclosure</title><p>The authors declare no competing interests.</p></sec><sec><title>Research registration unique identifying number (UIN)</title><p>None.</p></sec><sec><title>Guarantor</title><p>Aminul Islam.</p></sec><sec><title>Provenance and peer review</title><p>Not commissioned, externally peer-reviewed.</p></sec><sec sec-type="data-availability"><title>Data availability statement</title><p>The authors confirm that the data supporting the findings of this study are available within the article.</p></sec><ref-list><title>References</title><ref id="R1"><label>[1]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Agha</surname><given-names>RA</given-names></name><name name-style="western"><surname>Mathew</surname><given-names>G</given-names></name><name name-style="western"><surname>Rashid</surname><given-names>R</given-names></name><etal/></person-group>. <article-title>Transparency in the reporting of artificial intelligence &#8211; the TITAN guideline</article-title>. <source>Prem J Sci</source><volume>2025</volume>;<volume>10</volume>:<fpage>100082</fpage>.</mixed-citation></ref><ref id="R2"><label>[2]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Haibe-Kains</surname><given-names>B</given-names></name><name name-style="western"><surname>Adam</surname><given-names>GA</given-names></name><name name-style="western"><surname>Hosny</surname><given-names>A</given-names></name><etal/></person-group>. <article-title>Transparency and reproducibility in artificial intelligence</article-title>. <source>Nature</source><year>2020</year>;<volume>586</volume>:<fpage>E14</fpage>&#8211;<lpage>E16</lpage>.<pub-id pub-id-type="pmid">33057217</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41586-020-2766-y</pub-id><pub-id pub-id-type="pmcid">PMC8144864</pub-id></mixed-citation></ref><ref id="R3"><label>[3]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Menon</surname><given-names>D</given-names></name><name name-style="western"><surname>Shilpa</surname><given-names>K</given-names></name></person-group>. <article-title>&#8220;Chatting with ChatGPT&#8221;: analyzing the factors influencing users&#8217; intention to use the OpenAI&#8217;s ChatGPT using the UTAUT model</article-title>. <source>Heliyon</source><year>2023</year>;<volume>9</volume>:<fpage>e20962</fpage>.<pub-id pub-id-type="pmid">37928033</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.heliyon.2023.e20962</pub-id><pub-id pub-id-type="pmcid">PMC10623159</pub-id></mixed-citation></ref><ref id="R4"><label>[4]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chatterjee</surname><given-names>S</given-names></name><name name-style="western"><surname>Bhattacharya</surname><given-names>M</given-names></name><name name-style="western"><surname>Pal</surname><given-names>S</given-names></name><name name-style="western"><surname>Lee</surname><given-names>SS</given-names></name><name name-style="western"><surname>Chakraborty</surname><given-names>C</given-names></name></person-group>. <article-title>ChatGPT and large language models in orthopedics: from education and surgery to research</article-title>. <source>J Exp Orthop</source><year>2023</year>;<volume>10</volume>:<fpage>128</fpage>.<pub-id pub-id-type="pmid">38038796</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1186/s40634-023-00700-1</pub-id><pub-id pub-id-type="pmcid">PMC10692045</pub-id></mixed-citation></ref><ref id="R5"><label>[5]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chakraborty</surname><given-names>C</given-names></name><name name-style="western"><surname>Pal</surname><given-names>S</given-names></name><name name-style="western"><surname>Bhattacharya</surname><given-names>M</given-names></name><name name-style="western"><surname>Islam</surname><given-names>MA</given-names></name></person-group>. <article-title>ChatGPT or LLMs can provide treatment suggestions for critical patients with antibiotic-resistant infections: a next-generation revolution for medical science?</article-title><source>Int J Surg</source><pub-id pub-id-type="doi" assigning-authority="pmc">10.1097/JS9.0000000000000987</pub-id><pub-id pub-id-type="pmcid">PMC10942188</pub-id><pub-id pub-id-type="pmid">38085845</pub-id></mixed-citation></ref><ref id="R6"><label>[6]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pal</surname><given-names>S</given-names></name><name name-style="western"><surname>Bhattacharya</surname><given-names>M</given-names></name><name name-style="western"><surname>Islam</surname><given-names>MA</given-names></name><name name-style="western"><surname>Chakraborty</surname><given-names>C</given-names></name></person-group>. <article-title>ChatGPT or LLM in next-generation drug discovery and development: pharmaceutical and biotechnology companies can make use of the artificial intelligence (AI)-based device for a faster way of drug discovery and development</article-title>. <source>Int J Surg</source><year>2023</year>;<volume>109</volume>:<fpage>4382</fpage>&#8211;<lpage>84</lpage>.<pub-id pub-id-type="pmid">37707542</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1097/JS9.0000000000000719</pub-id><pub-id pub-id-type="pmcid">PMC10720782</pub-id></mixed-citation></ref><ref id="R7"><label>[7]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chakraborty</surname><given-names>C</given-names></name><name name-style="western"><surname>Bhattacharya</surname><given-names>M</given-names></name><name name-style="western"><surname>Lee</surname><given-names>SS</given-names></name></person-group>. <article-title>Artificial intelligence enabled ChatGPT and large language models in drug target discovery, drug discovery, and development</article-title>. <source>Mol Ther Nucleic Acids</source><year>2023</year>;<volume>33</volume>:<fpage>866</fpage>&#8211;<lpage>68</lpage>.<pub-id pub-id-type="pmid">37680991</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.omtn.2023.08.009</pub-id><pub-id pub-id-type="pmcid">PMC10481150</pub-id></mixed-citation></ref><ref id="R8"><label>[8]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chatterjee</surname><given-names>S</given-names></name><name name-style="western"><surname>Bhattacharya</surname><given-names>M</given-names></name><name name-style="western"><surname>Lee</surname><given-names>SS</given-names></name><name name-style="western"><surname>Chakraborty</surname><given-names>C</given-names></name></person-group>. <article-title>Can artificial intelligence-strengthened ChatGPT or other large language models transform nucleic acid research?</article-title><source>Mol Ther Nucleic Acids</source><year>2023</year>;<volume>33</volume>:<fpage>205</fpage>&#8211;<lpage>07</lpage>.<pub-id pub-id-type="pmid">37727444</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.omtn.2023.06.019</pub-id><pub-id pub-id-type="pmcid">PMC10505907</pub-id></mixed-citation></ref><ref id="R9"><label>[9]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pal</surname><given-names>S</given-names></name><name name-style="western"><surname>Bhattacharya</surname><given-names>M</given-names></name><name name-style="western"><surname>Lee</surname><given-names>-S-S</given-names></name><name name-style="western"><surname>Chakraborty</surname><given-names>C</given-names></name></person-group>. <article-title>A domain-specific next-generation large language model (LLM) or ChatGPT is required for biomedical engineering and research</article-title>. <source>Ann Biomed Eng</source><year>2023</year>;<volume>52</volume>:<fpage>451</fpage>&#8211;<lpage>54</lpage>.<pub-id pub-id-type="pmid">37428337</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s10439-023-03306-x</pub-id></mixed-citation></ref><ref id="R10"><label>[10]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yamada</surname><given-names>K</given-names></name><name name-style="western"><surname>Hamada</surname><given-names>M</given-names></name><name name-style="western"><surname>Arighi</surname><given-names>C</given-names></name></person-group>. <article-title>Prediction of RNA-protein interactions using a nucleotide language model</article-title>. <source>Bioinform Adv</source><year>2022</year>;<volume>2</volume>:<fpage>vbac023</fpage>.<pub-id pub-id-type="pmid">36699410</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/bioadv/vbac023</pub-id><pub-id pub-id-type="pmcid">PMC9710633</pub-id></mixed-citation></ref><ref id="R11"><label>[11]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Graham</surname><given-names>F</given-names></name></person-group>. <article-title>Daily briefing: what scientists think of GPT-4, the new AI chatbot</article-title>. <source>Nature</source><year>2023</year>. doi:<pub-id pub-id-type="doi">10.1038/d41586-023-00839-y</pub-id>.<pub-id pub-id-type="pmid">36941419</pub-id></mixed-citation></ref><ref id="R12"><label>[12]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>S</given-names></name><name name-style="western"><surname>Moayedpour</surname><given-names>S</given-names></name><name name-style="western"><surname>Li</surname><given-names>R</given-names></name><etal/></person-group>. <article-title>CodonBERT: large language models for mRNA design and optimization</article-title>. <source>bioRxiv</source><year>2023</year>;<volume>2023</volume>:<fpage>09.09.556981</fpage>.</mixed-citation></ref><ref id="R13"><label>[13]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Green</surname><given-names>A</given-names></name><name name-style="western"><surname>Ribas</surname><given-names>CE</given-names></name><name name-style="western"><surname>Ontiveros-Palacios</surname><given-names>N</given-names></name><etal/></person-group>. <article-title>LitSumm: large language models for literature summarization of noncoding RNAs</article-title>. <comment>Database (Oxford)</comment>. <year>2025</year>;<volume>2025</volume>:<fpage>baaf006</fpage>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/database/baaf006</pub-id><pub-id pub-id-type="pmcid">PMC11833236</pub-id><pub-id pub-id-type="pmid">39908113</pub-id></mixed-citation></ref><ref id="R14"><label>[14]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jorapur</surname><given-names>S</given-names></name><name name-style="western"><surname>Srivastava</surname><given-names>A</given-names></name><name name-style="western"><surname>Kulkarni</surname><given-names>S</given-names></name></person-group>. <article-title>Evaluating the usefulness of a large language model as a wholesome tool for de novo polymerase chain reaction (PCR) primer design</article-title>. <source>Cureus</source><year>2023</year>;<volume>15</volume>:<fpage>e47711</fpage>.<pub-id pub-id-type="pmid">38021866</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.7759/cureus.47711</pub-id><pub-id pub-id-type="pmcid">PMC10676229</pub-id></mixed-citation></ref><ref id="R15"><label>[15]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lee</surname><given-names>P</given-names></name><name name-style="western"><surname>Bubeck</surname><given-names>S</given-names></name><name name-style="western"><surname>Benefits</surname><given-names>PJ</given-names></name><name name-style="western"><surname>Drazen</surname><given-names>JM</given-names></name><name name-style="western"><surname>Kohane</surname><given-names>IS</given-names></name><name name-style="western"><surname>Leong</surname><given-names>T-Y</given-names></name></person-group>. <article-title>Limits, and risks of GPT-4 as an AI chatbot for medicine</article-title>. <source>New Engl J Med</source><year>2023</year>;<volume>388</volume>:<fpage>1233</fpage>&#8211;<lpage>39</lpage>.<pub-id pub-id-type="pmid">36988602</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1056/NEJMsr2214184</pub-id></mixed-citation></ref><ref id="R16"><label>[16]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hou</surname><given-names>W</given-names></name><name name-style="western"><surname>Ji</surname><given-names>Z</given-names></name></person-group>. <article-title>Assessing GPT-4 for cell type annotation in single-cell RNA-seq analysis</article-title>. <source>Nat Methods</source><year>2024</year>;<volume>21</volume>:<fpage>1462</fpage>&#8211;<lpage>65</lpage>.<pub-id pub-id-type="pmid">38528186</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41592-024-02235-4</pub-id><pub-id pub-id-type="pmcid">PMC11310073</pub-id></mixed-citation></ref><ref id="R17"><label>[17]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>TT</given-names></name></person-group><source>GPT: Origin, Theory, Application, and Future. ASCS CIS498/EAS499 Project and Thesis</source>. <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.cis.upenn.edu/wp-content/uploads/2021/10/Tianzheng_Troy_Wang_CIS498EAS499_Submission.pdf" ext-link-type="uri">https://www.cis.upenn.edu/wp-content/uploads/2021/10/Tianzheng_Troy_Wang_CIS498EAS499_Submission.pdf</ext-link><publisher-name>University of Pennsylvania</publisher-name><publisher-loc>Philadelphia, PA, USA</publisher-loc>; <year>2021</year>.</mixed-citation></ref><ref id="R18"><label>[18]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Brynjolfsson</surname><given-names>E</given-names></name><name name-style="western"><surname>Li</surname><given-names>D</given-names></name><name name-style="western"><surname>Raymond</surname><given-names>LR</given-names></name></person-group>. <source>Generative AI at Work, No. W31161</source>. Cambridge, MA: <publisher-name>National Bureau of Economic Research</publisher-name>; <year>2023</year>.</mixed-citation></ref><ref id="R19"><label>[19]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Team</surname><given-names>G</given-names></name><name name-style="western"><surname>Anil</surname><given-names>R</given-names></name><name name-style="western"><surname>Borgeaud</surname><given-names>S</given-names></name><etal/></person-group>. <article-title>Gemini: a family of highly capable multimodal models</article-title>. <comment>arXiv preprint arXiv:231211805</comment>. <year>2023</year>.</mixed-citation></ref><ref id="R20"><label>[20]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bi</surname><given-names>X</given-names></name><name name-style="western"><surname>Chen</surname><given-names>D</given-names></name><name name-style="western"><surname>Chen</surname><given-names>G</given-names></name><etal/></person-group>. <article-title>Deepseek llm: scaling open-source language models with longtermism</article-title>. <comment>arXiv preprint arXiv:240102954</comment>. <year>2024</year>.</mixed-citation></ref><ref id="R21"><label>[21]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chakraborty</surname><given-names>C</given-names></name><name name-style="western"><surname>Pal</surname><given-names>S</given-names></name><name name-style="western"><surname>Bhattacharya</surname><given-names>M</given-names></name><name name-style="western"><surname>Dash</surname><given-names>S</given-names></name><name name-style="western"><surname>Lee</surname><given-names>SS</given-names></name></person-group>. <article-title>Overview of chatbots with special emphasis on artificial intelligence-enabled ChatGPT in medical science</article-title>. <source>Front Artif Intell</source><year>2023</year>;<volume>6</volume>:<fpage>1237704</fpage>.<pub-id pub-id-type="pmid">38028668</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3389/frai.2023.1237704</pub-id><pub-id pub-id-type="pmcid">PMC10644239</pub-id></mixed-citation></ref><ref id="R22"><label>[22]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>White</surname><given-names>AD</given-names></name></person-group>. <article-title>The future of chemistry is language</article-title>. <source>Nat Rev Chem</source><year>2023</year>;<volume>7</volume>:<fpage>457</fpage>&#8211;<lpage>58</lpage>.<pub-id pub-id-type="pmid">37208543</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41570-023-00502-0</pub-id></mixed-citation></ref><ref id="R23"><label>[23]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ji</surname><given-names>Y</given-names></name><name name-style="western"><surname>Zhou</surname><given-names>Z</given-names></name><name name-style="western"><surname>Liu</surname><given-names>H</given-names></name><name name-style="western"><surname>Davuluri</surname><given-names>RV</given-names></name><name name-style="western"><surname>Kelso</surname><given-names>J</given-names></name></person-group>. <article-title>DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome</article-title>. <source>Bioinform</source><year>2021</year>;<volume>37</volume>:<fpage>2112</fpage>&#8211;<lpage>20</lpage>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/bioinformatics/btab083</pub-id><pub-id pub-id-type="pmcid">PMC11025658</pub-id><pub-id pub-id-type="pmid">33538820</pub-id></mixed-citation></ref><ref id="R24"><label>[24]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Danilevicz</surname><given-names>MF</given-names></name><name name-style="western"><surname>Gill</surname><given-names>M</given-names></name><name name-style="western"><surname>Fernandez</surname><given-names>CGT</given-names></name><etal/></person-group>. <article-title>DNABERT-based explainable lncRNA identification in plant genome assemblies</article-title>. <source>Comput Struct Biotechnol J</source><year>2023</year>;<volume>21</volume>:<fpage>5676</fpage>&#8211;<lpage>85</lpage>.<pub-id pub-id-type="pmid">38058296</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.csbj.2023.11.025</pub-id><pub-id pub-id-type="pmcid">PMC10696397</pub-id></mixed-citation></ref><ref id="R25"><label>[25]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sultan</surname><given-names>I</given-names></name><name name-style="western"><surname>Al-Abdallat</surname><given-names>H</given-names></name><name name-style="western"><surname>Alnajjar</surname><given-names>Z</given-names></name><etal/></person-group>. <article-title>Using ChatGPT to predict cancer predisposition genes: a promising tool for pediatric oncologists</article-title>. <source>Cureus</source><year>2023</year>;<volume>15</volume>:<fpage>e47594</fpage>.<pub-id pub-id-type="pmid">38021917</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.7759/cureus.47594</pub-id><pub-id pub-id-type="pmcid">PMC10666922</pub-id></mixed-citation></ref><ref id="R26"><label>[26]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Elsborg</surname><given-names>J</given-names></name><name name-style="western"><surname>Salvatore</surname><given-names>M</given-names></name></person-group>. <article-title>Using LLMs and explainable ml to analyze biomarkers at single-cell level for improved understanding of diseases</article-title>. <source>Biomol</source><year>2023</year>;<volume>13</volume>:<fpage>1516</fpage>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.3390/biom13101516</pub-id><pub-id pub-id-type="pmcid">PMC10605495</pub-id><pub-id pub-id-type="pmid">37892198</pub-id></mixed-citation></ref><ref id="R27"><label>[27]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yang</surname><given-names>F</given-names></name><name name-style="western"><surname>Wang</surname><given-names>W</given-names></name><name name-style="western"><surname>Wang</surname><given-names>F</given-names></name><etal/></person-group>. <article-title>scBERT as a large-scale pretrained deep language model for cell type annotation of single-cell RNA-seq data</article-title>. <source>Nature Mach Intell</source><year>2022</year>;<volume>4</volume>:<fpage>852</fpage>&#8211;<lpage>66</lpage>.</mixed-citation></ref><ref id="R28"><label>[28]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>Y</given-names></name><name name-style="western"><surname>Lang</surname><given-names>M</given-names></name><name name-style="western"><surname>Jiang</surname><given-names>J</given-names></name><etal/></person-group>. <article-title>Multiple sequence-alignment-based RNA language model and its application to structural inference</article-title>. <source>bioRxiv</source><year>2023</year>;<volume>2023</volume>:<fpage>15.532863</fpage>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/nar/gkad1031</pub-id><pub-id pub-id-type="pmcid">PMC10783488</pub-id><pub-id pub-id-type="pmid">37941140</pub-id></mixed-citation></ref><ref id="R29"><label>[29]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Song</surname><given-names>Y</given-names></name><name name-style="western"><surname>Yuan</surname><given-names>Q</given-names></name><name name-style="western"><surname>Zhao</surname><given-names>H</given-names></name><name name-style="western"><surname>Yang</surname><given-names>Y</given-names></name></person-group>. <article-title>Accurately identifying nucleic-acid-binding sites through geometric graph learning on language model predicted structures</article-title>. <source>Briefings Bioinf</source>. <year>2023</year>;<volume>24</volume>. <comment>Epub 2023/10/12</comment>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/bib/bbad360</pub-id><pub-id pub-id-type="pmid">37824738</pub-id></mixed-citation></ref><ref id="R30"><label>[30]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Roche</surname><given-names>R</given-names></name><name name-style="western"><surname>Moussad</surname><given-names>B</given-names></name><name name-style="western"><surname>Shuvo</surname><given-names>MH</given-names></name><name name-style="western"><surname>Tarafder</surname><given-names>S</given-names></name><name name-style="western"><surname>Bhattacharya</surname><given-names>D</given-names></name></person-group>. <article-title>EquiPNAS: improved protein-nucleic acid binding site prediction using protein-language-model-informed equivariant deep graph neural networks</article-title>. <source>Nucleic Acids Res</source><year>2024</year>;<volume>52</volume>:<fpage>e27</fpage>.<pub-id pub-id-type="pmid">38281252</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/nar/gkae039</pub-id><pub-id pub-id-type="pmcid">PMC10954458</pub-id></mixed-citation></ref><ref id="R31"><label>[31]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sanabria</surname><given-names>M</given-names></name><name name-style="western"><surname>Hirsch</surname><given-names>J</given-names></name><name name-style="western"><surname>Joubert</surname><given-names>PM</given-names></name><name name-style="western"><surname>Poetsch</surname><given-names>AR</given-names></name></person-group>. <article-title>DNA language model GROVER learns sequence context in the human genome</article-title>. <source>Nature Mach Intell</source><year>2024</year>;<volume>6</volume>:<fpage>911</fpage>&#8211;<lpage>23</lpage>.</mixed-citation></ref><ref id="R32"><label>[32]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Benegas</surname><given-names>G</given-names></name><name name-style="western"><surname>Ye</surname><given-names>C</given-names></name><name name-style="western"><surname>Albors</surname><given-names>C</given-names></name><name name-style="western"><surname>Li</surname><given-names>JC</given-names></name><name name-style="western"><surname>Song</surname><given-names>YS</given-names></name></person-group>. <article-title>Genomic language models: opportunities and challenges</article-title>. <source>Trends Genet</source><year>2025</year>;<volume>41</volume>:<fpage>286</fpage>&#8211;<lpage>302</lpage>.<pub-id pub-id-type="pmid">39753409</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.tig.2024.11.013</pub-id></mixed-citation></ref></ref-list></back></article></pmc-articleset>