<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xml:lang="en" article-type="research-article" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="pmc-domain-id">1660</journal-id><journal-id journal-id-type="pmc-domain">sensors</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>Multidisciplinary Digital Publishing Institute  (MDPI)</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12431538</article-id><article-id pub-id-type="pmcid-ver">PMC12431538.1</article-id><article-id pub-id-type="pmcaid">12431538</article-id><article-id pub-id-type="pmcaiid">12431538</article-id><article-id pub-id-type="doi">10.3390/s25175397</article-id><article-id pub-id-type="publisher-id">sensors-25-05397</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>GeoNR-PSW: Prompt-Aligned Localization Leveraging Ray-Traced 5G Channels and LLM Reasoning</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-3281-1743</contrib-id><name name-style="western"><surname>Shi</surname><given-names initials="W">Wenbin</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#8211; original draft</role><xref rid="af1-sensors-25-05397" ref-type="aff">1</xref><xref rid="af2-sensors-25-05397" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0004-0920-8737</contrib-id><name name-style="western"><surname>Zhan</surname><given-names initials="Z">Zhongxu</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><xref rid="af2-sensors-25-05397" ref-type="aff">2</xref><xref rid="c1-sensors-25-05397" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Lei</surname><given-names initials="J">Jingsheng</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Resources" vocab-term-identifier="https://credit.niso.org/contributor-roles/resources/">Resources</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><xref rid="af2-sensors-25-05397" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-1212-0715</contrib-id><name name-style="western"><surname>Gan</surname><given-names initials="X">Xingli</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Resources" vocab-term-identifier="https://credit.niso.org/contributor-roles/resources/">Resources</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><xref rid="af2-sensors-25-05397" ref-type="aff">2</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name name-style="western"><surname>Wen</surname><given-names initials="F">Fangqing</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name name-style="western"><surname>Wang</surname><given-names initials="X">Xianpeng</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name name-style="western"><surname>He</surname><given-names initials="J">Jin</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name name-style="western"><surname>Wan</surname><given-names initials="L">Liangtian</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name name-style="western"><surname>Zha</surname><given-names initials="Z">Zhiyuan</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-05397"><label>1</label>School of Computer Science, Hangzhou Dianzi University, Hangzhou 310018, China; <email>202244050093@hdu.edu.cn</email></aff><aff id="af2-sensors-25-05397"><label>2</label>School of Computer Science and Technology, Zhejiang University of Science and Technology, Hangzhou 310023, China; <email>118003@zust.edu.cn</email> (J.L.); <email>ganxingli@163.com</email> (X.G.)</aff><author-notes><corresp id="c1-sensors-25-05397"><label>*</label>Correspondence: <email>212408802002@zust.edu.cn</email></corresp></author-notes><pub-date pub-type="epub"><day>01</day><month>9</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>9</month><year>2025</year></pub-date><volume>25</volume><issue>17</issue><issue-id pub-id-type="pmc-issue-id">496815</issue-id><elocation-id>5397</elocation-id><history><date date-type="received"><day>23</day><month>7</month><year>2025</year></date><date date-type="rev-recd"><day>22</day><month>8</month><year>2025</year></date><date date-type="accepted"><day>29</day><month>8</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>01</day><month>09</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>13</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-13 14:25:13.570"><day>13</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="sensors-25-05397.pdf"/><abstract><p>Accurate user-equipment positioning is crucial for the successful deployment of 5G New Radio (NR) networks, particularly in dense urban and vehicular environments where multipath effects and signal blockage frequently compromise GNSS reliability. Building upon the pseudo-signal-word (PSW) paradigm initially developed for low-power wide-area networks, this paper proposes GeoNR-PSW, a novel localization architecture designed for sub-6 GHz (FR1, 2.8 GHz) and mmWave (FR2, 60 GHz) fingerprints from the Raymobtime S007 dataset. GeoNR-PSW encodes 5G channel snapshots into concise PSW sequences and leverages a frozen GPT-2 backbone enhanced by lightweight PSW-Adapters to enable few-shot 3D localization. Despite the limited size of the dataset, the proposed method achieves median localization errors of 5.90 m at FR1 and 3.25 m at FR2. These results highlight the potential of prompt-aligned language models for accurate and scalable 5G positioning with minimal supervision.</p></abstract><kwd-group><kwd>5G NR</kwd><kwd>6G</kwd><kwd>localization</kwd><kwd>large language models</kwd><kwd>few-shot learning</kwd><kwd>pseudo-signal words</kwd></kwd-group><funding-group><award-group><funding-source>the &#8220;Pioneer&#8221; and &#8220;Leading Goose&#8221; R&amp;D Program of Zhejiang</funding-source><award-id>2024C01109</award-id></award-group><funding-statement>This research was funded by the &#8220;Pioneer&#8221; and &#8220;Leading Goose&#8221; R&amp;D Program of Zhejiang (No. 2024C01109).</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-05397"><title>1. Introduction</title><p>3GPP Releases 16 through 18 have progressively introduced dedicated downlink Positioning Reference Signals (PRSs), uplink Time-Difference-of-Arrival (UL-TDoA), and block-edge tracking methods aimed at sub-meter accuracy. However, real-world deployment remains constrained by non-line-of-sight (NLOS) conditions, synchronization inaccuracies, and limited gNB densities [<xref rid="B1-sensors-25-05397" ref-type="bibr">1</xref>,<xref rid="B2-sensors-25-05397" ref-type="bibr">2</xref>,<xref rid="B3-sensors-25-05397" ref-type="bibr">3</xref>]. Joint communication-sensing paradigms further underscore the advantage of integrating radio resources for concurrent positioning and data transfer, particularly in 6G vehicular contexts [<xref rid="B4-sensors-25-05397" ref-type="bibr">4</xref>,<xref rid="B5-sensors-25-05397" ref-type="bibr">5</xref>].</p><p>Recent advancements have demonstrated data-driven techniques as the dominant paradigm in 5G localization research. Deep variational learning leverages multipath characteristics to achieve centimeter-level precision using a single anchor [<xref rid="B6-sensors-25-05397" ref-type="bibr">6</xref>], while physics-guided ray-traced simulators provide standardized benchmarks for both FR1 and FR2 frequency bands [<xref rid="B7-sensors-25-05397" ref-type="bibr">7</xref>]. Techniques involving multi-beam fingerprint fusion substantially reduce median indoor localization errors [<xref rid="B8-sensors-25-05397" ref-type="bibr">8</xref>], and self-supervised Channel State Information (CSI) encoders enable label-free localization in extensive driving datasets [<xref rid="B9-sensors-25-05397" ref-type="bibr">9</xref>]. Moreover, recent works exploit long-range channel correlations in ray-traced data and transformer-style radio foundation models for neural fingerprinting [<xref rid="B10-sensors-25-05397" ref-type="bibr">10</xref>,<xref rid="B11-sensors-25-05397" ref-type="bibr">11</xref>], and attention-based time-difference-of-multipath (TDM) inference further tightens sub-meter accuracy in richly scattered 5G NR scenes [<xref rid="B12-sensors-25-05397" ref-type="bibr">12</xref>].</p><p>Ensuring robust real-world deployment demands models that generalize across frequencies, hardware configurations, and varying environments. PARAMOUNT has demonstrated effective transfer of spatial knowledge from sub-6&#160;GHz to mmWave beam selection, significantly reducing overhead [<xref rid="B13-sensors-25-05397" ref-type="bibr">13</xref>]. Meta-learning and graph-based methods enhance rapid scene adaptation from minimal anchor data [<xref rid="B14-sensors-25-05397" ref-type="bibr">14</xref>,<xref rid="B15-sensors-25-05397" ref-type="bibr">15</xref>], while cross-band attention leverages FR1&#8211;FR2 reciprocity for joint positioning and beamforming [<xref rid="B16-sensors-25-05397" ref-type="bibr">16</xref>]. In parallel, Bayesian uncertainty frameworks mitigate outlier impacts across heterogeneous network setups [<xref rid="B17-sensors-25-05397" ref-type="bibr">17</xref>]. Recent tutorials synthesize these algorithmic and standardization trends, highlighting outstanding challenges for 5G&#8211;B5G positioning ecosystems.</p><p>Emerging trends highlight resource-efficient and distributed approaches for localization tasks. Edge-assisted multimodal fusion architectures integrate LiDAR, mapping, and RF cues for real-time vehicular tracking [<xref rid="B18-sensors-25-05397" ref-type="bibr">18</xref>,<xref rid="B19-sensors-25-05397" ref-type="bibr">19</xref>]. Reconfigurable intelligent surface (RIS)&#8211;assisted methods improve observability in challenging propagation [<xref rid="B20-sensors-25-05397" ref-type="bibr">20</xref>], and cooperative or anchor-free paradigms exploit inter-agent ranging and angle/delay geometry for robust GNSS-denied positioning [<xref rid="B21-sensors-25-05397" ref-type="bibr">21</xref>,<xref rid="B22-sensors-25-05397" ref-type="bibr">22</xref>]. Privacy-preserving federated localization maintains accuracy while minimizing backhaul and raw-data exposure [<xref rid="B23-sensors-25-05397" ref-type="bibr">23</xref>]. CSI imaging and tracking further enable fine-grained mmWave user localization and environmental mapping [<xref rid="B24-sensors-25-05397" ref-type="bibr">24</xref>]. Adaptive beam management increasingly couples communications throughput and positioning performance [<xref rid="B25-sensors-25-05397" ref-type="bibr">25</xref>].</p><p>Recent studies also explore foundation models&#8212;large language models and diffusion models&#8212;as generic priors for wireless. Frozen LLMs have been shown to perform in-context symbol detection [<xref rid="B26-sensors-25-05397" ref-type="bibr">26</xref>], while diffusion models synthesize realistic RF/CSI-style data to reduce collection costs [<xref rid="B27-sensors-25-05397" ref-type="bibr">27</xref>,<xref rid="B28-sensors-25-05397" ref-type="bibr">28</xref>]. Nevertheless, a unified evaluation on 5G New Radio channels is still lacking. The open Raymobtime dataset family therefore plays a pivotal role, providing synchronized FR1 and FR2 channel snapshots underpinning a wide range of localization benchmarks [<xref rid="B29-sensors-25-05397" ref-type="bibr">29</xref>].</p><p>Prompt alignment ladder denotes a staged prompt scaffold for in-context localization: an instruction template is gradually augmented with domain tokens (e.g., band, orientation), a compact set of anchor exemplars, and lightweight reasoning cues, aligning a frozen backbone to the task under a fixed prompt budget [<xref rid="B30-sensors-25-05397" ref-type="bibr">30</xref>,<xref rid="B31-sensors-25-05397" ref-type="bibr">31</xref>]. PSW alignment refers to normalizing and tokenizing multipath descriptors (power, delay/ToA, AoA/AoD, blockage cues) into pseudo-signal words whose co-occurrence encodes geometry; this textualization is consistent with fingerprint-based NR positioning practice and channel-informed feature design.</p><p>Despite these significant advancements, existing 5G localization methods either require dense calibration [<xref rid="B32-sensors-25-05397" ref-type="bibr">32</xref>] or fail to adequately generalize between sub-6&#160;GHz and mmWave bands. Moreover, few studies investigate prompt-driven reasoning for 5G NR localization. To bridge these gaps, this work proposes GeoNR-PSW, a model adapting PSW-based LLM reasoning to the Raymobtime&#160;S007 dataset, demonstrating robust, data-efficient localization across both FR1 (2.8&#160;GHz) and FR2 (60&#160;GHz) bands.</p><p>To bridge the aforementioned gaps, this work presents GeoNR-PSW, a localization framework that fuses 5G NR channel fingerprints with pretrained large language models (LLMs) on the Raymobtime&#160;S007 corpus. GeoNR-PSW transforms rich multipath descriptors into &#8220;pseudo-signal words&#8221; (PSWs) and performs few-shot 3D localization with a frozen LLM core enhanced by lightweight graph-aware adapters. The main contributions of this paper are summarized below:</p><p>Pseudo-Signal Words (PSWs).&#160;This work devises a discrete vocabulary that maps continuous 5G multipath features&#8212;power, ToA, AoA/AoD, and LOS flag&#8212;into token sequences natively interpretable by LLMs.</p><p>Few-Shot Prompting. By injecting only a handful of in-context exemplars per scene, a frozen pretrained LLM can infer user position, drastically reducing labeled-snapshot requirements. This few-shot strategy capitalizes on the generalization ability of LLMs, enabling high localization accuracy under minimal supervision&#8212;addressing a critical bottleneck in traditional fingerprinting approaches.</p><p>PSW-Adapters. This work introduces parameter-efficient, graph-inspired adapter blocks that refine LLM representations for radio-frequency tasks while adding less than 2&#160;% more parameters.</p><p>Progressive Alignment Ladder. A systematic ablation protocol quantifies the incremental gains provided by PSWs, adapters, and prompting, ensuring transparent performance attribution on Raymobtime&#160;S007.</p><p>Together, these innovations position GeoNR-PSW as a data-efficient route toward sub-meter 5G localization without full model retraining.</p></sec><sec id="sec2-sensors-25-05397"><title>2. Proposed Model</title><p>Urban 5G NR localization faces significant challenges due to multipath fading and rapidly fluctuating channel conditions, which are common in densely built urban environments. Traditional fingerprinting methods depend heavily on extensive, static radio maps, which are costly to generate and vulnerable to environmental changes. To overcome these limitations, this work proposes GeoNR-PSW, a novel few-shot learning framework leveraging a frozen, pretrained large language model (LLM). The overall architecture and key components of the GeoNR-PSW pipeline are comprehensively depicted in <xref rid="sensors-25-05397-f001" ref-type="fig">Figure 1</xref>.</p><p>Pseudo-signal words (PSWs) are first derived by normalizing per-link measurements from the Raymobtime dataset and quantizing them into discrete tokens, thereby casting each channel snapshot as a structured sequence. A prompt then concatenates a handful of reference PSW sequences with the query snapshot, allowing the LLM to infer location through in-context reasoning. Lightweight PSW-adapter modules&#8212;trained via low-rank updates&#8212;inject graph-based alignment cues into selected LLM layers without altering core&#160;weights.</p><sec id="sec2dot1-sensors-25-05397"><title>2.1. Preliminaries and Token Embedding</title><p>In the context of wireless geolocation, the problem involves determining the position of a receiver based on its 5G NR fingerprint from the Raymobtime dataset. Each snapshot includes multipath channel parameters such as received power, time of arrival (ToA), azimuth and elevation angles of departure (AoD), and azimuth and elevation angles of arrival (AoA). These measurements are time-varying and vary across different transmitter&#8211;receiver links due to the nature of radio propagation in urban environments. The goal is to learn a mapping from these channel parameters to geographic coordinates, typically expressed in 3D Cartesian coordinates <inline-formula><mml:math id="mm1" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, using a dataset of reference fingerprints with known locations.</p><p>Let <inline-formula><mml:math id="mm2" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow></mml:math></inline-formula> denote the sequence of Raymobtime channel measurements across <italic toggle="yes">D</italic> links capturing up to <italic toggle="yes">M</italic> multipath components, i.e., <inline-formula><mml:math id="mm3" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>M</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic toggle="yes">F</italic> represents the number of channel parameters. Given a query fingerprint <inline-formula><mml:math id="mm4" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">z</mml:mi><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> from a new snapshot, the task is to predict the corresponding geographic location <inline-formula><mml:math id="mm5" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">z</mml:mi><mml:mo>;</mml:mo><mml:mo>&#920;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="mm6" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> represents the predicted coordinates, and <inline-formula><mml:math id="mm7" overflow="scroll"><mml:mrow><mml:mo>&#920;</mml:mo></mml:mrow></mml:math></inline-formula> denotes the model parameters.</p><p>5G NR signals are subject to various distortions, including path loss, multipath fading, and environmental noise. To improve the model&#8217;s robustness, this work normalizes each received signal measurement using an Extended Kalman Filter (EKF) or Unscented Kalman Filter (UKF) to estimate and correct the channel dynamics. The normalized fingerprint <inline-formula><mml:math id="mm8" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow></mml:math></inline-formula> is then passed through a Channel Snapshot Normalization (CSN) stage to adjust for channel-specific biases:<disp-formula id="FD1-sensors-25-05397"><label>(1)</label><mml:math id="mm9" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">z</mml:mi><mml:mi>norm</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold">z</mml:mi><mml:mo>&#8722;</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>pred</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>In the above, <inline-formula><mml:math id="mm10" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>pred</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> represents the estimated signal values based on the current state. This normalized fingerprint is then tokenized for input into the LLM.</p><p>Once the signals are normalized, this work represents the fingerprint <inline-formula><mml:math id="mm11" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow></mml:math></inline-formula> as a sequence of pseudo-signal words (PSWs). Each measurement is tokenized into discrete representations corresponding to specific signal ranges. The tokenization function <inline-formula><mml:math id="mm12" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">T</mml:mi></mml:mrow></mml:math></inline-formula> converts the continuous signal values into discrete tokens:<disp-formula id="FD2-sensors-25-05397"><label>(2)</label><mml:math id="mm13" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="script">T</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>These tokens are embedded into a shared vector space for processing by the LLM, allowing the model to reason about spatial relationships between signals and locations. The resulting sequence of tokens is then passed as input to the LLM in subsequent stages.</p></sec><sec id="sec2dot2-sensors-25-05397"><title>2.2. Vanilla PSW Alignment (VPA)</title><p>The most straightforward approach to incorporating the PSW into a pretrained LLM is to concatenate the PSW token sequence directly with the prompt. In this Vanilla PSW Alignment (VPA) strategy, the model is fed with a sequence composed of both the PSWs and the textual prompt, as shown in the following equation:<disp-formula id="FD3-sensors-25-05397"><label>(3)</label><mml:math id="mm14" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">H</mml:mi><mml:mn>0</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>In the above, <inline-formula><mml:math id="mm15" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> denotes the PSW tokens corresponding to the fingerprint measurements and <inline-formula><mml:math id="mm16" overflow="scroll"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> represents the tokens from the textual prompt. The LLM is tasked with reasoning over this concatenated sequence and predicting the device location based on the alignment between the fingerprint tokens and the query prompt.</p><p>However, this approach has limitations, as the LLM does not inherently distinguish between structured data (the PSWs) and the natural language prompt. The lack of explicit structural alignment can lead the model to treat the PSWs as free-text tokens, resulting in suboptimal performance. Moreover, without logical alignment, the model may fail to correctly relate the PSWs to the prompt, leading to incoherent reasoning. To address these limitations, this work proposes an enhanced method of alignment that incorporates few-shot learning and adapter modules.</p></sec><sec id="sec2dot3-sensors-25-05397"><title>2.3. Few-Shot Prompting for PSW Alignment (FPSA)</title><p>Few-shot prompting provides a way to improve the alignment of PSWs with the query prompt by supplying the model with a small set of exemplar cases. In this Few-Shot Prompting for PSW Alignment (FPSA) strategy, this work augments the input with <italic toggle="yes">K</italic> reference fingerprints and their corresponding locations, allowing the model to infer the location of the new query based on previous examples. The few-shot prompt can be represented as follows:<disp-formula id="FD4-sensors-25-05397"><label>(4)</label><mml:math id="mm17" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">H</mml:mi><mml:mn>0</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mi>Example</mml:mi><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#8594;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:mspace width="1.em"/><mml:mrow><mml:mo>[</mml:mo><mml:mi>Example</mml:mi><mml:mn>2</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#8594;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>;</mml:mo><mml:mspace width="1.em"/><mml:mrow><mml:mo>[</mml:mo><mml:mi>Query</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>&#8594;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>q</mml:mi></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The model attends to the sequence of reference examples and their associated outputs to learn the mapping between the fingerprint tokens and the location labels. This in-context learning approach allows the LLM to align the PSW tokens with the query context, using the few-shot examples to guide its reasoning. The query fingerprint <inline-formula><mml:math id="mm18" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is then processed in the same manner, with the model generating the predicted location <inline-formula><mml:math id="mm19" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="sec2dot4-sensors-25-05397"><title>2.4. LLM Architecture with PSW Adapters</title><p>The core of the GeoNR-PSW framework is the integration of PSW adapters into a pretrained LLM. These adapters serve to align the structured PSW tokens with the language model&#8217;s reasoning process, enabling it to perform geolocation tasks effectively. The architecture is shown in <xref rid="sensors-25-05397-f001" ref-type="fig">Figure 1</xref>. At each layer of the LLM, the PSW tokens are processed alongside the prompt tokens, with the PSW adapters performing a structured alignment update. Specifically, at layer <italic toggle="yes">&#8467;</italic>, the hidden states of the PSW tokens <inline-formula><mml:math id="mm20" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">h</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#8467;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and the prompt tokens <inline-formula><mml:math id="mm21" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">h</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#8467;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> are updated through an attention mechanism that incorporates information from both domains. The PSW adapters are defined by the following update&#160;rule:<disp-formula id="FD5-sensors-25-05397"><label>(5)</label><mml:math id="mm22" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">h</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#8467;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>&#8592;</mml:mo><mml:msubsup><mml:mi mathvariant="bold">h</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#8467;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>&#945;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#8467;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold">W</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#8467;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:msubsup><mml:mi mathvariant="bold">h</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#8467;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>In the above, <inline-formula><mml:math id="mm23" overflow="scroll"><mml:mrow><mml:msup><mml:mi>&#945;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#8467;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is a learnable gate that controls the degree of influence from the PSW tokens on the prompt tokens, and <inline-formula><mml:math id="mm24" overflow="scroll"><mml:mrow><mml:msup><mml:mi mathvariant="bold">W</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#8467;</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is a weight matrix that projects the PSW embeddings into the prompt space. This update allows the model to align the structure of the PSW tokens with the semantic logic of the prompt, ensuring that the LLM generates the correct output based on both the spatial features of the fingerprint and the contextual cues from the prompt.</p></sec><sec id="sec2dot5-sensors-25-05397"><title>2.5. Optimization and Inference</title><p>The GeoNR-PSW model is trained end-to-end using a supervised loss function that minimizes the discrepancy between the predicted and true device locations. Specifically, this work uses the mean squared error (MSE) loss for continuous location prediction tasks:<disp-formula id="FD6-sensors-25-05397"><label>(6)</label><mml:math id="mm25" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="script">L</mml:mi><mml:mi>MSE</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac></mml:mstyle><mml:mo>&#8721;</mml:mo><mml:msup><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msup><mml:msup><mml:mfenced separators="" open="(" close=")"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mfenced separators="" open="(" close=")"><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mfenced separators="" open="(" close=")"><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>In the above, <inline-formula><mml:math id="mm26" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are the true locations and <inline-formula><mml:math id="mm27" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are the predicted locations. The model is trained using the Adam optimizer, with only the adapter parameters being updated, while the base LLM&#8217;s weights remain frozen to preserve the pre-learned knowledge. This results in a parameter-efficient fine-tuning process, as the adapters capture the domain-specific information required for geolocation.</p><p>At inference time, the trained model generates the predicted location <inline-formula><mml:math id="mm28" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for a new query fingerprint by processing it alongside a small set of few-shot reference examples. The inference process involves generating a prompt that aligns the PSWs with the query, then passing this prompt through the LLM with the PSW adapters to produce the final output. In scenarios where no few-shot examples are provided (i.e., zero-shot), the model still leverages its learned alignment capabilities to infer the location directly from the query fingerprint, demonstrating the power of LLMs in geolocation tasks.</p></sec></sec><sec id="sec3-sensors-25-05397"><title>3. Result</title><sec id="sec3dot1-sensors-25-05397"><title>3.1. Dataset and Pre-Processing Analysis</title><p>This study evaluates GeoNR-PSW using the public Raymobtime channel&#8211;ray-tracing dataset. Specifically, this work utilizes scenario <monospace>s007</monospace>, as it uniquely provides data for two carrier frequencies (2.8 GHz and 60 GHz), includes modeling of ten car-mounted receivers, and represents a dense urban boulevard environment in Beijing.</p><p>Each simulation episode (e0&#8211;e49) contains 40 sequential scenes captured at a cadence of 1 Hz. The episodes are spaced five seconds apart, uniquely identifying each receiver via the triplet <inline-formula><mml:math id="mm29" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#9001;</mml:mo><mml:mi mathvariant="monospace">EpisodeID</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="monospace">SceneID</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="monospace">VehicleArrayID</mml:mi><mml:mo>&#9002;</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>The analysis begins by examining the dynamic movement patterns of receivers. This also includes the resulting diversity in azimuth angles and transmitter&#8211;receiver ranges. To illustrate this, <xref rid="sensors-25-05397-f002" ref-type="fig">Figure 2</xref> depicts the trajectories of receivers for three selected simulation episodes (Episode 0, Episode 15, and Episode 30) along a fan-shaped elevated road. The scatter plots reveal a wide range of movement directions and distances. This diversity showcases the varied spatial relationships between the receivers and the transmitter. Specifically, the trajectories demonstrate how receivers traverse different paths. These range from horizontal movements near the base of the road to vertical shifts in the middle and consistent horizontal paths at higher elevations. Consequently, receivers encounter a broad spectrum of angles and distances relative to the transmitter.</p><p>This study explores how receiver heights and environmental shadowing influence signal quality, specifically focusing on transitions between line-of-sight (LOS) and non-line-of-sight (NLOS) conditions. <xref rid="sensors-25-05397-f003" ref-type="fig">Figure 3</xref> visualizes this phenomenon, presenting a three-dimensional distribution of received power. Within this visualization, color-coded trajectories indicate varying power levels across different elevations and positions.</p><p>The visualization clearly highlights the impact of environmental occlusions. Distinct transitions from LOS to NLOS conditions are observable as receivers move through regions with differing levels of shadowing. Furthermore, the received power levels, indicated by the color bar, notably decrease when receivers move to higher elevations or encounter obstructions, underscoring the critical role of spatial positioning in signal quality.</p><p>This section provides a comprehensive overview of the Raymobtime dataset. It details all available data fields, which include both metadata and detailed channel-path characteristics. Metadata encompasses spatial coordinates, episode identifiers, and receiver indices. Channel-path characteristics cover received power, time of arrival, angles of departure and arrival, and line-of-sight indicators. This detailed breakdown offers essential context for understanding the dataset&#8217;s structure and the specific parameters used in the analysis of receiver trajectories and signal quality. A full list of these data fields is presented in <xref rid="sensors-25-05397-t001" ref-type="table">Table 1</xref>.</p><p>A quantitative analysis of multipath characteristics at 2.8 GHz and 60 GHz reveals distinct differences between the two frequencies. <xref rid="sensors-25-05397-f004" ref-type="fig">Figure 4</xref>a presents a histogram of the valid path count. This histogram indicates that 60 GHz links have significantly fewer valid paths than 2.8 GHz, with a higher concentration of frames observed at lower path counts for 60 GHz.</p><p><xref rid="sensors-25-05397-f004" ref-type="fig">Figure 4</xref>b displays the cumulative distribution function (CDF) of the power of the ten strongest rays. Here, the 60 GHz curve rises more sharply at lower power levels compared to the gradual increase for 2.8 GHz. This sharper CDF and reduced path count confirm that 60 GHz links are sparser and characterized by fewer and weaker multipath components. These path statistics are depicted in <xref rid="sensors-25-05397-f004" ref-type="fig">Figure 4</xref>.</p><p>The angular-domain energy distribution for 2.8 GHz and 60 GHz is investigated to understand their spatial characteristics. <xref rid="sensors-25-05397-f005" ref-type="fig">Figure 5</xref>a and <xref rid="sensors-25-05397-f005" ref-type="fig">Figure 5</xref>b present heat-maps of the angle of departure (AoD) in the azimuth-elevation domain for 2.8 GHz and 60 GHz, respectively. The 60 GHz heat-map shows a more focused energy distribution within narrower angular sectors. In contrast, the 2.8 GHz heat-map reveals broader angular coverage. Additionally, line-of-sight (LOS) conditions across episodes are examined. <xref rid="sensors-25-05397-f005" ref-type="fig">Figure 5</xref>c plots the episode-wise LOS percentage, demonstrating that 60 GHz channels consistently exhibit fewer LOS frames compared to 2.8 GHz. These findings highlight the constrained angular spread and reduced LOS availability at 60 GHz. These spatial characteristics are illustrated in <xref rid="sensors-25-05397-f005" ref-type="fig">Figure 5</xref>.</p><p>The filtering process exclusively removes links flagged as invalid in the Raymobtime metadata. This also includes entries with placeholder coordinates.Notably, LOS/NLOS labels and path statistics are not employed as filtering criteria. While the count of receiver&#8211;scene pairs decreases (e.g., to approximately 45% after filtering), each retained link keeps its ten strongest rays, thereby preserving principal multipath energy and geometric information.</p><p>Post-filter distributions remain aligned with the raw dataset. Path count histograms and per-ray power CDFs continue to show the expected FR1/FR2 contrast. Similarly, AoA/AoD heat-maps maintain their angular structure. Coupled with a near-zero missing-path percentage after filtering; this indicates that diversity is preserved while label quality improves for supervision. As a practical future direction, methods to better utilize lower-quality frames will be explored. This includes noise-aware weighting and semi-supervised pretraining on low-confidence frames, all under the same split protocol.</p><p>Because the filter is metadata-driven rather than channel-statistic&#8211;driven, the retained set preserves the LOS/NLOS composition across episodes. Truncating to the top-10 rays retains the majority of link power while preserving angular trends. Terminal orientation is not explicitly annotated in Raymobtime; robustness to orientation variation is approximated through the natural angular diversity induced by the drive trajectories. This topic is further addressed in the <xref rid="sec5-sensors-25-05397" ref-type="sec">Section 5</xref>, where a planned field-validation protocol using IMU-conditioned features is outlined.</p><p>The pre-processing pipeline&#8217;s impact on multipath ray data is evaluated to enhance data quality and retain essential information. <xref rid="sensors-25-05397-f006" ref-type="fig">Figure 6</xref>a, <xref rid="sensors-25-05397-f006" ref-type="fig">Figure 6</xref>b and <xref rid="sensors-25-05397-f006" ref-type="fig">Figure 6</xref>c present power matrices for raw, filtered, and normalized data, respectively. The raw data exhibits significant variability with weak rays in low-power regions. Filtering addresses this by removing these weak rays, thereby reducing noise and enhancing clarity. Subsequently, normalization stabilizes variance, leading to a consistent power distribution.</p><p>Following filtering, <xref rid="sensors-25-05397-f006" ref-type="fig">Figure 6</xref>d and <xref rid="sensors-25-05397-f006" ref-type="fig">Figure 6</xref>e display the mean angle of departure (AoD) and angle of arrival (AoA) in the azimuth direction. These indicate that central paths align closely with the line of sight, while outer paths exhibit greater angular deviations. Furthermore, <xref rid="sensors-25-05397-f006" ref-type="fig">Figure 6</xref>f illustrates that the missing path percentage approaches 0% for most episodes and paths post-filtering, confirming the pipeline&#8217;s effectiveness. Overall, the pre-processing retains over 95% of principal information, significantly improving data quality.</p><p>Initially, the dataset comprises 20,000 receiver&#8211;scene combinations; after filtering invalid data (Val = V), 9078 valid samples (45.4%) remain. Each link retains the ten strongest multipath rays, resulting in a 70-dimensional channel vector after concatenating seven attributes per path with the receiver&#8217;s <inline-formula><mml:math id="mm30" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> coordinates.</p><p>The episodes are divided into training, validation, and testing subsets as detailed in <xref rid="sensors-25-05397-t002" ref-type="table">Table 2</xref>, ensuring temporal independence between subsets. Results presented primarily focus on the more challenging 2.8 GHz frequency due to its richer multipath environment.</p></sec><sec id="sec3dot2-sensors-25-05397"><title>3.2. Experimental Environment</title><p>All experimental procedures were conducted on an Ubuntu 20.04 platform equipped with dual NVIDIA RTX A6000 GPUs (48 GB each) and an Intel i7-14700KF CPU. The software stack includes Python 3.8 and PyTorch 2.4.1 with CUDA 12.1 support.</p><p>During fine-tuning, model training updates were restricted exclusively to the lightweight adapter layers within GeoNR-PSW. This work employed the Adam optimizer with a learning rate of <inline-formula><mml:math id="mm31" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#215;</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, a batch size of 64, and mixed-precision training (FP16). Early stopping, based on the mean localization error on the validation set, was used to avoid overfitting.</p><p>Complete source code, processed datasets, and detailed hyper-parameter configurations will be publicly available upon publication.</p></sec><sec id="sec3dot3-sensors-25-05397"><title>3.3. Overall Model Performance</title><p>Accurate three-dimensional (3D) localization is the ultimate objective of this work; therefore, a thorough examination of the training dynamics and the final inference quality is indispensable. To provide a comprehensive benchmark that later few-shot and down-sampling studies can rely on, this study evaluates two frequency regimes&#8212;2.8 GHz and 60 GHz&#8212;using the full Raymobtime data split.</p><p>The evolution of the training loss together with the validation mean, median, and root-mean-square errors exhibits a steep decline during the first 25 epochs, followed by a plateau where all curves fluctuate within a narrow band&#8212;evidence that the networks have converged without pronounced overfitting, as shown in <xref rid="sensors-25-05397-f007" ref-type="fig">Figure 7</xref>. Owing to the richer multipath structure and the larger antenna aperture available at millimeter-wave frequencies, the 60&#160;GHz configuration attains noticeably lower error values than its 2.8&#160;GHz counterpart.</p><p>A visual juxtaposition of predicted and ground-truth coordinates confirms that the model output is unbiased along each Cartesian axis; this is indicated by the substantial overlap between the predicted and actual point clouds, as presented in <xref rid="sensors-25-05397-f008" ref-type="fig">Figure 8</xref>. The predictions at 60&#160;GHz form a distinctly tighter cluster, reflecting the improved numerical performance of this frequency band. Both frequency models achieve their lowest mean errors at epoch 171. Nevertheless, a limited number of outliers persist. These are primarily located at extended distances and higher elevations, corresponding to scenarios with diminished signal-to-noise ratios.</p><p>A concise quantitative overview of the best validation and test results is presented in <xref rid="sensors-25-05397-t003" ref-type="table">Table 3</xref>. The model trained and evaluated at 60&#160;GHz achieves a validation mean 3D error of 4.718&#160;m, significantly improving upon the 8.746&#160;m error observed at 2.8&#160;GHz. This improvement is consistently reflected across median, root-mean-square, and 90th-percentile error metrics. Similar trends are observed in the test performance, where the 60&#160;GHz model maintains substantially lower localization errors compared to the 2.8&#160;GHz configuration.</p><p>Conversely, cross-frequency testing demonstrates markedly degraded accuracy. Applying the trained 2.8&#160;GHz model weights directly to the 60&#160;GHz test set yields a mean error of 58.208&#160;m, while transferring the 60&#160;GHz model to the 2.8&#160;GHz test set results in a mean error of 101.776&#160;m. These findings highlight the limited transferability of learned spatial features between different frequency domains, underscoring the necessity of dedicated training for each targeted operating frequency.</p><p>The proposed model demonstrated competitive localization accuracy and robustness, consistently outperforming baseline methods across both the 2.8 GHz and 60 GHz bands. At 2.8 GHz, the model achieved lower mean and 90th percentile errors, indicating a more effective approach for handling complex signal propagation compared to structured models like graph neural networks (GNNs).</p><p>This advantage was particularly pronounced at 60 GHz, where the proposed model exhibited a balanced performance. This contrasts sharply with kNN, which, despite its low median error, showed a high root-mean-square error (RMSE). This discrepancy suggests that while kNN performs adequately on familiar patterns, it struggles with generalization to unseen data&#8212;a critical limitation effectively addressed by the proposed model. The improved performance, as detailed in <xref rid="sensors-25-05397-t004" ref-type="table">Table 4</xref>, is attributed to the translation of signal measurements into pseudo-signal word sequences, which enables the large language model (LLM) to leverage contextual reasoning and generalization capabilities beyond those of traditional models.</p></sec><sec id="sec3dot4-sensors-25-05397"><title>3.4. Few-Shot Adaptation</title><p>In a realistic deployment, collecting a full-scale training set for every new site is impractical. This study therefore investigates few-shot adaptation: this work exposes the network to only <inline-formula><mml:math id="mm32" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#8712;</mml:mo><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> spatial reference frames per episode and then fine-tunes the prediction head. The remaining samples are kept for evaluation. All experiments are conducted independently on the sub-6 band (2.8&#160;GHz) and the mmWave band (60&#160;GHz).</p><p>This work reports five localization error metrics&#8212;mean, median, RMSE, 90th-percentile (p90), and maximum (max) distance error&#8212;averaged over 40 training episodes. The baseline <inline-formula><mml:math id="mm33" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> (no adaptation) corresponds to the cross-scene zero-shot setting. All errors are measured in three-dimensional Euclidean distance (meters).</p><p>The results of few-shot adaptation experiments are visually summarized in <xref rid="sensors-25-05397-f009" ref-type="fig">Figure 9</xref>, which comprises two subfigures: (a) plots the mean and median localization errors (in meters) against the number of reference frames <italic toggle="yes">k</italic> on a log-scale, and (b) illustrates the relative percentage change in all five error metrics compared to the <inline-formula><mml:math id="mm34" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> baseline, with blue indicating improvements (lower is better). <xref rid="sensors-25-05397-t005" ref-type="table">Table 5</xref> provides a detailed numerical breakdown of these metrics for both frequency bands across the range of <italic toggle="yes">k</italic> values. Three key observations emerge.</p><p>Incorporating just one reference frame (<inline-formula><mml:math id="mm35" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) yields substantial improvements. For the 2.8&#160;GHz band, the mean error decreases by 64.6% (from 24.70&#160;m to 8.75&#160;m), and the RMSE drops by 73.0% (from 53.06&#160;m to 14.34&#160;m). For the 60&#160;GHz band, the reductions are 52.9% (from 10.01&#160;m to 4.72&#160;m) for the mean and 49.3% (from 13.85&#160;m to 7.02&#160;m) for the RMSE. This demonstrates that a single in situ calibration point can effectively halve the error budget, underscoring the potential of few-shot learning to achieve rapid adaptation with minimal data.</p><p>Additional reference frames up to <inline-formula><mml:math id="mm36" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> continue to enhance performance, with a notable 70.6% RMSE reduction at 2.8&#160;GHz. However, beyond this point, the benefits diminish, and slight regressions are observed for <inline-formula><mml:math id="mm37" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm38" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> (e.g., mean error increases from 11.38&#160;m at <inline-formula><mml:math id="mm39" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> to 15.25&#160;m at <inline-formula><mml:math id="mm40" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> for 2.8&#160;GHz). This plateau effect suggests mild overfitting to the sparse anchor points, indicating an optimal adaptation range around <inline-formula><mml:math id="mm41" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>The 60&#160;GHz band exhibits a lower initial median error (6.91&#160;m) compared to 2.8&#160;GHz (13.09&#160;m) at <inline-formula><mml:math id="mm42" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, reflecting its narrower angular spread and reduced multipath richness. However, the relative improvement diminishes beyond <inline-formula><mml:math id="mm43" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, with percentage changes stabilizing (e.g., &#916;Median improves from &#8722;52.97% at <inline-formula><mml:math id="mm45" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> to &#8722;20.20% at <inline-formula><mml:math id="mm46" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). This highlights a band-specific response to increasing reference frames, where mmWave benefits less from additional data due to its inherent signal properties.</p><p>These findings robustly validate the central hypothesis of the system: accurate localization is achievable with minimal site-specific data. The ability to significantly reduce localization errors with as few as one or two reference frames is a critical attribute, enabling scalable and efficient low-altitude navigation solutions. This adaptability not only enhances deployment flexibility but also supports the practical implementation of the framework in resource-constrained environments. Diminishing returns emerge as <italic toggle="yes">k</italic> increases, with occasional degradation for <inline-formula><mml:math id="mm47" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#8712;</mml:mo><mml:mo>[</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Longer prompts may introduce heterogeneous or conflicting anchors that dilute in-context signals and increase the risk of overfitting to sparse anchor geometry. Under a fixed prompt budget, a small anchor set selected via validation is advisable, with <inline-formula><mml:math id="mm48" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#8804;</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> (typically <inline-formula><mml:math id="mm49" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#8712;</mml:mo><mml:mo>[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) to stabilize performance.</p></sec><sec id="sec3dot5-sensors-25-05397"><title>3.5. Training Data Efficiency</title><p>Accurate navigation in dense low-altitude air-spaces must remain robust when only a small fraction of the available measurements are labeled. To quantify this requirement, localization models are trained with five progressively smaller portions of the labeled set (train ratios from 1.0 down to 0.2). Two carrier frequencies are evaluated independently: 2.8&#160;GHz and 60&#160;GHz. For every ratio the network is trained until validation performance saturates; the epoch with the lowest validation median error is then used to compute all statistics on a disjoint test set.</p><p>Localization error distributions for five key statistics (mean, median, root-mean-square error, 90th percentile, and maximum) are depicted in <xref rid="sensors-25-05397-f010" ref-type="fig">Figure 10</xref>. A box plot summarizes 2.8&#160;GHz, whereas a violin plot illustrates the density for 60&#160;GHz. Medians and inter-quartile ranges contract as the training ratio increases, confirming that additional supervision reduces both central tendency and spread. Dispersion is consistently smaller for 60&#160;GHz, highlighting the benefit of the richer multipath structure at 60&#160;GHz.</p><p>Empirical cumulative distribution functions (CDFs) of the three-dimensional positional error for all training ratios are presented in <xref rid="sensors-25-05397-f011" ref-type="fig">Figure 11</xref>. As more labeled data are provided, the curves move steadily leftwards; however, beyond a ratio of 0.6, the additional gain is marginal. For 60&#160;GHz, the curve obtained with only 40% of the training data nearly overlaps the full-data curve up to the 95th percentile, indicating that the high-frequency model is markedly data-efficient.</p><p><xref rid="sensors-25-05397-t006" ref-type="table">Table 6</xref> lists the best-epoch statistics extracted from <xref rid="sensors-25-05397-f010" ref-type="fig">Figure 10</xref>. At 2.8&#160;GHz the mean error rises from 8.75&#160;m to 16.77&#160;m (+92&#160;%) when the ratio is reduced from 1.0 to 0.2, while the corresponding increase at 60&#160;GHz is from 4.72&#160;m to 8.19&#160;m (+74&#160;%). Maximum errors for 2.8&#160;GHz remain between 142&#160;m and 182&#160;m across all ratios, whereas the largest errors for 60&#160;GHz drop sharply once the ratio exceeds 0.2. High-frequency sensing therefore not only improves average accuracy but also suppresses extreme outliers under limited supervision.</p><p>This study confirms that the 60&#160;GHz model achieves near-optimal performance with as little as 40% of the labeled data, whereas the 2.8&#160;GHz model experiences notable degradation under the same constraint. In scenarios where annotation is costly, prioritizing high-frequency measurements and semi-supervised strategies emerges as a promising pathway towards efficient large-scale deployment.</p></sec><sec id="sec3dot6-sensors-25-05397"><title>3.6. Model Depth Ablation</title><p>The preceding analyses imply that the transformer backbone and the graph neural network (GNN) refinement blocks exert complementary effects on the localization task. This work therefore examines how the depth of each branch influences accuracy on two frequency regimes. For GPT-2, depth corresponds to the number of transformer layers <inline-formula><mml:math id="mm50" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>6</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>; for the GNN branch, a depth of <inline-formula><mml:math id="mm51" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>&#8712;</mml:mo><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>6</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the number of message-passing blocks inserted at pipeline positions &#8220;0&#8221;, &#8220;1/4&#8221;, or &#8220;2/4&#8221;, encoded as #LLM*#pos_GNN*#pos_L_GNN in the log. All remaining hyper-parameters are held constant so that performance differences arise solely from architectural depth.</p><p>Each depth combination is trained to convergence and assessed with four navigation-relevant metrics: mean error, median error, root-mean-square error (RMSE), and <inline-formula><mml:math id="mm52" overflow="scroll"><mml:mrow><mml:msup><mml:mn>90</mml:mn><mml:mi>th</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>-percentile error (<inline-formula><mml:math id="mm53" overflow="scroll"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>90</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>). Lower values indicate superior localization. The complete raw scores are listed in <xref rid="sensors-25-05397-t007" ref-type="table">Table 7</xref>.</p><p>The dual-polarity radar plots in <xref rid="sensors-25-05397-f012" ref-type="fig">Figure 12</xref> summarize the outcomes. <xref rid="sensors-25-05397-f012" ref-type="fig">Figure 12</xref>a groups results by GNN depth and marginalizes over transformer layers, whereas <xref rid="sensors-25-05397-f012" ref-type="fig">Figure 12</xref>b groups by GPT-2 depth and marginalizes over GNN configurations.</p><p>Both panels exhibit a distinct U-shaped trend: shallow models (<inline-formula><mml:math id="mm54" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mspace width="0.166667em"/><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) lack sufficient receptive field, whereas overly deep models (<inline-formula><mml:math id="mm55" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mspace width="0.166667em"/><mml:mn>6</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) suffer from optimization difficulties and over-smoothing, which elevates RMSE and <inline-formula><mml:math id="mm56" overflow="scroll"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>90</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. A moderate configuration&#8212;four GPT-2 layers combined with four GNN blocks inserted at the second quartile of the pipeline (<monospace>4*0_2_4*0_2_4</monospace>)&#8212;attains the lowest median error (3.25 m) and the best <inline-formula><mml:math id="mm57" overflow="scroll"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>90</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> (8.48 m) at 60 GHz, while maintaining competitive accuracy at 2.8 GHz. These findings indicate that moderate depth paired with mid-pipeline insertion offers the best balance between accuracy and computational cost.</p><p>From an architectural perspective, mid-pipeline insertion lets message-passing over the path/anchor graph inject geometry-aware constraints after the transformer has formed local token aggregates but before global decoding, avoiding early-stage washout and late-stage under-propagation. Empirically, input-only or output-only placements underperform: omitting the input-stage GNN degrades accuracy, whereas coupling an input-stage GNN (for initial context alignment) with a mid-stage GNN (for refinement) yields the most consistent gains; placing GNNs only near the head risks over-smoothing and limited receptive depth. Consequently, this configuration is adopted as the default architecture in subsequent experiments.</p></sec></sec><sec sec-type="conclusions" id="sec4-sensors-25-05397"><title>4. Conclusions</title><p>This paper presented GeoNR-PSW, a novel few-shot localization framework integrating 5G New Radio channel fingerprints with pretrained large language models (LLMs), leveraging the Raymobtime S007 dataset. By transforming multipath channel parameters into pseudo-signal words (PSWs), GeoNR-PSW demonstrated significant advancements in robustness and data efficiency for urban 5G localization, especially across two critical frequency bands: sub-6 GHz (2.8 GHz) and mmWave (60 GHz). The introduction of PSW tokens as discrete, interpretable units enabled effective in-context learning, significantly improving accuracy over baseline methods. Few-shot prompting emerged as an exceptionally efficient adaptation mechanism, substantially reducing localization errors with minimal additional data. Specifically, incorporating just one spatial reference frame per scenario reduced the mean localization error by approximately 65% at 2.8 GHz and around 53% at 60 GHz. The proposed lightweight PSW-adapter modules, integrated within the pretrained LLM, further facilitated rapid frequency-specific adaptation with minimal computational overhead, significantly enhancing localization performance under limited data scenarios.</p><p>Extensive ablation studies on model depth and architecture demonstrated that moderate configurations&#8212;particularly four transformer layers paired with mid-pipeline graph neural network refinement blocks&#8212;achieved the optimal balance between performance and computational complexity, notably attaining a median localization error of only 3.25 m at 60 GHz. Cross-frequency evaluation, however, revealed limited direct transferability of models trained on distinct frequency bands, highlighting the necessity for frequency-specific training or fine-tuning. The significantly increased mean localization errors observed when directly transferring models across frequencies underscored inherent differences in multipath characteristics and channel properties between sub-6 GHz and mmWave bands. Overall, GeoNR-PSW provides an innovative approach toward accurate, efficient, and scalable localization in complex urban environments, bridging gaps between traditional fingerprinting methods and modern deep learning techniques. Future research directions include enhancing transferability between frequency bands, exploring multi-modal integration to further improve accuracy, and extending the framework toward more complex urban scenarios and larger-scale deployments.</p></sec><sec sec-type="discussion" id="sec5-sensors-25-05397"><title>5. Discussion</title><p>This study&#8217;s GeoNR-PSW framework, by integrating few-shot learning, pseudo-signal words (PSWs), and pretrained large language models (LLMs), has achieved significant advancements in 5G localization, offering crucial new insights into wireless positioning. These results not only corroborate existing literature on the importance of structured representation and context-driven reasoning, but also expand the applicability of data-driven and transformer-based models in complex multipath environments. The substantial data efficiency gains realized through few-shot prompting provide strong support for deploying practical and scalable localization systems in real-world urban settings. Furthermore, ablation studies confirmed existing theories regarding optimal model complexity, indicating that excessively shallow or overly deep configurations negatively impact performance due to insufficient receptive fields or overfitting, respectively, and provide critical guidance for future architectural designs.</p><p>This study is scoped to within-band generalization, and the synthetic nature of Raymobtime leaves real-world generalization as an open issue. A crucial next step is to conduct staged field validation on outdoor NR links, which will involve sampling each waypoint under diverse device orientations and moderate mobility. This process will also incorporate simple robustness strategies, such as orientation-aware feature handling and lightweight augmentation, to assess whether the gains observed here persist under practical hardware and environmental variability. Cross-band transfer remains challenging due to the distribution shift between sub-6 GHz and mmWave (e.g., the 60 GHz&#8594;2.8 GHz setting can exceed 100 m error). Future work will explore spectrum-aware PSW normalization to reduce band-specific bias, lightweight frequency-conditioned adapters for the PSW&#8211;LLM interface, and small-sample adaptation in the target band; a complementary direction is joint training across FR1 and FR2 to learn shared structure while retaining band specificity.</p><p>While GPT-2 serves as a compact proof-of-concept, replacing it with more modern, larger foundation models (e.g., GPT-3.5, GPT-4, LLaMA-2) could strengthen in-context learning, support longer-context aggregation of PSWs and auxiliary signals (e.g., frequency/IMU tokens), and improve robustness to noisy or sparse PSWs, potentially lowering the few-shot requirement and median error. The main challenges are computational/memory overhead and latency, access/reproducibility constraints for closed models, and the risk of overfitting to band-specific priors; to keep the framework practical, upgrades should freeze the backbone and adjust only lightweight, frequency-conditioned adapters or PSW projections, with matched ablations to ensure fair comparison. As part of future work, deployment trade-offs will be profiled empirically&#8212;latency, memory footprint, and energy consumption&#8212;across backbone scales and adapter configurations to quantify the cost&#8211;accuracy balance.</p></sec></body><back><fn-group><fn><p><bold>Disclaimer/Publisher&#8217;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><notes><title>Author Contributions</title><p>W.S.: Writing&#8212;original draft, Methodology, Formal analysis, Conceptualization, Investigation, Validation. Z.Z.: Writing&#8212;review and editing, Validation, Software. J.L.: Supervision, Resources, Investigation, Funding acquisition. X.G.: Supervision, Resources, Investigation, Funding acquisition. All authors have read and agreed to the published version of the manuscript.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>The dataset used in this work is a publicly available dataset.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflicts of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-25-05397"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kanhere</surname><given-names>O.</given-names></name><name name-style="western"><surname>Rappaport</surname><given-names>T.S.</given-names></name></person-group><article-title>Position Location for Futuristic Cellular Communications: 5G and Beyond</article-title><source>IEEE Commun. Mag.</source><year>2021</year><volume>59</volume><fpage>70</fpage><lpage>75</lpage><pub-id pub-id-type="doi">10.1109/MCOM.001.2000150</pub-id></element-citation></ref><ref id="B2-sensors-25-05397"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Brambilla</surname><given-names>M.</given-names></name><name name-style="western"><surname>Alghisi</surname><given-names>M.</given-names></name><name name-style="western"><surname>Tedeschini</surname><given-names>B.C.</given-names></name><name name-style="western"><surname>Fumagalli</surname><given-names>A.</given-names></name><name name-style="western"><surname>Grec</surname><given-names>F.C.</given-names></name><name name-style="western"><surname>Italiano</surname><given-names>L.</given-names></name><name name-style="western"><surname>Pileggi</surname><given-names>C.</given-names></name><name name-style="western"><surname>Biagi</surname><given-names>L.</given-names></name><name name-style="western"><surname>Bianchi</surname><given-names>S.</given-names></name><name name-style="western"><surname>Gatti</surname><given-names>A.</given-names></name><etal/></person-group><article-title>Integration of 5G and GNSS Technologies for Enhanced Positioning: An Experimental Study</article-title><source>IEEE Open J. Commun. Soc.</source><year>2024</year><volume>5</volume><fpage>7197</fpage><lpage>7215</lpage><pub-id pub-id-type="doi">10.1109/OJCOMS.2024.3487270</pub-id></element-citation></ref><ref id="B3-sensors-25-05397"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Italiano</surname><given-names>L.</given-names></name><name name-style="western"><surname>Denis</surname><given-names>B.</given-names></name><name name-style="western"><surname>Raulefs</surname><given-names>R.</given-names></name><name name-style="western"><surname>Wymeersch</surname><given-names>H.</given-names></name></person-group><article-title>A Tutorial on 5G Positioning</article-title><source>IEEE Commun. Surveys Tutorials</source><year>2024</year><pub-id pub-id-type="doi">10.1109/COMST.2024.3449031</pub-id></element-citation></ref><ref id="B4-sensors-25-05397"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhong</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Peng</surname><given-names>Z.</given-names></name></person-group><article-title>Joint Resource Allocation for V2X Sensing and Communication Based on MADDPG</article-title><source>IEEE Access</source><year>2025</year><volume>13</volume><fpage>12764</fpage><lpage>12776</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2025.3527049</pub-id></element-citation></ref><ref id="B5-sensors-25-05397"><label>5.</label><element-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>F.</given-names></name><name name-style="western"><surname>Du</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Li</surname><given-names>G.Y.</given-names></name><name name-style="western"><surname>Han</surname><given-names>T.X.</given-names></name><name name-style="western"><surname>Heath</surname><given-names>R.W.</given-names></name></person-group><article-title>Frame Structure and Protocol Design for Sensing-Assisted NR-V2X</article-title><source>IEEE Trans. Mobile Comput.</source><year>2024</year><comment><italic toggle="yes">early access</italic></comment><pub-id pub-id-type="doi">10.1109/TMC.2024.3389697</pub-id></element-citation></ref><ref id="B6-sensors-25-05397"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>T.</given-names></name><name name-style="western"><surname>Li</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>J.</given-names></name><name name-style="western"><surname>Hu</surname><given-names>K.</given-names></name><name name-style="western"><surname>Shen</surname><given-names>Y.</given-names></name></person-group><article-title>Multipath-Assisted Single-Anchor Localization via Deep Variational Learning</article-title><source>IEEE Trans. Wirel. Commun.</source><year>2024</year><volume>23</volume><fpage>9113</fpage><lpage>9128</lpage><pub-id pub-id-type="doi">10.1109/TWC.2024.3359047</pub-id></element-citation></ref><ref id="B7-sensors-25-05397"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>T.</given-names></name><name name-style="western"><surname>Lei</surname><given-names>H.</given-names></name><name name-style="western"><surname>Guo</surname><given-names>H.</given-names></name><name name-style="western"><surname>Yin</surname><given-names>M.</given-names></name><name name-style="western"><surname>Hu</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Zhu</surname><given-names>Q.</given-names></name><name name-style="western"><surname>Rangan</surname><given-names>S.</given-names></name></person-group><article-title>Digital Twin-Enhanced Wireless Indoor Navigation: Achieving Efficient Environment Sensing with Zero-Shot Reinforcement Learning</article-title><source>IEEE Open J. Commun. Soc.</source><year>2025</year><volume>6</volume><fpage>2356</fpage><lpage>2372</lpage><pub-id pub-id-type="doi">10.1109/OJCOMS.2025.3552277</pub-id></element-citation></ref><ref id="B8-sensors-25-05397"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhou</surname><given-names>X.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>L.</given-names></name><name name-style="western"><surname>Ruan</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>R.</given-names></name></person-group><article-title>Indoor Localization with Multi-Beam of 5G New Radio Signals</article-title><source>IEEE Trans. Wireless Commun.</source><year>2024</year><volume>23</volume><fpage>11260</fpage><lpage>11275</lpage><pub-id pub-id-type="doi">10.1109/TWC.2024.3380737</pub-id></element-citation></ref><ref id="B9-sensors-25-05397"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Salihu</surname><given-names>A.</given-names></name><name name-style="western"><surname>Rupp</surname><given-names>M.</given-names></name><name name-style="western"><surname>Schwarz</surname><given-names>S.</given-names></name></person-group><article-title>Self-Supervised and Invariant Representations for Wireless Localization</article-title><source>IEEE Trans. Wirel. Commun.</source><year>2024</year><volume>23</volume><fpage>8281</fpage><lpage>8296</lpage><pub-id pub-id-type="doi">10.1109/TWC.2023.3348203</pub-id></element-citation></ref><ref id="B10-sensors-25-05397"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zecchin</surname><given-names>M.</given-names></name><name name-style="western"><surname>Mashhadi</surname><given-names>M.B.</given-names></name><name name-style="western"><surname>Jankowski</surname><given-names>M.</given-names></name><name name-style="western"><surname>G&#252;nd&#252;z</surname><given-names>D.</given-names></name><name name-style="western"><surname>Kountouris</surname><given-names>M.</given-names></name><name name-style="western"><surname>Gesbert</surname><given-names>D.</given-names></name></person-group><article-title>LIDAR and Position-Aided mmWave Beam Selection with Non-Local CNNs and Curriculum Training</article-title><source>IEEE Trans. Veh. Technol.</source><year>2022</year><volume>71</volume><fpage>2979</fpage><lpage>2990</lpage><pub-id pub-id-type="doi">10.1109/TVT.2022.3142513</pub-id></element-citation></ref><ref id="B11-sensors-25-05397"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ott</surname><given-names>J.</given-names></name></person-group><article-title>Radio Foundation Models: Pre-training Transformers for 5G-based Indoor Localization</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type="doi">10.48550/arXiv.2410.00617</pub-id></element-citation></ref><ref id="B12-sensors-25-05397"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ott</surname><given-names>J.</given-names></name><name name-style="western"><surname>Stahlke</surname><given-names>M.</given-names></name><name name-style="western"><surname>Feigl</surname><given-names>T.</given-names></name><name name-style="western"><surname>Mutschler</surname><given-names>C.</given-names></name></person-group><article-title>Estimating Multipath Component Delays with Transformer Models</article-title><source>IEEE J. Indoor Seamless Posit. Navig.</source><year>2024</year><volume>2</volume><fpage>219</fpage><lpage>229</lpage><pub-id pub-id-type="doi">10.1109/JISPIN.2024.3422908</pub-id></element-citation></ref><ref id="B13-sensors-25-05397"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vuckovic</surname><given-names>K.</given-names></name><name name-style="western"><surname>Mashhadi</surname><given-names>M.</given-names></name><name name-style="western"><surname>Hejazi</surname><given-names>F.</given-names></name><name name-style="western"><surname>Alkhateeb</surname><given-names>A.</given-names></name></person-group><article-title>PARAMOUNT: Generalizable Deep Learning for mmWave Beam Selection Using Sub-6,GHz Channels</article-title><source>IEEE Trans. Wirel. Commun.</source><year>2024</year><volume>23</volume><fpage>5187</fpage><lpage>5202</lpage><pub-id pub-id-type="doi">10.1109/TWC.2023.3324916</pub-id></element-citation></ref><ref id="B14-sensors-25-05397"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gao</surname><given-names>J.</given-names></name><name name-style="western"><surname>Wu</surname><given-names>D.</given-names></name><name name-style="western"><surname>Yin</surname><given-names>F.</given-names></name><name name-style="western"><surname>Kong</surname><given-names>Q.</given-names></name><name name-style="western"><surname>Xu</surname><given-names>L.</given-names></name><name name-style="western"><surname>Cui</surname><given-names>S.</given-names></name></person-group><article-title>MetaLoc: Learning to Learn Wireless Localization</article-title><source>IEEE J. Sel. Areas Commun.</source><year>2023</year><volume>41</volume><fpage>3831</fpage><lpage>3847</lpage><pub-id pub-id-type="doi">10.1109/JSAC.2023.3322766</pub-id></element-citation></ref><ref id="B15-sensors-25-05397"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kang</surname><given-names>X.</given-names></name><name name-style="western"><surname>Liang</surname><given-names>X.</given-names></name><name name-style="western"><surname>Liang</surname><given-names>Q.</given-names></name></person-group><article-title>Indoor Localization Algorithm Based on a High-Order Graph Neural Network (HoGNNLoc)</article-title><source>Sensors</source><year>2023</year><volume>23</volume><elocation-id>8221</elocation-id><pub-id pub-id-type="doi">10.3390/s23198221</pub-id><pub-id pub-id-type="pmid">37837051</pub-id><pub-id pub-id-type="pmcid">PMC10575147</pub-id></element-citation></ref><ref id="B16-sensors-25-05397"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gouda</surname><given-names>A.A.E.M.M.</given-names></name><name name-style="western"><surname>Hamad</surname><given-names>E.K.I.</given-names></name><name name-style="western"><surname>Hussein</surname><given-names>A.I.</given-names></name><name name-style="western"><surname>Mabrook</surname><given-names>M.M.</given-names></name><name name-style="western"><surname>Donkol</surname><given-names>A.A.</given-names></name></person-group><article-title>Enhanced Position-Aided Beam Prediction Using Real-World Data and Enhanced-Convolutional Neural Networks</article-title><source>IEEE Access</source><year>2025</year><volume>13</volume><fpage>74917</fpage><lpage>74929</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2025.3563797</pub-id></element-citation></ref><ref id="B17-sensors-25-05397"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Booth</surname><given-names>M.B.</given-names></name><name name-style="western"><surname>Suresh</surname><given-names>V.</given-names></name><name name-style="western"><surname>Michelusi</surname><given-names>N.</given-names></name><name name-style="western"><surname>Love</surname><given-names>D.J.</given-names></name></person-group><article-title>Multi-Armed Bandit Beam Alignment and Tracking for Mobile Millimeter Wave Communications</article-title><source>IEEE Commun. Lett.</source><year>2019</year><volume>23</volume><fpage>1244</fpage><lpage>1248</lpage><pub-id pub-id-type="doi">10.1109/LCOMM.2019.2919016</pub-id></element-citation></ref><ref id="B18-sensors-25-05397"><label>18.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Shi</surname><given-names>S.</given-names></name><name name-style="western"><surname>Cui</surname><given-names>J.</given-names></name><name name-style="western"><surname>Jiang</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Yan</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Xing</surname><given-names>G.</given-names></name><name name-style="western"><surname>Niu</surname><given-names>J.</given-names></name><name name-style="western"><surname>Ouyang</surname><given-names>Z.</given-names></name></person-group><article-title>VIPS: Real-time perception fusion for infrastructure-assisted autonomous driving</article-title><source>Proceedings of the 28th Annual International Conference on Mobile Computing And Networking (MobiCom &#8216;22)</source><conf-loc>Sydney, NSW, Australia</conf-loc><conf-date>17&#8211;21 October 2022</conf-date><pub-id pub-id-type="doi">10.1145/3495243.3560539</pub-id></element-citation></ref><ref id="B19-sensors-25-05397"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ye</surname><given-names>Q.</given-names></name><name name-style="western"><surname>Bie</surname><given-names>H.</given-names></name><name name-style="western"><surname>Li</surname><given-names>K.-C.</given-names></name><name name-style="western"><surname>Fan</surname><given-names>X.</given-names></name><name name-style="western"><surname>Gong</surname><given-names>L.</given-names></name><name name-style="western"><surname>He</surname><given-names>X.</given-names></name><name name-style="western"><surname>Fang</surname><given-names>G.</given-names></name></person-group><article-title>EdgeLoc: A Robust and Real-Time Localization System Toward Heterogeneous IoT Devices</article-title><source>IEEE Internet Things J.</source><year>2022</year><volume>9</volume><fpage>3865</fpage><lpage>3876</lpage><pub-id pub-id-type="doi">10.1109/JIOT.2021.3101368</pub-id></element-citation></ref><ref id="B20-sensors-25-05397"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rahal</surname><given-names>M.</given-names></name><name name-style="western"><surname>Denis</surname><given-names>B.</given-names></name><name name-style="western"><surname>Keskin</surname><given-names>M.F.</given-names></name><name name-style="western"><surname>Uguen</surname><given-names>B.</given-names></name><name name-style="western"><surname>Wymeersch</surname><given-names>H.</given-names></name></person-group><article-title>RIS-Enabled NLoS Near-Field Joint Position and Velocity Estimation Under User Mobility</article-title><source>IEEE J. Sel. Top. Signal Process.</source><year>2024</year><volume>18</volume><fpage>633</fpage><lpage>645</lpage><pub-id pub-id-type="doi">10.1109/JSTSP.2024.3414110</pub-id></element-citation></ref><ref id="B21-sensors-25-05397"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rastorgueva-Foi</surname><given-names>E.</given-names></name><name name-style="western"><surname>Kaltiokallio</surname><given-names>O.</given-names></name><name name-style="western"><surname>Ge</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Turunen</surname><given-names>M.</given-names></name><name name-style="western"><surname>Talvitie</surname><given-names>J.</given-names></name><name name-style="western"><surname>Tan</surname><given-names>B.</given-names></name><name name-style="western"><surname>Furkan Keskin</surname><given-names>M.</given-names></name><name name-style="western"><surname>Wymeersch</surname><given-names>H.</given-names></name><name name-style="western"><surname>Valkama</surname><given-names>M.</given-names></name></person-group><article-title>Millimeter-Wave Radio SLAM: End-to-End Processing Methods and Experimental Validation</article-title><source>IEEE J. Sel. Areas Commun.</source><year>2024</year><volume>42</volume><fpage>2550</fpage><lpage>2567</lpage><pub-id pub-id-type="doi">10.1109/JSAC.2024.3413995</pub-id></element-citation></ref><ref id="B22-sensors-25-05397"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wymeersch</surname><given-names>H.</given-names></name><name name-style="western"><surname>Seco-Granados</surname><given-names>G.</given-names></name><name name-style="western"><surname>Destino</surname><given-names>G.</given-names></name><name name-style="western"><surname>Dardari</surname><given-names>D.</given-names></name><name name-style="western"><surname>Tufvesson</surname><given-names>F.</given-names></name></person-group><article-title>5G mmWave Positioning for Vehicular Networks</article-title><source>IEEE Wirel. Commun.</source><year>2017</year><volume>24</volume><fpage>80</fpage><lpage>86</lpage><pub-id pub-id-type="doi">10.1109/MWC.2017.1600374</pub-id></element-citation></ref><ref id="B23-sensors-25-05397"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ciftler</surname><given-names>B.S.</given-names></name></person-group><article-title>Federated Learning for Localization: A Privacy-Preserving Crowdsourcing Method</article-title><source>arXiv</source><year>2020</year><pub-id pub-id-type="doi">10.48550/arXiv.2001.01911</pub-id></element-citation></ref><ref id="B24-sensors-25-05397"><label>24.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Aladsani</surname><given-names>M.</given-names></name><name name-style="western"><surname>Trichopoulos</surname><given-names>G.</given-names></name><name name-style="western"><surname>Alkhateeb</surname><given-names>A.</given-names></name></person-group><article-title>Leveraging mmWave Imaging and Communications for Simultaneous Localization and Mapping</article-title><source>Proceedings of the ICASSP 2019&#8212;2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</source><conf-loc>Brighton, UK</conf-loc><conf-date>12&#8211;17 May 2019</conf-date><fpage>4534</fpage><lpage>4538</lpage><pub-id pub-id-type="doi">10.1109/ICASSP.2019.8682741</pub-id></element-citation></ref><ref id="B25-sensors-25-05397"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Khan</surname><given-names>M.Q.</given-names></name><name name-style="western"><surname>Gaber</surname><given-names>A.</given-names></name><name name-style="western"><surname>Parvini</surname><given-names>M.</given-names></name><name name-style="western"><surname>Schulz</surname><given-names>P.</given-names></name><name name-style="western"><surname>Fettweis</surname><given-names>G.</given-names></name></person-group><article-title>Multi-Task Learning for mmWave Transceiver Beam Prediction</article-title><source>IEEE Open J. Commun. Soc.</source><year>2025</year><volume>6</volume><fpage>5535</fpage><lpage>5551</lpage><pub-id pub-id-type="doi">10.1109/OJCOMS.2025.3583074</pub-id></element-citation></ref><ref id="B26-sensors-25-05397"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Abbas</surname><given-names>M.</given-names></name><name name-style="western"><surname>Kar</surname><given-names>K.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>T.</given-names></name></person-group><article-title>Leveraging Large Language Models for Wireless Symbol Detection via In-Context Learning</article-title><source>arXiv</source><year>2024</year><pub-id pub-id-type="doi">10.48550/arXiv.2409.00124</pub-id></element-citation></ref><ref id="B27-sensors-25-05397"><label>27.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>W.</given-names></name><name name-style="western"><surname>Yang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Yu</surname><given-names>S.</given-names></name><name name-style="western"><surname>Hu</surname><given-names>G.</given-names></name><name name-style="western"><surname>Wen</surname><given-names>C.</given-names></name><name name-style="western"><surname>Cheng</surname><given-names>M.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>C.</given-names></name></person-group><article-title>DiffLoc: Diffusion Model for Outdoor LiDAR Localization</article-title><source>Proceedings of the 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</source><conf-loc>Seattle, WA, USA</conf-loc><conf-date>16&#8211;22 June 2024</conf-date><fpage>15045</fpage><lpage>15054</lpage><pub-id pub-id-type="doi">10.1109/CVPR52733.2024.01425</pub-id></element-citation></ref><ref id="B28-sensors-25-05397"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Attaoui</surname><given-names>W.</given-names></name><name name-style="western"><surname>Bouraqia</surname><given-names>K.</given-names></name><name name-style="western"><surname>Sabir</surname><given-names>E.</given-names></name></person-group><article-title>Initial Access &amp; Beam Alignment for mmWave and Terahertz Communications</article-title><source>IEEE Access</source><year>2022</year><volume>10</volume><fpage>35363</fpage><lpage>35397</lpage><pub-id pub-id-type="doi">10.1109/access.2022.3161951</pub-id></element-citation></ref><ref id="B29-sensors-25-05397"><label>29.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Klautau</surname><given-names>A.</given-names></name><name name-style="western"><surname>Batista</surname><given-names>P.</given-names></name><name name-style="western"><surname>Gonz&#225;lez-Prelcic</surname><given-names>N.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Heath</surname><given-names>R.W.</given-names></name></person-group><article-title>5G MIMO Data for Machine Learning: Application to Beam-Selection Using Deep Learning</article-title><source>Proceedings of the 2018 Information Theory and Applications Workshop (ITA)</source><conf-loc>San Diego, CA, USA</conf-loc><conf-date>11&#8211;16 February 2018</conf-date><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1109/ITA.2018.8503086</pub-id></element-citation></ref><ref id="B30-sensors-25-05397"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>P.</given-names></name><name name-style="western"><surname>Yuan</surname><given-names>W.</given-names></name><name name-style="western"><surname>Fu</surname><given-names>J.</given-names></name><name name-style="western"><surname>Jiang</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Hayashi</surname><given-names>H.</given-names></name><name name-style="western"><surname>Neubig</surname><given-names>G.</given-names></name></person-group><article-title>Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing</article-title><source>ACM Comput. Surv.</source><year>2023</year><volume>55</volume><fpage>1</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1145/3560815</pub-id></element-citation></ref><ref id="B31-sensors-25-05397"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dong</surname><given-names>Q.</given-names></name><name name-style="western"><surname>Dai</surname><given-names>D.</given-names></name><name name-style="western"><surname>Zheng</surname><given-names>C.</given-names></name><name name-style="western"><surname>Wu</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Chang</surname><given-names>B.</given-names></name><name name-style="western"><surname>Sun</surname><given-names>X.</given-names></name><name name-style="western"><surname>Xu</surname><given-names>J.</given-names></name><name name-style="western"><surname>Li</surname><given-names>L.</given-names></name><name name-style="western"><surname>Sui</surname><given-names>Z.</given-names></name></person-group><article-title>A Survey on In-Context Learning</article-title><source>arXiv</source><year>2023</year><pub-id pub-id-type="doi">10.48550/arXiv.2301.00234</pub-id></element-citation></ref><ref id="B32-sensors-25-05397"><label>32.</label><element-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Morselli</surname><given-names>F.</given-names></name><name name-style="western"><surname>Razavi</surname><given-names>S.M.</given-names></name><name name-style="western"><surname>Rossi</surname><given-names>F.</given-names></name></person-group><article-title>Soft-Information-Based Localization for 5G Networks and Beyond</article-title><source>IEEE Trans. Wirel. Commun.</source><year>2023</year><comment><italic toggle="yes">early access</italic></comment><pub-id pub-id-type="doi">10.1109/TWC.2023.3275122</pub-id></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-05397-f001" orientation="portrait"><label>Figure 1</label><caption><p>Architecture of the GeoNR-PSW model, highlighting data collection, pre-processing, tokenization, few-shot prompting, and integration of PSW adapters with the LLM.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05397-g001.jpg"/></fig><fig position="float" id="sensors-25-05397-f002" orientation="portrait"><label>Figure 2</label><caption><p>Receiver trajectories for three episodes (XY view).</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05397-g002.jpg"/></fig><fig position="float" id="sensors-25-05397-f003" orientation="portrait"><label>Figure 3</label><caption><p>3D power heat-maps illustrating received power distribution for different episodes. Height encodes <italic toggle="yes">z</italic> (receiver height), and color encodes received power (dBm). (<bold>a</bold>) Visualization for Episode 0; (<bold>b</bold>) Visualization for Episode 15; (<bold>c</bold>) Visualization for Episode 30.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05397-g003.jpg"/></fig><fig position="float" id="sensors-25-05397-f004" orientation="portrait"><label>Figure 4</label><caption><p>Path statistics: (<bold>a</bold>) valid path count; (<bold>b</bold>) CDF of the ten strongest rays.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05397-g004.jpg"/></fig><fig position="float" id="sensors-25-05397-f005" orientation="portrait"><label>Figure 5</label><caption><p>Angular-domain energy distribution heat-maps and episode-wise Line-of-Sight (LOS) percentage. (<bold>a</bold>) Angle of Departure (AoD) heat-map in the azimuth-elevation domain for 2.8 GHz; (<bold>b</bold>) Angle of Departure (AoD) heat-map in the azimuth-elevation domain for 60 GHz; (<bold>c</bold>) Episode-wise LOS percentage, comparing 2.8 GHz and 60 GHz channels.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05397-g005.jpg"/></fig><fig position="float" id="sensors-25-05397-f006" orientation="portrait"><label>Figure 6</label><caption><p>Overview of the pre-processing pipeline&#8217;s impact on multipath ray data. (<bold>a</bold>) Power matrix for raw data; (<bold>b</bold>) Power matrix for filtered data; (<bold>c</bold>) Power matrix for normalized data; (<bold>d</bold>) Mean Angle of Departure (AoD) in the azimuth direction after filtering; (<bold>e</bold>) Mean Angle of Arrival (AoA) in the azimuth direction after filtering; (<bold>f</bold>) Missing path percentage after filtering.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05397-g006.jpg"/></fig><fig position="float" id="sensors-25-05397-f007" orientation="portrait"><label>Figure 7</label><caption><p>Training convergence of the proposed localization network. (<bold>a</bold>) 2.8 GHz; (<bold>b</bold>) 60 GHz. The left ordinate shows the training loss, while the right ordinate shows the validation errors.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05397-g007.jpg"/></fig><fig position="float" id="sensors-25-05397-f008" orientation="portrait"><label>Figure 8</label><caption><p>Predicted versus ground-truth 3D coordinates on the validation set. (<bold>a</bold>) 2.8 GHz; (<bold>b</bold>) 60 GHz.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05397-g008.jpg"/></fig><fig position="float" id="sensors-25-05397-f009" orientation="portrait"><label>Figure 9</label><caption><p>Few-shot adaptation results: (<bold>a</bold>) mean and median localization error (m) vs. number of reference frames <italic toggle="yes">k</italic> (log-scale); (<bold>b</bold>) relative change (%) of five error metrics with respect to the <inline-formula><mml:math id="mm58" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> baseline (blue = lower is better).</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05397-g009.jpg"/></fig><fig position="float" id="sensors-25-05397-f010" orientation="portrait"><label>Figure 10</label><caption><p>Localization error statistics versus training data ratio. (<bold>a</bold>) 2.8 GHz illustrated with a box plot; (<bold>b</bold>) 60 GHz illustrated with a violin plot.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05397-g010.jpg"/></fig><fig position="float" id="sensors-25-05397-f011" orientation="portrait"><label>Figure 11</label><caption><p>Empirical CDFs of 3D localization error for different training ratios. (<bold>a</bold>) 2.8 GHz. (<bold>b</bold>) 60 GHz.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05397-g011.jpg"/></fig><fig position="float" id="sensors-25-05397-f012" orientation="portrait"><label>Figure 12</label><caption><p>Model depth ablation. (<bold>a</bold>) GNN depth (<inline-formula><mml:math id="mm59" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mspace width="0.166667em"/><mml:mo>=</mml:mo><mml:mspace width="0.166667em"/></mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>6</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) on the two frequencies; (<bold>b</bold>) GPT-2 layers (<inline-formula><mml:math id="mm60" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mrow><mml:mspace width="0.166667em"/><mml:mo>=</mml:mo><mml:mspace width="0.166667em"/></mml:mrow><mml:mo>{</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>6</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) on the two frequencies. Each polygon encloses (mean, median, RMSE, <inline-formula><mml:math id="mm61" overflow="scroll"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>90</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>); a smaller area indicates better performance.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05397-g012.jpg"/></fig><table-wrap position="float" id="sensors-25-05397-t001" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05397-t001_Table 1</object-id><label>Table 1</label><caption><p>Raymobtime-<monospace>s007</monospace>: metadata and channel-path fields.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">File</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Field</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Units</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Description</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">CSV</td><td align="center" valign="middle" rowspan="1" colspan="1">EpisodeID</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8211;</td><td align="center" valign="middle" rowspan="1" colspan="1">Simulation episode (0&#8211;49)</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">CSV</td><td align="center" valign="middle" rowspan="1" colspan="1">SceneID</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8211;</td><td align="center" valign="middle" rowspan="1" colspan="1">Temporal scene inside episode (0&#8211;39)</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">CSV</td><td align="center" valign="middle" rowspan="1" colspan="1">VehicleArrayID</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8211;</td><td align="center" valign="middle" rowspan="1" colspan="1">Receiver index (0&#8211;9)</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">CSV</td><td align="center" valign="middle" rowspan="1" colspan="1">VehicleName</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8211;</td><td align="center" valign="middle" rowspan="1" colspan="1">SUMO vehicle tag</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">CSV</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm62" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">m</td><td align="center" valign="middle" rowspan="1" colspan="1">3D receiver coordinates</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">CSV</td><td align="center" valign="middle" rowspan="1" colspan="1">Val</td><td align="center" valign="middle" rowspan="1" colspan="1">V/I</td><td align="center" valign="middle" rowspan="1" colspan="1">Valid/invalid link flag</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">CSV</td><td align="center" valign="middle" rowspan="1" colspan="1">LOS</td><td align="center" valign="middle" rowspan="1" colspan="1">0/1</td><td align="center" valign="middle" rowspan="1" colspan="1">1 = line-of-sight to TX</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">HDF5</td><td align="center" valign="middle" rowspan="1" colspan="1">Power</td><td align="center" valign="middle" rowspan="1" colspan="1">dBm</td><td align="center" valign="middle" rowspan="1" colspan="1">Received power of path</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">HDF5</td><td align="center" valign="middle" rowspan="1" colspan="1">ToA</td><td align="center" valign="middle" rowspan="1" colspan="1">s</td><td align="center" valign="middle" rowspan="1" colspan="1">Time of arrival</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">HDF5</td><td align="center" valign="middle" rowspan="1" colspan="1">AoD&#160;(el,az)</td><td align="center" valign="middle" rowspan="1" colspan="1">&#176;</td><td align="center" valign="middle" rowspan="1" colspan="1">Angles of departure</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">HDF5</td><td align="center" valign="middle" rowspan="1" colspan="1">AoA&#160;(el,az)</td><td align="center" valign="middle" rowspan="1" colspan="1">&#176;</td><td align="center" valign="middle" rowspan="1" colspan="1">Angles of arrival</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">HDF5</td><td align="center" valign="middle" rowspan="1" colspan="1">LOS flag</td><td align="center" valign="middle" rowspan="1" colspan="1">0/1</td><td align="center" valign="middle" rowspan="1" colspan="1">1 = path is LOS</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">HDF5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Phase</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#176;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Ray phase (unused)</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05397-t002" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05397-t002_Table 2</object-id><label>Table 2</label><caption><p>Episode-level split used in this work.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Train (e0&#8211;e39)</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Val (e40&#8211;e44)</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Test (e45&#8211;e49)</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">2.8 GHz</td><td align="center" valign="middle" rowspan="1" colspan="1">7316</td><td align="center" valign="middle" rowspan="1" colspan="1">870</td><td align="center" valign="middle" rowspan="1" colspan="1">892</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">60 GHz</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7316</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">870</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">892</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05397-t003" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05397-t003_Table 3</object-id><label>Table 3</label><caption><p>Localization accuracy on the validation and test sets.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">Freq.</th><th colspan="4" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Validation (m)</th><th colspan="4" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Test (m)</th></tr><tr><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Mean
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Median
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
RMSE
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
90th
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Mean
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Median
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
RMSE
</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
90th
</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">2.8&#160;GHz</td><td align="center" valign="middle" rowspan="1" colspan="1">8.746</td><td align="center" valign="middle" rowspan="1" colspan="1">5.899</td><td align="center" valign="middle" rowspan="1" colspan="1">14.344</td><td align="center" valign="middle" rowspan="1" colspan="1">15.555</td><td align="center" valign="middle" rowspan="1" colspan="1">12.971</td><td align="center" valign="middle" rowspan="1" colspan="1">8.882</td><td align="center" valign="middle" rowspan="1" colspan="1">25.805</td><td align="center" valign="middle" rowspan="1" colspan="1">21.989</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">60&#160;GHz</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4.718</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3.249</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7.206</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8.477</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8.154</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5.630</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.360</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15.719</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">2.8&#160;GHz&#8594;60&#160;GHz</td><td colspan="4" align="center" valign="middle" rowspan="1">N/A</td><td align="center" valign="middle" rowspan="1" colspan="1">58.208</td><td align="center" valign="middle" rowspan="1" colspan="1">44.414</td><td align="center" valign="middle" rowspan="1" colspan="1">72.051</td><td align="center" valign="middle" rowspan="1" colspan="1">108.468</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">60&#160;GHz&#8594;2.8&#160;GHz</td><td colspan="4" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">N/A</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">101.776</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">105.748</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">116.924</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">168.088</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05397-t004" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05397-t004_Table 4</object-id><label>Table 4</label><caption><p>Comparison of localization error (in meters) between baseline models and the proposed method on the validation and test sets. Results are presented for both 2.8 GHz and 60 GHz frequency bands. The best-performing results from the proposed model are highlighted in bold.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Model</th><th colspan="4" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Validation</th><th colspan="4" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Test</th></tr><tr><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Mean
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Median
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
RMSE
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
90th
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Mean
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Median
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
RMSE
</th><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
90th
</th></tr></thead><tbody><tr><td colspan="9" align="left" valign="middle" style="border-bottom:solid thin" rowspan="1">
<bold>2.8 GHz</bold>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">MLP</td><td align="left" valign="middle" rowspan="1" colspan="1">16.81</td><td align="left" valign="middle" rowspan="1" colspan="1">12.57</td><td align="left" valign="middle" rowspan="1" colspan="1">22.66</td><td align="left" valign="middle" rowspan="1" colspan="1">33.08</td><td align="left" valign="middle" rowspan="1" colspan="1">19.86</td><td align="left" valign="middle" rowspan="1" colspan="1">14.21</td><td align="left" valign="middle" rowspan="1" colspan="1">30.06</td><td align="left" valign="middle" rowspan="1" colspan="1">40.08</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">GNN</td><td align="left" valign="middle" rowspan="1" colspan="1">13.36</td><td align="left" valign="middle" rowspan="1" colspan="1">9.05</td><td align="left" valign="middle" rowspan="1" colspan="1">19.37</td><td align="left" valign="middle" rowspan="1" colspan="1">27.09</td><td align="left" valign="middle" rowspan="1" colspan="1">16.30</td><td align="left" valign="middle" rowspan="1" colspan="1">10.16</td><td align="left" valign="middle" rowspan="1" colspan="1">27.38</td><td align="left" valign="middle" rowspan="1" colspan="1">32.99</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CNN</td><td align="left" valign="middle" rowspan="1" colspan="1">15.58</td><td align="left" valign="middle" rowspan="1" colspan="1">11.44</td><td align="left" valign="middle" rowspan="1" colspan="1">20.26</td><td align="left" valign="middle" rowspan="1" colspan="1">32.66</td><td align="left" valign="middle" rowspan="1" colspan="1">17.96</td><td align="left" valign="middle" rowspan="1" colspan="1">12.50</td><td align="left" valign="middle" rowspan="1" colspan="1">25.29</td><td align="left" valign="middle" rowspan="1" colspan="1">33.93</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">kNN</td><td align="left" valign="middle" rowspan="1" colspan="1">14.71</td><td align="left" valign="middle" rowspan="1" colspan="1">4.19</td><td align="left" valign="middle" rowspan="1" colspan="1">28.41</td><td align="left" valign="middle" rowspan="1" colspan="1">42.90</td><td align="left" valign="middle" rowspan="1" colspan="1">20.35</td><td align="left" valign="middle" rowspan="1" colspan="1">5.83</td><td align="left" valign="middle" rowspan="1" colspan="1">38.55</td><td align="left" valign="middle" rowspan="1" colspan="1">63.56</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Proposed Model</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>8.75</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>5.90</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>14.34</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>15.56</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>12.97</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>8.88</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>25.81</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>21.99</bold>
</td></tr><tr><td colspan="9" align="left" valign="middle" style="border-bottom:solid thin" rowspan="1">
<bold>60 GHz</bold>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">MLP</td><td align="left" valign="middle" rowspan="1" colspan="1">8.38</td><td align="left" valign="middle" rowspan="1" colspan="1">5.73</td><td align="left" valign="middle" rowspan="1" colspan="1">11.50</td><td align="left" valign="middle" rowspan="1" colspan="1">17.31</td><td align="left" valign="middle" rowspan="1" colspan="1">9.26</td><td align="left" valign="middle" rowspan="1" colspan="1">6.80</td><td align="left" valign="middle" rowspan="1" colspan="1">13.18</td><td align="left" valign="middle" rowspan="1" colspan="1">17.69</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">GNN</td><td align="left" valign="middle" rowspan="1" colspan="1">7.26</td><td align="left" valign="middle" rowspan="1" colspan="1">5.26</td><td align="left" valign="middle" rowspan="1" colspan="1">10.44</td><td align="left" valign="middle" rowspan="1" colspan="1">14.10</td><td align="left" valign="middle" rowspan="1" colspan="1">8.21</td><td align="left" valign="middle" rowspan="1" colspan="1">5.54</td><td align="left" valign="middle" rowspan="1" colspan="1">12.94</td><td align="left" valign="middle" rowspan="1" colspan="1">15.52</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CNN</td><td align="left" valign="middle" rowspan="1" colspan="1">9.40</td><td align="left" valign="middle" rowspan="1" colspan="1">7.92</td><td align="left" valign="middle" rowspan="1" colspan="1">10.99</td><td align="left" valign="middle" rowspan="1" colspan="1">16.06</td><td align="left" valign="middle" rowspan="1" colspan="1">10.22</td><td align="left" valign="middle" rowspan="1" colspan="1">8.34</td><td align="left" valign="middle" rowspan="1" colspan="1">12.16</td><td align="left" valign="middle" rowspan="1" colspan="1">18.02</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">kNN</td><td align="left" valign="middle" rowspan="1" colspan="1">5.39</td><td align="left" valign="middle" rowspan="1" colspan="1">1.34</td><td align="left" valign="middle" rowspan="1" colspan="1">13.21</td><td align="left" valign="middle" rowspan="1" colspan="1">15.47</td><td align="left" valign="middle" rowspan="1" colspan="1">6.39</td><td align="left" valign="middle" rowspan="1" colspan="1">1.49</td><td align="left" valign="middle" rowspan="1" colspan="1">15.53</td><td align="left" valign="middle" rowspan="1" colspan="1">18.31</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>Proposed Model</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>4.72</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>3.25</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>7.21</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>8.48</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>8.15</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>5.63</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>12.36</bold>
</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<bold>15.72</bold>
</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05397-t005" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05397-t005_Table 5</object-id><label>Table 5</label><caption><p>Few-shot localization accuracy (m) and improvement (% with regard to <inline-formula><mml:math id="mm66" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). The &#8595; symbol indicates that lower values are better, while the &#8593; symbol indicates that higher values are better.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Freq</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">
<italic toggle="yes">k</italic>
</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Mean &#8595;</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Median &#8595;</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">RMSE &#8595;</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">&#916;Mean (%) &#8593;</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">&#916;Median (%) &#8593;</th><th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">&#916;RMSE (%) &#8593;</th></tr></thead><tbody><tr><td rowspan="6" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">2.8&#160;GHz</td><td align="center" valign="middle" rowspan="1" colspan="1">0</td><td align="center" valign="middle" rowspan="1" colspan="1">24.70</td><td align="center" valign="middle" rowspan="1" colspan="1">13.09</td><td align="center" valign="middle" rowspan="1" colspan="1">53.06</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8211;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8211;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8211;</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">8.75</td><td align="center" valign="middle" rowspan="1" colspan="1">5.90</td><td align="center" valign="middle" rowspan="1" colspan="1">14.34</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm70" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>64.59</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm71" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>54.93</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm72" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>72.97</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">11.38</td><td align="center" valign="middle" rowspan="1" colspan="1">8.64</td><td align="center" valign="middle" rowspan="1" colspan="1">15.60</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm73" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>53.91</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm74" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>34.01</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm75" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>70.61</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">15.25</td><td align="center" valign="middle" rowspan="1" colspan="1">11.23</td><td align="center" valign="middle" rowspan="1" colspan="1">22.56</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm76" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>38.24</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm77" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>14.18</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm78" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>57.47</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">4</td><td align="center" valign="middle" rowspan="1" colspan="1">11.06</td><td align="center" valign="middle" rowspan="1" colspan="1">7.82</td><td align="center" valign="middle" rowspan="1" colspan="1">16.73</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm79" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>55.20</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm80" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>40.29</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm81" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>68.46</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.28</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9.41</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">16.66</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm82" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>50.29</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm83" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>28.06</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm84" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>68.60</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td rowspan="6" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">60&#160;GHz</td><td align="center" valign="middle" rowspan="1" colspan="1">0</td><td align="center" valign="middle" rowspan="1" colspan="1">10.01</td><td align="center" valign="middle" rowspan="1" colspan="1">6.91</td><td align="center" valign="middle" rowspan="1" colspan="1">13.85</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8211;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8211;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8211;</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">4.72</td><td align="center" valign="middle" rowspan="1" colspan="1">3.25</td><td align="center" valign="middle" rowspan="1" colspan="1">7.02</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm85" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>52.88</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm86" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>52.97</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm87" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>49.32</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">4.99</td><td align="center" valign="middle" rowspan="1" colspan="1">3.47</td><td align="center" valign="middle" rowspan="1" colspan="1">7.36</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm88" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>50.18</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm89" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>49.82</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm90" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>46.86</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">6.21</td><td align="center" valign="middle" rowspan="1" colspan="1">4.44</td><td align="center" valign="middle" rowspan="1" colspan="1">8.32</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm91" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>37.95</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm92" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>35.72</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm93" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>39.95</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">4</td><td align="center" valign="middle" rowspan="1" colspan="1">6.41</td><td align="center" valign="middle" rowspan="1" colspan="1">4.35</td><td align="center" valign="middle" rowspan="1" colspan="1">8.82</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm94" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>35.98</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm95" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>37.10</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm96" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>36.35</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7.30</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5.51</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9.29</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm97" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>27.12</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm98" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>20.20</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm99" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>32.91</mml:mn></mml:mrow></mml:mrow></mml:math>
</inline-formula>
</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05397-t006" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05397-t006_Table 6</object-id><label>Table 6</label><caption><p>Best-epoch localization statistics for each training data ratio.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Band</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Ratio</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Mean&#160;(m)</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Median&#160;(m)</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1"><inline-formula><mml:math id="mm100" overflow="scroll"><mml:mrow><mml:mstyle mathvariant="bold"><mml:msub><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mn>90</mml:mn></mml:msub></mml:mstyle></mml:mrow></mml:math></inline-formula>&#160;(m)</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Max&#160;(m)</th></tr></thead><tbody><tr><td rowspan="5" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">2.8&#160;GHz</td><td align="center" valign="middle" rowspan="1" colspan="1">0.2</td><td align="center" valign="middle" rowspan="1" colspan="1">16.77</td><td align="center" valign="middle" rowspan="1" colspan="1">9.92</td><td align="center" valign="middle" rowspan="1" colspan="1">33.93</td><td align="center" valign="middle" rowspan="1" colspan="1">182.46</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">0.4</td><td align="center" valign="middle" rowspan="1" colspan="1">12.08</td><td align="center" valign="middle" rowspan="1" colspan="1">7.80</td><td align="center" valign="middle" rowspan="1" colspan="1">21.26</td><td align="center" valign="middle" rowspan="1" colspan="1">146.41</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">0.6</td><td align="center" valign="middle" rowspan="1" colspan="1">10.30</td><td align="center" valign="middle" rowspan="1" colspan="1">7.09</td><td align="center" valign="middle" rowspan="1" colspan="1">18.18</td><td align="center" valign="middle" rowspan="1" colspan="1">142.75</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">0.8</td><td align="center" valign="middle" rowspan="1" colspan="1">9.57</td><td align="center" valign="middle" rowspan="1" colspan="1">6.42</td><td align="center" valign="middle" rowspan="1" colspan="1">18.50</td><td align="center" valign="middle" rowspan="1" colspan="1">157.89</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8.75</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5.90</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.34</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">170.22</td></tr><tr><td rowspan="5" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">60&#160;GHz</td><td align="center" valign="middle" rowspan="1" colspan="1">0.2</td><td align="center" valign="middle" rowspan="1" colspan="1">8.19</td><td align="center" valign="middle" rowspan="1" colspan="1">5.94</td><td align="center" valign="middle" rowspan="1" colspan="1">15.17</td><td align="center" valign="middle" rowspan="1" colspan="1">177.36</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">0.4</td><td align="center" valign="middle" rowspan="1" colspan="1">6.54</td><td align="center" valign="middle" rowspan="1" colspan="1">4.31</td><td align="center" valign="middle" rowspan="1" colspan="1">11.89</td><td align="center" valign="middle" rowspan="1" colspan="1">70.98</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">0.6</td><td align="center" valign="middle" rowspan="1" colspan="1">5.65</td><td align="center" valign="middle" rowspan="1" colspan="1">4.23</td><td align="center" valign="middle" rowspan="1" colspan="1">10.73</td><td align="center" valign="middle" rowspan="1" colspan="1">75.07</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">0.8</td><td align="center" valign="middle" rowspan="1" colspan="1">5.51</td><td align="center" valign="middle" rowspan="1" colspan="1">4.19</td><td align="center" valign="middle" rowspan="1" colspan="1">10.06</td><td align="center" valign="middle" rowspan="1" colspan="1">77.44</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4.72</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3.25</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8.48</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">90.67</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05397-t007" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05397-t007_Table 7</object-id><label>Table 7</label><caption><p>Raw localization errors for every depth configuration on <inline-formula><mml:math id="mm101" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="sans-serif">fr</mml:mi><mml:mn mathvariant="sans-serif">1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>2.8</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>&#160;GHz and <inline-formula><mml:math id="mm102" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="sans-serif">fr</mml:mi><mml:mn mathvariant="sans-serif">2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>60</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>&#160;GHz.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">
</th><th colspan="4" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">2.8&#160;GHz</th><th colspan="4" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">60&#160;GHz</th></tr><tr><th align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Layer_Index
</th><th align="right" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Mean
</th><th align="right" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Median
</th><th align="right" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
RMSE
</th><th align="right" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm103" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mn mathvariant="bold">90</mml:mn></mml:msub></mml:mrow></mml:math>
</inline-formula>
</th><th align="right" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Mean
</th><th align="right" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
Median
</th><th align="right" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
RMSE
</th><th align="right" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula>
<mml:math id="mm104" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mn mathvariant="bold">90</mml:mn></mml:msub></mml:mrow></mml:math>
</inline-formula>
</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">2*0_0*0_0</td><td align="right" valign="middle" rowspan="1" colspan="1">9.700</td><td align="right" valign="middle" rowspan="1" colspan="1">6.933</td><td align="right" valign="middle" rowspan="1" colspan="1">14.060</td><td align="right" valign="middle" rowspan="1" colspan="1">16.774</td><td align="right" valign="middle" rowspan="1" colspan="1">5.671</td><td align="right" valign="middle" rowspan="1" colspan="1">4.363</td><td align="right" valign="middle" rowspan="1" colspan="1">7.641</td><td align="right" valign="middle" rowspan="1" colspan="1">10.401</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">4*0_0*0_0</td><td align="right" valign="middle" rowspan="1" colspan="1">8.940</td><td align="right" valign="middle" rowspan="1" colspan="1">6.600</td><td align="right" valign="middle" rowspan="1" colspan="1">13.496</td><td align="right" valign="middle" rowspan="1" colspan="1">15.642</td><td align="right" valign="middle" rowspan="1" colspan="1">5.749</td><td align="right" valign="middle" rowspan="1" colspan="1">3.915</td><td align="right" valign="middle" rowspan="1" colspan="1">8.026</td><td align="right" valign="middle" rowspan="1" colspan="1">11.153</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">6*0_0*0_0</td><td align="right" valign="middle" rowspan="1" colspan="1">9.769</td><td align="right" valign="middle" rowspan="1" colspan="1">7.457</td><td align="right" valign="middle" rowspan="1" colspan="1">14.646</td><td align="right" valign="middle" rowspan="1" colspan="1">16.598</td><td align="right" valign="middle" rowspan="1" colspan="1">6.033</td><td align="right" valign="middle" rowspan="1" colspan="1">4.476</td><td align="right" valign="middle" rowspan="1" colspan="1">7.709</td><td align="right" valign="middle" rowspan="1" colspan="1">11.281</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">2*0_4*0_4</td><td align="right" valign="middle" rowspan="1" colspan="1">9.700</td><td align="right" valign="middle" rowspan="1" colspan="1">6.933</td><td align="right" valign="middle" rowspan="1" colspan="1">14.060</td><td align="right" valign="middle" rowspan="1" colspan="1">16.774</td><td align="right" valign="middle" rowspan="1" colspan="1">5.671</td><td align="right" valign="middle" rowspan="1" colspan="1">4.363</td><td align="right" valign="middle" rowspan="1" colspan="1">7.641</td><td align="right" valign="middle" rowspan="1" colspan="1">10.401</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">4*0_4*0_4</td><td align="right" valign="middle" rowspan="1" colspan="1">8.756</td><td align="right" valign="middle" rowspan="1" colspan="1">5.902</td><td align="right" valign="middle" rowspan="1" colspan="1">14.340</td><td align="right" valign="middle" rowspan="1" colspan="1">17.665</td><td align="right" valign="middle" rowspan="1" colspan="1">5.493</td><td align="right" valign="middle" rowspan="1" colspan="1">4.140</td><td align="right" valign="middle" rowspan="1" colspan="1">7.541</td><td align="right" valign="middle" rowspan="1" colspan="1">10.131</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">6*0_4*0_4</td><td align="right" valign="middle" rowspan="1" colspan="1">9.389</td><td align="right" valign="middle" rowspan="1" colspan="1">6.409</td><td align="right" valign="middle" rowspan="1" colspan="1">13.843</td><td align="right" valign="middle" rowspan="1" colspan="1">17.339</td><td align="right" valign="middle" rowspan="1" colspan="1">5.697</td><td align="right" valign="middle" rowspan="1" colspan="1">4.446</td><td align="right" valign="middle" rowspan="1" colspan="1">7.684</td><td align="right" valign="middle" rowspan="1" colspan="1">11.134</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">2*0_1_4*0_1_4</td><td align="right" valign="middle" rowspan="1" colspan="1">9.575</td><td align="right" valign="middle" rowspan="1" colspan="1">7.210</td><td align="right" valign="middle" rowspan="1" colspan="1">14.367</td><td align="right" valign="middle" rowspan="1" colspan="1">16.979</td><td align="right" valign="middle" rowspan="1" colspan="1">5.955</td><td align="right" valign="middle" rowspan="1" colspan="1">4.484</td><td align="right" valign="middle" rowspan="1" colspan="1">8.321</td><td align="right" valign="middle" rowspan="1" colspan="1">10.716</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">4*0_1_4*0_1_4</td><td align="right" valign="middle" rowspan="1" colspan="1">10.268</td><td align="right" valign="middle" rowspan="1" colspan="1">8.099</td><td align="right" valign="middle" rowspan="1" colspan="1">14.253</td><td align="right" valign="middle" rowspan="1" colspan="1">18.779</td><td align="right" valign="middle" rowspan="1" colspan="1">6.006</td><td align="right" valign="middle" rowspan="1" colspan="1">4.536</td><td align="right" valign="middle" rowspan="1" colspan="1">7.797</td><td align="right" valign="middle" rowspan="1" colspan="1">11.875</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">6*0_1_4*0_1_4</td><td align="right" valign="middle" rowspan="1" colspan="1">9.678</td><td align="right" valign="middle" rowspan="1" colspan="1">7.283</td><td align="right" valign="middle" rowspan="1" colspan="1">13.937</td><td align="right" valign="middle" rowspan="1" colspan="1">19.387</td><td align="right" valign="middle" rowspan="1" colspan="1">5.897</td><td align="right" valign="middle" rowspan="1" colspan="1">4.477</td><td align="right" valign="middle" rowspan="1" colspan="1">7.759</td><td align="right" valign="middle" rowspan="1" colspan="1">10.931</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">2*0_2_4*0_2_4</td><td align="right" valign="middle" rowspan="1" colspan="1">9.718</td><td align="right" valign="middle" rowspan="1" colspan="1">7.170</td><td align="right" valign="middle" rowspan="1" colspan="1">14.834</td><td align="right" valign="middle" rowspan="1" colspan="1">17.155</td><td align="right" valign="middle" rowspan="1" colspan="1">5.031</td><td align="right" valign="middle" rowspan="1" colspan="1">3.411</td><td align="right" valign="middle" rowspan="1" colspan="1">7.121</td><td align="right" valign="middle" rowspan="1" colspan="1">9.800</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">4*0_2_4*0_2_4</td><td align="right" valign="middle" rowspan="1" colspan="1">10.492</td><td align="right" valign="middle" rowspan="1" colspan="1">8.045</td><td align="right" valign="middle" rowspan="1" colspan="1">15.172</td><td align="right" valign="middle" rowspan="1" colspan="1">19.251</td><td align="right" valign="middle" rowspan="1" colspan="1">4.718</td><td align="right" valign="middle" rowspan="1" colspan="1">3.249</td><td align="right" valign="middle" rowspan="1" colspan="1">7.206</td><td align="right" valign="middle" rowspan="1" colspan="1">8.477</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6*0_2_4*0_2_4</td><td align="right" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10.370</td><td align="right" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8.205</td><td align="right" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">14.916</td><td align="right" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">17.638</td><td align="right" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5.883</td><td align="right" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4.554</td><td align="right" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7.997</td><td align="right" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">10.949</td></tr></tbody></table></table-wrap></floats-group></article></pmc-articleset>