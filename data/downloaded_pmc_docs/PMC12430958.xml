<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xml:lang="en" article-type="research-article" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="pmc-domain-id">1660</journal-id><journal-id journal-id-type="pmc-domain">sensors</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>Multidisciplinary Digital Publishing Institute  (MDPI)</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12430958</article-id><article-id pub-id-type="pmcid-ver">PMC12430958.1</article-id><article-id pub-id-type="pmcaid">12430958</article-id><article-id pub-id-type="pmcaiid">12430958</article-id><article-id pub-id-type="doi">10.3390/s25175423</article-id><article-id pub-id-type="publisher-id">sensors-25-05423</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>A Formative Assessment System in Baduanjin Physical Education Based on Inertial Measurement Unit Motion Capture</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0006-8219-8189</contrib-id><name name-style="western"><surname>Ma</surname><given-names initials="X">Xinyi</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#8211; original draft</role><xref rid="af1-sensors-25-05423" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0003-6720-9909</contrib-id><name name-style="western"><surname>Shao</surname><given-names initials="M">Mingrui</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><xref rid="af1-sensors-25-05423" ref-type="aff">1</xref><xref rid="c1-sensors-25-05423" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-3006-4545</contrib-id><name name-style="western"><surname>Feng</surname><given-names initials="X">Xiaowei</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><xref rid="af2-sensors-25-05423" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Du</surname><given-names initials="W">Weiping</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><xref rid="af3-sensors-25-05423" ref-type="aff">3</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Yi</surname><given-names initials="Q">Qing</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><xref rid="af4-sensors-25-05423" ref-type="aff">4</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Chi</surname><given-names initials="P">Puyan</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><xref rid="af5-sensors-25-05423" ref-type="aff">5</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-1160-3777</contrib-id><name name-style="western"><surname>Li</surname><given-names initials="H">Hai</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><xref rid="af4-sensors-25-05423" ref-type="aff">4</xref><xref rid="af6-sensors-25-05423" ref-type="aff">6</xref><xref rid="c1-sensors-25-05423" ref-type="corresp">*</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name name-style="western"><surname>Peham</surname><given-names initials="C">Christian</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-05423"><label>1</label>School of Physical Education, Shanghai Normal University, Shanghai 201418, China; <email>1000569030@smail.shnu.edu.cn</email></aff><aff id="af2-sensors-25-05423"><label>2</label>School of Physical Education, Hainan Normal University, Haikou 571158, China</aff><aff id="af3-sensors-25-05423"><label>3</label>School of Physical Education, Ningxia Normal University, Guyuan 756099, China</aff><aff id="af4-sensors-25-05423"><label>4</label>Faculty of Sports and Exercise Science, University of Malaya, Kuala Lumpur 50603, Malaysia</aff><aff id="af5-sensors-25-05423"><label>5</label>Department of Physical Education, Shanghai Maritime University, Shanghai 201306, China</aff><aff id="af6-sensors-25-05423"><label>6</label>College of Sport, Neijiang Normal University, Neijiang 641100, China</aff><author-notes><corresp id="c1-sensors-25-05423"><label>*</label>Correspondence: <email>1000548576@smail.shnu.edu.cn</email> (M.S.); <email>10000861@njtc.edu.cn</email> (H.L.)</corresp></author-notes><pub-date pub-type="epub"><day>02</day><month>9</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>9</month><year>2025</year></pub-date><volume>25</volume><issue>17</issue><issue-id pub-id-type="pmc-issue-id">496815</issue-id><elocation-id>5423</elocation-id><history><date date-type="received"><day>20</day><month>6</month><year>2025</year></date><date date-type="rev-recd"><day>19</day><month>8</month><year>2025</year></date><date date-type="accepted"><day>28</day><month>8</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>02</day><month>09</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>13</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-13 17:25:36.317"><day>13</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="sensors-25-05423.pdf"/><abstract><p>Traditional assessment methods in physical education often emphasize final grades, lacking real-time monitoring and feedback during the learning process. To address this limitation and enhance the formative evaluation of student performance, this study proposes a real-time assessment system for Baduanjin instruction in physical education, utilizing a commercially available inertial measurement unit-based motion capture device. The system was developed in four stages. First, a dataset was created by recruiting 20 university students and one expert physical education instructor. Participants were asked to perform standardized Baduanjin routines while wearing wireless inertial measurement unit sensors on key body joints. The collected kinematic data, sampled at 100 Hz, included joint angles and movement trajectories. Second, preprocessing and feature extraction techniques were applied to the raw data to construct a labeled dataset for training. Third, supervised machine learning algorithms were used to build models for motion type recognition and motion accuracy evaluation. Model performance was assessed using cross-validation and compared with expert evaluations. Finally, a user-facing formative assessment system was developed and tested in a controlled classroom environment. The system demonstrated a high motion recognition accuracy of 99.77%, and the correlation coefficient between system-assessed motion accuracy and expert ratings exceeded 0.80, indicating strong validity. The results demonstrate that the formative assessment system built on inertial measurement unit is appropriate for the Baduanjin physical education.</p></abstract><kwd-group><kwd>physical education</kwd><kwd>Baduanijn</kwd><kwd>inertial measurement unit</kwd><kwd>motion capture</kwd><kwd>formative assessment</kwd></kwd-group><funding-group><funding-statement>This research received no external funding.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-05423"><title>1. Introduction</title><p>Traditionally, educational evaluation has focused on the ultimate achievement of students at a given point in time. Formative evaluation breaks this pattern and shifts the focus to the whole process of learning. Formative assessment is a method of educational evaluation that emphasizes real-time observation, feedback, and guidance of students during the learning process [<xref rid="B1-sensors-25-05423" ref-type="bibr">1</xref>]. Through continuous monitoring and timely feedback of students&#8217; learning processes, formative assessment provides educators with a powerful tool to improve students&#8217; comprehensive literacy in sports activities [<xref rid="B2-sensors-25-05423" ref-type="bibr">2</xref>]. In physical education (PE) teaching, formative assessment is not only a tool, but also a key factor to promote students&#8217; all-round development [<xref rid="B3-sensors-25-05423" ref-type="bibr">3</xref>].</p><p>In the context of physical education, formative assessment serves as a dynamic and process-oriented feedback mechanism that has increasingly been recognized as a crucial approach for enhancing both student learning outcomes and instructional quality [<xref rid="B4-sensors-25-05423" ref-type="bibr">4</xref>]. Unlike summative assessment, which focuses on evaluating final performance, formative assessment emphasizes continuous feedback, diagnosis, and instructional adjustment during the learning process [<xref rid="B5-sensors-25-05423" ref-type="bibr">5</xref>]. This approach is particularly valuable in skill-based physical education activities, such as Baduanjin or Tai Chi, where students exhibit considerable individual variability, and final performance alone is insufficient to reflect their learning trajectories. Baduanjin is a traditional Chinese Qigong exercise that dates back to the Song Dynasty (960&#8211;1279 AD). Unlike vigorous physical exercise, Baduanjin is characterized by a low-to-moderate intensity and is suitable for individuals across age groups, including older adults and patients with chronic conditions. Each movement targets different muscle groups and is believed to promote energy flow (Qi), improve flexibility, and enhance mind&#8211;body coordination. Given its accessibility and holistic benefits, Baduanjin has been widely implemented as a non-pharmacological intervention in physical and cognitive health programs [<xref rid="B6-sensors-25-05423" ref-type="bibr">6</xref>,<xref rid="B7-sensors-25-05423" ref-type="bibr">7</xref>]. A complete demonstration of the Baduanjin routine can be accessed online at <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.youtube.com/watch?v=bZhlLAoDzPA">https://www.youtube.com/watch?v=bZhlLAoDzPA</uri>, accessed on 14 March 2023. The details of each motion are provided in manuscript-<xref rid="app1-sensors-25-05423" ref-type="app">Supplementary S1</xref>. Through formative assessment, instructors can identify subtle errors in movement execution, provide timely and personalized feedback, and ultimately support students in developing body awareness, self-regulation, and autonomous learning skills. Furthermore, recent studies have demonstrated that integrating digital tools, such as wearable devices and motion capture systems, into formative assessment enhances the objectivity and precision of evaluations while also increasing students&#8217; engagement and motivation [<xref rid="B8-sensors-25-05423" ref-type="bibr">8</xref>].</p><p>In implementing formative assessment, various methods are employed in physical education to comprehensively understand students&#8217; performance during physical activities. These methods include real-time observation and feedback, student self-assessment, peer evaluation, and video analysis [<xref rid="B5-sensors-25-05423" ref-type="bibr">5</xref>,<xref rid="B9-sensors-25-05423" ref-type="bibr">9</xref>,<xref rid="B10-sensors-25-05423" ref-type="bibr">10</xref>]. While these approaches facilitate timely correction of students&#8217; movements and provide guidance, they also exhibit certain limitations. Specifically, subjective assessments such as real-time observation and peer evaluation may suffer from inconsistencies in evaluation criteria, thereby compromising the objectivity of assessment [<xref rid="B11-sensors-25-05423" ref-type="bibr">11</xref>]. Moreover, some assessment methods may be time-consuming, particularly when dealing with a large number of students, making it challenging for teachers to provide feedback and correction for each individual student&#8217;s movements [<xref rid="B12-sensors-25-05423" ref-type="bibr">12</xref>,<xref rid="B13-sensors-25-05423" ref-type="bibr">13</xref>]. Additionally, the utilization of technological aids is constrained by equipment limitations and insufficient school resources, resulting in some students being unable to fully benefit from such tools. Therefore, it is increasingly necessary to construct an objective, automated, and scalable movement assessment tool in physical education that can provide real-time, data-driven support for formative assessment.</p><p>The integration of digital technologies into PE teaching, such as motion capture systems, computer vision, and wearable sensors, has opened up new opportunities for formative assessment [<xref rid="B14-sensors-25-05423" ref-type="bibr">14</xref>]. Among them, inertial measurement unit (IMU)-based motion capture technology has demonstrated high potential due to its low cost, portability, and ability to provide objective quantitative data on body movements in real-time [<xref rid="B14-sensors-25-05423" ref-type="bibr">14</xref>,<xref rid="B15-sensors-25-05423" ref-type="bibr">15</xref>,<xref rid="B16-sensors-25-05423" ref-type="bibr">16</xref>]. Previous studies have applied IMU in domains such as gait analysis, rehabilitation, and athletic training to track movement patterns, assess motion quality, and provide biofeedback [<xref rid="B17-sensors-25-05423" ref-type="bibr">17</xref>,<xref rid="B18-sensors-25-05423" ref-type="bibr">18</xref>]. Recent studies have demonstrated the growing potential of wearable IMUs in sports and human motion analysis. Deep learning models trained on raw IMU data can achieve high accuracy in estimating motion speed, especially when sensors are placed on the lower limbs, such as the shoe [<xref rid="B19-sensors-25-05423" ref-type="bibr">19</xref>]. Distributed IMU arrays have also been successfully applied in outdoor sports equipment testing, such as skill evaluation, enabling objective, high-frequency data collection in real-world conditions [<xref rid="B20-sensors-25-05423" ref-type="bibr">20</xref>]. As wearable technology advances, IMUs and GPS sensors are becoming increasingly central in delivering real-time, personalized feedback in both professional and consumer sports contexts [<xref rid="B21-sensors-25-05423" ref-type="bibr">21</xref>].</p><p>Furthermore, recent pedagogical research emphasizes that technological innovation in formative assessment must be grounded in both educational theory and subject-specific practice. Digital assessment tools can foster more individualized, inclusive, and efficient PE learning environments by enabling real-time feedback, self-regulation, and teacher support [<xref rid="B18-sensors-25-05423" ref-type="bibr">18</xref>]. Thus, integrating IMU into PE instruction aligns with current trends in evidence-based pedagogical reform. Baduanjin, a traditional Chinese qigong routine consisting of eight standardized movements, is widely used in school and community physical education for its safety, accessibility, and benefits to both physical and mental health [<xref rid="B22-sensors-25-05423" ref-type="bibr">22</xref>,<xref rid="B23-sensors-25-05423" ref-type="bibr">23</xref>,<xref rid="B24-sensors-25-05423" ref-type="bibr">24</xref>]. However, its accurate practice requires coordination of body posture, balance, and breathing rhythm&#8212;making it challenging to evaluate in large-group PE classes using subjective observation alone.</p><p>The present study aims to develop an objective movement assessment system using IMU to support formative assessment in Baduanjin-based PE. The system is designed to recognize motion sequences and evaluate motion accuracy based on predefined criteria, enabling teachers to receive accurate real-time feedback on students&#8217; practice. This research not only contributes to the development of innovative assessment tools but also bridges modern technology and traditional physical culture. By establishing this objective assessment framework, we seek to empower physical educators with evidence-based tools to enhance teaching efficiency, support personalized learning, and improve overall instructional quality in PE.</p></sec><sec sec-type="methods" id="sec2-sensors-25-05423"><title>2. Methods</title><sec sec-type="subjects" id="sec2dot1-sensors-25-05423"><title>2.1. Study Design and Participants</title><p>This study employed a quasi-experimental, cross-sectional design to evaluate whether an IMU-based motion capture system (Perception Neuron 2.0) can effectively differentiate Baduanjin motion accuracy across learners with different experience levels. A total of 20 undergraduate students (aged 18&#8211;22 years; 12 females and 8 males) from a university in Southwest China participated. They were assigned to either a Novice Group (<italic toggle="yes">n</italic> = 9) or an Experienced Group (<italic toggle="yes">n</italic> = 11) based on whether they had completed and passed the university&#8217;s Baduanjin course. Novice participants had no previous experience in Baduanjin and received a 30 min introductory session before motion capture. Expert grading was performed independently by two instructors with over ten years of Chinese martial arts teaching experience. All evaluation data were anonymized by replacing student names with randomly assigned participant IDs, and no identifying information was provided to the evaluators. The experts were blinded to participants&#8217; experience levels and group assignments. Inclusion criteria required that participants had no previous formal instruction in Baduanjin, demonstrated the physical capacity to engage in low-to-moderate intensity exercise as verified through a pre-participation health screening, and provided written informed consent prior to enrolment. Participants were excluded if they presented with musculoskeletal injuries, cardiovascular disorders, or other medical conditions likely to interfere with safe participation; possessed advanced or competitive-level training experience in martial arts, Tai Chi, or Qigong; were unable to commit to the full schedule of instructional and assessment sessions; or accumulated an absence rate exceeding 20% over the course of the intervention. Ethical approval was obtained from the Research Ethics Committee of the University of Malaya (UM.TNC2/UMREC-558), and informed consent was collected from all participants.</p></sec><sec id="sec2dot2-sensors-25-05423"><title>2.2. Procedure</title><p>This research is divided into three stages (<xref rid="sensors-25-05423-f001" ref-type="fig">Figure 1</xref>). Stage 1 assessed the capability of the IMU system to differentiate between motion accuracy levels. Stage 2 involved the development and verification of motion recognition methods using a labeled dataset of Baduanjin movements. Stage 3 implemented and evaluated the formative assessment system in an actual Baduanjin PE course. In section one, two groups of students with different motor accuracy levels of Baduanjin were recruited to verify the ability of IMU MoCap to distinguish the difference between the motion accuracy. In section two, methods for assessing and recognizing Baduanjin motions were developed and verified using a dataset of Baduanjin motions. Students and teachers from a university in southwestern China were recruited to create the database of Baduanjin motions. In this study, the verified methods are two commonly used types of methods for recognizing motions: sample-based and sequence-based methods. The final section applied the selected methods to develop a formative assessment system in Baduanjin PE and evaluated the system&#8217;s efficacy in Baduanjin courses. Students were recruited to test and record their Baduanjin motions while teaching Baduanjin using the built system.</p></sec><sec id="sec2dot3-sensors-25-05423"><title>2.3. Stage 1: Verifying IMU Effectiveness in Accuracy of Baduanjin Motions Discrimination</title><p>This study employed a commercial IMU system, the Perception Neuron 2.0 (Noitom Technology, Miami, FL, USA, 2018)), which has been widely used in motion capture research [<xref rid="B25-sensors-25-05423" ref-type="bibr">25</xref>,<xref rid="B26-sensors-25-05423" ref-type="bibr">26</xref>]. To our knowledge, no prior research has investigated the use of an IMU to distinguish the motion accuracy of Baduanjin movements. Each participant completed three motion capture trials using the Perception Neuron 2.0 system, following standardized instructions and wearing the full-body IMU suit (<xref rid="sensors-25-05423-f002" ref-type="fig">Figure 2</xref>). The captured data were processed to extract joint rotation data, which were then converted into quaternion format for analysis. The dynamic time warping (DTW) algorithm was used to compare student performance with the expert model, providing quantitative distance measures that represent motion accuracy.</p><p>Perception Neuron 2.0 contains multiple inertial sensor units, including a three-axis gyroscope, three-axis accelerometer, and three-axis magnetometer [<xref rid="B27-sensors-25-05423" ref-type="bibr">27</xref>]. A total of 17 inertial sensing units were used in the investigation. The output file for the motion data captured by Perception Neuron 2.0 is the Biovision Hierarchy (BVH) file generated by the supporting software (Axis Neuron Pro, version 3.8, Noitom Technology, Miami, FL, USA)) of Perception Neuron 2.0. The BVH file format was established to store skeleton information and motion data [<xref rid="B28-sensors-25-05423" ref-type="bibr">28</xref>]. In this research, the rotation data for each skeleton point in the BVH of motions was extracted to identify and assess motions. BVH skeletons are formed of 17 skeleton points, and rotation data is expressed in Euler angles. The rotation data was transformed into quaternions because Euler angles have gimbal lock and singularity [<xref rid="B16-sensors-25-05423" ref-type="bibr">16</xref>,<xref rid="B24-sensors-25-05423" ref-type="bibr">24</xref>]. All participants completed three motion captures using Perception Neuron 2.0. The novice group captured the motions immediately after 30 min of initial Baduanjin learning. The captured motion data were converted into quaternions and used dynamic time warping (DTW) to calculate the distances between the standard motions (captured from the invited teacher) and the motions of the two student groups to assess the motion accuracy of the students&#8217; motions [<xref rid="B18-sensors-25-05423" ref-type="bibr">18</xref>]. Since the captured motions consist of 17 skeleton points, it is necessary to calculate the distances between the corresponding skeletal points through DTW and then average the distances. In addition, considering the issue of the wrong matching by excessive time warping in DTW, the global warping window was set as 10% of the entire window span in this research to constrain the warp path to be near the diagonal of the matrix [<xref rid="B29-sensors-25-05423" ref-type="bibr">29</xref>].</p></sec><sec id="sec2dot4-sensors-25-05423"><title>2.4. Stage 2: Development and Verification of Motion Recognition Methods</title><p>In the research, two common different types of methods (the sample-based and the sequence-based methods) were applied to assess the motion accuracy and recognize the motions within Baduanjin. In the sample-based methods, the features were extracted from the motion data and reduced in dimensionality to prevent data redundancy. In sequence-based methods, keyframes were extracted to prevent data redundancy and reduce processing time. Both methods were classification methods that used supervised learning based on the dataset of Baduanjin motions captured by students and teachers. Motions were assigned labels for motion accuracy or motion name. The methods used the motion data to train the classifiers based on the labels. After the model parameters of the classifier were trained, unlabeled motions could be classified. Experts in Baduanjin were invited to grade the motion accuracy of the captured motions, and then use the assessment result as labels to train the classifiers.</p><sec id="sec2dot4dot1-sensors-25-05423"><title>2.4.1. Developing a Dataset of Baduanjin Motions</title><p>In this research, the dataset of Baduanjin motions was captured from undergraduate students, including 20 students and 1 professional teacher recruited in the first stage and 35 students recruited later. The dataset includes all eight standard Baduanjin motions, as described in manuscript-<xref rid="app1-sensors-25-05423" ref-type="app">Supplementary S1</xref>. The second batch of recruited students carried out the Baduanjin motions once. Two professional Chinese martial art teachers with more than ten years of experience teaching Baduanjin at the university were invited to assess the motion accuracy according to the videos recorded when capturing the students&#8217; motions. The assessment applied the grading method used in the Baduanjin course in which the motion accuracy of Baduanjin motions is divided into three grades: Fail, Pass, and Good. The Kendall test for the assessment results of the two teachers shows that the Kendall consistency of the evaluation of the eight Baduanjin movements is above 0.8, indicating that the assessment of the teachers is highly consistent.</p></sec><sec id="sec2dot4dot2-sensors-25-05423"><title>2.4.2. The Sample-Based Methods</title><p>In sample-based methods, each motion is represented by features taken from motion data. The multiple classifier models are trained on the extracted features and the labels of motions and used to classify unlabeled motions. Previous researchers have used time-domain, frequency-domain, and wavelet features to extract features to recognize motions [<xref rid="B30-sensors-25-05423" ref-type="bibr">30</xref>,<xref rid="B31-sensors-25-05423" ref-type="bibr">31</xref>]. This research obtained time-domain features such as mean, variance, standard deviation, skewness, kurtosis, and quartile deviation. Since the motion data comprises 17 skeleton points, the number of features extracted by one motion dataset was 17 &#215; 3 &#215; 6 = 306. The extracted features need to be normalized and reduced dimensionality for subsequent training models. The extracted features were normalized to the range [0, 1], and Principal component analysis was used to reduce the dimensionality of features [<xref rid="B32-sensors-25-05423" ref-type="bibr">32</xref>]. Based on the features and labels of motions, the classifiers, including <italic toggle="yes">k</italic>-Nearest Neighbor (<italic toggle="yes">k</italic>-NN), Support Vector Machines (SVM), Naive Bayes (NB), Logistic Regression, Decision Tree (DT), Back Propagation neural network (BPNN), Radial basis function neural network (RBFNN) and One-dimensional CNN (1D-CNN) were trained to assess and recognize motions. The sample-based methods involved in this research were constructed and verified using Matlab 2020b as the platform.</p></sec><sec id="sec2dot4dot3-sensors-25-05423"><title>2.4.3. The Sequence-Based Methods</title><p>The difference from sample-based methods is that frequency-based methods do not extract features but analyze motion data on quaternions as time-series data. Considering the limited storage space and bandwidth capacity available to users in teaching, extracting keyframes is used to reduce motion data to improve application adaptability. The study used k-means clustering to extract keyframes corresponding to the compression rate using a preset compression rate [<xref rid="B33-sensors-25-05423" ref-type="bibr">33</xref>]. In order to confirm the efficacy of extracting keyframes and obtain a reasonable compression ratio, the interpolation method was applied for reconstructing motions, calculating motion reconstruction error, and then setting the extraction compression ratio to 15% [<xref rid="B34-sensors-25-05423" ref-type="bibr">34</xref>,<xref rid="B35-sensors-25-05423" ref-type="bibr">35</xref>]. Based on the keyframes and labels of motions, the sequence-based methods, including DTW combined with classifiers (<italic toggle="yes">k</italic>-NN, SVM, NB, Logistic Regression, DT, BPNN, and RBFNN), Hidden Markov Model (HMM), and Long Short-Term Memory (LSTM), Bidirectional LSTM (BiLTSM), and Gated Recurrent Units (GRUs), were applied to train the models to assess and recognize motions. The frequency-based methods involved in this research were constructed and verified using Matlab 2020b as the platform.</p></sec></sec><sec id="sec2dot5-sensors-25-05423"><title>2.5. Stage 3: Developing a Formative Assessment System and Taking Objective User Test</title><p>The objective user test was conducted to evaluate the effectiveness of the developed formative assessment system in Baduanjin PE and to examine whether the implemented motion assessment and recognition methods could be applied in a teaching context. Undergraduate students with no prior experience in Baduanjin, no physical disabilities, and no clinical or mental illnesses were recruited. All participants completed the eight-week Baduanjin PE curriculum, which comprised eight lessons. After each lesson, students were required to repeat the movements learned in that session. Their performance was evaluated both by the course instructor using traditional manual assessment and by the formative assessment system. The evaluation considered two aspects: the accuracy of each individual motion and the integrity of the motion sequence, including missing motions and sequence errors. This process was repeated after every lesson, and the results from the instructor and the system were compared at the end of the course to assess the system&#8217;s validity.</p><p>The formative assessment system was designed as a general framework for assessing motion accuracy and detecting missing or incorrectly ordered motions. The framework supports the integration of different classification algorithms; in the present implementation, the system served as a platform to test motion analysis methods without claiming optimality for any specific model. Further comparative studies with alternative algorithms will be undertaken to determine the most effective approach for this application. The system processes IMU-captured motion data in a continuous workflow. Motion data in BVH file format are imported, skeletal information is extracted, and joint rotation data are converted into quaternion format. Feature values are then computed and reduced in dimensionality using principal component analysis to minimize redundancy. The chosen classification algorithm is applied to assess individual motion accuracy and to recognize motion types. Recognized sequences are compared with a reference sequence to detect missing motions or ordering errors, and the results are output for further analysis and instructional feedback.</p></sec><sec id="sec2dot6-sensors-25-05423"><title>2.6. Statistical Analysis</title><p>Based on the calculated distances, IBM SPSS Statistics 25.0, using independent samples T-test for normally distributed data and Mann&#8211;Whitney U test for normally distributed data, was used as a platform to evaluate the significance of the differences in motion accuracy between motions</p></sec></sec><sec sec-type="results" id="sec3-sensors-25-05423"><title>3. Results</title><sec id="sec3dot1-sensors-25-05423"><title>3.1. Results of Accuracy Discrimination of Baduanjin Exercise</title><p>Baduanjin comprises eight standardized movements. In this study, each movement was recorded three times from 20 students and 1 instructor, producing 63 motion datasets. Using the instructor&#8217;s performance as the reference, dynamic time warping (DTW) was applied to calculate the distance between each student and the instructor at 17 skeletal points, representing movement accuracy. For Motions 2, 3, and 4 (independent-samples t-tests, <xref rid="sensors-25-05423-t001" ref-type="table">Table 1</xref>), novice students showed significantly greater DTW distances than experienced students, indicating lower movement accuracy. Specifically, for Motion 2, novices (M = 640.76, SD = 74.38) scored higher than seniors (M = 565.72, SD = 61.64), <italic toggle="yes">t</italic> (58) = 4.28, <italic toggle="yes">p</italic> &lt; 0.001. For Motion 3, novices (M = 543.46, SD = 78.92) again scored higher than seniors (M = 455.75, SD = 54.30), <italic toggle="yes">t</italic> (58) = 5.09, <italic toggle="yes">p</italic> &lt; 0.001. For Motion 4, novices (M = 536.45, SD = 41.44) scored higher than seniors (M = 468.66, SD = 47.70), <italic toggle="yes">t</italic> (58) = 5.81, <italic toggle="yes">p</italic> &lt; 0.001. </p><p>For Motions 1, 5, 6, 7, and 8 (Mann&#8211;Whitney U tests, <xref rid="sensors-25-05423-t002" ref-type="table">Table 2</xref>), significant differences were also observed, with experienced students achieving better accuracy in every case. Motion 1 yielded U = 229.00, Z = &#8722;3.22, <italic toggle="yes">p</italic> = 0.001; Motion 5, U = 136.00, Z = &#8722;4.60, <italic toggle="yes">p</italic> &lt; 0.001; Motion 6, U = 299.00, Z = &#8722;2.18, <italic toggle="yes">p</italic> = 0.029; Motion 7, U = 259.00, Z = &#8722;2.77, <italic toggle="yes">p</italic> = 0.006; and Motion 8, U = 130.00, Z = &#8722;4.69, <italic toggle="yes">p</italic> &lt; 0.001. Across all eight movements, experienced students consistently demonstrated smaller DTW distances from the instructor&#8217;s performance, confirming that the Perception Neuron 2.0 motion data can effectively differentiate performance accuracy levels in Baduanjin practice.</p></sec><sec id="sec3dot2-sensors-25-05423"><title>3.2. Results of Assessing and Recognizing Motions on the Developed Methods</title><p>Using the established motion dataset and the motion scores from two professional Chinese martial arts instructors (Teacher A and Teacher B) as labels, the classification accuracies of different methods under 10-fold cross-validation are presented in <xref rid="sensors-25-05423-t003" ref-type="table">Table 3</xref> and <xref rid="sensors-25-05423-t004" ref-type="table">Table 4</xref>. For Teacher A (<xref rid="sensors-25-05423-t003" ref-type="table">Table 3</xref>), the highest accuracy for Motion 1 was achieved by the sequence-based DTW + k-NN method (94.74%), and for Motion 7 by the sample-based SVM method (95.79%); for the remaining six motions, the sample-based k-NN method produced the highest accuracy. For Teacher B (<xref rid="sensors-25-05423-t004" ref-type="table">Table 4</xref>), the sample-based k-NN method achieved the highest accuracy for six of the eight motions, with only Motion 1 and Motion 7 showing different best-performing methods. Overall, while no single method achieved the top accuracy across all motions, the sample-based k-NN method consistently outperformed other approaches for the majority of movements.</p><p>From <xref rid="sensors-25-05423-t005" ref-type="table">Table 5</xref>, the processing time of the sample-based <italic toggle="yes">k</italic>-NN method is the shortest among the validated methods (0.008 s). Therefore, considering the accuracy and processing time comprehensively, the method for assessing motion accuracy chose the sample-based <italic toggle="yes">k</italic>-NN method. Six methods recognized motions with over 99% accuracy. They were SVM (99.47%), Logistics regression (99.21%) and 1D-CNN (99.74%) in the sample-based methods and DTW + <italic toggle="yes">k</italic>-NN (99.47%), DTW + SVM (99.61%), and HMM (99.08%) in the sequence-based methods. However, the processing times of the six methods varied widely. The sample-based 1D-CNN method with the highest accuracy took 80.958 s, but the sample-based SVM method took 0.914 s.</p><p>The Chi-square test assessed the significant differences in recognizing motions of the six methods on the current experimental test results, and the results show there are no significant differences (<xref rid="sensors-25-05423-t006" ref-type="table">Table 6</xref>). Therefore, considering the accuracy and processing time comprehensively, the method we chose for recognizing motions was the sample-based SVM method.</p></sec><sec id="sec3dot3-sensors-25-05423"><title>3.3. Results of the Objective User Test</title><p>The Baduanjin PE course comprised eight lessons delivered over eight weeks, with one lesson per week. The teaching schedule progressed as follows: Lesson 1 introduced Motions 1&#8211;3; Lessons 2 and 3 provided practice for Motions 1&#8211;3; Lesson 4 introduced Motions 4&#8211;6; Lesson 5 provided practice for Motions 1&#8211;6; Lesson 6 introduced Motions 7&#8211;8; and Lessons 7 and 8 provided practice for the complete set of eight motions. As learning and practice were scheduled in different weeks, not every lesson involved new movements. Over the course, each student performed eight repetitions of Motion 1, eight repetitions of Motion 2, and eight repetitions of Motion 3 (in Lessons 1&#8211;8). Motions 4, 5, and 6 were each performed five times (in Lessons 4&#8211;8), while Motions 7 and 8 were each performed three times (in Lessons 6&#8211;8). In total, 45 motion samples were recorded for each student across the eight-week course.</p><p>Although a total of 450 motion data points (45 data sets &#215; 10 students = 450 data points) could have been obtained to verify the established formative assessment system, only 439 motions data were recorded because some students missed the motions in the learning process. It was found that the developed system wrongly recognized Motion 5 as Motion 3 for one student. In general, the recognition rate was still excellent, reaching 99.77%. There are four missing motions in the data recorded for Motion 3 for three students. Student ID 1 and 4 had one missing motion (Lesson 4), and Student ID 3 had two missing motions (Lessons 4 and 5). All three missing motions happened in Lesson 4 when students learned new motions. The formative assessment system can output the captured motions of any particular student to analyze errors in the sequence of motions and missing motions. Student ID 1 completed all motion assessments for the first three lessons. However, after learning the new motions (Motion 4 to Motion 6) in Lesson 4, the student missed Motion 3 in the assessment. Moreover, after learning the new motion (Motion 7 and Motion 8) in Lesson 6, the student missed Motion 6 in the assessment. The phenomenon of &#8220;forgetting a motion&#8221; reappeared in Lesson 4 and Lesson 6.</p><p>The effectiveness of the developed formative assessment system was evaluated by comparing its grading results with those of the instructor, as shown in <xref rid="sensors-25-05423-t007" ref-type="table">Table 7</xref>. Motion assessments were classified into three levels: Fail, Pass, and Good. Across all eight Baduanjin movements, the system&#8217;s evaluations showed high agreement with the instructor&#8217;s, with Kendall&#8217;s correlation coefficients exceeding 0.80 for every motion (range: 0.835&#8211;0.904). For Motion 1, the system recorded 14 Fail, 58 Pass, and 8 Good ratings, closely matching the instructor&#8217;s 16 Fail, 58 Pass, and 6 Good ratings (Kendall&#8217;s &#964; = 0.904). A similar consistency was observed for Motion 2 (system: 6/52/22; instructor: 5/58/17; &#964; = 0.865), Motion 3 (9/28/39 vs. 9/35/32; &#964; = 0.855), Motion 4 (6/22/18 vs. 7/25/14; &#964; = 0.867), Motion 5 (4/26/20 vs. 5/29/16; &#964; = 0.862), Motion 6 (5/31/11 vs. 7/32/8; &#964; = 0.835), and Motion 7 (3/22/5 vs. 3/24/3; &#964; = 0.850). For Motion 8, no Fail ratings were recorded by either the system or the instructor. According to the instructors, this is the simplest movement in Baduanjin and can be mastered in a short time, though long-term practice is still required to achieve high accuracy. For this motion, only Pass and Good ratings were assigned, with identical counts from the system (15/15) and the instructor (15/15), yielding a Kendall&#8217;s &#964; = 0.867. These results confirm that, in the objective user test, the formative assessment system can reliably evaluate the accuracy of students&#8217; Baduanjin performances, producing grading outcomes highly consistent with expert judgment.</p></sec></sec><sec sec-type="discussion" id="sec4-sensors-25-05423"><title>4. Discussion and Implications</title><p>This study aimed to address a pressing challenge in Chinese physical education&#8212;the difficulty of conducting formative assessment in large-class settings, particularly for traditional Chinese sports such as Baduanjin. The results demonstrated that commercial IMU-based motion capture, specifically Perception Neuron 2.0, could effectively distinguish between students of differing skill levels in terms of motion accuracy. The verification stage showed statistically significant differences in DTW-based distance metrics between novices and experienced practitioners, affirming the feasibility of using this technology to support formative assessments in physical education.</p><p>The results of Section One show significant differences in the distance between the two groups of students&#8217; motions and the teacher&#8217;s motions that verify that the motion data captured by the chosen commercial IMU MoCap: Perception Neuron 2.0 could effectively distinguish Baduanjin motions with different motion accuracy (<xref rid="sensors-25-05423-t001" ref-type="table">Table 1</xref> and <xref rid="sensors-25-05423-t002" ref-type="table">Table 2</xref>). Based on the verification results from Section One, Section Two developed and selected the appropriate methods for assessing motion accuracy and recognizing the motions of Baduanjin. Two different types of methods (sample-based and sequence-based methods) were applied to assess movement accuracy and recognize the motions of Baduanjin. Using the built dataset of Baduanjin motions, the results show that the sample-based <italic toggle="yes">k</italic>-NN method was selected for assessing motion accuracy for high accuracy and short processing time. In recognizing motions, although there were several methods with accuracy over 99%, there is no significant difference in the chi-square test between the methods in the current results. The sample-based SVM method was selected for recognizing motions considering the processing time. The findings clearly indicate that experienced students performed Baduanjin movements with significantly greater accuracy than novices. This aligns with previous research on skill acquisition in traditional and modern sports, which shows that experienced practitioners typically display smoother kinematic trajectories, reduced intra-movement variability, and enhanced postural control. Our results extend these observations to the context of Baduanjin and underscore that the level of practice and familiarity plays a key role in improving biomechanical execution. Moreover, the system successfully identified specific student learning difficulties&#8212;such as forgetting previously learned motions during the acquisition of new ones&#8212;highlighting its potential for real-time educational intervention. The formative assessment system in Baduanjin PE was developed based on the optimal assessment of motion accuracy and recognizing motion methods selected by the verification methods. Moreover, the objective user test of the system was carried out. The objective user test results show that the accuracy of the formative assessment system in the motion recognition of students reaches 99.77%. The consistency test (Kendall test) of the formative assessment system and teacher on assessing the motion accuracy of students exceeds 0.8. These objective user test results show that the developed formative assessment system effectively assesses motion accuracy and recognizes motions. In addition, using the formative assessment system, problems students face in the learning process can be detected immediately. For example, using recognizing the motions of students as a metric, the system shows the problem of forgetting motions that often occur when learning Baduanjin. The system detected three students who forgot Motion-3 in learning Baduanjin in Lesson 4. Lesson 4 requires students to learn new motions, which leads some students to forget the previously learned motions when learning the new motions. This phenomenon is seen for Student ID 1. The formative assessment system shows that the student was unable to remember Motion 3 (during Lesson 4) and Motion 6 (during Lesson 6). Lastly, the developed formative assessment system could trace the learning process. As an example, for Student ID 1, the recorded result clearly shows the learning progress of all the motion accuracy throughout the eight-week learning process. Therefore, the objective user test results reflect that the first-generation formative assessment system can assess students in the learning process to discover the mistakes made by students.</p><p>Formative assessment refers to the assessment to discover the problems of students during the learning process, and it usually consists of a small number of items but requires frequent measurement. Formative assessment can assess how well students are progressing and provide teachers with important information about managing instruction. In contrast, summative assessment does not consider the development of students and problems in the process of learning and feedback from teachers [<xref rid="B3-sensors-25-05423" ref-type="bibr">3</xref>]. While previous research on formative assessment tools has primarily focused on mainstream sports or dynamic activities, this study is one of the few to validate such technologies in slow, meditative traditional Chinese exercises. Compared to yoga, Tai Chi, or martial arts, which have also benefited from similar analyses, Baduanjin poses unique challenges due to its subtle motion characteristics and emphasis on internal flow. Despite this, our approach demonstrated similar efficacy in quantifying motion accuracy and identifying learning gaps. This reinforces the argument that motion tracking technologies are not limited to high-intensity sports and can be effectively adapted to diverse physical disciplines. Similar trends have been observed in studies on other sports, such as Tai Chi, yoga, or martial arts: experienced practitioners typically demonstrate smoother joint trajectories, reduced movement variability, and better postural stability [<xref rid="B36-sensors-25-05423" ref-type="bibr">36</xref>,<xref rid="B37-sensors-25-05423" ref-type="bibr">37</xref>]. Our study provides additional empirical support that motion capture-based assessments can distinguish between skill levels not only in dynamic or competitive sports but also in slow, meditative forms of exercise like Baduanjin. This contributes to the growing literature on the quantification of traditional Chinese exercises using wearable technology.</p><p>The results of this study hold significant implications for the field of physical education. Firstly, the successful development of a formative assessment system capable of real-time monitoring of student movements and accurate evaluation of motion accuracy, achieved through the use of commercial IMU technology, provides physical education teachers with an effective tool. This tool enables them to better understand students&#8217; performance during the learning process, promptly identify issues, and offer personalized guidance and support. This contributes to enhancing teaching quality and enables students to develop their physical literacy more comprehensively. Secondly, the study results demonstrate the immense potential of commercial IMU technology in the context of traditional Chinese physical education. Despite limited research in this area, the study validates the effectiveness of this technology in recognizing motion accuracy. This provides a reliable theoretical basis for future efforts to promote the use of IMU MoCap technology in traditional Chinese physical education. Furthermore, the study confirms the practicality and feasibility of the formative assessment system. Through objective user testing, the system demonstrates excellent performance in student motion recognition and high consistency with teacher evaluations. This indicates that the system can serve as an effective tool to help teachers manage classrooms, provide personalized guidance to students, and promptly identify and address issues encountered during the learning process. Practical implications of this study extend to physical education and health promotion. The ability to objectively assess movement quality using wearable sensors offers a promising tool for PE teachers to provide personalized instruction and track student progress. Additionally, the framework developed here may be adapted for other sports or rehabilitation programs where form and accuracy are crucial. For example, similar motion evaluation systems could be applied in yoga, gymnastics, or elderly balance training, aligning well with current trends in digitized, data-driven sport pedagogy [<xref rid="B38-sensors-25-05423" ref-type="bibr">38</xref>,<xref rid="B39-sensors-25-05423" ref-type="bibr">39</xref>].</p><p>Although the present study focused on Baduanjin movements, the proposed IMU-based formative assessment framework is not limited to this discipline. With appropriate adjustments to the reference motion library and accuracy criteria, the system could be applied to assess other structured movement practices, such as Tai Chi, yoga, and martial arts, as well as technical skills in sports like gymnastics, golf, and swimming. Beyond sports and traditional exercises, the approach could be extended to rehabilitation and physical therapy settings to monitor patients&#8217; progress, provide objective feedback, and support remote or home-based training. These examples illustrate the potential for broader application of this technology in movement assessment and skill acquisition monitoring across diverse domains.</p><p>This study has several limitations that should be considered when interpreting the findings. The sample consisted of full-time students from a single institution, which may limit the generalizability of the results to other populations. Future research should recruit participants from a wider range of age groups, backgrounds, and physical ability levels to improve external validity. The IMU-based assessment system was tested in a controlled indoor setting, and its performance under different environmental conditions was not evaluated. Further studies should assess its reliability and accuracy in varied real-world contexts, such as outdoor classes or settings with limited space. The evaluation framework focused primarily on kinematic accuracy and did not incorporate physiological or perceptual measures, which could provide a more comprehensive understanding of learning outcomes. Future work could integrate motion data with physiological indicators and self-reported measures. Finally, while the system demonstrated potential for enhancing formative assessment, the need for technical setup and calibration may hinder large-scale adoption in schools with limited resources. Streamlining system deployment and automating data processing should be priorities for future development to support broader implementation.</p></sec><sec sec-type="conclusions" id="sec5-sensors-25-05423"><title>5. Conclusions</title><p>The study demonstrates that integrating commercial IMU technology into formative assessment practices in PE holds promise for improving teaching and learning outcomes. The developed formative assessment system effectively monitors student motion in real-time and accurately evaluates motion accuracy. By leveraging technology in assessment, educators can gain valuable insights into student performance and provide timely guidance and support. This research contributes to advancing assessment methods in physical education and underscores the potential of technology in enhancing teaching practices and student learning experiences.</p></sec></body><back><ack><title>Acknowledgments</title><p>We would like to acknowledge the participants who took part in this study.</p></ack><fn-group><fn><p><bold>Disclaimer/Publisher&#8217;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><app-group><app id="app1-sensors-25-05423"><title>Supplementary Materials</title><p>The following supporting information can be downloaded at: <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.mdpi.com/article/10.3390/s25175423/s1">https://www.mdpi.com/article/10.3390/s25175423/s1</uri>, Supplementary S1: The standard Baduanjin routine consists of eight sequential movements.</p><supplementary-material id="sensors-25-05423-s001" position="float" content-type="local-data" orientation="portrait"><media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="sensors-25-05423-s001.zip" position="float" orientation="portrait"/></supplementary-material></app></app-group><notes><title>Author Contributions</title><p>X.M. led data collection and user testing, and drafted the manuscript. M.S. supervised the project, designed the methodology, and revised the manuscript (corresponding author). X.F. contributed to algorithm development and data analysis. W.D. managed equipment setup and assisted in data acquisition. Q.Y. conducted statistical validation. P.C. worked on educational evaluation and user testing. H.L. contributed to the theoretical framework and manuscript editing (corresponding author). All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Institutional Review Board Statement</title><p>Ethics Approval and Consent to Participate.</p></notes><notes><title>Informed Consent Statement</title><p>All participants consented to the publication of the findings.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>The datasets used and/or analyzed during the current study are available from the corresponding author on reasonable request.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflict of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-25-05423"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Huaranga</surname><given-names>N.E.R.</given-names></name><name name-style="western"><surname>Cuadros</surname><given-names>M.J.L.</given-names></name></person-group><article-title>Formative evaluation in a virtual context: A systematic review</article-title><source>Alpha Centauri</source><year>2024</year><volume>5</volume><fpage>2</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.47422/ac.v5i1.161</pub-id></element-citation></ref><ref id="B2-sensors-25-05423"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ca&#241;adas</surname><given-names>L.</given-names></name></person-group><article-title>Contribution of formative assessment for developing teaching competences in teacher education</article-title><source>Eur. J. Teach. Educ.</source><year>2023</year><volume>46</volume><fpage>516</fpage><lpage>532</lpage><pub-id pub-id-type="doi">10.1080/02619768.2021.1950684</pub-id></element-citation></ref><ref id="B3-sensors-25-05423"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mastagli</surname><given-names>M.</given-names></name><name name-style="western"><surname>Malini</surname><given-names>D.</given-names></name><name name-style="western"><surname>Hainaut</surname><given-names>J.-P.</given-names></name><name name-style="western"><surname>Van Hoye</surname><given-names>A.</given-names></name><name name-style="western"><surname>Bolmont</surname><given-names>B.</given-names></name></person-group><article-title>Summative assessment versus formative assessment: An ecological study of physical education by analyzing state-anxiety and shot-put performance among French high school students</article-title><source>J. Phys. Educ. Sport</source><year>2020</year><volume>20</volume><fpage>2220</fpage><lpage>2229</lpage></element-citation></ref><ref id="B4-sensors-25-05423"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stenberg</surname><given-names>M.</given-names></name><name name-style="western"><surname>Mangrio</surname><given-names>E.</given-names></name><name name-style="western"><surname>Bengtsson</surname><given-names>M.</given-names></name><name name-style="western"><surname>Carlson</surname><given-names>E.</given-names></name></person-group><article-title>Formative peer assessment in higher healthcare education programmes: A scoping review</article-title><source>BMJ Open</source><year>2021</year><volume>11</volume><fpage>e045345</fpage><pub-id pub-id-type="doi">10.1136/bmjopen-2020-045345</pub-id><pub-id pub-id-type="pmid">33563627</pub-id><pub-id pub-id-type="pmcid">PMC7875268</pub-id></element-citation></ref><ref id="B5-sensors-25-05423"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Otero-Saborido</surname><given-names>F.M.</given-names></name><name name-style="western"><surname>Torreblanca-Mart&#237;nez</surname><given-names>V.</given-names></name><name name-style="western"><surname>Gonz&#225;lez-Jurado</surname><given-names>J.A.</given-names></name></person-group><article-title>Systematic Review of Self-Assessment in Physical Education</article-title><source>Int. J. Environ. Res. Public Health</source><year>2021</year><volume>18</volume><elocation-id>766</elocation-id><pub-id pub-id-type="doi">10.3390/ijerph18020766</pub-id><pub-id pub-id-type="pmid">33477483</pub-id><pub-id pub-id-type="pmcid">PMC7831071</pub-id></element-citation></ref><ref id="B6-sensors-25-05423"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gong</surname><given-names>X.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>L.</given-names></name><name name-style="western"><surname>Yang</surname><given-names>L.-L.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>F.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>D.-N.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>A.</given-names></name></person-group><article-title>Effects of Baduanjin exercise on cognitive impairment in older adults: A systematic review and meta-analysis</article-title><source>Front. Public Health</source><year>2025</year><volume>13</volume><elocation-id>1586011</elocation-id><pub-id pub-id-type="doi">10.3389/fpubh.2025.1586011</pub-id><pub-id pub-id-type="pmid">40678632</pub-id><pub-id pub-id-type="pmcid">PMC12267035</pub-id></element-citation></ref><ref id="B7-sensors-25-05423"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>M.</given-names></name><name name-style="western"><surname>Fang</surname><given-names>Q.</given-names></name><name name-style="western"><surname>Li</surname><given-names>J.</given-names></name><name name-style="western"><surname>Zheng</surname><given-names>X.</given-names></name><name name-style="western"><surname>Tao</surname><given-names>J.</given-names></name><name name-style="western"><surname>Yan</surname><given-names>X.</given-names></name><name name-style="western"><surname>Lin</surname><given-names>Q.</given-names></name><name name-style="western"><surname>Lan</surname><given-names>X.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>B.</given-names></name><name name-style="western"><surname>Zheng</surname><given-names>G.</given-names></name></person-group><article-title>The effect of Chinese traditional exercise-Baduanjin on physical and psychological well-being of college students: A randomized controlled trial</article-title><source>PLoS ONE</source><year>2015</year><volume>10</volume><elocation-id>e0130544</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0130544</pub-id><pub-id pub-id-type="pmid">26158769</pub-id><pub-id pub-id-type="pmcid">PMC4497728</pub-id></element-citation></ref><ref id="B8-sensors-25-05423"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Herrera-Ligero</surname><given-names>C.</given-names></name><name name-style="western"><surname>Chaler</surname><given-names>J.</given-names></name><name name-style="western"><surname>Bermejo-Bosch</surname><given-names>I.</given-names></name></person-group><article-title>Strengthening education in rehabilitation: Assessment technology and digitalization</article-title><source>Front. Rehabil. Sci.</source><year>2022</year><volume>3</volume><elocation-id>883270</elocation-id><pub-id pub-id-type="doi">10.3389/fresc.2022.883270</pub-id><pub-id pub-id-type="pmid">36188966</pub-id><pub-id pub-id-type="pmcid">PMC9449490</pub-id></element-citation></ref><ref id="B9-sensors-25-05423"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bores-Garc&#237;a</surname><given-names>D.</given-names></name><name name-style="western"><surname>Hortig&#252;ela-Alcal&#225;</surname><given-names>D.</given-names></name><name name-style="western"><surname>Gonz&#225;lez-Calvo</surname><given-names>G.</given-names></name><name name-style="western"><surname>Barba-Mart&#237;n</surname><given-names>R.</given-names></name></person-group><article-title>Peer assessment in physical education: A systematic review of the last five years</article-title><source>Sustainability</source><year>2020</year><volume>12</volume><elocation-id>9233</elocation-id><pub-id pub-id-type="doi">10.3390/su12219233</pub-id></element-citation></ref><ref id="B10-sensors-25-05423"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Barrientos Hern&#225;n</surname><given-names>E.J.</given-names></name><name name-style="western"><surname>L&#243;pez-Pastor</surname><given-names>V.M.</given-names></name><name name-style="western"><surname>Lorente-Catal&#225;n</surname><given-names>E.</given-names></name><name name-style="western"><surname>Kirk</surname><given-names>D.</given-names></name></person-group><article-title>Challenges with using formative and authentic assessment in physical education teaching from experienced teachers&#8217; perspectives</article-title><source>Curric. Stud. Health Phys. Educ.</source><year>2023</year><volume>14</volume><fpage>109</fpage><lpage>126</lpage><pub-id pub-id-type="doi">10.1080/25742981.2022.2060118</pub-id></element-citation></ref><ref id="B11-sensors-25-05423"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Griban</surname><given-names>G.</given-names></name><name name-style="western"><surname>Kuznietsova</surname><given-names>O.</given-names></name><name name-style="western"><surname>Tkachenko</surname><given-names>P.</given-names></name><name name-style="western"><surname>Oleniev</surname><given-names>D.</given-names></name><name name-style="western"><surname>Khurtenko</surname><given-names>O.</given-names></name><name name-style="western"><surname>Dikhtiarenko</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Yeromenko</surname><given-names>E.</given-names></name><name name-style="western"><surname>Lytvynenko</surname><given-names>A.</given-names></name><name name-style="western"><surname>Khatko</surname><given-names>A.</given-names></name><name name-style="western"><surname>Pustoliakova</surname><given-names>L.</given-names></name></person-group><article-title>Formation of the students&#8217; volitional qualities in the process of physical education</article-title><source>Int. J. Hum. Mov. Sports Sci.</source><year>2020</year><volume>8</volume><fpage>505</fpage><lpage>517</lpage><pub-id pub-id-type="doi">10.13189/saj.2020.080625</pub-id></element-citation></ref><ref id="B12-sensors-25-05423"><label>12.</label><element-citation publication-type="webpage"><person-group person-group-type="author"><collab>Department of Education of Jiangsu</collab></person-group><article-title>Notice of Provincial Education Department on the Results of the Fifth Batch of Public Physical Education Courses in Colleges and Universities</article-title><year>2015</year><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://wenku.baidu.com/view/bb4c0d8f876fb84ae45c3b3567ec102de2bddf83.html" ext-link-type="uri">https://wenku.baidu.com/view/bb4c0d8f876fb84ae45c3b3567ec102de2bddf83.html</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2020-08-07">(accessed on 7 August 2020)</date-in-citation></element-citation></ref><ref id="B13-sensors-25-05423"><label>13.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Zhan</surname><given-names>Y.Y.</given-names></name></person-group><article-title>Exploring a New System of Martial Arts Teaching Content in Common Universities in Shanghai</article-title><source>Master&#8217;s Thesis</source><publisher-name>East China Normal University</publisher-name><publisher-loc>Shanghai, China</publisher-loc><year>2015</year></element-citation></ref><ref id="B14-sensors-25-05423"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>van der Kruk</surname><given-names>E.</given-names></name><name name-style="western"><surname>Reijne</surname><given-names>M.M.</given-names></name></person-group><article-title>Accuracy of human motion capture systems for sport applications; state-of-the-art review</article-title><source>Eur. J. Sport Sci.</source><year>2018</year><volume>18</volume><fpage>806</fpage><lpage>819</lpage><pub-id pub-id-type="doi">10.1080/17461391.2018.1463397</pub-id><pub-id pub-id-type="pmid">29741985</pub-id></element-citation></ref><ref id="B15-sensors-25-05423"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Schuler</surname><given-names>N.</given-names></name><name name-style="western"><surname>Bey</surname><given-names>M.</given-names></name><name name-style="western"><surname>Shearn</surname><given-names>J.</given-names></name><name name-style="western"><surname>Butler</surname><given-names>D.</given-names></name></person-group><article-title>Evaluation of an electromagnetic position tracking device for measuring in vivo, dynamic joint kinematics</article-title><source>J. Biomech.</source><year>2005</year><volume>38</volume><fpage>2113</fpage><lpage>2117</lpage><pub-id pub-id-type="doi">10.1016/j.jbiomech.2004.09.015</pub-id><pub-id pub-id-type="pmid">16084212</pub-id></element-citation></ref><ref id="B16-sensors-25-05423"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yap</surname><given-names>H.J.</given-names></name><name name-style="western"><surname>Taha</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Dawal</surname><given-names>S.Z.M.A.</given-names></name></person-group><article-title>A generic approach of integrating 3D models into virtual manufacturing</article-title><source>J. Zhejiang Univ.-Sci. C Comput. Electron.</source><year>2012</year><volume>13</volume><fpage>22</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1631/jzus.C11a0077</pub-id></element-citation></ref><ref id="B17-sensors-25-05423"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yamaoka</surname><given-names>K.</given-names></name><name name-style="western"><surname>Uehara</surname><given-names>M.</given-names></name><name name-style="western"><surname>Shima</surname><given-names>T.</given-names></name><name name-style="western"><surname>Tamura</surname><given-names>Y.</given-names></name></person-group><article-title>Feedback of flying disc throw with Kinect and its evaluation</article-title><source>Procedia Comput. Sci.</source><year>2013</year><volume>22</volume><fpage>912</fpage><lpage>920</lpage><pub-id pub-id-type="doi">10.1016/j.procs.2013.09.174</pub-id></element-citation></ref><ref id="B18-sensors-25-05423"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>X.M.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>Z.B.</given-names></name><name name-style="western"><surname>Li</surname><given-names>Y.</given-names></name><name name-style="western"><surname>He</surname><given-names>T.Y.</given-names></name><name name-style="western"><surname>Hou</surname><given-names>J.H.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>S.</given-names></name><name name-style="western"><surname>He</surname><given-names>Y.</given-names></name></person-group><article-title>ImmerTai: Immersive motion learning in VR environments</article-title><source>J. Vis. Commun. Image Represent.</source><year>2019</year><volume>58</volume><fpage>416</fpage><lpage>427</lpage><pub-id pub-id-type="doi">10.1016/j.jvcir.2018.11.039</pub-id></element-citation></ref><ref id="B19-sensors-25-05423"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Justa</surname><given-names>J.</given-names></name><name name-style="western"><surname>&#352;m&#237;dl</surname><given-names>V.</given-names></name><name name-style="western"><surname>Ham&#225;&#269;ek</surname><given-names>A.</given-names></name></person-group><article-title>Deep Learning Methods for Speed Estimation of Bipedal Motion from Wearable IMU Sensors</article-title><source>Sensors</source><year>2022</year><volume>22</volume><elocation-id>3865</elocation-id><pub-id pub-id-type="doi">10.3390/s22103865</pub-id><pub-id pub-id-type="pmid">35632274</pub-id><pub-id pub-id-type="pmcid">PMC9144294</pub-id></element-citation></ref><ref id="B20-sensors-25-05423"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Beuken</surname><given-names>L.G.</given-names></name><name name-style="western"><surname>Priest</surname><given-names>J.L.</given-names></name><name name-style="western"><surname>Hainsworth</surname><given-names>T.</given-names></name><name name-style="western"><surname>Humbert</surname><given-names>J.S.</given-names></name></person-group><article-title>Distributed IMU Sensors for In-Field Dynamic Measurements on an Alpine Ski</article-title><source>Sensors</source><year>2024</year><volume>24</volume><elocation-id>1805</elocation-id><pub-id pub-id-type="doi">10.3390/s24061805</pub-id><pub-id pub-id-type="pmid">38544068</pub-id><pub-id pub-id-type="pmcid">PMC10974825</pub-id></element-citation></ref><ref id="B21-sensors-25-05423"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Aroganam</surname><given-names>G.</given-names></name><name name-style="western"><surname>Manivannan</surname><given-names>N.</given-names></name><name name-style="western"><surname>Harrison</surname><given-names>D.</given-names></name></person-group><article-title>Review on Wearable Technology Sensors Used in Consumer Sport Applications</article-title><source>Sensors</source><year>2019</year><volume>19</volume><elocation-id>1983</elocation-id><pub-id pub-id-type="doi">10.3390/s19091983</pub-id><pub-id pub-id-type="pmid">31035333</pub-id><pub-id pub-id-type="pmcid">PMC6540270</pub-id></element-citation></ref><ref id="B22-sensors-25-05423"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zeng</surname><given-names>Z.-P.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>Y.-B.</given-names></name><name name-style="western"><surname>Fang</surname><given-names>J.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Luo</surname><given-names>J.</given-names></name><name name-style="western"><surname>Yang</surname><given-names>M.</given-names></name></person-group><article-title>Effects of Baduanjin exercise for knee osteoarthritis: A systematic review and meta-analysis</article-title><source>Complement. Ther. Med.</source><year>2020</year><volume>48</volume><fpage>102279</fpage><pub-id pub-id-type="doi">10.1016/j.ctim.2019.102279</pub-id><pub-id pub-id-type="pmid">31987253</pub-id></element-citation></ref><ref id="B23-sensors-25-05423"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kong</surname><given-names>L.</given-names></name><name name-style="western"><surname>Ren</surname><given-names>J.</given-names></name><name name-style="western"><surname>Fang</surname><given-names>S.</given-names></name><name name-style="western"><surname>He</surname><given-names>T.</given-names></name><name name-style="western"><surname>Zhou</surname><given-names>X.</given-names></name><name name-style="western"><surname>Fang</surname><given-names>M.</given-names></name></person-group><article-title>Effects of traditional Chinese mind-body exercise-Baduanjin for type 2 diabetes on psychological well-being: A systematic review and meta-analysis</article-title><source>Front. Public Health</source><year>2022</year><volume>10</volume><elocation-id>923411</elocation-id><pub-id pub-id-type="doi">10.3389/fpubh.2022.923411</pub-id><pub-id pub-id-type="pmid">35968439</pub-id><pub-id pub-id-type="pmcid">PMC9371619</pub-id></element-citation></ref><ref id="B24-sensors-25-05423"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>H.</given-names></name><name name-style="western"><surname>Selina</surname><given-names>K.</given-names></name><name name-style="western"><surname>Yap</surname><given-names>H.J.</given-names></name></person-group><article-title>Differences in Motion Accuracy of Baduanjin between Novice and Senior Students on Inertial Sensor Measurement Systems</article-title><source>Sensors</source><year>2020</year><volume>20</volume><elocation-id>6258</elocation-id><pub-id pub-id-type="doi">10.3390/s20216258</pub-id><pub-id pub-id-type="pmid">33147851</pub-id><pub-id pub-id-type="pmcid">PMC7662330</pub-id></element-citation></ref><ref id="B25-sensors-25-05423"><label>25.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Zhou</surname><given-names>L.</given-names></name><name name-style="western"><surname>Tunca</surname><given-names>C.</given-names></name><name name-style="western"><surname>Fischer</surname><given-names>E.</given-names></name><name name-style="western"><surname>Brahms</surname><given-names>C.M.</given-names></name><name name-style="western"><surname>Ersoy</surname><given-names>C.</given-names></name><name name-style="western"><surname>Granacher</surname><given-names>U.</given-names></name><name name-style="western"><surname>Arnrich</surname><given-names>B.</given-names></name></person-group><article-title>Validation of an IMU Gait Analysis Algorithm for Gait Monitoring in Daily Life Situations</article-title><source>Proceedings of the 2020 42nd Annual International Conference of the IEEE Engineering in Medicine &amp; Biology Society (EMBC)</source><conf-loc>Montreal, QC, Canada</conf-loc><conf-date>20&#8211;24 July 2020</conf-date><fpage>4229</fpage><lpage>4232</lpage><pub-id pub-id-type="doi">10.1109/embc44109.2020.9176827</pub-id><pub-id pub-id-type="pmid">33018930</pub-id></element-citation></ref><ref id="B26-sensors-25-05423"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhu</surname><given-names>K.</given-names></name><name name-style="western"><surname>Li</surname><given-names>J.</given-names></name><name name-style="western"><surname>Li</surname><given-names>D.</given-names></name><name name-style="western"><surname>Fan</surname><given-names>B.</given-names></name><name name-style="western"><surname>Shull</surname><given-names>P.B.</given-names></name></person-group><article-title>IMU Shoulder Angle Estimation: Effects of Sensor-to-Segment Misalignment and Sensor Orientation Error</article-title><source>IEEE Trans. Neural Syst. Rehabil. Eng.</source><year>2023</year><volume>31</volume><fpage>4481</fpage><lpage>4491</lpage><pub-id pub-id-type="doi">10.1109/TNSRE.2023.3331238</pub-id><pub-id pub-id-type="pmid">37938963</pub-id></element-citation></ref><ref id="B27-sensors-25-05423"><label>27.</label><element-citation publication-type="webpage"><person-group person-group-type="author"><collab>Noitom Technology</collab></person-group><article-title>Perception Neuron 2.0. Beijing, China</article-title><year>2018</year><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.noitom.com.cn" ext-link-type="uri">https://www.noitom.com.cn</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2020-08-20">(accessed on 20 August 2020)</date-in-citation></element-citation></ref><ref id="B28-sensors-25-05423"><label>28.</label><element-citation publication-type="confproc"><person-group person-group-type="editor"><name name-style="western"><surname>Dai</surname><given-names>H.</given-names></name><name name-style="western"><surname>Cai</surname><given-names>B.</given-names></name><name name-style="western"><surname>Song</surname><given-names>J.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>D.Y.</given-names></name></person-group><article-title>Skeletal animation based on BVH motion data</article-title><source>Proceedings of the 2nd International Conference on Information Engineering and Computer Science</source><conf-loc>Wuhan, China</conf-loc><conf-date>25&#8211;26 December 2010</conf-date><publisher-name>IEEE</publisher-name><publisher-loc>New York, NY, USA</publisher-loc></element-citation></ref><ref id="B29-sensors-25-05423"><label>29.</label><element-citation publication-type="confproc"><person-group person-group-type="editor"><name name-style="western"><surname>Zhang</surname><given-names>W.J.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>J.J.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>X.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>K.</given-names></name><name name-style="western"><surname>Ren</surname><given-names>Y.</given-names></name></person-group><article-title>A novel cardiac arrhythmia detection method relying on improved DTW method</article-title><source>Proceedings of the 2017 IEEE 2nd Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)</source><conf-loc>Chongqing, China</conf-loc><conf-date>25 March 2017</conf-date><publisher-name>IEEE</publisher-name><publisher-loc>New York, NY, USA</publisher-loc></element-citation></ref><ref id="B30-sensors-25-05423"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Altun</surname><given-names>K.</given-names></name><name name-style="western"><surname>Barshan</surname><given-names>B.</given-names></name><name name-style="western"><surname>Tunel</surname><given-names>O.</given-names></name></person-group><article-title>Comparative study on classifying human activities with miniature inertial and magnetic sensors</article-title><source>Pattern Recognit.</source><year>2010</year><volume>43</volume><fpage>3605</fpage><lpage>3620</lpage><pub-id pub-id-type="doi">10.1016/j.patcog.2010.04.019</pub-id></element-citation></ref><ref id="B31-sensors-25-05423"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Khan</surname><given-names>A.M.</given-names></name><name name-style="western"><surname>Lee</surname><given-names>Y.K.</given-names></name><name name-style="western"><surname>Lee</surname><given-names>S.Y.</given-names></name><name name-style="western"><surname>Kim</surname><given-names>T.S.</given-names></name></person-group><article-title>A Triaxial Accelerometer-Based Physical-Activity Recognition via Augmented-Signal Features and a Hierarchical Recognizer</article-title><source>IEEE Trans. Inf. Technol. Biomed.</source><year>2010</year><volume>14</volume><fpage>1166</fpage><lpage>1172</lpage><pub-id pub-id-type="doi">10.1109/TITB.2010.2051955</pub-id><pub-id pub-id-type="pmid">20529753</pub-id></element-citation></ref><ref id="B32-sensors-25-05423"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Subasi</surname><given-names>A.</given-names></name><name name-style="western"><surname>Gursoy</surname><given-names>M.I.</given-names></name></person-group><article-title>EEG signal classification using PCA, ICA, LDA and support vector machines</article-title><source>Expert Syst. Appl.</source><year>2010</year><volume>37</volume><fpage>8659</fpage><lpage>8666</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2010.06.065</pub-id></element-citation></ref><ref id="B33-sensors-25-05423"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shi</surname><given-names>X.B.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>S.P.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>D.Y.</given-names></name></person-group><article-title>Human action recognition method based on key frames</article-title><source>J. Syst. Simul.</source><year>2015</year><volume>27</volume><fpage>2401</fpage><lpage>2408</lpage><pub-id pub-id-type="doi">10.16182/j.cnki.joss.2015.10.026</pub-id></element-citation></ref><ref id="B34-sensors-25-05423"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>H.</given-names></name><name name-style="western"><surname>Selina</surname><given-names>K.</given-names></name><name name-style="western"><surname>Yap</surname><given-names>H.J.</given-names></name></person-group><article-title>Implementation of Sequence-Based Classification Methods for Motion Assessment and Recognition in a Traditional Chinese Sport (Baduanjin)</article-title><source>Int. J. Environ. Res. Public Health</source><year>2022</year><volume>19</volume><elocation-id>1744</elocation-id><pub-id pub-id-type="doi">10.3390/ijerph19031744</pub-id><pub-id pub-id-type="pmid">35162767</pub-id><pub-id pub-id-type="pmcid">PMC8834705</pub-id></element-citation></ref><ref id="B35-sensors-25-05423"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>S.Y.</given-names></name><name name-style="western"><surname>Hou</surname><given-names>J.</given-names></name><name name-style="western"><surname>Gan</surname><given-names>L.Y.</given-names></name></person-group><article-title>Extraction of motion key-frame based on inter-frame pitch</article-title><source>Comput. Eng.</source><year>2015</year><volume>41</volume><fpage>242</fpage><lpage>247</lpage><pub-id pub-id-type="doi">10.3969/j.issn.1000-3428.2015.02.046</pub-id></element-citation></ref><ref id="B36-sensors-25-05423"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>X.</given-names></name><name name-style="western"><surname>Zou</surname><given-names>L.</given-names></name><name name-style="western"><surname>Li</surname><given-names>H.</given-names></name></person-group><article-title>Tai Chi Movement Recognition and Precise Intervention for the Elderly Based on Inertial Measurement Units and Temporal Convolutional Neural Networks</article-title><source>Sensor</source><year>2024</year><volume>24</volume><elocation-id>4208</elocation-id><pub-id pub-id-type="doi">10.3390/s24134208</pub-id><pub-id pub-id-type="pmid">39000985</pub-id><pub-id pub-id-type="pmcid">PMC11244047</pub-id></element-citation></ref><ref id="B37-sensors-25-05423"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lin</surname><given-names>A.C.</given-names></name><name name-style="western"><surname>Lin</surname><given-names>T.T.</given-names></name><name name-style="western"><surname>Tan</surname><given-names>Y.K.</given-names></name><name name-style="western"><surname>Pan</surname><given-names>W.R.</given-names></name><name name-style="western"><surname>Shih</surname><given-names>C.J.</given-names></name><name name-style="western"><surname>Lee</surname><given-names>C.J.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>S.F.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>F.C.</given-names></name></person-group><article-title>Superior Gait Symmetry and Postural Stability among Yoga Instructors-Inertial Measurement Unit-Based Evaluation</article-title><source>Sensor</source><year>2022</year><volume>22</volume><elocation-id>9683</elocation-id><pub-id pub-id-type="doi">10.3390/s22249683</pub-id><pub-id pub-id-type="pmid">36560050</pub-id><pub-id pub-id-type="pmcid">PMC9781467</pub-id></element-citation></ref><ref id="B38-sensors-25-05423"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lesinski</surname><given-names>M.</given-names></name><name name-style="western"><surname>Hortob&#225;gyi</surname><given-names>T.</given-names></name><name name-style="western"><surname>Muehlbauer</surname><given-names>T.</given-names></name><name name-style="western"><surname>Gollhofer</surname><given-names>A.</given-names></name><name name-style="western"><surname>Granacher</surname><given-names>U.</given-names></name></person-group><article-title>Effects of Balance Training on Balance Performance in Healthy Older Adults: A Systematic Review and Meta-analysis</article-title><source>Sports Med.</source><year>2015</year><volume>45</volume><fpage>1721</fpage><lpage>1738</lpage><pub-id pub-id-type="doi">10.1007/s40279-015-0375-y</pub-id><pub-id pub-id-type="pmid">26325622</pub-id><pub-id pub-id-type="pmcid">PMC4656699</pub-id></element-citation></ref><ref id="B39-sensors-25-05423"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ekvall Hansson</surname><given-names>E.</given-names></name><name name-style="western"><surname>Valkonen</surname><given-names>E.</given-names></name><name name-style="western"><surname>Olsson M&#246;ller</surname><given-names>U.</given-names></name><name name-style="western"><surname>Chen Lin</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Magnusson</surname><given-names>M.</given-names></name><name name-style="western"><surname>Fransson</surname><given-names>P.A.</given-names></name></person-group><article-title>Gait Flexibility among Older Persons Significantly More Impaired in Fallers Than Non-Fallers-A Longitudinal Study</article-title><source>Int. J. Environ. Res. Public Health</source><year>2021</year><volume>18</volume><elocation-id>7074</elocation-id><pub-id pub-id-type="doi">10.3390/ijerph18137074</pub-id><pub-id pub-id-type="pmid">34281011</pub-id><pub-id pub-id-type="pmcid">PMC8297078</pub-id></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-05423-f001" orientation="portrait"><label>Figure 1</label><caption><p>Flow diagram of the study.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05423-g001.jpg"/></fig><fig position="float" id="sensors-25-05423-f002" orientation="portrait"><label>Figure 2</label><caption><p>Flow diagram of verifying the effectiveness of Perception Neuron 2.0 in distinguishing motion accuracy of Baduanjin motions.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05423-g002.jpg"/></fig><table-wrap position="float" id="sensors-25-05423-t001" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05423-t001_Table 1</object-id><label>Table 1</label><caption><p>Differences in motion accuracy between novice and senior students (independent sample T-test).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Motion</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Group</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">N</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Mean</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Std. M</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">F</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Sig.</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">t</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Sig. <sup>a</sup></th></tr></thead><tbody><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Motion-2</td><td align="center" valign="middle" rowspan="1" colspan="1">N.S</td><td align="center" valign="middle" rowspan="1" colspan="1">27</td><td align="center" valign="middle" rowspan="1" colspan="1">640.76</td><td align="center" valign="middle" rowspan="1" colspan="1">74.38</td><td align="center" valign="middle" rowspan="1" colspan="1">2.29</td><td align="center" valign="middle" rowspan="1" colspan="1">0.14</td><td align="center" valign="middle" rowspan="1" colspan="1">4.28</td><td align="center" valign="middle" rowspan="1" colspan="1">0.000</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">S.S</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">565.72</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">61.64</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4.20</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.000</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Motion-3</td><td align="center" valign="middle" rowspan="1" colspan="1">N.S</td><td align="center" valign="middle" rowspan="1" colspan="1">27</td><td align="center" valign="middle" rowspan="1" colspan="1">543.46</td><td align="center" valign="middle" rowspan="1" colspan="1">78.92</td><td align="center" valign="middle" rowspan="1" colspan="1">4.88</td><td align="center" valign="middle" rowspan="1" colspan="1">0.03</td><td align="center" valign="middle" rowspan="1" colspan="1">5.09</td><td align="center" valign="middle" rowspan="1" colspan="1">0.000</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">S.S</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">455.75</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">54.30</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4.90</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.000</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Motion-4</td><td align="center" valign="middle" rowspan="1" colspan="1">N.S</td><td align="center" valign="middle" rowspan="1" colspan="1">27</td><td align="center" valign="middle" rowspan="1" colspan="1">536.45</td><td align="center" valign="middle" rowspan="1" colspan="1">41.44</td><td align="center" valign="middle" rowspan="1" colspan="1">0.06</td><td align="center" valign="middle" rowspan="1" colspan="1">0.81</td><td align="center" valign="middle" rowspan="1" colspan="1">5.81</td><td align="center" valign="middle" rowspan="1" colspan="1">0.000</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">S.S</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">468.66</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">47.70</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5.89</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.000</td></tr></tbody></table><table-wrap-foot><fn><p><sup>a</sup> 2-tailed; N.S, novice students; S.S, senior students.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-05423-t002" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05423-t002_Table 2</object-id><label>Table 2</label><caption><p>Differences in motion accuracy between novice and senior students (Mann&#8211;Whitney U test).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Motion</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Group</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">N</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Mean Rank</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Sum of Ranks</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">M-W U <sup>a</sup></th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Wilcoxon</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Z</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Asymp. Sig. <sup>b</sup></th></tr></thead><tbody><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Motion-1</td><td align="center" valign="middle" rowspan="1" colspan="1">N.S </td><td align="center" valign="middle" rowspan="1" colspan="1">27</td><td align="center" valign="middle" rowspan="1" colspan="1">38.52</td><td align="center" valign="middle" rowspan="1" colspan="1">1040.00</td><td align="center" valign="middle" rowspan="1" colspan="1">229.00</td><td align="center" valign="middle" rowspan="1" colspan="1">790.00</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;3.22</td><td align="center" valign="middle" rowspan="1" colspan="1">0.001</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">S.S </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">23.94</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">790.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Motion-5</td><td align="center" valign="middle" rowspan="1" colspan="1">N.S </td><td align="center" valign="middle" rowspan="1" colspan="1">27</td><td align="center" valign="middle" rowspan="1" colspan="1">41.96</td><td align="center" valign="middle" rowspan="1" colspan="1">1133.00</td><td align="center" valign="middle" rowspan="1" colspan="1">136.00</td><td align="center" valign="middle" rowspan="1" colspan="1">697.00</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;4.60</td><td align="center" valign="middle" rowspan="1" colspan="1">0.000</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">S.S </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">21.12</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">697.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Motion-6</td><td align="center" valign="middle" rowspan="1" colspan="1">N.S </td><td align="center" valign="middle" rowspan="1" colspan="1">27</td><td align="center" valign="middle" rowspan="1" colspan="1">35.93</td><td align="center" valign="middle" rowspan="1" colspan="1">970.00</td><td align="center" valign="middle" rowspan="1" colspan="1">299.00</td><td align="center" valign="middle" rowspan="1" colspan="1">860.00</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;2.18</td><td align="center" valign="middle" rowspan="1" colspan="1">0.029</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">S.S </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">26.06</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">860.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Motion-7</td><td align="center" valign="middle" rowspan="1" colspan="1">N.S </td><td align="center" valign="middle" rowspan="1" colspan="1">27</td><td align="center" valign="middle" rowspan="1" colspan="1">37.41</td><td align="center" valign="middle" rowspan="1" colspan="1">1010.00</td><td align="center" valign="middle" rowspan="1" colspan="1">259.00</td><td align="center" valign="middle" rowspan="1" colspan="1">820.00</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;2.77</td><td align="center" valign="middle" rowspan="1" colspan="1">0.000</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">S.S </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">24.85</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">820.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td></tr><tr><td rowspan="2" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Motion-8</td><td align="center" valign="middle" rowspan="1" colspan="1">N.S </td><td align="center" valign="middle" rowspan="1" colspan="1">27</td><td align="center" valign="middle" rowspan="1" colspan="1">42.19</td><td align="center" valign="middle" rowspan="1" colspan="1">1139.00</td><td align="center" valign="middle" rowspan="1" colspan="1">130.00</td><td align="center" valign="middle" rowspan="1" colspan="1">691.00</td><td align="center" valign="middle" rowspan="1" colspan="1">4.69</td><td align="center" valign="middle" rowspan="1" colspan="1">0.000</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">S.S </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">33</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">20.94</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">691.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td></tr></tbody></table><table-wrap-foot><fn><p><sup>a</sup> Mann&#8211;Whitney U; <sup>b</sup> 2-tailed; N.S, novice students; S.S, senior students.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-05423-t003" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05423-t003_Table 3</object-id><label>Table 3</label><caption><p>Accuracy of assessing motion accuracy on different methods using the scores of Teacher A as labels.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Methods</th><th colspan="8" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Accuracy (%)</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1 <sup>a</sup></th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</th></tr></thead><tbody><tr><td rowspan="8" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Sample-based</td><td align="center" valign="middle" rowspan="1" colspan="1">k-NN</td><td align="center" valign="middle" rowspan="1" colspan="1">89.47 </td><td align="center" valign="middle" rowspan="1" colspan="1">92.63 <sup>b</sup></td><td align="center" valign="middle" rowspan="1" colspan="1">91.58 <sup>b</sup></td><td align="center" valign="middle" rowspan="1" colspan="1">92.63 <sup>b</sup></td><td align="center" valign="middle" rowspan="1" colspan="1">89.47 <sup>b</sup></td><td align="center" valign="middle" rowspan="1" colspan="1">92.63 <sup>b</sup></td><td align="center" valign="middle" rowspan="1" colspan="1">87.37</td><td align="center" valign="middle" rowspan="1" colspan="1">88.42 <sup>b</sup></td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">SVM</td><td align="center" valign="middle" rowspan="1" colspan="1">89.47 </td><td align="center" valign="middle" rowspan="1" colspan="1">84.21</td><td align="center" valign="middle" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" rowspan="1" colspan="1">92.63 </td><td align="center" valign="middle" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" rowspan="1" colspan="1">75.79</td><td align="center" valign="middle" rowspan="1" colspan="1">95.79 <sup>b</sup></td><td align="center" valign="middle" rowspan="1" colspan="1">80.00</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">NB</td><td align="center" valign="middle" rowspan="1" colspan="1">81.05</td><td align="center" valign="middle" rowspan="1" colspan="1">83.16</td><td align="center" valign="middle" rowspan="1" colspan="1">74.74</td><td align="center" valign="middle" rowspan="1" colspan="1">90.53</td><td align="center" valign="middle" rowspan="1" colspan="1">77.89</td><td align="center" valign="middle" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" rowspan="1" colspan="1">82.11</td><td align="center" valign="middle" rowspan="1" colspan="1">76.84</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">LR</td><td align="center" valign="middle" rowspan="1" colspan="1">78.95</td><td align="center" valign="middle" rowspan="1" colspan="1">71.58</td><td align="center" valign="middle" rowspan="1" colspan="1">62.11</td><td align="center" valign="middle" rowspan="1" colspan="1">81.05</td><td align="center" valign="middle" rowspan="1" colspan="1">84.21</td><td align="center" valign="middle" rowspan="1" colspan="1">77.89</td><td align="center" valign="middle" rowspan="1" colspan="1">81.05</td><td align="center" valign="middle" rowspan="1" colspan="1">76.84</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DT</td><td align="center" valign="middle" rowspan="1" colspan="1">73.68</td><td align="center" valign="middle" rowspan="1" colspan="1">65.26</td><td align="center" valign="middle" rowspan="1" colspan="1">65.26</td><td align="center" valign="middle" rowspan="1" colspan="1">61.05</td><td align="center" valign="middle" rowspan="1" colspan="1">65.26</td><td align="center" valign="middle" rowspan="1" colspan="1">62.11</td><td align="center" valign="middle" rowspan="1" colspan="1">73.68</td><td align="center" valign="middle" rowspan="1" colspan="1">65.26</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">BPNN</td><td align="center" valign="middle" rowspan="1" colspan="1">73.68</td><td align="center" valign="middle" rowspan="1" colspan="1">61.05</td><td align="center" valign="middle" rowspan="1" colspan="1">63.16</td><td align="center" valign="middle" rowspan="1" colspan="1">70.53</td><td align="center" valign="middle" rowspan="1" colspan="1">78.95</td><td align="center" valign="middle" rowspan="1" colspan="1">66.32</td><td align="center" valign="middle" rowspan="1" colspan="1">81.05</td><td align="center" valign="middle" rowspan="1" colspan="1">73.68</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">RBFNN</td><td align="center" valign="middle" rowspan="1" colspan="1">83.16</td><td align="center" valign="middle" rowspan="1" colspan="1">67.37</td><td align="center" valign="middle" rowspan="1" colspan="1">75.79</td><td align="center" valign="middle" rowspan="1" colspan="1">75.79</td><td align="center" valign="middle" rowspan="1" colspan="1">78.95</td><td align="center" valign="middle" rowspan="1" colspan="1">75.79</td><td align="center" valign="middle" rowspan="1" colspan="1">84.21</td><td align="center" valign="middle" rowspan="1" colspan="1">70.53</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1D-CNN</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.58 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">76.84 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">69.47 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">76.84 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">88.42 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">91.58 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.95 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">74.74 </td></tr><tr><td rowspan="8" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Sequence-based</td><td align="center" valign="middle" rowspan="1" colspan="1">DTW + k-NN</td><td align="center" valign="middle" rowspan="1" colspan="1">94.74 <sup>b</sup></td><td align="center" valign="middle" rowspan="1" colspan="1">86.32</td><td align="center" valign="middle" rowspan="1" colspan="1">77.90 </td><td align="center" valign="middle" rowspan="1" colspan="1">80.00 </td><td align="center" valign="middle" rowspan="1" colspan="1">84.21 </td><td align="center" valign="middle" rowspan="1" colspan="1">77.90 </td><td align="center" valign="middle" rowspan="1" colspan="1">87.37 </td><td align="center" valign="middle" rowspan="1" colspan="1">85.26 </td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DTW + SVM</td><td align="center" valign="middle" rowspan="1" colspan="1">66.32</td><td align="center" valign="middle" rowspan="1" colspan="1">62.11</td><td align="center" valign="middle" rowspan="1" colspan="1">69.47 </td><td align="center" valign="middle" rowspan="1" colspan="1">74.74 </td><td align="center" valign="middle" rowspan="1" colspan="1">63.16 </td><td align="center" valign="middle" rowspan="1" colspan="1">65.26 </td><td align="center" valign="middle" rowspan="1" colspan="1">69.47 </td><td align="center" valign="middle" rowspan="1" colspan="1">78.95 </td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DTW + NB</td><td align="center" valign="middle" rowspan="1" colspan="1">77.90 </td><td align="center" valign="middle" rowspan="1" colspan="1">72.63 </td><td align="center" valign="middle" rowspan="1" colspan="1">74.74 </td><td align="center" valign="middle" rowspan="1" colspan="1">84.21 </td><td align="center" valign="middle" rowspan="1" colspan="1">65.26 </td><td align="center" valign="middle" rowspan="1" colspan="1">70.53 </td><td align="center" valign="middle" rowspan="1" colspan="1">70.53 </td><td align="center" valign="middle" rowspan="1" colspan="1">74.74 </td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DTW + LR</td><td align="center" valign="middle" rowspan="1" colspan="1">66.32 </td><td align="center" valign="middle" rowspan="1" colspan="1">63.16 </td><td align="center" valign="middle" rowspan="1" colspan="1">67.37 </td><td align="center" valign="middle" rowspan="1" colspan="1">73.68 </td><td align="center" valign="middle" rowspan="1" colspan="1">63.16 </td><td align="center" valign="middle" rowspan="1" colspan="1">63.16 </td><td align="center" valign="middle" rowspan="1" colspan="1">66.32 </td><td align="center" valign="middle" rowspan="1" colspan="1">74.74 </td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DTW + DT</td><td align="center" valign="middle" rowspan="1" colspan="1">69.47 </td><td align="center" valign="middle" rowspan="1" colspan="1">63.16 </td><td align="center" valign="middle" rowspan="1" colspan="1">82.11 </td><td align="center" valign="middle" rowspan="1" colspan="1">70.53 </td><td align="center" valign="middle" rowspan="1" colspan="1">67.37 </td><td align="center" valign="middle" rowspan="1" colspan="1">68.42 </td><td align="center" valign="middle" rowspan="1" colspan="1">74.74 </td><td align="center" valign="middle" rowspan="1" colspan="1">69.47 </td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DTW + BPNN</td><td align="center" valign="middle" rowspan="1" colspan="1">85.26 </td><td align="center" valign="middle" rowspan="1" colspan="1">71.58 </td><td align="center" valign="middle" rowspan="1" colspan="1">71.58 </td><td align="center" valign="middle" rowspan="1" colspan="1">73.68 </td><td align="center" valign="middle" rowspan="1" colspan="1">66.32 </td><td align="center" valign="middle" rowspan="1" colspan="1">67.37 </td><td align="center" valign="middle" rowspan="1" colspan="1">69.47 </td><td align="center" valign="middle" rowspan="1" colspan="1">84.21 </td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DTW + RBFNN</td><td align="center" valign="middle" rowspan="1" colspan="1">89.47 </td><td align="center" valign="middle" rowspan="1" colspan="1">84.21 </td><td align="center" valign="middle" rowspan="1" colspan="1">72.63 </td><td align="center" valign="middle" rowspan="1" colspan="1">75.79 </td><td align="center" valign="middle" rowspan="1" colspan="1">80.00 </td><td align="center" valign="middle" rowspan="1" colspan="1">81.05 </td><td align="center" valign="middle" rowspan="1" colspan="1">82.11 </td><td align="center" valign="middle" rowspan="1" colspan="1">83.16 </td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">HMM</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">84.21 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">80.00 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.95 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">90.53 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">76.84 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.95 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">83.16 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">77.90 </td></tr><tr><td rowspan="3" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">LSTM</td><td align="center" valign="middle" rowspan="1" colspan="1">75.79 </td><td align="center" valign="middle" rowspan="1" colspan="1">77.90 </td><td align="center" valign="middle" rowspan="1" colspan="1">82.11 </td><td align="center" valign="middle" rowspan="1" colspan="1">84.21 </td><td align="center" valign="middle" rowspan="1" colspan="1">72.63 </td><td align="center" valign="middle" rowspan="1" colspan="1">84.21 </td><td align="center" valign="middle" rowspan="1" colspan="1">78.95 </td><td align="center" valign="middle" rowspan="1" colspan="1">78.95 </td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">BiLSTM</td><td align="center" valign="middle" rowspan="1" colspan="1">84.21 </td><td align="center" valign="middle" rowspan="1" colspan="1">80.00 </td><td align="center" valign="middle" rowspan="1" colspan="1">78.95 </td><td align="center" valign="middle" rowspan="1" colspan="1">90.53 </td><td align="center" valign="middle" rowspan="1" colspan="1">76.84 </td><td align="center" valign="middle" rowspan="1" colspan="1">78.95 </td><td align="center" valign="middle" rowspan="1" colspan="1">83.16 </td><td align="center" valign="middle" rowspan="1" colspan="1">77.90 </td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">GRU</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">80.00 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">75.79 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">67.37 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">83.16 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">74.74 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">81.05 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">82.11 </td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">72.63 </td></tr></tbody></table><table-wrap-foot><fn><p>Note: <sup>a</sup> Motion; <sup>b</sup> The highest accuracy. Dynamic time warping (DTW), k-Nearest Neighbor (k-NN), Support Vector Machines (SVM), Naive Bayes (NB), Logistic Regression (LR), Decision Tree (DT), Back Propagation neural network (BPNN), Radial basis function neural network (RBFNN), One-dimensional CNN (1D-CNN), Hidden Markov Model (HMM), Long Short-Term Memory (LSTM), Bidirectional LSTM (BiLTSM), and Gated Recurrent Units (GRU).</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-05423-t004" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05423-t004_Table 4</object-id><label>Table 4</label><caption><p>Accuracy of assessing motion accuracy on different methods using the scores of Teacher B as labels.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Methods</th><th colspan="8" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Accuracy (%)</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1 <sup>a</sup></th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</th></tr></thead><tbody><tr><td rowspan="8" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Sample-based</td><td align="center" valign="middle" rowspan="1" colspan="1">k-NN</td><td align="center" valign="middle" rowspan="1" colspan="1">89.47</td><td align="center" valign="middle" rowspan="1" colspan="1">86.32 <sup>b</sup></td><td align="center" valign="middle" rowspan="1" colspan="1">88.42 <sup>b</sup></td><td align="center" valign="middle" rowspan="1" colspan="1">91.58 <sup>b</sup></td><td align="center" valign="middle" rowspan="1" colspan="1">91.58 <sup>b</sup></td><td align="center" valign="middle" rowspan="1" colspan="1">86.32 <sup>b</sup></td><td align="center" valign="middle" rowspan="1" colspan="1">85.26</td><td align="center" valign="middle" rowspan="1" colspan="1">86.32 <sup>b</sup></td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">SVM</td><td align="center" valign="middle" rowspan="1" colspan="1">83.16</td><td align="center" valign="middle" rowspan="1" colspan="1">72.63</td><td align="center" valign="middle" rowspan="1" colspan="1">74.74</td><td align="center" valign="middle" rowspan="1" colspan="1">86.32</td><td align="center" valign="middle" rowspan="1" colspan="1">83.16</td><td align="center" valign="middle" rowspan="1" colspan="1">84.21</td><td align="center" valign="middle" rowspan="1" colspan="1">87.37 <sup>b</sup></td><td align="center" valign="middle" rowspan="1" colspan="1">73.68</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">NB</td><td align="center" valign="middle" rowspan="1" colspan="1">78.95</td><td align="center" valign="middle" rowspan="1" colspan="1">78.95</td><td align="center" valign="middle" rowspan="1" colspan="1">68.42</td><td align="center" valign="middle" rowspan="1" colspan="1">88.42</td><td align="center" valign="middle" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" rowspan="1" colspan="1">81.05</td><td align="center" valign="middle" rowspan="1" colspan="1">84.21</td><td align="center" valign="middle" rowspan="1" colspan="1">75.79</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">LR</td><td align="center" valign="middle" rowspan="1" colspan="1">78.95</td><td align="center" valign="middle" rowspan="1" colspan="1">71.58</td><td align="center" valign="middle" rowspan="1" colspan="1">62.11</td><td align="center" valign="middle" rowspan="1" colspan="1">81.05</td><td align="center" valign="middle" rowspan="1" colspan="1">84.21</td><td align="center" valign="middle" rowspan="1" colspan="1">77.89</td><td align="center" valign="middle" rowspan="1" colspan="1">81.05</td><td align="center" valign="middle" rowspan="1" colspan="1">76.84</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DT</td><td align="center" valign="middle" rowspan="1" colspan="1">73.68</td><td align="center" valign="middle" rowspan="1" colspan="1">65.26</td><td align="center" valign="middle" rowspan="1" colspan="1">65.26</td><td align="center" valign="middle" rowspan="1" colspan="1">61.05</td><td align="center" valign="middle" rowspan="1" colspan="1">65.26</td><td align="center" valign="middle" rowspan="1" colspan="1">62.11</td><td align="center" valign="middle" rowspan="1" colspan="1">73.68</td><td align="center" valign="middle" rowspan="1" colspan="1">65.26</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">BPNN</td><td align="center" valign="middle" rowspan="1" colspan="1">73.68</td><td align="center" valign="middle" rowspan="1" colspan="1">61.05</td><td align="center" valign="middle" rowspan="1" colspan="1">63.16</td><td align="center" valign="middle" rowspan="1" colspan="1">70.53</td><td align="center" valign="middle" rowspan="1" colspan="1">78.95</td><td align="center" valign="middle" rowspan="1" colspan="1">66.32</td><td align="center" valign="middle" rowspan="1" colspan="1">81.05</td><td align="center" valign="middle" rowspan="1" colspan="1">73.68</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">RBFNN</td><td align="center" valign="middle" rowspan="1" colspan="1">83.16</td><td align="center" valign="middle" rowspan="1" colspan="1">67.37</td><td align="center" valign="middle" rowspan="1" colspan="1">75.79</td><td align="center" valign="middle" rowspan="1" colspan="1">75.79</td><td align="center" valign="middle" rowspan="1" colspan="1">78.95</td><td align="center" valign="middle" rowspan="1" colspan="1">75.79</td><td align="center" valign="middle" rowspan="1" colspan="1">84.21</td><td align="center" valign="middle" rowspan="1" colspan="1">70.53</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1D-CNN</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">72.63</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">62.11</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">76.84</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">87.37</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">81.05</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.95</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">72.63</td></tr><tr><td rowspan="11" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Sequence-based</td><td align="center" valign="middle" rowspan="1" colspan="1">DTW + k-NN</td><td align="center" valign="middle" rowspan="1" colspan="1">92.63 <sup>b</sup></td><td align="center" valign="middle" rowspan="1" colspan="1">77.89</td><td align="center" valign="middle" rowspan="1" colspan="1">77.90</td><td align="center" valign="middle" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" rowspan="1" colspan="1">83.16</td><td align="center" valign="middle" rowspan="1" colspan="1">83.16</td><td align="center" valign="middle" rowspan="1" colspan="1">86.32</td><td align="center" valign="middle" rowspan="1" colspan="1">83.16</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DTW + SVM</td><td align="center" valign="middle" rowspan="1" colspan="1">66.31</td><td align="center" valign="middle" rowspan="1" colspan="1">60.00</td><td align="center" valign="middle" rowspan="1" colspan="1">69.47</td><td align="center" valign="middle" rowspan="1" colspan="1">69.47</td><td align="center" valign="middle" rowspan="1" colspan="1">66.32</td><td align="center" valign="middle" rowspan="1" colspan="1">65.26</td><td align="center" valign="middle" rowspan="1" colspan="1">72.63</td><td align="center" valign="middle" rowspan="1" colspan="1">77.90</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DTW + NB</td><td align="center" valign="middle" rowspan="1" colspan="1">75.79</td><td align="center" valign="middle" rowspan="1" colspan="1">73.68</td><td align="center" valign="middle" rowspan="1" colspan="1">71.58</td><td align="center" valign="middle" rowspan="1" colspan="1">71.58</td><td align="center" valign="middle" rowspan="1" colspan="1">74.74</td><td align="center" valign="middle" rowspan="1" colspan="1">75.79</td><td align="center" valign="middle" rowspan="1" colspan="1">74.74</td><td align="center" valign="middle" rowspan="1" colspan="1">67.37</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DTW + LR</td><td align="center" valign="middle" rowspan="1" colspan="1">64.21</td><td align="center" valign="middle" rowspan="1" colspan="1">61.05</td><td align="center" valign="middle" rowspan="1" colspan="1">61.05</td><td align="center" valign="middle" rowspan="1" colspan="1">68.42</td><td align="center" valign="middle" rowspan="1" colspan="1">61.05</td><td align="center" valign="middle" rowspan="1" colspan="1">62.11</td><td align="center" valign="middle" rowspan="1" colspan="1">70.53</td><td align="center" valign="middle" rowspan="1" colspan="1">71.58</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DTW + DT</td><td align="center" valign="middle" rowspan="1" colspan="1">67.37</td><td align="center" valign="middle" rowspan="1" colspan="1">62.11</td><td align="center" valign="middle" rowspan="1" colspan="1">60.00</td><td align="center" valign="middle" rowspan="1" colspan="1">70.53</td><td align="center" valign="middle" rowspan="1" colspan="1">76.84</td><td align="center" valign="middle" rowspan="1" colspan="1">76.84</td><td align="center" valign="middle" rowspan="1" colspan="1">73.68</td><td align="center" valign="middle" rowspan="1" colspan="1">81.05</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DTW + BPNN</td><td align="center" valign="middle" rowspan="1" colspan="1">68.42</td><td align="center" valign="middle" rowspan="1" colspan="1">62.11</td><td align="center" valign="middle" rowspan="1" colspan="1">66.32</td><td align="center" valign="middle" rowspan="1" colspan="1">65.26</td><td align="center" valign="middle" rowspan="1" colspan="1">66.32</td><td align="center" valign="middle" rowspan="1" colspan="1">54.74</td><td align="center" valign="middle" rowspan="1" colspan="1">71.58</td><td align="center" valign="middle" rowspan="1" colspan="1">78.95</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DTW + RBFNN</td><td align="center" valign="middle" rowspan="1" colspan="1">78.95</td><td align="center" valign="middle" rowspan="1" colspan="1">74.74</td><td align="center" valign="middle" rowspan="1" colspan="1">76.84</td><td align="center" valign="middle" rowspan="1" colspan="1">62.11</td><td align="center" valign="middle" rowspan="1" colspan="1">86.32</td><td align="center" valign="middle" rowspan="1" colspan="1">78.95</td><td align="center" valign="middle" rowspan="1" colspan="1">86.32</td><td align="center" valign="middle" rowspan="1" colspan="1">83.16</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">HMM</td><td align="center" valign="middle" rowspan="1" colspan="1">83.16</td><td align="center" valign="middle" rowspan="1" colspan="1">73.68</td><td align="center" valign="middle" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" rowspan="1" colspan="1">80.00</td><td align="center" valign="middle" rowspan="1" colspan="1">77.90</td><td align="center" valign="middle" rowspan="1" colspan="1">76.84</td><td align="center" valign="middle" rowspan="1" colspan="1">82.11</td><td align="center" valign="middle" rowspan="1" colspan="1">85.26</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">LSTM</td><td align="center" valign="middle" rowspan="1" colspan="1">76.84</td><td align="center" valign="middle" rowspan="1" colspan="1">71.58</td><td align="center" valign="middle" rowspan="1" colspan="1">77.90</td><td align="center" valign="middle" rowspan="1" colspan="1">75.79</td><td align="center" valign="middle" rowspan="1" colspan="1">76.84</td><td align="center" valign="middle" rowspan="1" colspan="1">82.11</td><td align="center" valign="middle" rowspan="1" colspan="1">84.21</td><td align="center" valign="middle" rowspan="1" colspan="1">82.11</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">BiLSTM</td><td align="center" valign="middle" rowspan="1" colspan="1">82.11</td><td align="center" valign="middle" rowspan="1" colspan="1">75.79</td><td align="center" valign="middle" rowspan="1" colspan="1">78.95</td><td align="center" valign="middle" rowspan="1" colspan="1">74.74</td><td align="center" valign="middle" rowspan="1" colspan="1">76.84</td><td align="center" valign="middle" rowspan="1" colspan="1">82.11</td><td align="center" valign="middle" rowspan="1" colspan="1">83.16</td><td align="center" valign="middle" rowspan="1" colspan="1">85.26</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">GRU</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">76.84</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">67.37</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">69.47</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.58</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">75.79</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">78.95</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">77.90</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">88.42</td></tr></tbody></table><table-wrap-foot><fn><p>Note: <sup>a</sup> Motion; <sup>b</sup> The highest accuracy. Dynamic time warping (DTW), k-Nearest Neighbor (k-NN), Support Vector Machines (SVM), Naive Bayes (NB), Logistic Regression (LR), Decision Tree (DT), Back Propagation neural network (BPNN), Radial basis function neural network (RBFNN), One-dimensional CNN (1D-CNN), Hidden Markov Model (HMM), Long Short-Term Memory (LSTM), Bidirectional LSTM (BiLTSM), and Gated Recurrent Units (GRU).</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-05423-t005" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05423-t005_Table 5</object-id><label>Table 5</label><caption><p>Accuracy and processing time of different methods for assessing and recognizing motions.</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Methods</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Accuracy (%)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Assessing (Seconds)</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Recognizing (Seconds)</th></tr></thead><tbody><tr><td rowspan="8" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Sample-based</td><td align="center" valign="middle" rowspan="1" colspan="1">k-NN</td><td align="center" valign="middle" rowspan="1" colspan="1">97.63</td><td align="center" valign="middle" rowspan="1" colspan="1">0.008 <sup>a</sup></td><td align="center" valign="middle" rowspan="1" colspan="1">0.055 <sup>b</sup></td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">SVM</td><td align="center" valign="middle" rowspan="1" colspan="1">99.47</td><td align="center" valign="middle" rowspan="1" colspan="1">4.751</td><td align="center" valign="middle" rowspan="1" colspan="1">0.914</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">NB</td><td align="center" valign="middle" rowspan="1" colspan="1">97.89</td><td align="center" valign="middle" rowspan="1" colspan="1">0.021</td><td align="center" valign="middle" rowspan="1" colspan="1">0.174</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">LR</td><td align="center" valign="middle" rowspan="1" colspan="1">99.21</td><td align="center" valign="middle" rowspan="1" colspan="1">0.020</td><td align="center" valign="middle" rowspan="1" colspan="1">0.407</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DT</td><td align="center" valign="middle" rowspan="1" colspan="1">84.47</td><td align="center" valign="middle" rowspan="1" colspan="1">0.010</td><td align="center" valign="middle" rowspan="1" colspan="1">0.087</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">BPNN</td><td align="center" valign="middle" rowspan="1" colspan="1">86.97</td><td align="center" valign="middle" rowspan="1" colspan="1">7.709</td><td align="center" valign="middle" rowspan="1" colspan="1">13.270</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">RBFNN</td><td align="center" valign="middle" rowspan="1" colspan="1">75.53</td><td align="center" valign="middle" rowspan="1" colspan="1">0.063</td><td align="center" valign="middle" rowspan="1" colspan="1">0.295</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1D-CNN</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">99.74 *</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9.179</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">80.958</td></tr><tr><td rowspan="11" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Sequence-based</td><td align="center" valign="middle" rowspan="1" colspan="1">DTW + k-NN</td><td align="center" valign="middle" rowspan="1" colspan="1">99.47</td><td align="center" valign="middle" rowspan="1" colspan="1">3.810</td><td align="center" valign="middle" rowspan="1" colspan="1">3.823</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DTW + SVM</td><td align="center" valign="middle" rowspan="1" colspan="1">99.61</td><td align="center" valign="middle" rowspan="1" colspan="1">4.119</td><td align="center" valign="middle" rowspan="1" colspan="1">6.909</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DTW + NB</td><td align="center" valign="middle" rowspan="1" colspan="1">91.84</td><td align="center" valign="middle" rowspan="1" colspan="1">4.057</td><td align="center" valign="middle" rowspan="1" colspan="1">6.757</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DTW + LR</td><td align="center" valign="middle" rowspan="1" colspan="1">94.21</td><td align="center" valign="middle" rowspan="1" colspan="1">4.382</td><td align="center" valign="middle" rowspan="1" colspan="1">10.163</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DTW + DT</td><td align="center" valign="middle" rowspan="1" colspan="1">93.68</td><td align="center" valign="middle" rowspan="1" colspan="1">3.947</td><td align="center" valign="middle" rowspan="1" colspan="1">4.809</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DTW + BPNN</td><td align="center" valign="middle" rowspan="1" colspan="1">91.05</td><td align="center" valign="middle" rowspan="1" colspan="1">14.830</td><td align="center" valign="middle" rowspan="1" colspan="1">24.665</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DTW + RBFNN</td><td align="center" valign="middle" rowspan="1" colspan="1">75.79</td><td align="center" valign="middle" rowspan="1" colspan="1">3.898</td><td align="center" valign="middle" rowspan="1" colspan="1">5.439</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">HMM</td><td align="center" valign="middle" rowspan="1" colspan="1">99.08</td><td align="center" valign="middle" rowspan="1" colspan="1">4.119</td><td align="center" valign="middle" rowspan="1" colspan="1">61.144</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">LSTM</td><td align="center" valign="middle" rowspan="1" colspan="1">96.45</td><td align="center" valign="middle" rowspan="1" colspan="1">14.132</td><td align="center" valign="middle" rowspan="1" colspan="1">123.477</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">BiLSTM</td><td align="center" valign="middle" rowspan="1" colspan="1">97.37</td><td align="center" valign="middle" rowspan="1" colspan="1">27.995</td><td align="center" valign="middle" rowspan="1" colspan="1">239.190</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">GRU</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">97.50</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11.943</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">106.513</td></tr></tbody></table><table-wrap-foot><fn><p>Note: * The highest accuracy; <sup>a</sup> minimum processing time. <sup>b</sup> Minimum processing time. dynamic time warping (DTW), k-Nearest Neighbor (k-NN), Support Vector Machines (SVM), Naive Bayes (NB), Logistic Regression (LR), Decision Tree (DT), Back Propagation neural network (BPNN), Radial basis function neural network (RBFNN), One-dimensional CNN (1D-CNN), Hidden Markov Model (HMM), Long Short-Term Memory (LSTM), Bidirectional LSTM (BiLTSM), and Gated Recurrent Units (GRU).</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-05423-t006" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05423-t006_Table 6</object-id><label>Table 6</label><caption><p>Chi-square test on the methods for recognizing motions with over 99% accuracy.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Methods</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Recognized Motions</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Total</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Correct</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Incorrect</th></tr></thead><tbody><tr><td rowspan="3" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Sample-based</td><td align="center" valign="middle" rowspan="1" colspan="1">SVM</td><td align="center" valign="middle" rowspan="1" colspan="1">756</td><td align="center" valign="middle" rowspan="1" colspan="1">4</td><td align="center" valign="middle" rowspan="1" colspan="1">760</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Logistics regression</td><td align="center" valign="middle" rowspan="1" colspan="1">754</td><td align="center" valign="middle" rowspan="1" colspan="1">6</td><td align="center" valign="middle" rowspan="1" colspan="1">760</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1D-CNN</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">758</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">760</td></tr><tr><td rowspan="3" align="center" valign="middle" style="border-bottom:solid thin" colspan="1">Sequence-based</td><td align="center" valign="middle" rowspan="1" colspan="1">DTW + k-NN</td><td align="center" valign="middle" rowspan="1" colspan="1">756</td><td align="center" valign="middle" rowspan="1" colspan="1">4</td><td align="center" valign="middle" rowspan="1" colspan="1">760</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DTW + SVM</td><td align="center" valign="middle" rowspan="1" colspan="1">757</td><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">760</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">HMM</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">753</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">760</td></tr><tr><td colspan="2" align="center" valign="middle" rowspan="1">Value of Pearson Chi-Square</td><td align="center" valign="middle" rowspan="1" colspan="1">4.023 <sup>a</sup></td><td align="center" valign="middle" rowspan="1" colspan="1">
</td><td align="center" valign="middle" rowspan="1" colspan="1">
</td></tr><tr><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">Asymptotic Significance (2-sided) of Pearson Chi-Square</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.546</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td></tr></tbody></table><table-wrap-foot><fn><p><sup>a</sup> Five cells (50.0%) have an expected count of less than 6. The minimum expected count is 4.33.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="sensors-25-05423-t007" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05423-t007_Table 7</object-id><label>Table 7</label><caption><p>The assessment results and consistency analysis (Kendall test) between the system and teacher.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Motion <sup>a</sup></th><th colspan="3" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">System</th><th colspan="3" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Teacher</th><th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" colspan="1">Kendall Value</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Fail</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Pass</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Good</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Fail</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Pass</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Good</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">14</td><td align="center" valign="middle" rowspan="1" colspan="1">58</td><td align="center" valign="middle" rowspan="1" colspan="1">8</td><td align="center" valign="middle" rowspan="1" colspan="1">16</td><td align="center" valign="middle" rowspan="1" colspan="1">58</td><td align="center" valign="middle" rowspan="1" colspan="1">6</td><td align="center" valign="middle" rowspan="1" colspan="1">0.904</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">6</td><td align="center" valign="middle" rowspan="1" colspan="1">52</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">58</td><td align="center" valign="middle" rowspan="1" colspan="1">17</td><td align="center" valign="middle" rowspan="1" colspan="1">0.865</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">9</td><td align="center" valign="middle" rowspan="1" colspan="1">28</td><td align="center" valign="middle" rowspan="1" colspan="1">39</td><td align="center" valign="middle" rowspan="1" colspan="1">9</td><td align="center" valign="middle" rowspan="1" colspan="1">35</td><td align="center" valign="middle" rowspan="1" colspan="1">32</td><td align="center" valign="middle" rowspan="1" colspan="1">0.855</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">4</td><td align="center" valign="middle" rowspan="1" colspan="1">6</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">18</td><td align="center" valign="middle" rowspan="1" colspan="1">7</td><td align="center" valign="middle" rowspan="1" colspan="1">25</td><td align="center" valign="middle" rowspan="1" colspan="1">14</td><td align="center" valign="middle" rowspan="1" colspan="1">0.867</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">4</td><td align="center" valign="middle" rowspan="1" colspan="1">26</td><td align="center" valign="middle" rowspan="1" colspan="1">20</td><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">29</td><td align="center" valign="middle" rowspan="1" colspan="1">16</td><td align="center" valign="middle" rowspan="1" colspan="1">0.862</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">6</td><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">31</td><td align="center" valign="middle" rowspan="1" colspan="1">11</td><td align="center" valign="middle" rowspan="1" colspan="1">7</td><td align="center" valign="middle" rowspan="1" colspan="1">32</td><td align="center" valign="middle" rowspan="1" colspan="1">8</td><td align="center" valign="middle" rowspan="1" colspan="1">0.835</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">7</td><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">22</td><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">24</td><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">0.850</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">8</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">NA</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">NA</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.867</td></tr></tbody></table><table-wrap-foot><fn><p><sup>a</sup> Motion-1.</p></fn></table-wrap-foot></table-wrap></floats-group></article></pmc-articleset>