<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xml:lang="en" article-type="research-article" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="pmc-domain-id">1660</journal-id><journal-id journal-id-type="pmc-domain">sensors</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>Multidisciplinary Digital Publishing Institute  (MDPI)</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12431450</article-id><article-id pub-id-type="pmcid-ver">PMC12431450.1</article-id><article-id pub-id-type="pmcaid">12431450</article-id><article-id pub-id-type="pmcaiid">12431450</article-id><article-id pub-id-type="doi">10.3390/s25175509</article-id><article-id pub-id-type="publisher-id">sensors-25-05509</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Geohash-Based High-Definition Map Provisioning System Using Smart RSU</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0001-0372-8756</contrib-id><name name-style="western"><surname>Park</surname><given-names initials="W">Wangyu</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software/">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation/">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation/">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#8211; original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Resources" vocab-term-identifier="https://credit.niso.org/contributor-roles/resources/">Resources</role></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0009-0002-5331-6773</contrib-id><name name-style="western"><surname>Lee</surname><given-names initials="J">Jimin</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization/">Visualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project administration</role></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-2200-0020</contrib-id><name name-style="western"><surname>Moon</surname><given-names initials="C">Changjoo</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Writing &#x2013; review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration/">Project administration</role><xref rid="c1-sensors-25-05509" ref-type="corresp">*</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name name-style="western"><surname>Collings</surname><given-names initials="I">Iain</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-05509">Department of Smart Vehicle Engineering, Konkuk University, Seoul 05029, Republic of Korea; <email>wqpark123@konkuk.ac.kr</email> (W.P.); <email>easymean0417@konkuk.ac.kr</email> (J.L.)</aff><author-notes><corresp id="c1-sensors-25-05509"><label>*</label>Correspondence: <email>cjmoon@konkuk.ac.kr</email></corresp></author-notes><pub-date pub-type="epub"><day>04</day><month>9</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>9</month><year>2025</year></pub-date><volume>25</volume><issue>17</issue><issue-id pub-id-type="pmc-issue-id">496815</issue-id><elocation-id>5509</elocation-id><history><date date-type="received"><day>05</day><month>8</month><year>2025</year></date><date date-type="rev-recd"><day>29</day><month>8</month><year>2025</year></date><date date-type="accepted"><day>01</day><month>9</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>04</day><month>09</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>13</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-13 14:25:13.570"><day>13</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="sensors-25-05509.pdf"/><abstract><p>High-definition (HD) maps are essential for safe and reliable autonomous driving, but their growing size and the need for real-time updates pose significant challenges for in-vehicle storage and communication efficiency. This study proposes a lightweight and scalable HD map provisioning system based on Geohash spatial indexing and Smart Roadside Units (Smart RSUs). The system divides HD map data into Geohash-based spatial blocks and enables vehicles to request only the map segments corresponding to their current location, reducing storage burden and communication load. To validate the system&#8217;s effectiveness, we constructed a simulation environment where multiple vehicle clients simultaneously request map data from a Smart RSU. Experimental results showed that the proposed Geohash-based approach achieved an average response time (RTT) of 1244.82 ms&#8212;approximately 296.3% faster than the conventional GPS-based spatial query method&#8212;and improved database query performance by 1072.6%. Additionally, we demonstrate the system&#8217;s scalability by adjusting Geohash levels according to road density, using finer blocks in urban areas and coarser blocks in rural areas. The hierarchical nature of Geohash also enables consistent integration of blocks with different resolutions. These results confirm that the proposed method provides an efficient and real-time HD map delivery framework suitable for dynamic and dense traffic environments.</p></abstract><kwd-group><kwd>HD map</kwd><kwd>Geohash</kwd><kwd>Smart RSU (Road Side Unit)</kwd><kwd>PostgreSQL 15</kwd><kwd>PostGIS</kwd></kwd-group><funding-group><award-group><funding-source>Korea Institute for Advancement of Technology (KIAT)</funding-source><funding-source>Korean Government (MOTIE)</funding-source><award-id>P0020536</award-id></award-group><funding-statement>This paper was supported by the Korea Institute for Advancement of Technology (KIAT) grant funded by the Korean Government (MOTIE) (P0020536, HRD Program for Industrial Innovation).</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-05509"><title>1. Introduction</title><p>With the recent push toward the commercialization of autonomous driving, competition in autonomous driving technologies has become more advanced than ever before. Consequently, the types of external environmental information that vehicles must perceive and process have grown increasingly complex, requiring centimeter-level precision spatial data such as lane widths, road boundaries, intersection structures, and traffic signs. Although sensors such as LiDAR, cameras, and GPS can acquire this information in real-time, their performance deteriorates under adverse conditions such as inclement weather, changes in lighting, or sensor blind spots. To overcome these limitations, prior knowledge in the form of high-precision spatial data&#8212;such as road structure and traffic regulations&#8212;is required, and high-definition (HD) maps have emerged as a critical complement to real-time sensor data [<xref rid="B1-sensors-25-05509" ref-type="bibr">1</xref>].</p><p>HD maps contain a variety of road objects, including lanes, traffic lights, signs, road boundaries, and roadside structures. Recently, even 3D point cloud-based terrain information has been utilized to enrich these maps [<xref rid="B2-sensors-25-05509" ref-type="bibr">2</xref>]. Such high-precision spatial data play a crucial role in the perception-decision-control pipeline of autonomous driving systems. However, in practice, HD maps for autonomous vehicles can occupy tens to hundreds of megabytes per kilometer, and when high-resolution point clouds are included, the size can reach several gigabytes. This poses a burden on the storage capacity of the vehicle [<xref rid="B2-sensors-25-05509" ref-type="bibr">2</xref>].</p><p>To address this issue, instead of storing the entire HD map onboard, a selective provisioning strategy has been considered, where only the data relevant to the vehicle&#8217;s current location is provided in real time by a central C-ITS (Cooperative Intelligent Transport Systems) server. This method involves dividing HD map data into segments based on road objects (links), and providing only the map information for the link corresponding to the vehicle&#8217;s current GPS location [<xref rid="B3-sensors-25-05509" ref-type="bibr">3</xref>].</p><p>However, segmenting HD maps solely by road objects presents several limitations. First, road object units are not spatially continuous. While they are useful for expressing logical connectivity in road networks, spatially adjacent regions are often stored as separate links, which can fragment the map [<xref rid="B3-sensors-25-05509" ref-type="bibr">3</xref>]. Second, road object units are not directly linked to the vehicle&#8217;s GPS coordinates. Since vehicle positions are typically represented using latitude and longitude, they do not directly map to road objects [<xref rid="B4-sensors-25-05509" ref-type="bibr">4</xref>]. As a result, spatial computations and queries are required to identify the corresponding segment of the HD map, increasing system load and latency&#8212;especially detrimental for real-time communication with moving vehicles.</p><p>To overcome these limitations, this study proposes an HD map provisioning system based on Geohash spatial indexing. Geohash encodes latitude and longitude coordinates into fixed-length strings, dividing geographic space into uniform grid blocks [<xref rid="B5-sensors-25-05509" ref-type="bibr">5</xref>]. This approach addresses the limitations of the conventional road object-based segmentation in the following ways. First, by leveraging Geohash&#8217;s continuous block-based indexing, the system can ensure spatial continuity of map data, even when adjacent roads are divided into different links. Since neighboring Geohash blocks share common prefixes, continuous data delivery is possible as the vehicle moves across regions. Second, Geohash enables direct mapping between a vehicle&#8217;s GPS coordinates and pre-indexed HD map blocks, eliminating the need for complex spatial queries. This reduction in computational overhead enhances real-time performance and contributes to improved safety and reliability in autonomous driving.</p><p>A real-time HD map provisioning infrastructure is also essential for this system. Conventionally, infrastructure components such as RSUs (Roadside Units), traffic signal controllers, CCTV, and VDS (Video Detection Systems) are integrated with a centralized C-ITS server to deliver data to vehicles. However, C-ITS centers are typically located far from the vehicles, introducing network latency. Moreover, as HD maps can be hundreds of megabytes in size, providing such data to a growing number of vehicles in a short period puts significant strain on the centralized servers [<xref rid="B6-sensors-25-05509" ref-type="bibr">6</xref>].</p><p>Therefore, this study introduces Smart Roadside Units (Smart RSUs) as the primary map providers. Unlike traditional RSUs, which serve merely as transmitters, Smart RSUs are equipped with edge computing capabilities, possessing local storage and processing power [<xref rid="B7-sensors-25-05509" ref-type="bibr">7</xref>]. By storing Geohash-partitioned HD map data locally, Smart RSUs can respond to vehicle requests in real-time based on their GPS-derived Geohash code. Being physically closer to the vehicles also helps reduce communication delays. Additionally, regional deployment of Smart RSUs can mitigate load concentration issues inherent to centralized systems [<xref rid="B8-sensors-25-05509" ref-type="bibr">8</xref>].</p><p>Therefore, this study proposes a high-definition (HD) map provisioning system based on Geohash spatial indexing using Smart RSUs. Actual HD map data for autonomous driving was preprocessed and divided in advance into Geohash block units, and a database was constructed to map the road objects contained within each block. When a vehicle sends a request to the Smart RSU using its GPS-derived Geohash code, the server responds with the corresponding HD map data for that block. This allows the vehicle to receive only the necessary map segments in real-time without needing to store the entire HD map locally. To evaluate the system&#8217;s performance, a scenario was constructed in which multiple vehicles simultaneously connect to the Smart RSU and request map data. Experimental results showed that the Geohash-based method achieved an average response delay of 1244.82 ms, representing approximately a 296.3% improvement over the GPS-based method (4654.93 ms). In addition, the average database query time was measured at 15.90 ms, which is approximately 1072.6% faster than the GPS-based method (324.91 ms). These results demonstrate that the proposed method significantly improves the real-time performance and efficiency of HD map provisioning compared to traditional approaches.</p><p>The remainder of this paper is structured as follows: <xref rid="sec2-sensors-25-05509" ref-type="sec">Section 2</xref> reviews related work. <xref rid="sec3-sensors-25-05509" ref-type="sec">Section 3</xref> describes the system architecture and implementation of each module. <xref rid="sec4-sensors-25-05509" ref-type="sec">Section 4</xref> details the acquisition and preprocessing of HD map data. <xref rid="sec5-sensors-25-05509" ref-type="sec">Section 5</xref> presents experimental scenarios and performance evaluations. Finally, <xref rid="sec6-sensors-25-05509" ref-type="sec">Section 6</xref> discusses conclusions and future research directions.</p></sec><sec id="sec2-sensors-25-05509"><title>2. Related Works</title><p>In the past, data processing in autonomous driving and intelligent transportation systems was primarily carried out either on the vehicle&#8217;s onboard computer or at centralized cloud servers [<xref rid="B9-sensors-25-05509" ref-type="bibr">9</xref>]. However, as the volume of sensor data generated by vehicles has significantly increased, the computational resources of onboard systems have become insufficient for real-time processing. At the same time, transmitting all data to cloud servers has led to network latency and communication bottlenecks. To overcome these limitations, Roadside Units (RSUs) have been introduced. Evolving beyond simple communication relays, RSUs have developed into edge computing nodes capable of processing data near the vehicle. This enables partial offloading of computational tasks from the vehicle to RSUs, thereby reducing onboard processing burden, minimizing cloud dependency, and satisfying real-time operational requirements.</p><p>Liu et al. proposed an RSU-based computation offloading architecture in which the RSU processes tasks received from vehicles, demonstrating experimentally that this structure can reduce latency and improve execution success rates [<xref rid="B10-sensors-25-05509" ref-type="bibr">10</xref>]. While prior RSU-based offloading studies have shown effectiveness in latency reduction and improved task reliability, they have limitations in handling large-scale data segmentation, provisioning, and real-time delivery. Cho et al. proposed an energy-efficient offloading technique that utilizes multiple RSUs deployed along a vehicle&#8217;s path as cooperative edge computing nodes [<xref rid="B11-sensors-25-05509" ref-type="bibr">11</xref>]. By dividing computational tasks across multiple RSUs and having each node pre-compute results before the vehicle enters its communication range, their approach minimized total energy consumption and addressed the inefficiency of relying on a single RSU during high-speed driving. However, as their work primarily focused on energy optimization, it lacked comprehensive analysis regarding real-time performance factors such as latency and communication stability. Furthermore, the study did not adequately consider resource management and data synchronization between RSUs.</p><p>Thukkani et al. leveraged the hierarchical block structure of Geohash to aggregate vehicle location data at the regional level and combined this approach with a Redis-based distributed in-memory database to significantly enhance the performance of range queries and neighboring vehicle searches [<xref rid="B12-sensors-25-05509" ref-type="bibr">12</xref>]. Their experiments showed that, compared to traditional RDBMS-based approaches, the proposed system achieved superior performance in low-latency location queries and handling large-scale concurrent connections. However, their work utilized Geohash merely as an indexing key for location lookup and did not explore the structural partitioning or management of large-scale spatial databased on Geohash.</p><p>To address these limitations in existing research, this paper proposes a novel approach that utilizes RSUs not only as computation offloading nodes but also as the core entities responsible for provisioning HD map data. In addition, Geohash is employed not just as a lookup optimization tool but as the fundamental unit for HD map request handling and data management. While previous RSU studies focused on offloading and energy efficiency, the proposed system uniquely integrates RSU and Geohash technologies to construct a unified architecture that supports the partitioning, management, and provisioning of high-definition spatial data. This design improves both the real-time responsiveness and efficiency of HD map delivery systems, offering a distinctive contribution beyond the scope of earlier research.</p></sec><sec id="sec3-sensors-25-05509"><title>3. System Architecture and Implementation</title><p>This section describes the architecture of the vehicle client and Smart RSU server, as well as the implementation of their communication structure.</p><sec id="sec3dot1-sensors-25-05509"><title>3.1. System Architecture</title><p><xref rid="sensors-25-05509-f001" ref-type="fig">Figure 1</xref> illustrates the overall system architecture proposed in this study, which consists of two main components: the vehicle client and the Smart RSU server. The vehicle client requests high-definition (HD) map databased on its current location and utilizes the received map data to support driving-related tasks. The Smart RSU server is responsible for providing the corresponding HD map data to the vehicle client based on the requested location. <xref rid="sensors-25-05509-f002" ref-type="fig">Figure 2</xref> explains the actual implementation structure and the flow of data within the system.</p></sec><sec id="sec3dot2-sensors-25-05509"><title>3.2. Vehicle Client</title><p>The vehicle client is a module that virtually simulates a real autonomous vehicle and is responsible for requesting HD map data from the Smart RSU and receiving the corresponding response. As shown in <xref rid="sensors-25-05509-f002" ref-type="fig">Figure 2</xref>, the vehicle client was implemented in a Docker-based container environment [<xref rid="B13-sensors-25-05509" ref-type="bibr">13</xref>]. Docker 28.1.1 was chosen for its lightweight virtualization, which enables easy deployment and execution, as well as the ability to independently generate multiple vehicle clients&#8212;making it well-suited for large-scale experimental setups. The overall experimental environment was configured on Windows 11.</p><p>The core function of the vehicle client is to request HD map data for the area corresponding to the vehicle&#8217;s current location (GPS coordinates). First, the vehicle client assigns arbitrary latitude and longitude values to simulate GPS data. This GPS data is then encoded into a Geohash string using the Python 3.10 APIlibrary pygeohash [<xref rid="B14-sensors-25-05509" ref-type="bibr">14</xref>], which is referred to as the Geohash code. The vehicle client sends this Geohash code to the Smart RSU to request the HD map data corresponding to that region. The request is transmitted via a TCP communication method using a TCP client socket, which delivers the request message&#8212;containing the Geohash code&#8212;to the Smart RSU server [<xref rid="B15-sensors-25-05509" ref-type="bibr">15</xref>]. The message includes the vehicle identifier (vehicle ID), latitude and longitude coordinates, and the Geohash code. As shown in <xref rid="sensors-25-05509-f003" ref-type="fig">Figure 3</xref>, the message is formatted in JSON.</p><p>After sending the request, the vehicle client receives the .xodr file corresponding to the requested Geohash code from the Smart RSU server and saves it in the local directory. The .xodr file is a standardized HD map format designed for autonomous driving applications [<xref rid="B16-sensors-25-05509" ref-type="bibr">16</xref>]. When using the Geohash block format, map data can be spatially divided more efficiently, allowing the vehicle to selectively receive only the necessary areas. This reduces data transmission volume and improves processing speed. Additionally, it enables rapid switching between adjacent blocks during continuous driving, which is advantageous for ensuring real-time responsiveness.</p></sec><sec id="sec3dot3-sensors-25-05509"><title>3.3. Smart RSU</title><p>The Smart RSU server is responsible for providing the HD map data corresponding to the Geohash block based on the Geohash code received from the vehicle client. To simulate a realistic autonomous driving environment, the Smart RSU server was implemented on a VirtualBox-based virtual machine running Ubuntu 24.04.2, as shown in <xref rid="sensors-25-05509-f002" ref-type="fig">Figure 2</xref>, and was composed of the components listed in <xref rid="sensors-25-05509-t001" ref-type="table">Table 1</xref>.</p><p>This environment was selected because VirtualBox 7.1.8 allows for independent network configuration and resource allocation, separate from the Windows-based local PC environment used for vehicle client development. In addition, the network was configured in bridged mode, allowing the Smart RSU server to be assigned a unique IP address independent of the host system [<xref rid="B17-sensors-25-05509" ref-type="bibr">17</xref>]. This setup effectively emulates the operational characteristics of a standalone Smart RSU device in real-world deployment.</p><p>Furthermore, the service coverage of the Smart RSU was defined within a practical distance range that satisfies the target V2I communication quality. According to standards and field measurement reports, typical coverage spans 300&#8211;500 m in dense urban areas, 500&#8211;700 m in suburban corridors, and up to 0.8&#8211;1.0 km on highways. These ranges were adopted as default reference values, acknowledging potential variations depending on the wireless technology employed (ITS-G5/IEEE 802.11p, C-V2X/NR-V2X) and the surrounding urban environment.</p><p>Road geometry and traffic density are critical factors influencing RSU coverage. In areas with short intersection spacing, concentrated turning or branching points, and high traffic density during peak hours, higher request frequency necessitates smaller service ranges and denser RSU deployment. In contrast, larger coverage can be supported in suburban and highway corridors with lower density and longer straight segments. Based on these considerations, the RSU map provision unit was set to approximately 1 km &#215; 1 km, and the effective service range of the RSU was assumed to ensure continuity within this scale.</p><p>The primary function of the Smart RSU server is to provide HD map data in .xodr format for the region corresponding to the Geohash code received from the vehicle client. The vehicle&#8217;s TCP client socket sends a request message containing the Geohash code, which is received by the TCP server socket of the Smart RSU. The server uses this Geohash code as a key to query the PostgreSQL database for the file path of the corresponding .xodr file. Once the file path is retrieved, the server accesses the pre-stored .xodr file (in OpenDRIVE format) from the local file system and transmits it to the vehicle client via the TCP server socket. The vehicle client then saves the received file locally under the name received_hdmap.xodr for further use.</p></sec></sec><sec id="sec4-sensors-25-05509"><title>4. Acquisition and Preprocessing of High-Definition Map Data</title><sec id="sec4dot1-sensors-25-05509"><title>4.1. Structure of High-Definition Map Data</title><p>In this study, to construct an HD map provisioning system suitable for use in real-world autonomous driving environments, we utilized a combination of road structure data and visual feature data provided by Naver Labs [<xref rid="B18-sensors-25-05509" ref-type="bibr">18</xref>]. The road structure data includes essential information that forms the basis of the driving path, such as lane geometry, road connectivity, intersections, and the locations of traffic signs. The detailed components of this dataset are summarized in <xref rid="sensors-25-05509-t002" ref-type="table">Table 2</xref>.</p><p>Conventional centralized high-definition (HD) map provisioning services based on the C-ITS center face limitations in delivering HD maps in real time due to bottlenecks caused by the large volume of map data. Therefore, this study aims to demonstrate that the Smart RSU-based approach can ensure real-time performance even as the size of HD map data increases. While HD map data is typically structured around spatial geometry, this study additionally incorporates visual attribute data corresponding to each road object in order to further increase data volume and more reliably evaluate the system&#8217;s real-time processing limits. The visual attribute data provides semantic information required for sensor perception, such as the type and orientation of traffic signs, the pattern of stop lines and crosswalks, and the color and width of lane markings. These data are stored in .h5 format, containing visual features extracted through deep learning-based perception algorithms. Each .h5 file is organized by road object ID, which corresponds to link or lane objects in the HD map database [<xref rid="B19-sensors-25-05509" ref-type="bibr">19</xref>].</p></sec><sec id="sec4dot2-sensors-25-05509"><title>4.2. Geohash-Based Spatial Segmentation and Mapping</title><p>The Geohash segmentation level was determined based on several key considerations. If the block size is too large, it may include an excessive amount of HD map data, increasing communication overhead and processing time. Conversely, if the block is too small, communication may occur too frequently, negatively impacting network throughput and latency. An analysis of HD map data for the Pangyo region in South Korea using QGIS [<xref rid="B20-sensors-25-05509" ref-type="bibr">20</xref>] confirmed that a single Geohash level 6 block can individually encompass major intersections and road segments in urban areas, as shown in <xref rid="sensors-25-05509-f004" ref-type="fig">Figure 4</xref>. This allows vehicles to request and process only the map data required for short-range driving paths. In addition, as long as the vehicle does not move a significant distance, it can continue driving within the same Geohash region, thereby reducing unnecessary map requests and alleviating the overall processing load on the system. Furthermore, the average size of a map file contained within a single Geohash block was approximately 230 MB, which is a practical size for storage within an autonomous vehicle&#8217;s onboard system and demonstrates the feasibility of lightweight, block-based map delivery. In addition, the map file size contained in a single Geohash block is approximately 230 MB on average. This corresponds to the context introduced in the Introduction, where real-world HD maps are reported to require tens to hundreds of megabytes per kilometer, and reflects the adoption of a 1 km spatial block scale. Accordingly, the evaluation of the block-based delivery mechanism was conducted under realistic conditions. The measured values in this study (RTT, database lookup time, and per-request payload) thus represent a practical operating range, demonstrating that the data size is feasible for in-vehicle systems and further substantiating the effectiveness of lightweight, block-level map delivery.</p><p>In an additional comparison with 50 vehicles, Level 6 exhibited an average RTT of 1.6 s with a block size of approximately 230 MB, whereas Level 5 resulted in a block size of about 700 MB with an RTT of 3 s, and Level 4 in a block size of about 2.5 GB with an RTT of 6 s. These results indicate that larger block sizes lead to increased transmission delays, confirming that Level 6 provides the most practical balance between block size and latency.</p><p>Conventional approaches that retrieve map databased on individual road links often involve repeated searches and computations across multiple links to obtain the map for a specific region. This process increases computational overhead and leads to query processing delays. In contrast, using the Geohash block method eliminates the need for complex spatial operations by utilizing predefined string-based keys. This allows all road links within a specific block to be retrieved at once. As a result, the management of map data is simplified from a link-based to a block-based approach, significantly improving storage and retrieval efficiency. Therefore, the Geohash technique provides an advantage in terms of real-time performance by addressing the computational burden and inefficient data management issues inherent in traditional link-based query methods.</p><p>The HD map data was stored in a spatial database using PostgreSQL 15 with PostGIS support [<xref rid="B21-sensors-25-05509" ref-type="bibr">21</xref>]. The database was structured as shown in <xref rid="sensors-25-05509-t003" ref-type="table">Table 3</xref>. All tables include a geom field that represents the spatial geometry of each object, such as points, lines, or polygons, expressed in coordinate form. From this geometry field, the geographic center point (latitude and longitude) of each object is calculated. Based on this central point, a Geohash level 6 code is generated and stored in the geohash6 field. This field serves as the identifier for determining which spatial block the vehicle client&#8217;s request corresponds to.</p><p>For example, if the geometry information of a linkid object yields a centroid at latitude 37.4&#176; and longitude 127.1&#176;, the Geohash level 6 encoding would produce the code wydku3, which is then stored in the geohash6 column. This process is performed once during the preprocessing phase. The Smart RSU server then uses the geohash6 field to query and retrieve HD map data corresponding to the requested region. The assignment of Geohash codes was implemented using spatial operations within the database and the external Python 3.10 library pygeohash.</p><p>Based on the high-definition map data annotated with Geohash codes as shown in the <xref rid="sensors-25-05509-t004" ref-type="table">Table 4</xref> above, pre-generated .xodr files were created for each Geohash code. The .xodr file is a high-definition map file formatted according to the OpenDRIVE standard and contains detailed road object information required for autonomous driving, such as road geometry, lane information, and traffic signs. When this file is delivered to the vehicle client, the client can utilize the detailed road environment information for path planning and driving decision-making.</p><p>To generate the .xodr files, spatial objects such as road centerlines, lanes, nodes, stop lines, and traffic signs were retrieved for each Geohash code and structured in JSON format. Then, using a Python 3.10-based conversion module (json_to_xodr.py), the data was converted into the OpenDRIVE schema by mapping elements such as roads, lanes, and junctions to XML nodes and constructing a hierarchical structure accordingly [<xref rid="B16-sensors-25-05509" ref-type="bibr">16</xref>].</p><p>The converted .xodr files were stored in a single local repository, and since the storage unit and transmission unit coincide at the block level, this study did not introduce a hierarchical structure across different map elements. However, in large-scale operations where differential updates at the element level may be required, element-specific hierarchization would be a valid direction for future extensions.</p><p><xref rid="sensors-25-05509-f005" ref-type="fig">Figure 5</xref> illustrates the internal structure of a generated OpenDRIVE (.xodr) file. The OpenDRIVE schema is hierarchically organized around the &lt;road&gt; node, which serves as the core unit encompassing each road object. The schema is primarily structured with the &lt;planeView&gt; and &lt;lanes&gt; nodes. The &lt;road&gt; node at the top level contains metadata such as a unique road identifier, road length, and junction presence. The &lt;planeView&gt; node at the lower level describes the continuous road geometry using lines, arcs, and splines, while the &lt;lanes&gt; node defines the detailed configuration of drivable lanes, lane boundaries, and center lanes. When necessary, the &lt;junction&gt; node specifies the connectivity between roads. The converted files are saved with filenames that include the corresponding Geohash code (e.g., hdmap_wydku3.xodr).</p><p><xref rid="sensors-25-05509-f006" ref-type="fig">Figure 6</xref> shows a visualization result by uploading the generated .xodr files to the Online OpenDRIVE Viewer, allowing comparison with the actual map [<xref rid="B22-sensors-25-05509" ref-type="bibr">22</xref>]. It confirms that each file contains multiple links corresponding to the respective Geohash region.</p><p>This pre-generation process is intended to reduce the computational burden on the Smart RSU of converting large-scale spatial data in real time upon receiving a request from a vehicle client, thereby enabling immediate provision of high-definition map data for the requested Geohash region. </p></sec></sec><sec id="sec5-sensors-25-05509"><title>5. Experimental Overview and Measurement of Evaluation Metrics </title><sec id="sec5dot1-sensors-25-05509"><title>5.1. Overview of the Experiments </title><p>In this study, experiments were conducted to evaluate the efficiency of the Geohash-based spatial indexing method and the effectiveness of the HD map provisioning system using Smart RSUs (edge servers). The experiments were designed around four main comparative criteria. First, to compare delay times based on request methods, the response time was measured when the vehicle client requested map data using the Geohash-based method versus the traditional GPS radius-based method. Second, to compare performance based on the data provider, the processing speed and system load were evaluated when HD map data was provided by the Smart RSU versus by a centralized C-ITS cloud server(GCP, Google LLC, Seoul, Republic of Korea). Third, to assess the scalability of the Smart RSU server, system resource usage was monitored as the number of vehicle clients increased. Fourth, the accuracy and completeness of HD map data provided by the Smart RSU were verified to ensure no data loss occurred during transmission. In addition, the system&#8217;s scalability was evaluated by verifying the ability to flexibly adjust the size of spatial blocks according to road network complexity. All experiments were conducted in the same testbed location&#8212;Pangyo Intersection, South Korea&#8212;to ensure consistent conditions for performance analysis and evaluation.</p></sec><sec id="sec5dot2-sensors-25-05509"><title>5.2. Experiment 1: Comparison of Delay Time According to Request Method</title><p>The purpose of this experiment is to quantitatively compare the system response delay (RTT; Round Trip Time) and database processing time between the traditional GPS-coordinate-based request method and the proposed Geohash-code-based request method for retrieving high-definition map data.</p><p>The Geohash-based request experiment in this study was conducted using the wydksx block, which includes Pangyo Station Intersection in South Korea. This block corresponds to Geohash Level 6 (1.22 km &#215; 0.61 km). For comparison, the GPS-based request experiment used the latitude and longitude of the center point of the wydksx block (37.394701, 127.116833), and retrieved road object data within a radius of 0.8627 km&#8212;chosen to match the area size of a Geohash Level 6 block.</p><p>The size of the received data was approximately 236.31 MB for the Geohash method and 245.37 MB for the GPS method, maintaining similar volumes. Each method was tested 100 times using the same geographic region.</p><p>First, the system response delay time was evaluated. This delay is defined as the total round-trip time from the moment the vehicle client sends a request containing the Geohash code to the Smart RSU server, to the moment the .xodr file is successfully transmitted back to the client. This includes network transmission time, server-side request processing time, file retrieval time, and file transfer time, thereby representing the comprehensive responsiveness of the system.</p><p>The experimental results are presented in <xref rid="sensors-25-05509-f007" ref-type="fig">Figure 7</xref>. The average RTT for the Geohash-based method was measured at 1240.75 ms, whereas the GPS-based method recorded an average RTT of 4699.72 ms. This indicates that the Geohash-based method achieves a response time approximately 278.8% faster than the GPS-based method. These findings suggest that the Geohash-based approach effectively overcomes structural limitations inherent in existing methods, which rely on real-time spatial computations such as PostGIS distance queries based on GPS coordinates.</p><p>In contrast, the Geohash method enables efficient data retrieval through simple string matching, significantly reducing computational and lookup overhead. This allows even large-scale spatial data such as high-definition maps to be provided in real time. As a result, vehicles can perform critical driving decisions&#8212;such as route changes, intersection entry, or emergency response&#8212;without delay, thereby enhancing driving safety and overall system reliability.</p><p>Moreover, the average RTT of 1240.75 ms (approximately 1.2 s) satisfies the map update interval requirements of 1 to 5 s presented in prior HD map research [<xref rid="B9-sensors-25-05509" ref-type="bibr">9</xref>], and more specifically, meets the recommended update interval of under 1&#8211;2 s for urban driving environments. Therefore, the proposed Geohash-based method demonstrates sufficient performance to support real-time HD map provisioning for autonomous vehicle decision-making.</p><p>The next experiment compares the database processing time. This metric refers solely to the time required for the Smart RSU server to query the PostgreSQL 15 database using the received Geohash code and retrieve the corresponding file path of the .xodr map file. This time was measured independently to evaluate the performance difference stemming from the structural divergence in data lookup mechanisms between the two request methods.</p><p>The experimental results are shown in <xref rid="sensors-25-05509-f008" ref-type="fig">Figure 8</xref>. The average database query time for the Geohash-based method was 16.57 ms, whereas the GPS-based method recorded an average of 321.20 ms. This indicates that the database processing speed of the Geohash-based method is approximately 1838.4% faster than that of the GPS-based method. While the database processing speed showed a 1,838.4% improvement, the RTT improved by only 278.8%. This discrepancy is attributed to the structural characteristics of the GPS-based method. The GPS-based method performs real-time spatial queries to search for all relevant road objects, resulting in significantly longer database processing times. However, once the data is retrieved, it is transmitted in a relatively straightforward manner, allowing for faster response handling. In contrast, although the Geohash-based method enables faster data retrieval through lightweight indexing, it involves additional steps such as file lookup and transmission, which limit the overall improvement in RTT.</p><p>This significant performance gap stems from fundamental structural differences in the data retrieval processes of the two approaches. The Geohash method retrieves high-definition map data using a simple condition such as WHERE geohash6 = &#8217;wydksx&#8217;, allowing direct access to the corresponding .xodr file path through a single string-matching operation. Since this approach avoids full table scans and leverages indexed lookups, it enables faster query execution while minimizing CPU resource usage.</p><p>In contrast, the GPS-based method involves spatial distance calculations between the vehicle&#8217;s latitude and longitude coordinates and surrounding road objects. This spatial computation introduces overhead, leading to substantially longer query times than the Geohash approach.</p><p>The reduced database processing delay in the Geohash method directly contributes to the lower overall system response time (RTT) observed in previous experiments. Therefore, the Geohash-based approach minimizes database query overhead and is well-suited for real-time high-definition map delivery systems, particularly in autonomous driving environments where continuous and consistent responses to frequent data requests are critical.</p><p>In addition, this study analyzed the scalability of the two approaches under concurrent vehicle requests. When 30, 50, and 100 vehicles simultaneously accessed the RSU to request HD map data, the GPS-based method exhibited severe performance degradation. The average RTT sharply increased from 5.9 s to more than 12.2 s as the number of concurrent requests grew, and the database query latency rose from 428.5 ms to 921.7 ms. This degradation is attributed to bottlenecks in PostGIS caused by repeated distance calculations, spatial index searches, and multi-table joins during the ST_DWithin operation. In contrast, the Geohash-based method showed only a moderate increase, from 1.3 s with 30 clients to 2.7 s with 100 clients, while the database query latency remained stable within the range of 20&#8211;35 ms.</p><p>These results demonstrate that the Geohash-based approach maintains stable performance even under high query concurrency, owing to its lightweight string comparison and pre-indexed mapping structure. Particularly in autonomous driving environments, where tens to hundreds of vehicles continuously generate real-time requests, the proposed Geohash-based method effectively mitigates the bottlenecks and performance degradation risks of PostGIS, thereby experimentally proving its suitability for real-time HD map provisioning systems.</p></sec><sec id="sec5dot3-sensors-25-05509"><title>5.3. Experiment 2: Performance Comparison Based on Map Data Provider</title><p>The purpose of this experiment is to quantitatively compare the impact of different high-definition map data providers&#8212;Smart RSU (Konkuk University, Seoul, Republic of Korea) and Cloud(Google LLC, Seoul, Republic of Korea)&#8212;on system response delay (RTT; Round Trip Time). In both environments, the Geohash-based request method was used to deliver data of identical size and structure, enabling a fair evaluation of performance differences arising solely from architectural disparities between the two providers.</p><p>The experiment was conducted using the wydksx Geohash block (Level 61.22 km &#215; 0.61 km), which corresponds to the Pangyo Station intersection area in South Korea. The vehicle client sent the same Geohash code (wydksx) to both the Smart RSU and the Cloud server. Each server then transmitted the same pre-generated .xodr file (approximately 236 MB) in response.</p><p>For the cloud environment, a Google Cloud Platform (GCP, Google LLC, Seoul, Republic of Korea) VM instance was configured to serve as the C-ITS center, while the Smart RSU was implemented as an edge node operating on a VirtualBox-based environment. To simulate varying traffic loads, the experiment was repeated with 30, 50, and 100 vehicles making concurrent requests. The RTT for each vehicle was recorded until all requests were completed, and the average RTT per scenario was then calculated for comparison.</p><p>As shown in <xref rid="sensors-25-05509-f009" ref-type="fig">Figure 9</xref>, the Smart RSU consistently recorded lower RTT values than the Cloud across all test scenarios. As the number of vehicles increased, the performance gap between the two environments widened, with the Cloud environment exhibiting a non-linear increase in RTT as the request load grew.</p><p>This result can be attributed to fundamental structural differences in the data provisioning scope and processing methods of each system. In this study, the Smart RSU was designed to manage only a single designated Geohash block (e.g., wydksx) and directly retrieve and transmit the corresponding .xodr file from its local file system. In contrast, the Cloud server is structured to handle concurrent requests from multiple regions (e.g., wydksx, wydksw wydksr, etc.), and the high-definition map data is distributed across different areas.</p><p>Moreover, the Cloud must perform spatial queries or coordinate-based dynamic lookups for each request, which, combined with the overhead introduced by virtualization layers and multiple network hops inherent to cloud infrastructure, results in significantly increased latency. Thus, the observed RTT differences are not merely due to differences in computing environments, but rather reflect deeper architectural distinctions in request handling and data retrieval strategies.</p><p>The performance comparison experiment confirms that the Smart RSU achieved response times 4 to 5 times faster than the Cloud (C-ITS Center) on average. Notably, this performance advantage became even more pronounced under higher vehicle loads. These results empirically demonstrate that the Smart RSU is more suitable than a centralized cloud-based architecture for serving high-definition map data in autonomous driving environments where real-time responsiveness is critical.</p><p>In this study, the experiments were conducted up to 30, 50, and 100 simultaneous vehicle requests, but the proposed system architecture is inherently scalable to larger traffic flows. Since Smart RSUs operate as distributed edge units, traffic requests are naturally partitioned by road segments, and in overload situations, requests can be further alleviated through load sharing among neighboring RSUs.</p><p>Moreover, the Geohash-based indexing scheme processes queries through simple string comparisons, ensuring that the computational cost increases linearly with the number of requests while minimizing CPU resource usage. In large-scale environments, resource management and scheduling mechanisms can also be incorporated. For example, round-robin request distribution, priority-based scheduling for safety-critical requests, and load balancing among adjacent RSUs can be seamlessly integrated into the modular design of the RSU server.</p><p>Therefore, although the experiments were limited to 100 vehicles, the distributed edge-based architecture and lightweight Geohash indexing structure confirm that the proposed system can be effectively applied to large-scale autonomous driving environments with significantly higher traffic volumes.</p></sec><sec id="sec5dot4-sensors-25-05509"><title>5.4. Experiment 3: Evaluation of RSU Server Resource Utilization</title><p>This experiment was conducted to evaluate the resource efficiency of the Smart RSU server as the number of vehicles increases. In a high-definition map provisioning system, the RSU must handle simultaneous requests from multiple vehicles, making it essential to quantitatively analyze the impact of increased vehicle traffic on the server&#8217;s computational and communication resources. In particular, since the Smart RSU is responsible for real-time data processing and transmission at the edge, CPU usage (indicating computational load) and network throughput (indicating communication load) serve as key indicators for assessing the system&#8217;s scalability and stability.</p><p><xref rid="sensors-25-05509-f010" ref-type="fig">Figure 10</xref> presents the average CPU usage (%) and average network throughput (MB/s) of the Smart RSU server as the number of vehicles increases from 30 to 50 and then to 100. The results show a clear upward trend in CPU usage, rising from 35.2% with 30 vehicles to 48.3% with 50 vehicles, and reaching 78.4% with 100 vehicles. This increase reflects the higher volume of simultaneous map retrieval and file transmission tasks that the RSU must handle as the number of vehicles grows. Similarly, network throughput also increased steadily&#8212;from 18.5 MB/s (30 vehicles) to 26.7 MB/s (50 vehicles), and 55.6 MB/s (100 vehicles)&#8212;as more .xodr files were required to be transmitted concurrently.</p><p>These results demonstrate that the Smart RSU server can handle up to 100 vehicles with a linear increase in resource usage, maintaining stable performance. The fact that CPU usage remained below 80% suggests that the server still has some processing headroom, even at higher loads. Additionally, the increase in network throughput occurred at a consistent rate without signs of congestion or overload. Therefore, the findings indicate that the Smart RSU server can reliably provide services even under high concurrency, and possesses sufficient scalability to support larger-scale deployments through potential hardware upgrades.</p></sec><sec id="sec5dot5-sensors-25-05509"><title>5.5. Experiment 4: Evaluation of Data Consistency and Scalability</title><p>The purpose of this experiment is to evaluate whether the high-definition maps provided by the Smart RSU to vehicle clients are delivered stably and continuously without any data loss. In particular, the experiment focused on verifying boundary continuity between adjacent blocks in a Geohash-based map provisioning structure where the data is divided and delivered in block units.</p><p>First, the number of boundary roads in four Geohash blocks&#8212;wydksx, wydksr, wydksq, and wydksw&#8212;was calculated. Then, for each pair of adjacent blocks, the presence of matching link IDs was examined to determine continuity. Continuity was defined as the ratio of boundary roads in the reference block that also exist in the neighboring block, where a higher ratio indicates a more seamless connection between the two blocks. The evaluation results are shown in <xref rid="sensors-25-05509-t005" ref-type="table">Table 5</xref>, and all adjacent block pairs demonstrated 100% continuity.</p><p>These findings confirm that the boundary roads of the high-definition maps received by vehicles are consistently shared across Geohash blocks, enabling uninterrupted map reception along the vehicle&#8217;s driving path without any data omission.</p><p>In addition, Geohash offers scalability by enabling flexible adjustment of spatial block sizes based on its hierarchical encoding structure, which can adapt to varying road network complexities. For example, in dense urban areas such as the Pangyo intersection&#8212;where intersections are closely clustered and road objects are intricately distributed&#8212;Geohash level 6 segmentation is required for precise HD map management. In practice, a single level 6 block in the Pangyo region resulted in an average .xodr file size of approximately 230 MB.</p><p>In contrast, for regions with low road density and simpler structures&#8212;such as Daehwa-myeon in Pyeongchang-gun, Gangwon Province&#8212;the average file size of .xodr files generated with the same level 6 setting was approximately 60 MB. In such simple areas, using broader blocks (e.g., level 5 or higher levels) is more efficient, helping reduce storage requirements and communication overhead.</p><p>Moreover, since Geohash has a hierarchical structure in which higher-level codes contain lower-level ones, the system can be expanded without structural conflict. For example, even if the system was initially designed using level 6 blocks, it can later be extended to store outer suburban areas using level 5 blocks without any inconsistency or system error. This is because all blocks are managed coherently within the prefix-based Geohash key structure. Therefore, the proposed system ensures both architectural flexibility and scalability in HD map provisioning.</p></sec></sec><sec id="sec6-sensors-25-05509"><title>6. Conclusions and Future Work</title><p>This study proposed a system architecture for real-time high-definition (HD) map provision using a Smart RSU-based Geohash spatial indexing method and validated its performance using actual autonomous driving map data. To overcome the spatial computation overhead and communication delay issues inherent in conventional GPS-based radius query methods, the system adopted a lightweight indexing scheme based on Geohash strings to maximize data retrieval efficiency. Furthermore, the role of the map provider was shifted from a centralized cloud-based C-ITS server to an edge-based RSU, alleviating both response delay and server load.</p><p>Experimental results showed that the proposed Geohash-based request method achieved significant improvements in average response time (RTT) and database query processing time compared to the GPS-based method. In addition, the Smart RSU maintained consistent and stable response performance even as the number of vehicles increased, and its resource usage remained within acceptable limits, demonstrating the system&#8217;s scalability and stability. Notably, the Smart RSU architecture, which searches for and transmits pre-generated .xodr files by region, proved to be an effective solution for addressing real-time requirements and mitigating network bottlenecks in autonomous driving environments.</p><p>The continuity verification between adjacent Geohash blocks confirmed that no data loss or disconnection occurred at block boundaries, ensuring seamless map reception along vehicle routes. Furthermore, the scalability evaluation revealed that adjusting Geohash levels based on regional data complexity (e.g., urban vs. rural) can reduce storage and communication costs, confirming the flexibility of the system.</p><p>In summary, this study presents a practical architecture that achieves both structural efficiency and real-time performance in HD map provisioning. It holds significance in that it experimentally validates the potential of edge-based map provisioning technologies for the future expansion of large-scale autonomous driving infrastructure.</p><p>In future work, we plan to implement a distributed processing architecture among multiple Smart RSUs and develop a dynamic HD map update system, while conducting a comprehensive performance evaluation of real-time responsiveness and communication reliability in a C-V2X-based environment. Additionally, we aim to establish a methodology for flexibly adjusting Geohash levels based on regional road characteristics to achieve a balance between spatial efficiency and real-time performance.</p><p>Furthermore, while this study assumed Smart RSUs to be statically deployed, in real-world environments, mobile RSUs mounted on vehicles, buses, or drones can also play an important role. Accordingly, future work will investigate the applicability of mobile RSUs and evaluate how coverage changes and latency variations caused by mobility affect system performance, thereby further extending the generality and practicality of the proposed architecture.</p></sec></body><back><fn-group><fn><p><bold>Disclaimer/Publisher&#8217;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><notes><title>Author Contributions</title><p>Conceptualization, W.P. and J.L.; methodology, W.P. and C.M.; software, W.P.; validation, W.P.; formal analysis, W.P. and J.L.; investigation, W.P. and J.L.; resources, W.P.; data curation, W.P.; writing&#8212;original draft preparation, W.P. and J.L.; writing&#8212;review and editing, W.P., J.L. and C.M.; visualization, W.P. and J.L.; supervision, C.M.; project administration, J.L. and C.M.; funding acquisition, C.M. All authors have read and agreed to the published version of the manuscript.</p></notes><notes><title>Institutional Review Board Statement</title><p>Not applicable.</p></notes><notes><title>Informed Consent Statement</title><p>Not applicable.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>Data are available upon request from the authors.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflicts of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-25-05509"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bao</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Hossain</surname><given-names>S.</given-names></name><name name-style="western"><surname>Lang</surname><given-names>H.</given-names></name><name name-style="western"><surname>Lin</surname><given-names>X.</given-names></name></person-group><article-title>High-Definition Map Generation Technologies for Autonomous Driving</article-title><source>arXiv</source><year>2022</year><pub-id pub-id-type="doi">10.48550/arXiv.2206.05400</pub-id><pub-id pub-id-type="arxiv">2206.05400</pub-id></element-citation></ref><ref id="B2-sensors-25-05509"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bardak</surname><given-names>G.</given-names></name><name name-style="western"><surname>Sodano</surname><given-names>M.</given-names></name><name name-style="western"><surname>Scholz</surname><given-names>M.</given-names></name></person-group><article-title>Integration of HD Maps and Point Clouds: An Efficient 3D Reconstruction Framework for Autonomous Driving Applications</article-title><source>Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci.</source><year>2025</year><volume>XLVIII-4/W13</volume><fpage>49</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.5194/isprs-archives-XLVIII-4-W13-2025-49-2025</pub-id></element-citation></ref><ref id="B3-sensors-25-05509"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Song</surname><given-names>H.</given-names></name><name name-style="western"><surname>Hu</surname><given-names>B.</given-names></name><name name-style="western"><surname>Huang</surname><given-names>Q.</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Song</surname><given-names>J.</given-names></name></person-group><article-title>A Lightweight High Definition Mapping Method Based on Multi-Source Data Fusion Perception</article-title><source>Appl. Sci.</source><year>2023</year><volume>13</volume><elocation-id>3264</elocation-id><pub-id pub-id-type="doi">10.3390/app13053264</pub-id></element-citation></ref><ref id="B4-sensors-25-05509"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>C.</given-names></name><name name-style="western"><surname>Fan</surname><given-names>H.</given-names></name><name name-style="western"><surname>Li</surname><given-names>W.</given-names></name></person-group><article-title>Automated Detecting and Placing Road Objects from Street-Level Images</article-title><source>Comput. Urban Sci.</source><year>2021</year><volume>1</volume><fpage>15</fpage><pub-id pub-id-type="doi">10.1007/s43762-021-00019-6</pub-id></element-citation></ref><ref id="B5-sensors-25-05509"><label>5.</label><element-citation publication-type="webpage"><article-title>Geohash</article-title><year>2025</year><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://en.wikipedia.org/wiki/Geohash" ext-link-type="uri">https://en.wikipedia.org/wiki/Geohash</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-07-30">(accessed on 30 July 2025)</date-in-citation></element-citation></ref><ref id="B6-sensors-25-05509"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>R.</given-names></name><name name-style="western"><surname>Cai</surname><given-names>K.</given-names></name></person-group><article-title>The Key Technology of High-Definition Maps Distribution Based on Edge Computing</article-title><source>Int. J. Comput. Commun. Eng.</source><year>2021</year><volume>10</volume><fpage>52</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.17706/IJCCE.2021.10.3.52-67</pub-id></element-citation></ref><ref id="B7-sensors-25-05509"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Busacca</surname><given-names>F.</given-names></name><name name-style="western"><surname>Grasso</surname><given-names>C.</given-names></name><name name-style="western"><surname>Palazzo</surname><given-names>S.</given-names></name><name name-style="western"><surname>Schembra</surname><given-names>G.</given-names></name></person-group><article-title>A Smart Road Side Unit in a Microeolic Box to Provide Edge Computing for Vehicular Applications</article-title><source>IEEE Trans. Green Commun. Netw.</source><year>2022</year><volume>7</volume><fpage>194</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1109/TGCN.2022.3187674</pub-id></element-citation></ref><ref id="B8-sensors-25-05509"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Xie</surname><given-names>J.</given-names></name><name name-style="western"><surname>Tang</surname><given-names>J.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>S.</given-names></name></person-group><article-title>An Energy-Efficient High Definition Map Data Distribution Mechanism for Autonomous Driving</article-title><source>arXiv</source><year>2020</year><pub-id pub-id-type="doi">10.48550/arXiv.2010.05233</pub-id><pub-id pub-id-type="arxiv">2010.05233</pub-id></element-citation></ref><ref id="B9-sensors-25-05509"><label>9.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Damacharla</surname><given-names>P.</given-names></name><name name-style="western"><surname>Mehta</surname><given-names>D.</given-names></name><name name-style="western"><surname>Javaid</surname><given-names>A.Y.</given-names></name><name name-style="western"><surname>Devabhaktuni</surname><given-names>V.K.</given-names></name></person-group><article-title>Study on State-of-the-Art Cloud Services Integration Capabilities with Autonomous Ground Vehicles</article-title><source>Proceedings of the 2018 IEEE 88th Vehicular Technology Conference (VTC-Fall)</source><conf-loc>Chicago, IL, USA</conf-loc><conf-date>27&#8211;30 August 2018</conf-date><fpage>1</fpage><lpage>5</lpage></element-citation></ref><ref id="B10-sensors-25-05509"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>P.</given-names></name><name name-style="western"><surname>Li</surname><given-names>J.</given-names></name><name name-style="western"><surname>Sun</surname><given-names>Z.</given-names></name></person-group><article-title>Matching-Based Task Offloading for Vehicular Edge Computing</article-title><source>IEEE Access</source><year>2019</year><volume>7</volume><fpage>27628</fpage><lpage>27640</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2019.2896000</pub-id></element-citation></ref><ref id="B11-sensors-25-05509"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cho</surname><given-names>H.</given-names></name><name name-style="western"><surname>Cui</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Lee</surname><given-names>J.</given-names></name></person-group><article-title>Energy-Efficient Cooperative Offloading for Edge Computing-Enabled Vehicular Networks</article-title><source>IEEE Trans. Wirel. Commun.</source><year>2022</year><volume>21</volume><fpage>10709</fpage><lpage>10723</lpage><pub-id pub-id-type="doi">10.1109/TWC.2022.3186590</pub-id></element-citation></ref><ref id="B12-sensors-25-05509"><label>12.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Thukkani</surname><given-names>S.</given-names></name></person-group><article-title>Scalable Vehicle Location Tracking Using Geohash and Redis</article-title><source>Proceedings of the International Conference on Inventive Computation Technologies (ICICT)</source><conf-loc>Kirtipur, Nepal</conf-loc><conf-date>23&#8211;25 April 2025</conf-date><fpage>1673</fpage><lpage>1680</lpage></element-citation></ref><ref id="B13-sensors-25-05509"><label>13.</label><element-citation publication-type="webpage"><article-title>What Is a Container?</article-title><year>2025</year><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://docs.docker.com/get-started/docker-concepts/the-basics/what-is-a-container/" ext-link-type="uri">https://docs.docker.com/get-started/docker-concepts/the-basics/what-is-a-container/</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-07-30">(accessed on 30 July 2025)</date-in-citation></element-citation></ref><ref id="B14-sensors-25-05509"><label>14.</label><element-citation publication-type="webpage"><article-title>PyGeoHash</article-title><year>2025</year><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/wdm0006/pygeohash" ext-link-type="uri">https://github.com/wdm0006/pygeohash</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-07-30">(accessed on 30 July 2025)</date-in-citation></element-citation></ref><ref id="B15-sensors-25-05509"><label>15.</label><element-citation publication-type="webpage"><person-group person-group-type="author"><name name-style="western"><surname>Jennings</surname><given-names>N.</given-names></name></person-group><article-title>Socket Programming in Python (Guide)</article-title><year>2024</year><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://realpython.com/python-sockets" ext-link-type="uri">https://realpython.com/python-sockets</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-07-30">(accessed on 30 July 2025)</date-in-citation></element-citation></ref><ref id="B16-sensors-25-05509"><label>16.</label><element-citation publication-type="webpage"><article-title>ASAM OpenDRIVE</article-title><year>2025</year><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.asam.net/standards/detail/opendrive" ext-link-type="uri">https://www.asam.net/standards/detail/opendrive</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-07-30">(accessed on 30 July 2025)</date-in-citation></element-citation></ref><ref id="B17-sensors-25-05509"><label>17.</label><element-citation publication-type="webpage"><article-title>Chapter 6: Virtual Networking</article-title><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.virtualbox.org/manual/ch06.html" ext-link-type="uri">https://www.virtualbox.org/manual/ch06.html</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-07-30">(accessed on 30 July 2025)</date-in-citation></element-citation></ref><ref id="B18-sensors-25-05509"><label>18.</label><element-citation publication-type="webpage"><person-group person-group-type="author"><collab>NAVER LABS</collab></person-group><article-title>HD Map for Autonomous Driving</article-title><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.naverlabs.com/datasets/requestDataset" ext-link-type="uri">https://www.naverlabs.com/datasets/requestDataset</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-07-30">(accessed on 30 July 2025)</date-in-citation></element-citation></ref><ref id="B19-sensors-25-05509"><label>19.</label><element-citation publication-type="webpage"><article-title>The HDF Group Support Site</article-title><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://support.hdfgroup.org" ext-link-type="uri">https://support.hdfgroup.org</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-07-30">(accessed on 30 July 2025)</date-in-citation></element-citation></ref><ref id="B20-sensors-25-05509"><label>20.</label><element-citation publication-type="webpage"><article-title>QGIS Official Website</article-title><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://qgis.org" ext-link-type="uri">https://qgis.org</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-07-30">(accessed on 30 July 2025)</date-in-citation></element-citation></ref><ref id="B21-sensors-25-05509"><label>21.</label><element-citation publication-type="webpage"><article-title>PostgreSQL Global Development Group</article-title><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.postgresql.org/docs/15/release-15.html" ext-link-type="uri">https://www.postgresql.org/docs/15/release-15.html</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-07-30">(accessed on 30 July 2025)</date-in-citation></element-citation></ref><ref id="B22-sensors-25-05509"><label>22.</label><element-citation publication-type="webpage"><article-title>Online OpenDRIVE Viewer</article-title><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://odrviewer.io/" ext-link-type="uri">https://odrviewer.io/</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-07-30">(accessed on 30 July 2025)</date-in-citation></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-05509-f001" orientation="portrait"><label>Figure 1</label><caption><p>System Architecture.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05509-g001.jpg"/></fig><fig position="float" id="sensors-25-05509-f002" orientation="portrait"><label>Figure 2</label><caption><p>Implementation Structure and Data Flow.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05509-g002.jpg"/></fig><fig position="float" id="sensors-25-05509-f003" orientation="portrait"><label>Figure 3</label><caption><p>JSON-formatted request message from the vehicle client.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05509-g003.jpg"/></fig><fig position="float" id="sensors-25-05509-f004" orientation="portrait"><label>Figure 4</label><caption><p>Visualization of Geohash level 6 blocks.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05509-g004.jpg"/></fig><fig position="float" id="sensors-25-05509-f005" orientation="portrait"><label>Figure 5</label><caption><p>Internal Structure of a Generated OpenDRIVE (.xodr) File.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05509-g005.jpg"/></fig><fig position="float" id="sensors-25-05509-f006" orientation="portrait"><label>Figure 6</label><caption><p>Actual map and visualization of .xodr file for wydksx, wydksr. (<bold>a</bold>) The actual map of the wydksx region, (<bold>b</bold>) Visualization of .xodr file for wydksx, (<bold>c</bold>) The actual map of the wydksr region, (<bold>d</bold>) Visualization of .xodr file for wydksr.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05509-g006.jpg"/></fig><fig position="float" id="sensors-25-05509-f007" orientation="portrait"><label>Figure 7</label><caption><p>Comparison of Average RTT between Geohash-based and GPS-based Requests.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05509-g007.jpg"/></fig><fig position="float" id="sensors-25-05509-f008" orientation="portrait"><label>Figure 8</label><caption><p>Comparison of Average Database Query Time between Geohash-based and GPS-based Requests.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05509-g008.jpg"/></fig><fig position="float" id="sensors-25-05509-f009" orientation="portrait"><label>Figure 9</label><caption><p>RTT Comparison Between Cloud and Smart RSU Under Varying Vehicle Loads.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05509-g009.jpg"/></fig><fig position="float" id="sensors-25-05509-f010" orientation="portrait"><label>Figure 10</label><caption><p>CPU Usage and Network Throughput of Smart RSU Under Increasing Vehicle Loads.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05509-g010.jpg"/></fig><table-wrap position="float" id="sensors-25-05509-t001" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05509-t001_Table 1</object-id><label>Table 1</label><caption><p>System configuration for the Smart RSU server.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Item</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Description</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">OS</td><td align="center" valign="middle" rowspan="1" colspan="1">Ubuntu 24.04.2 LTS (VirtualBox 7.1.8 VM)</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">DBMS</td><td align="center" valign="middle" rowspan="1" colspan="1">PostgreSQL 15, PostGIS Extension</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Communication</td><td align="center" valign="middle" rowspan="1" colspan="1">Python 3.10 socket-based TCP server</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Storage</td><td align="center" valign="middle" rowspan="1" colspan="1">Directory storing .xodr files by Geohash blocks</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">External Libraries</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Psycopg2, Shapely, PyProj, PyGeohash 2.1.0</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05509-t002" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05509-t002_Table 2</object-id><label>Table 2</label><caption><p>Components of road structure data.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Category</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">File Name</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Description</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Format</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Lane</td><td align="center" valign="middle" rowspan="1" colspan="1">Pangyo_A1_Lane_3D</td><td align="center" valign="middle" rowspan="1" colspan="1">Land information on the road</td><td align="center" valign="middle" rowspan="1" colspan="1">.shp, .dbf, .shx, .prj</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Stop Line</td><td align="center" valign="middle" rowspan="1" colspan="1">Pangyo_A2_STOP_3D</td><td align="center" valign="middle" rowspan="1" colspan="1">Stop line location and geometry information</td><td align="center" valign="middle" rowspan="1" colspan="1">.shp, .dbf, .shx</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Road Centerline</td><td align="center" valign="middle" rowspan="1" colspan="1">Pangyo_A3_LINK_3D</td><td align="center" valign="middle" rowspan="1" colspan="1">Road connectivity information between nodes</td><td align="center" valign="middle" rowspan="1" colspan="1">.shp, .dbf, .shx, .prj</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Traffic Sign(Direction)</td><td align="center" valign="middle" rowspan="1" colspan="1">Pangyo_B2_SURFSIGN_DIRECTION_3D</td><td align="center" valign="middle" rowspan="1" colspan="1">Directional sign and other visual element data</td><td align="center" valign="middle" rowspan="1" colspan="1">.shp, .dbf, .shx, .prj</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Traffic Sign (Line)</td><td align="center" valign="middle" rowspan="1" colspan="1">Pangyo_B2_SURFSIGN_LINE_3D</td><td align="center" valign="middle" rowspan="1" colspan="1">Linear traffic sign data</td><td align="center" valign="middle" rowspan="1" colspan="1">.shp, .dbf, .shx, .prj</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Traffic Sign (Plane)</td><td align="center" valign="middle" rowspan="1" colspan="1">Pangyo_B2_SURFSIGN_PLANE_3D</td><td align="center" valign="middle" rowspan="1" colspan="1">Area-type traffic sign data</td><td align="center" valign="middle" rowspan="1" colspan="1">.shp, .dbf, .shx, .prj</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Node</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Pangyo_C1_NODE_3D</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Node-to-link connection information</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">.shp, .dbf, .shx, .prj</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05509-t003" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05509-t003_Table 3</object-id><label>Table 3</label><caption><p>Comparison of Geohash levels in terms of block size and RTT.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Geohash Level</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Average Block Size</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Average RTT</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Level 4</td><td align="center" valign="middle" rowspan="1" colspan="1">2.5 GB</td><td align="center" valign="middle" rowspan="1" colspan="1">6.0 s</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Level 5</td><td align="center" valign="middle" rowspan="1" colspan="1">700 MB</td><td align="center" valign="middle" rowspan="1" colspan="1">3.0 s</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Level 6</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">230 MB</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.6 s</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05509-t004" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05509-t004_Table 4</object-id><label>Table 4</label><caption><p>Schema of HD Map Data Tables.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Table Name</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Column Name</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Pangyo_A1_LANE_3D</td><td align="center" valign="middle" rowspan="1" colspan="1">Id, Geom, Lanecode, Geohash6</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">pangyo_A2_STOP_3D</td><td align="center" valign="middle" rowspan="1" colspan="1">Id, Geom, Geohash6</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Pangyo_A3_LINK_3D</td><td align="center" valign="middle" rowspan="1" colspan="1">Id, Geom, Linkid, Fromnode, Tonode, Lane, Route_id, Geohash6</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Pangyo_B2_SURFSIGN_DIRECTION_3D</td><td align="center" valign="middle" rowspan="1" colspan="1">Id, Geom, Signtype, Geohash6</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Pangyo_B2_SURFSIGN_LINE_3D</td><td align="center" valign="middle" rowspan="1" colspan="1">Id, Geom, Signtype, Geohash6</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Pangyo_B2_SURFSIGN_PLANE_3D</td><td align="center" valign="middle" rowspan="1" colspan="1">Id, Geom, Signtype, Geohash6</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Pangyo_C1_NODE_3D</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Id, Geom, Nodeid, Nodetype, Geohash6</td></tr></tbody></table></table-wrap><table-wrap position="float" id="sensors-25-05509-t005" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05509-t005_Table 5</object-id><label>Table 5</label><caption><p>Continuity of Boundary Roads Between Adjacent Geohash Blocks (&#8220;<monospace>&#8596;</monospace>&#8221; denotes adjacency).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Geohash Pair</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Number of Boundary Roads</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Number of Common Roads</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Continuity (%)</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">wydksx <monospace>&#8596;</monospace> wydksr</td><td align="center" valign="middle" rowspan="1" colspan="1">7070</td><td align="center" valign="middle" rowspan="1" colspan="1">70</td><td align="center" valign="middle" rowspan="1" colspan="1">100</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">wydksr <monospace>&#8596;</monospace> wydksq</td><td align="center" valign="middle" rowspan="1" colspan="1">59</td><td align="center" valign="middle" rowspan="1" colspan="1">59</td><td align="center" valign="middle" rowspan="1" colspan="1">100</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">wydksq <monospace>&#8596;</monospace> wydksw</td><td align="center" valign="middle" rowspan="1" colspan="1">12</td><td align="center" valign="middle" rowspan="1" colspan="1">12</td><td align="center" valign="middle" rowspan="1" colspan="1">100</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">wydksw <monospace>&#8596;</monospace> wydksx</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">113</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">113</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">100</td></tr></tbody></table></table-wrap></floats-group></article></pmc-articleset>