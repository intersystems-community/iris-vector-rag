<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xml:lang="en" article-type="research-article" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS One</journal-id><journal-id journal-id-type="pmc-domain-id">440</journal-id><journal-id journal-id-type="pmc-domain">plosone</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-title-group><journal-title>PLOS One</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>PLOS</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12431212</article-id><article-id pub-id-type="pmcid-ver">PMC12431212.1</article-id><article-id pub-id-type="pmcaid">12431212</article-id><article-id pub-id-type="pmcaiid">12431212</article-id><article-id pub-id-type="pmid">40938832</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0330839</article-id><article-id pub-id-type="publisher-id">PONE-D-25-18768</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied Mathematics</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Simulation and Modeling</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Systems Science</subject><subj-group><subject>Nonlinear Systems</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Systems Science</subject><subj-group><subject>Nonlinear Systems</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Optimization</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Equipment</subject><subj-group><subject>Optical Equipment</subject><subj-group><subject>Cameras</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Structural Engineering</subject><subj-group><subject>Built Structures</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Navigation</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Remote Sensing</subject><subj-group><subject>Lidar</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Intelligence</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Intelligence</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Intelligence</subject></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Enhanced RGB-D SLAM through orthogonal plane constraints and point-line-plane collaborative optimization</article-title><alt-title alt-title-type="running-head">Enhanced RGB-D SLAM through orthogonal plane constraints and point-line-plane collaborative optimization</alt-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0006-8242-0237</contrib-id><name name-style="western"><surname>Yang</surname><given-names initials="G">Gaochao</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role><role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role content-type="http://credit.niso.org/contributor-roles/software/">Software</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#8211; review &amp; editing</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref><xref rid="cor001" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Liu</surname><given-names initials="P">Pengfei</given-names></name><role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role><role content-type="http://credit.niso.org/contributor-roles/software/">Software</role><role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#8211; original draft</role><xref rid="aff002" ref-type="aff">
<sup>2</sup>
</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Ma</surname><given-names initials="W">Weifeng</given-names></name><role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role><role content-type="http://credit.niso.org/contributor-roles/software/">Software</role><role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role><xref rid="aff003" ref-type="aff">
<sup>3</sup>
</xref></contrib></contrib-group><aff id="aff001"><label>1</label>
<addr-line>College of Computer Science and Artificial Intelligence, Changzhou University, Changzhou, Jiangsu, China</addr-line></aff><aff id="aff002"><label>2</label>
<addr-line>College of Instrumentation Science and Engineering, Southeast University, Nanjing, Jiangsu, China</addr-line></aff><aff id="aff003"><label>3</label>
<addr-line>Department of Geography, Yunnan Normal University, Kunming, Yunnan, China</addr-line></aff><contrib-group><contrib contrib-type="editor"><name name-style="western"><surname>Ngo</surname><given-names initials="HQT">Ha Quang Thinh</given-names></name><role>Editor</role><xref rid="edit1" ref-type="aff"/></contrib></contrib-group><aff id="edit1">
<addr-line>VNUHCM HCMUT: VNUHCM-Ho Chi Minh City University of Technology, VIET NAM</addr-line>
</aff><author-notes><corresp id="cor001">* E-mail: <email>00003463@cczu.edu.cn</email></corresp><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="epub"><day>12</day><month>9</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>20</volume><issue>9</issue><issue-id pub-id-type="pmc-issue-id">496058</issue-id><elocation-id>e0330839</elocation-id><history><date date-type="received"><day>9</day><month>4</month><year>2025</year></date><date date-type="accepted"><day>6</day><month>8</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>12</day><month>09</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>13</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-13 11:25:14.803"><day>13</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; 2025 Yang et al</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Yang et al</copyright-holder><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="pone.0330839.pdf"/><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pdf" xlink:href="pone.0330839.pdf"/><abstract><p>Accurate visual localization in complex indoor environments remains a significant challenge due to feature degradation and cumulative errors. In response, we propose PLPM-SLAM, a novel RGB-D SLAM framework that integrates orthogonal Manhattan plane constraints with point-line-plane joint optimization to enhance both robustness and accuracy. Unlike traditional approaches that decouple only the rotation matrix, PLPM-SLAM utilizes three mutually orthogonal planes to jointly decouple both rotation and translation, effectively mitigating global drift. To address scenarios lacking a complete Manhattan structure, we introduce a virtual plane construction strategy based on heterogeneous feature associations. Additionally, PLPM-SLAM incorporates both homogeneous (point-point, line-line, plane-plane) and heterogeneous (point-line, point-plane, line-plane) geometric constraints throughout the tracking and optimization processes. In unstructured environments, a vanishing-point&#8211;guided joint optimization model is employed to improve geometric consistency. Extensive evaluations on public datasets (TUM, ICL-NUIM) and real-world sequences demonstrate that PLPM-SLAM consistently outperforms ORB-SLAM3 in both structured and low-texture settings. Specifically, PLPM-SLAM achieves RMSE reductions of up to 82.77% and 92.16% on the public and real-world datasets, respectively.</p></abstract><funding-group><award-group id="award001"><funding-source><institution>Open Project of Jiangsu Petrochemical Process Key Equipment Digital Twin Technology Engineering Research Center</institution></funding-source><award-id>DTEC202201</award-id><principal-award-recipient><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0006-8242-0237</contrib-id><name name-style="western"><surname>Yang</surname><given-names>Gaochao</given-names></name></principal-award-recipient></award-group><award-group id="award002"><funding-source><institution>2024 Changzhou University Undergraduate Extracurricular Innovation and Entrepreneurship Fund Project Funding</institution></funding-source><award-id>QZX24020191</award-id><principal-award-recipient><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0006-8242-0237</contrib-id><name name-style="western"><surname>Yang</surname><given-names>Gaochao</given-names></name></principal-award-recipient></award-group><funding-statement>The author(s) received no specific funding for this work.</funding-statement></funding-group><counts><fig-count count="50"/><table-count count="4"/><page-count count="38"/></counts><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>The data underlying the results presented in the study are available from Computer Vision Group, TUM School of Computation, Information and Technology Technical University of Munich (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://cvg.cit.tum.de/data/datasets/rgbd-dataset/download?utm_source=chatgpt.com" ext-link-type="uri">https://cvg.cit.tum.de/data/datasets/rgbd-dataset/download?utm_source=chatgpt.com</ext-link>).</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>The data underlying the results presented in the study are available from Computer Vision Group, TUM School of Computation, Information and Technology Technical University of Munich (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://cvg.cit.tum.de/data/datasets/rgbd-dataset/download?utm_source=chatgpt.com" ext-link-type="uri">https://cvg.cit.tum.de/data/datasets/rgbd-dataset/download?utm_source=chatgpt.com</ext-link>).</p></notes></front><body><sec sec-type="intro" id="sec001"><title>1 Introduction</title><p>Robot intelligence technologies are advancing rapidly worldwide, with autonomous navigation serving as a fundamental prerequisite for realizing truly intelligent robotic systems [<xref rid="pone.0330839.ref001" ref-type="bibr">1</xref>,<xref rid="pone.0330839.ref002" ref-type="bibr">2</xref>]. In this context, Visual Simultaneous Localization and Mapping (VSLAM) plays a crucial role by enabling effective and reliable navigation. Most feature-based V-SLAM approaches rely heavily on feature points to represent the environment and estimate camera poses [<xref rid="pone.0330839.ref003" ref-type="bibr">3</xref>]. Owing to their computational efficiency and simple representation, feature points are widely adopted in both indoor and outdoor scenarios [<xref rid="pone.0330839.ref004" ref-type="bibr">4</xref>]. However, these methods face substantial challenges under complex real-world conditions, such as low-texture environments and significant lighting variations [<xref rid="pone.0330839.ref005" ref-type="bibr">5</xref>]. Further limitations include inaccurate data association, noise in feature point extraction, and error accumulation during pose estimation in large-scale environments, all of which hinder the robustness of SLAM systems that rely solely on feature points [<xref rid="pone.0330839.ref006" ref-type="bibr">6</xref>].</p><p>Indoor environments&#8212;common operational domains for mobile robots&#8212;often contain abundant structural geometric primitives such as walls, floors, and ceilings. These structures offer higher-level features, such as lines and planes, which go beyond traditional point features [<xref rid="pone.0330839.ref007" ref-type="bibr">7</xref>]. Compared to feature points, line and plane features are less susceptible to texture sparsity and illumination changes, enabling more consistent and reliable extraction under challenging conditions. This, in turn, enhances pose estimation accuracy and improves the overall SLAM performance, particularly in low-texture or poorly lit indoor scenarios [<xref rid="pone.0330839.ref008" ref-type="bibr">8</xref>,<xref rid="pone.0330839.ref009" ref-type="bibr">9</xref>,<xref rid="pone.0330839.ref010" ref-type="bibr">10</xref>]. Moreover, many man-made indoor environments exhibit dominant planar relationships such as parallelism and orthogonality. Exploiting these structural constraints allows for more robust long-term plane associations, thereby mitigating pose drift and reducing cumulative error over time [<xref rid="pone.0330839.ref011" ref-type="bibr">11</xref>,<xref rid="pone.0330839.ref012" ref-type="bibr">12</xref>].</p><p>SLAM systems rely on inter-frame pose propagation to support continuous localization and mapping, where the pose of the current frame is inferred from the previously estimated pose. Over extended operations, this propagation process leads to the accumulation of pose errors, resulting in trajectory drift and reduced mapping accuracy. The impact of such drift becomes increasingly significant in large-scale or long-duration deployments. To address these issues, two primary strategies are commonly adopted:</p><list list-type="bullet"><list-item><p>Loop Closure: Detecting when the current frame resembles a previously visited scene and performing loop closure corrections to address accumulated drift. However, loop closure involves significant computational overhead and only triggers when the same scene is revisited [<xref rid="pone.0330839.ref003" ref-type="bibr">3</xref>].</p></list-item><list-item><p>Manhattan World (MW) Assumption: Structured environments that adhere to the Manhattan assumption, known as MW, are rich in structural features, explicitly representing the pose relationship between the camera and world coordinates [<xref rid="pone.0330839.ref013" ref-type="bibr">13</xref>]. This assumption is based on the orthogonal structural patterns of buildings and indoor environments, where 3 dominant orthogonal directions exist [<xref rid="pone.0330839.ref014" ref-type="bibr">14</xref>].</p></list-item></list><p>The above review underscores that Manhattan World (MW) assumptions based solely on line features often lack robustness, particularly in environments with weak structural regularity, thereby posing significant challenges for practical applications. Traditional point-line-plane visual SLAM systems tend to process these geometric primitives independently at both the front-end and back-end stages, rarely considering their underlying spatial correlations. Moreover, most classical studies on Manhattan coordinate systems rely heavily on line features and primarily focus on decoupling rotation matrices, with limited attention given to the decoupling of translation matrices. Although many RGB-D SLAM systems incorporate point and plane features as essential observations, and several studies have successfully utilized plane features to estimate the Manhattan Frame (MF), the spatial relationships between point and plane features are often neglected.</p><p>To overcome these limitations, we propose a novel RGB-D SLAM framework, PLPM-SLAM, which jointly optimizes point, line, and plane features under Manhattan coordinate system constraints. In structured environments such as tunnels or long corridors&#8212;where typically only two orthogonal planes are observable&#8212;we introduce an auxiliary hypothetical plane construction strategy to form a complete orthogonal frame. This facilitates the decoupling of both rotation and translation matrices while preserving spatial consistency between point and plane features in the current frame. For unstructured or weakly structured environments, we further propose a joint optimization model that minimizes both homogeneous (e.g., point-to-point, plane-to-plane) and heterogeneous (e.g., point-to-plane, line-to-plane) feature association errors, guided by vanishing point constraints to enhance robustness. The key contributions of this work are summarized as follows:</p><list list-type="simple"><list-item><p>(1) This study introduces PLPM-SLAM, an enhanced RGB-D SLAM framework that jointly optimizes point, line, and plane features under Manhattan plane constraints. The proposed method decouples both rotation and translation matrices to mitigate global drift commonly encountered in SLAM systems. To address scenarios where only two orthogonal planes are visible&#8212;such as in tunnels or corridors&#8212;an auxiliary hypothetical plane is constructed, enabling the formation of a complete orthogonal frame and facilitating accurate translation estimation while maintaining spatial consistency between point and plane features in the current frame.</p></list-item><list-item><p>(2) A coplanar line&#8211;assisted Agglomerative Hierarchical Clustering (AHC) strategy is developed to extract more reliable planar features. This improves the density and reliability of structural constraints, enhancing the overall stability and robustness of the system.</p></list-item><list-item><p>(3) In contrast to conventional visual SLAM methods, PLPM-SLAM integrates both homogeneous (point-to-point, line-to-line, plane-to-plane) and heterogeneous (point-to-line, point-to-plane, line-to-plane) geometric relationships during tracking and optimization. For unstructured environments, a joint optimization model guided by vanishing point constraints is proposed to simultaneously minimize geometric matching errors and semantic association inconsistencies, thereby improving robustness.</p></list-item><list-item><p>(4) The effectiveness of PLPM-SLAM is validated through extensive experiments on public benchmark datasets (TUM and ICL-NUIM) and custom datasets collected using a ZED2i RGB-D camera in real-world corridor and underground scenarios. Comparative analysis against state-of-the-art RGB-D SLAM systems&#8212;including ORB-SLAM3 [<xref rid="pone.0330839.ref015" ref-type="bibr">15</xref>], MSC-VO [<xref rid="pone.0330839.ref016" ref-type="bibr">16</xref>], Planar-SLAM [<xref rid="pone.0330839.ref017" ref-type="bibr">17</xref>], and Manhattan-SLAM [<xref rid="pone.0330839.ref018" ref-type="bibr">18</xref>]&#8212;demonstrates the superior accuracy and robustness of the proposed method.</p></list-item></list><p>The structure of this paper is organized as follows: the Related Work section reviews previous studies; the Manhattan Coordinate System Constraints and Nonlinear Optimization Based on Imaginary Planes section elaborates on the proposed constraints and optimization framework; the Experimental Verification and Evaluation section presents experimental results and performance analysis; finally, the Conclusion section summarizes the main findings and outlines future research directions.</p></sec><sec id="sec002"><title>2 Related work</title><p>The related work is presented from two perspectives, namely the line-feature-based MW and the plane-feature-based MW.</p><sec id="sec003"><title>2.1 Manhattan world based on line features</title><p>Indoor environments&#8212;such as corners, ceilings, and other architectural structures&#8212;often conform to a globally consistent Manhattan coordinate system. Aligning the detected structural lines and plane normals in each frame with this coordinate system facilitates globally consistent rotation estimation and effectively suppresses the accumulation of pose drift [<xref rid="pone.0330839.ref019" ref-type="bibr">19</xref>,<xref rid="pone.0330839.ref020" ref-type="bibr">20</xref>]. Jiang et al. [<xref rid="pone.0330839.ref021" ref-type="bibr">21</xref>] proposed a general line-based SLAM framework that integrates points, structured lines, and unstructured lines. Their approach addresses the common challenges of line-only systems, such as triangulation degeneracy and unstable tracking, highlighting the importance of multi-feature fusion to improve SLAM robustness.</p><p>Lim et al. [<xref rid="pone.0330839.ref022" ref-type="bibr">22</xref>] and Chen et al. [<xref rid="pone.0330839.ref023" ref-type="bibr">23</xref>] further investigated the extraction of vanishing points using structural line features. By leveraging vanishing point constraints, they were able to reduce long-term pose drift, demonstrating the effectiveness of geometric priors in enhancing SLAM stability. Company et al. [<xref rid="pone.0330839.ref016" ref-type="bibr">16</xref>] introduced an RGB-D SLAM method that employs line features to constrain the Manhattan axes. Their system reduces camera pose drift through local map optimization in the backend, thereby improving overall localization accuracy and consistency. Li et al. [<xref rid="pone.0330839.ref024" ref-type="bibr">24</xref>] exploited the structural regularities of line features to estimate both absolute and relative camera poses. Their method introduced a novel decoupling approach for rotation and translation estimation, enabling more accurate and efficient pose inference in complex indoor scenes. Xu et al. [<xref rid="pone.0330839.ref025" ref-type="bibr">25</xref>] proposed a line optical flow tracking method based on grayscale invariance and collinearity constraints, significantly improving the efficiency of line-based feature matching. Wang et al. [<xref rid="pone.0330839.ref006" ref-type="bibr">6</xref>] developed LF-SLAM, a line-flow-based SLAM system modeled using Bayesian networks. By incorporating uncertainty and prior knowledge, their probabilistic formulation enhances the robustness of camera pose estimation. Kim et al. [<xref rid="pone.0330839.ref026" ref-type="bibr">26</xref>] proposed an efficient SO(3) manifold-constrained mean-shift algorithm to track spatial regularities. Their method jointly estimates drift-free rotational motion from both line and plane features, effectively leveraging environmental regularities. Straub et al. [<xref rid="pone.0330839.ref027" ref-type="bibr">27</xref>] presented a real-time MAP inference algorithm capable of estimating Manhattan Frames (MFs) in complex scenes. They extended the MF model to a probabilistic mixture formulation, enabling more accurate and flexible representation of real-world indoor environments.</p><p>In corridor-like environments, line-feature-based SLAM methods may fail to extract a reliable Manhattan coordinate system due to the predominance of lines aligned with the camera&#8217;s trajectory. However, such scenes typically contain two orthogonal planes (e.g., floor and wall), whose normals can be used to infer a third orthogonal direction. This allows for the construction of a complete Manhattan coordinate system, even in the absence of sufficient line features.</p></sec><sec id="sec004"><title>2.2 Manhattan world based on plane features</title><p>In large-scale environments, planar features tend to exhibit greater stability and continuity than line features. They are less susceptible to variations in lighting and texture and carry richer structural information [<xref rid="pone.0330839.ref028" ref-type="bibr">28</xref>,<xref rid="pone.0330839.ref029" ref-type="bibr">29</xref>]. However, the extraction and parameterization of planar features are inherently more complex compared to points and lines. Despite these challenges, numerous vision-based SLAM systems have been developed that exploit planar features [<xref rid="pone.0330839.ref030" ref-type="bibr">30</xref>]. For example, Zhang et al. [<xref rid="pone.0330839.ref031" ref-type="bibr">31</xref>] introduced SP-SLAM, which integrates point, planar, and hypothesized planar features. In their approach, planes are parameterized using spherical coordinates, and hypothesized planes are generated based on planar edge constraints and associated with contour points. Vertical and parallel geometric constraints are incorporated into the optimization process to reduce drift in indoor environments.</p><p>Li et al. [<xref rid="pone.0330839.ref032" ref-type="bibr">32</xref>] proposed a tightly coupled monocular visual odometry system that combines point and line features with coplanar constraints. By triangulating endpoints of lines and points, they extracted planar grids from image sequences and 3D meshes. Coplanar constraints derived from the regularity of planar structures were introduced to enhance localization accuracy. Subsequently, Li et al. [<xref rid="pone.0330839.ref033" ref-type="bibr">33</xref>] presented Structure-SLAM, a monocular SLAM framework that incorporates points, lines, planes, and the Manhattan World (MW) assumption. This system employs convolutional neural networks to estimate point cloud normals and uses a decoupling strategy to cluster 3D points and structural lines into dominant Manhattan directions. Given the relatively low precision of CNN-estimated normals compared to those derived from depth maps, a pose refinement module based on point and line features is integrated. Later, Li et al. [<xref rid="pone.0330839.ref017" ref-type="bibr">17</xref>] extended this work with Planar-SLAM, which leverages line and planar features to estimate camera pose and incorporates geometric planar relationships into bundle adjustment. However, Planar-SLAM&#8217;s performance degrades significantly in unstructured environments.</p><p>Both Planar-SLAM and Structure-SLAM employ mean-shift clustering to extract Manhattan coordinate systems. In contrast, Yunus et al. [<xref rid="pone.0330839.ref018" ref-type="bibr">18</xref>] proposed Manhattan-SLAM, which utilizes orthogonal plane relationships to extract the Manhattan frame. This method addresses the problem of inconsistent dominant directions in mixed Manhattan frames by detecting orthogonal plane normals and associating co-visible planes across keyframes. However, it is limited to scenes with stable planar features and fails when only parallel orthogonal planes exist between the current and historical frames. Dong et al. [<xref rid="pone.0330839.ref034" ref-type="bibr">34</xref>] developed an efficient Manhattan frame detection strategy based on orthogonal planes and lines, enabling decoupling of rotation and translation via the extracted Manhattan frame. UPLP-SLAM [<xref rid="pone.0330839.ref035" ref-type="bibr">35</xref>] introduced a unified, tightly coupled multi-feature optimization framework that employs mutual association mechanisms for both homogeneous and heterogeneous features, enhancing multimodal integration. Nonetheless, it still underutilizes structural information and relies heavily on high-precision depth data, limiting its applicability in structured environments with low-quality sensors.</p><p>Alternative models such as the Hong Kong World [<xref rid="pone.0330839.ref036" ref-type="bibr">36</xref>] and Atlanta World [<xref rid="pone.0330839.ref037" ref-type="bibr">37</xref>] have also been proposed. However, whether based on the MW, Hong Kong World, or Atlanta World assumptions, these models require the scene to conform to specific structural patterns. Other studies [<xref rid="pone.0330839.ref038" ref-type="bibr">38</xref>,<xref rid="pone.0330839.ref039" ref-type="bibr">39</xref>] have leveraged the MW assumption to estimate drift-free rotations. While these approaches yield favorable results in well-structured scenes, their performance degrades in environments lacking regular structure. Despite considerable advances, most existing Manhattan coordinate system studies rely predominantly on line features, with limited investigation into planar features. Furthermore, the majority of research focuses on the decoupling of rotation matrices, with relatively little attention given to translation matrix decoupling.</p></sec></sec><sec id="sec005"><title>3 Manhattan coordinate system constraints and nonlinear optimization based on imaginary plane</title><p>In 3D space, the projection of parallel lines converging at a single vanishing point (VP) serves as a fundamental cue for constructing a Manhattan coordinate system, particularly in environments with regular architectural structures. In such scenes, three mutually perpendicular vanishing points are typically detectable, forming the basis of MF. When a scene&#8217;s structural layout is relatively regular, this coordinate system can effectively constrain global trajectory drift. Many classical vision-based Simultaneous Localization and Mapping (SLAM) approaches that adopt the Manhattan World (MW) assumption rely on line features to extract the MF. However, due to noise in line feature detection, MF estimation can become unstable and exhibit considerable fluctuations. Furthermore, these methods often assume that the principal directions of the MF remain consistent throughout the entire scene. When the dominant structural directions vary, the algorithms may fail to adapt accordingly&#8212;sometimes even leading to system crashes, as reported in [<xref rid="pone.0330839.ref016" ref-type="bibr">16</xref>].</p><p>Building upon the methodologies presented in [<xref rid="pone.0330839.ref015" ref-type="bibr">15</xref>] and [<xref rid="pone.0330839.ref038" ref-type="bibr">38</xref>], this paper introduces PLPM-SLAM, a novel RGB-D SLAM framework that incorporates MF system constraints through auxiliary hypothetical planes. PLPM-SLAM is designed to operate robustly in both structured and unstructured environments. Similar to the method in [<xref rid="pone.0330839.ref038" ref-type="bibr">38</xref>], PLPM-SLAM initially extracts the MF using detected orthogonal plane features and decouples the rotation matrix accordingly. The translation matrix is then decoupled by measuring the distances from the camera coordinate system to the three orthogonal planes. In scenarios where only two orthogonal planes are observable, the framework introduces an auxiliary hypothetical plane to complete the orthogonal triplet, thereby enabling full pose decoupling. The overall algorithmic workflow is illustrated in <xref rid="pone.0330839.g001" ref-type="fig">Fig 1</xref>.</p><fig position="float" id="pone.0330839.g001" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g001</object-id><label>Fig 1</label><caption><title>Overall architecture diagram.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g001.jpg"/></fig><p>Unlike conventional visual SLAM systems, which are typically divided into front-end and back-end modules, the proposed framework employs a three-tier architecture comprising front-end, middle-end, and back-end modules. The front-end is responsible for extracting and matching point, line, and plane features. The middle-end handles alignment with the Manhattan coordinate system and decouples the pose matrix. The back-end performs local nonlinear optimization and loop closure detection. Detailed descriptions of Manhattan plane feature matching, pose matrix decoupling, and back-end optimization are provided in &#8220;Manhattan coordinate system constraints and nonlinear optimization based on imaginary plane&#8221; section. Since loop closure is not the primary focus of this work, further analysis of that module is omitted.</p><p>As shown in <xref rid="pone.0330839.g001" ref-type="fig">Fig 1</xref>, the green module represents the plane feature tracking and matching strategy based on plane descriptors. The yellow module denotes the pose matrix decoupling process using orthogonal Manhattan plane features, including the construction of auxiliary hypothetical planes and line feature classification based on vanishing points. The brown module corresponds to the graph optimization backend, which integrates point-line-plane collaborative optimization with vanishing point constraints.</p><p>Initially, the environmental map is constructed to obtain the pose and depth information of 3D landmarks. Depth data is directly obtained through back-projection from the RGB-D camera. When orthogonal plane features are detected, they are used to extract the MF for the current frame, which serves as the initial system matrix. Subsequently, feature matching is employed for pose tracking, including tracking between adjacent frames and local maps using both homogeneous and heterogeneous features. Once the Manhattan coordinate system is successfully extracted, it is used to assist in the classification and tracking of plane and line features.</p><sec id="sec006"><title>3.1 Association strategy between heterogeneous features of points, lines and planes</title><sec id="sec007"><title>3.1.1 A plane feature construction method for the AHC method assisted by coplanar line features.</title><p>Unlike points or lines, an ideal infinite plane does not have a direct projection in the image plane and must be reconstructed from 3D data. A common approach is to use the RANSAC algorithm on point clouds. However, random sampling can be problematic when the point cloud is sparse or unevenly distributed, which is often the case for feature-based landmarks. Even in well-developed SLAM systems, reconstructed sparse 3D points can only provide a rough representation of the scene structure. In contrast, human perception can interpret the scene by leveraging prior knowledge from the input images&#8212;a capability we aim to emulate.</p><p>Dirk et al. [<xref rid="pone.0330839.ref040" ref-type="bibr">40</xref>] introduced a foundational method for plane segmentation from point clouds using clustering algorithms. Building on this, AHCP [<xref rid="pone.0330839.ref041" ref-type="bibr">41</xref>] improves plane extraction accuracy by employing the AHC method. AHCP identifies point cloud blocks with the smallest Mean Squared Error (MSE) and merges them with adjacent blocks. Merged blocks that exceed a predefined error threshold are discarded.</p><p>However, the AHC method is computationally intensive. To reduce processing time, block sizes are typically set such that only larger blocks are considered for plane feature extraction. Incorporating smaller plane features into front-end tracking and back-end optimization could significantly enhance pose estimation accuracy. For RGB-D cameras, depth information becomes unreliable beyond approximately 7 meters or in the presence of transparent objects, rendering the AHC method ineffective for plane feature construction in such cases. To address these limitations and improve SLAM system stability, this study proposes a strategy that leverages coplanar line features to assist the AHC method in constructing plane features. Specifically, only coplanar line features are used for plane construction. To ensure robustness, the coplanarity of line pairs is verified before plane extraction. Plane features are parameterized using the Hesse form, which represents a plane in the world coordinate system by its unit normal vector <inline-formula id="pone.0330839.e001"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e001g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e001.jpg"/><mml:math id="M1" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and the perpendicular distance <inline-formula id="pone.0330839.e002"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e002g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e002.jpg"/><mml:math id="M2" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> from the origin.</p><p>Eq. (1) represents line feature <inline-formula id="pone.0330839.e003"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e003g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e003.jpg"/><mml:math id="M3" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, and Eq. (2) represents line feature <inline-formula id="pone.0330839.e004"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e004g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e004.jpg"/><mml:math id="M4" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>:</p><disp-formula id="pone.0330839.e005"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e005g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e005.jpg"/><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(1)</label></disp-formula><disp-formula id="pone.0330839.e006"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e006g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e006.jpg"/><mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(2)</label></disp-formula><disp-formula id="pone.0330839.e007"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e007g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e007.jpg"/><mml:math id="M7" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">&#8214;</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:msub><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:msub><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:msub><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:msub><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:msub><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:msub><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" form="postfix" stretchy="true">&#8214;</mml:mo></mml:mrow><mml:mo>&#8804;</mml:mo><mml:mrow><mml:mi>&#948;</mml:mi></mml:mrow></mml:mrow></mml:math></alternatives><label>(3)</label></disp-formula><p>When the line features and the line features satisfy Eq. (3), the line features and the line features are coplanar.</p><p>Two intersecting 3D lines <inline-formula id="pone.0330839.e008"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e008g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e008.jpg"/><mml:math id="M8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e009"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e009g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e009.jpg"/><mml:math id="M9" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> can determine a plane. According to literature [<xref rid="pone.0330839.ref042" ref-type="bibr">42</xref>], the normal vector of the plane feature is obtained by using the cross product of <inline-formula id="pone.0330839.e010"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e010g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e010.jpg"/><mml:math id="M10" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e011"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e011g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e011.jpg"/><mml:math id="M11" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and normalization. <inline-formula id="pone.0330839.e012"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e012g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e012.jpg"/><mml:math id="M12" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> can be obtained by Eq. (4):</p><disp-formula id="pone.0330839.e013"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e013g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e013.jpg"/><mml:math id="M13" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mi>&#215;</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">&#8214;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mi>&#215;</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub><mml:mo fence="true" form="postfix" stretchy="true">&#8214;</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(4)</label></disp-formula><p>The distance <inline-formula id="pone.0330839.e014"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e014g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e014.jpg"/><mml:math id="M14" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> can be computed using the following formula, as described in [<xref rid="pone.0330839.ref017" ref-type="bibr">17</xref>]:</p><disp-formula id="pone.0330839.e015"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e015g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e015.jpg"/><mml:math id="M15" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mi>&#215;</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(5)</label></disp-formula><p>where, <inline-formula id="pone.0330839.e016"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e016g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e016.jpg"/><mml:math id="M16" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e017"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e017g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e017.jpg"/><mml:math id="M17" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> are the coordinates of the two endpoints of line <inline-formula id="pone.0330839.e018"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e018g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e018.jpg"/><mml:math id="M18" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>; <inline-formula id="pone.0330839.e019"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e019g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e019.jpg"/><mml:math id="M19" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e020"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e020g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e020.jpg"/><mml:math id="M20" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> are the coordinates of the two endpoints of line <inline-formula id="pone.0330839.e021"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e021g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e021.jpg"/><mml:math id="M21" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. To further eliminate the non-planar line features, we calculate the maximum value <inline-formula id="pone.0330839.e022"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e022g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e022.jpg"/><mml:math id="M22" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and the minimum value <inline-formula id="pone.0330839.e023"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e023g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e023.jpg"/><mml:math id="M23" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> of the distance respectively.</p><disp-formula id="pone.0330839.e024"><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e024g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e024.jpg"/><label>(6)</label></disp-formula><p>Check whether <inline-formula id="pone.0330839.e025"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e025g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e025.jpg"/><mml:math id="M25" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">|</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo fence="true" form="postfix" stretchy="true">|</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mo>&#8706;</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is satisfied. If not, it will be eliminated.</p></sec><sec id="sec008"><title>3.1.2 A novel plane feature tracking and matching strategy based on plane feature descriptor.</title><p>This paper introduces an association strategy that leverages the mutual inclusion of both homogeneous and heterogeneous features, including point-line, point-plane, and line-plane relationships [<xref rid="pone.0330839.ref035" ref-type="bibr">35</xref>]. The proposed strategy considers the geometric associations among these features at both the global level&#8212;between the current frame and all features within the global map&#8212;and the local level&#8212;between the current frame and the most recent frame, as well as between the current frame and keyframes.</p><p>SLAM systems typically operate under the assumption of a rigid environment, wherein the relative spatial relationships among features within the same frame remain invariant. Based on the principle of rigid body motion and assuming minimal detection errors, the distances between corresponding features across different image frames should remain consistent. For instance, as illustrated in <xref rid="pone.0330839.g002" ref-type="fig">Fig 2</xref>, the distance between two point features, or between a point and a plane feature, remains unchanged across frames.</p><fig position="float" id="pone.0330839.g002" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g002</object-id><label>Fig 2</label><caption><title>Schematic diagram of point-to-plane association strategy.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g002.jpg"/></fig><p>To address the low efficiency of plane feature matching, this study introduces a data association strategy based on plane feature descriptors. The specific steps are as <xref rid="pone.0330839.g003" ref-type="fig">Fig 3</xref> below:</p><fig position="float" id="pone.0330839.g003" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g003</object-id><label>Fig 3</label><caption><title>Flowchart of plane feature construction and matching.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g003.jpg"/></fig><p>First, identify <italic toggle="yes">n</italic> (where <italic toggle="yes">n</italic>&#8201;&#8805;&#8201;4) common keypoints between the current frame and the reference frame. Obtain the 3D coordinates of these keypoints in the respective camera coordinate systems of both frames. Next, compute the distances from each of the n keypoints to every plane feature in both frames and store these distances in a container. The distances are then sorted in descending order to construct descriptors for the corresponding plane features. Plane feature matching is subsequently performed based on these descriptors. As this matching strategy does not depend on camera pose information, it demonstrates strong robustness against pose estimation errors and enables accurate plane correspondence. Furthermore, the method supports simultaneous matching of structural plane configurations, including parallel and perpendicular planes.</p></sec></sec><sec id="sec009"><title>3.2 Manhattan coordinate system constraints based on the construction of imaginary planes</title><p>This paper proposes a method to decouple the rotation and translation matrices using orthogonal Manhattan plane features. Rotation matrix decoupling requires either (i) the alignment or parallelism of the normal vectors of three mutually orthogonal plane features between the current and historical frames, or (ii) the alignment or parallelism of the normal vectors of two plane features. In contrast, translation matrix decoupling necessitates exact correspondence among all three plane features. Accordingly, rotation matrix decoupling is performed first. Once the rotation matrix is successfully decoupled, the consistency of the three plane features is verified. If all three planes are consistent, translation matrix decoupling is performed. Otherwise, conventional algorithms cannot be applied for translation decoupling. The detailed process is illustrated in <xref rid="pone.0330839.g004" ref-type="fig">Fig 4</xref>.</p><fig position="float" id="pone.0330839.g004" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g004</object-id><label>Fig 4</label><caption><title>Flowchart of posture decoupling based on Manhattan coordinate system.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g004.jpg"/></fig><p>For long corridor environments, this paper introduces a translation matrix decoupling method assisted by hypothetical plane features. When corresponding Manhattan plane features cannot be matched, pose estimation is performed using a collaborative point-line-plane optimization model constrained by vanishing points. This model jointly minimizes homogeneous feature matching errors and heterogeneous feature association errors.</p><sec id="sec010"><title>3.2.1 Rotation matrix decoupling based on manhattan coordinate system.</title><p>First, we introduce the following definition. As illustrated in <xref rid="pone.0330839.g005" ref-type="fig">Fig 5</xref>, suppose three mutually perpendicular lines (represented by red arrows) are detected in the image. The coordinate system formed by these three orthogonal directions is referred to as the Manhattan coordinate system, also known as the MF. The three mutually orthogonal planes that contain these lines are referred to as Manhattan planes (MPs).</p><fig position="float" id="pone.0330839.g005" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g005</object-id><label>Fig 5</label><caption><title>The specific definitions of MF and MP, as well as the relationship between them.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g005.jpg"/></fig><p>Let <inline-formula id="pone.0330839.e026"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e026g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e026.jpg"/><mml:math id="M26" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> denote the rotation matrix from the camera coordinate system to the Manhattan coordinate system in frame <inline-formula id="pone.0330839.e027"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e027g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e027.jpg"/><mml:math id="M27" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, constructed using three orthogonal plane features extracted from the historical frame <inline-formula id="pone.0330839.e028"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e028g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e028.jpg"/><mml:math id="M28" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. Let <inline-formula id="pone.0330839.e029"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e029g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e029.jpg"/><mml:math id="M29" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> represent the rotation matrix from the camera coordinate system in frame <inline-formula id="pone.0330839.e030"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e030g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e030.jpg"/><mml:math id="M30" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> to the world coordinate system. Similarly, let <inline-formula id="pone.0330839.e031"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e031g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e031.jpg"/><mml:math id="M31" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> be the rotation matrix from the camera coordinate system to the Manhattan coordinate system in the current frame <inline-formula id="pone.0330839.e032"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e032g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e032.jpg"/><mml:math id="M32" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, constructed using three mutually orthogonal plane features detected in <inline-formula id="pone.0330839.e033"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e033g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e033.jpg"/><mml:math id="M33" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, which are matched with those used in <inline-formula id="pone.0330839.e034"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e034g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e034.jpg"/><mml:math id="M34" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> &#8212;the rotation matrix from the camera coordinate system in <inline-formula id="pone.0330839.e035"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e035g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e035.jpg"/><mml:math id="M35" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> to the world coordinate system. In this case, <inline-formula id="pone.0330839.e036"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e036g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e036.jpg"/><mml:math id="M36" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is the unknown quantity to be determined.</p><p>As illustrated in <xref rid="pone.0330839.g006" ref-type="fig">Fig 6</xref>, if the rotation matrix of the MF in <inline-formula id="pone.0330839.e037"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e037g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e037.jpg"/><mml:math id="M37" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> relative to the world coordinate system can be obtained, then the camera&#8217;s rotation matrix <inline-formula id="pone.0330839.e038"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e038g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e038.jpg"/><mml:math id="M38" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> can also be determined accordingly. Since the MF detected in both <inline-formula id="pone.0330839.e039"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e039g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e039.jpg"/><mml:math id="M39" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e040"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e040g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e040.jpg"/><mml:math id="M40" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is consistent, their respective rotation matrices to the world coordinate system must also be consistent. Given that <inline-formula id="pone.0330839.e041"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e041g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e041.jpg"/><mml:math id="M41" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is already known (the rotation matrix from the camera coordinate system in <inline-formula id="pone.0330839.e042"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e042g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e042.jpg"/><mml:math id="M42" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> the world coordinate system), the rotation matrix of the MF in frame <inline-formula id="pone.0330839.e043"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e043g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e043.jpg"/><mml:math id="M43" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> relative to the world coordinate system can be computed as in Eq. (7):</p><fig position="float" id="pone.0330839.g006" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g006</object-id><label>Fig 6</label><caption><title>The relationship between the world coordinate system (W), the historical frame camera coordinate system (L), the Manhattan coordinate system (M), and the current frame camera coordinate system (C).</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g006.jpg"/></fig><disp-formula id="pone.0330839.e044"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e044g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e044.jpg"/><mml:math id="M44" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives><label>(7)</label></disp-formula><p>When the current frame <inline-formula id="pone.0330839.e045"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e045g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e045.jpg"/><mml:math id="M45" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> detects three mutually orthogonal plane features, a MF system <inline-formula id="pone.0330839.e046"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e046g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e046.jpg"/><mml:math id="M46" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> can be constructed according to the principles of the MW assumption. The normal vectors of these three planes define the coordinate axes of <inline-formula id="pone.0330839.e047"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e047g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e047.jpg"/><mml:math id="M47" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, and the rotation matrix from the camera coordinate system in <inline-formula id="pone.0330839.e048"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e048g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e048.jpg"/><mml:math id="M48" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> to the MF system is denoted as <inline-formula id="pone.0330839.e049"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e049g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e049.jpg"/><mml:math id="M49" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. Assuming that the same set of three orthogonal plane features can also be identified in a historical frame <inline-formula id="pone.0330839.e050"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e050g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e050.jpg"/><mml:math id="M50" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, the corresponding Manhattan coordinate system is denoted as <inline-formula id="pone.0330839.e051"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e051g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e051.jpg"/><mml:math id="M51" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, with the rotation matrix from the camera coordinate system in <inline-formula id="pone.0330839.e052"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e052g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e052.jpg"/><mml:math id="M52" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> to the Manhattan frame represented as <inline-formula id="pone.0330839.e053"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e053g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e053.jpg"/><mml:math id="M53" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. Since the Manhattan frames <inline-formula id="pone.0330839.e054"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e054g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e054.jpg"/><mml:math id="M54" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e055"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e055g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e055.jpg"/><mml:math id="M55" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> are consistent, the rotation matrix of the camera in frame <inline-formula id="pone.0330839.e056"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e056g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e056.jpg"/><mml:math id="M56" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> with respect to the world coordinate system can be inferred. Following the approach in [<xref rid="pone.0330839.ref018" ref-type="bibr">18</xref>], the relationship can be expressed by the Eq. (8):</p><disp-formula id="pone.0330839.e057"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e057g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e057.jpg"/><mml:math id="M57" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives><label>(8)</label></disp-formula><p>From Eq. (8), it can be seen that since <inline-formula id="pone.0330839.e058"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e058g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e058.jpg"/><mml:math id="M58" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e059"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e059g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e059.jpg"/><mml:math id="M59" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> depend solely on the accuracy of plane feature extraction within their respective frames, their computation does not involve error accumulation across frames. Therefore, the accuracy of <inline-formula id="pone.0330839.e060"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e060g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e060.jpg"/><mml:math id="M60" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is directly influenced only by the accuracy of <inline-formula id="pone.0330839.e061"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e061g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e061.jpg"/><mml:math id="M61" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, and is unaffected by errors in other intermediate frames. In other words, assuming that the estimation errors of <inline-formula id="pone.0330839.e062"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e062g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e062.jpg"/><mml:math id="M62" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e063"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e063g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e063.jpg"/><mml:math id="M63" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> are negligible, the accuracy of <inline-formula id="pone.0330839.e064"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e064g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e064.jpg"/><mml:math id="M64" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> can be considered equivalent to that of <inline-formula id="pone.0330839.e065"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e065g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e065.jpg"/><mml:math id="M65" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>.</p><list list-type="bullet"><list-item><p>In scenarios where only two mutually orthogonal plane features or parallel orthogonal planes can be detected and matched in the scene:</p></list-item></list><p>When frame <inline-formula id="pone.0330839.e066"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e066g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e066.jpg"/><mml:math id="M66" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> detects only two mutually orthogonal plane features, as illustrated in <xref rid="pone.0330839.g007" ref-type="fig">Fig 7</xref>, the cross product of the two normal vectors can be used to infer the third orthogonal direction, thereby completing the MF. Alternatively, when frame <inline-formula id="pone.0330839.e067"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e067g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e067.jpg"/><mml:math id="M67" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> cannot detect the same orthogonal planes as in the historical frame but can detect parallel orthogonal planes, the system can still extract the normal vectors of these parallel orthogonal planes. These vectors can be used to reconstruct a Manhattan coordinate system and enable rotation matrix decoupling, as detailed in the following steps:</p><fig position="float" id="pone.0330839.g007" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g007</object-id><label>Fig 7</label><caption><title>Two parallel orthogonal plane features.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g007.jpg"/></fig><disp-formula id="pone.0330839.e068"><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e068g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e068.jpg"/><label>(9)</label></disp-formula><p>Let <inline-formula id="pone.0330839.e069"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e069g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e069.jpg"/><mml:math id="M69" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e070"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e070g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e070.jpg"/><mml:math id="M70" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> denote the normal vectors of the two mutually orthogonal plane features detected in frame <inline-formula id="pone.0330839.e071"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e071g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e071.jpg"/><mml:math id="M71" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. The third orthogonal direction <inline-formula id="pone.0330839.e072"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e072g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e072.jpg"/><mml:math id="M72" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is obtained via the cross product of <inline-formula id="pone.0330839.e073"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e073g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e073.jpg"/><mml:math id="M73" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e074"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e074g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e074.jpg"/><mml:math id="M74" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. Similarly, let <inline-formula id="pone.0330839.e075"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e075g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e075.jpg"/><mml:math id="M75" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e076"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e076g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e076.jpg"/><mml:math id="M76" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> represent the normal vectors of two orthogonal plane features detected in frame <inline-formula id="pone.0330839.e077"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e077g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e077.jpg"/><mml:math id="M77" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, and the vector <inline-formula id="pone.0330839.e078"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e078g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e078.jpg"/><mml:math id="M78" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is the third direction obtained from the cross product of <inline-formula id="pone.0330839.e079"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e079g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e079.jpg"/><mml:math id="M79" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e080"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e080g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e080.jpg"/><mml:math id="M80" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. Based on these orthogonal vectors, the rotation matrices of the MF relative to the camera coordinate system in frames <inline-formula id="pone.0330839.e081"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e081g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e081.jpg"/><mml:math id="M81" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e082"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e082g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e082.jpg"/><mml:math id="M82" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> can be constructed as shown in Eq. (10):</p><disp-formula id="pone.0330839.e083"><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e083g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e083.jpg"/><label>(10)</label></disp-formula><list list-type="bullet"><list-item><p>When only one pair of parallel or orthogonal plane features and another orthogonal vertical plane feature can be detected and matched in the scene:</p></list-item></list><p>As illustrated in <xref rid="pone.0330839.g008" ref-type="fig">Fig 8</xref>, the third orthogonal direction can still be determined using the cross product of the available plane normals, following the same procedure as described previously. Then, the rotation matrices are constructed. For instance, let <inline-formula id="pone.0330839.e084"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e084g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e084.jpg"/><mml:math id="M84" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> be a normal vector that is either parallel or orthogonal to <inline-formula id="pone.0330839.e085"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e085g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e085.jpg"/><mml:math id="M85" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, and let <inline-formula id="pone.0330839.e086"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e086g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e086.jpg"/><mml:math id="M86" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> be orthogonal to <inline-formula id="pone.0330839.e087"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e087g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e087.jpg"/><mml:math id="M87" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. If the resulting MF systems <inline-formula id="pone.0330839.e088"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e088g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e088.jpg"/><mml:math id="M88" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e089"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e089g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e089.jpg"/><mml:math id="M89" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> are not equivalent (i.e., <inline-formula id="pone.0330839.e090"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e090g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e090.jpg"/><mml:math id="M90" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>&#8800;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>), the corresponding rotation matrices can be constructed as follows:</p><fig position="float" id="pone.0330839.g008" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g008</object-id><label>Fig 8</label><caption><title>One parallel or orthogonal plane feature and another orthogonal vertical plane feature.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g008.jpg"/></fig><disp-formula id="pone.0330839.e091"><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e091g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e091.jpg"/><label>(11)</label></disp-formula><p>For example, when the camera detects only the ground plane feature and the wall plane feature from time <inline-formula id="pone.0330839.e092"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e092g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e092.jpg"/><mml:math id="M92" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> to <inline-formula id="pone.0330839.e093"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e093g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e093.jpg"/><mml:math id="M93" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, we can apply the right-hand rule and define the matrix E as: <inline-formula id="pone.0330839.e094"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e094g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e094.jpg"/><mml:math id="M94" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd><mml:mtd><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>&#8722;</mml:mo><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd><mml:mtd><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>.</p><p>This matrix is used to rotate <inline-formula id="pone.0330839.e095"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e095g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e095.jpg"/><mml:math id="M95" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> to align with <inline-formula id="pone.0330839.e096"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e096g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e096.jpg"/><mml:math id="M96" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. After unifying the indices, the rotation matrix is given by:</p><disp-formula id="pone.0330839.e097"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e097g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e097.jpg"/><mml:math id="M97" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mi>&#215;</mml:mi><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives><label>(12)</label></disp-formula></sec><sec id="sec011"><title>3.2.2 Translation matrix decoupling based on manhattan coordinate system.</title><p>As shown in <xref rid="pone.0330839.g009" ref-type="fig">Fig 9</xref>, once the rotation matrix is decoupled, the decoupling of the translation matrix can typically be classified into three scenarios:</p><fig position="float" id="pone.0330839.g009" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g009</object-id><label>Fig 9</label><caption><title>Decoupling of the translation matrix.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g009.jpg"/></fig><list list-type="simple"><list-item><p>(1) Matching three fully orthogonal plane features;</p></list-item></list><p>Let <inline-formula id="pone.0330839.e098"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e098g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e098.jpg"/><mml:math id="M98" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e099"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e099g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e099.jpg"/><mml:math id="M99" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> denote the translation and rotation matrices from the camera coordinate system of frame <inline-formula id="pone.0330839.e100"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e100g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e100.jpg"/><mml:math id="M100" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> to the world coordinate system, respectively. It is assumed that <inline-formula id="pone.0330839.e101"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e101g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e101.jpg"/><mml:math id="M101" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> has already been decoupled via the MF system. The vector <inline-formula id="pone.0330839.e102"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e102g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e102.jpg"/><mml:math id="M102" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:msub><mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:msub><mml:mrow><mml:mrow><mml:mi>Z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo><mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> represents the distances from the origin of the camera coordinate system in frame <inline-formula id="pone.0330839.e103"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e103g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e103.jpg"/><mml:math id="M103" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>&#160;</mml:mo><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> to the MF system constructed using the MP features. The rotation matrix from the MF system (constructed in frame <inline-formula id="pone.0330839.e104"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e104g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e104.jpg"/><mml:math id="M104" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>) to the world coordinate system is denoted as <inline-formula id="pone.0330839.e105"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e105g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e105.jpg"/><mml:math id="M105" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>&#160;</mml:mo><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, which can be obtained using <inline-formula id="pone.0330839.e106"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e106g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e106.jpg"/><mml:math id="M106" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0330839.e107"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e107g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e107.jpg"/><mml:math id="M107" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e108"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e108g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e108.jpg"/><mml:math id="M108" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>&#160;</mml:mo><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, as shown in Eq. (13).</p><disp-formula id="pone.0330839.e109"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e109g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e109.jpg"/><mml:math id="M109" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mi>&#215;</mml:mi><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives><label>(13)</label></disp-formula><p>Assuming that frame <inline-formula id="pone.0330839.e110"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e110g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e110.jpg"/><mml:math id="M110" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> observes the same set of three mutually orthogonal plane features, let <inline-formula id="pone.0330839.e111"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e111g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e111.jpg"/><mml:math id="M111" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:msub><mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:msub><mml:mrow><mml:mrow><mml:mi>Z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo><mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> represent the distances from the origin of the camera coordinate system in frame <inline-formula id="pone.0330839.e112"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e112g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e112.jpg"/><mml:math id="M112" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> to its corresponding MF system. The rotation matrix <inline-formula id="pone.0330839.e113"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e113g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e113.jpg"/><mml:math id="M113" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> from frame <inline-formula id="pone.0330839.e114"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e114g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e114.jpg"/><mml:math id="M114" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>&#8217;s camera coordinate system to the world coordinate system is assumed to have already been obtained through MF decoupling. To compute the translation matrix <inline-formula id="pone.0330839.e115"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e115g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e115.jpg"/><mml:math id="M115" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, we first estimate the translation matrix <inline-formula id="pone.0330839.e116"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e116g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e116.jpg"/><mml:math id="M116" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, which denotes the translation from the MF system constructed in frame <inline-formula id="pone.0330839.e117"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e117g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e117.jpg"/><mml:math id="M117" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> to the world coordinate system.</p><disp-formula id="pone.0330839.e118"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e118g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e118.jpg"/><mml:math id="M118" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mi>&#215;</mml:mi><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives><label>(14)</label></disp-formula><p>Given that <inline-formula id="pone.0330839.e119"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e119g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e119.jpg"/><mml:math id="M119" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, and <inline-formula id="pone.0330839.e120"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e120g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e120.jpg"/><mml:math id="M120" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, we define <inline-formula id="pone.0330839.e121"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e121g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e121.jpg"/><mml:math id="M121" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> as the translation matrix from the Manhattan coordinate system to the world coordinate system, and <inline-formula id="pone.0330839.e122"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e122g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e122.jpg"/><mml:math id="M122" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> as the corresponding rotation matrix. Once <inline-formula id="pone.0330839.e123"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e123g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e123.jpg"/><mml:math id="M123" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is computed, the translation matrix <inline-formula id="pone.0330839.e124"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e124g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e124.jpg"/><mml:math id="M124" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> can be obtained based on the intrinsic relationships among the world coordinate system, MF system, and camera coordinate system:</p><disp-formula id="pone.0330839.e125"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e125g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e125.jpg"/><mml:math id="M125" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mi>&#215;</mml:mi><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives><label>(15)</label></disp-formula><p>From Eq. (15), it is evident that the translation matrix <inline-formula id="pone.0330839.e126"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e126g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e126.jpg"/><mml:math id="M126" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> depends solely on <inline-formula id="pone.0330839.e127"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e127g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e127.jpg"/><mml:math id="M127" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e128"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e128g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e128.jpg"/><mml:math id="M128" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, under the assumption that there is no error in <inline-formula id="pone.0330839.e129"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e129g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e129.jpg"/><mml:math id="M129" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0330839.e130"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e130g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e130.jpg"/><mml:math id="M130" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e131"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e131g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e131.jpg"/><mml:math id="M131" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. Since <inline-formula id="pone.0330839.e132"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e132g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e132.jpg"/><mml:math id="M132" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> itself is only dependent on <inline-formula id="pone.0330839.e133"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e133g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e133.jpg"/><mml:math id="M133" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, the final translation matrix <inline-formula id="pone.0330839.e134"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e134g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e134.jpg"/><mml:math id="M134" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is thus determined exclusively by the pose of the camera in frame <inline-formula id="pone.0330839.e135"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e135g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e135.jpg"/><mml:math id="M135" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, remaining independent of poses in other frames. Therefore, provided that <inline-formula id="pone.0330839.e136"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e136g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e136.jpg"/><mml:math id="M136" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e137"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e137g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e137.jpg"/><mml:math id="M137" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> are initialized without error accumulation, the translation matrix <inline-formula id="pone.0330839.e138"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e138g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e138.jpg"/><mml:math id="M138" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> can be accurately decoupled from the camera coordinate system in frame <inline-formula id="pone.0330839.e139"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e139g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e139.jpg"/><mml:math id="M139" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> to the world coordinate system. Crucially, this process is unaffected by any intermediate pose errors between frames. <xref rid="pone.0330839.g010" ref-type="fig">Fig 10</xref> presents the pseudocode for the pose decoupling procedure, where the sections highlighted in red indicate the decoupled translation matrix components.</p><fig position="float" id="pone.0330839.g010" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g010</object-id><label>Fig 10</label><caption><title>Pseudocode implementation of pose matrix decoupling.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g010.jpg"/></fig><p>For simplification, when the MF system constructed from the three-plane features is aligned with the initial world coordinate system, the translation matrix <inline-formula id="pone.0330839.e140"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e140g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e140.jpg"/><mml:math id="M140" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> can be directly simplified as <inline-formula id="pone.0330839.e141"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e141g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e141.jpg"/><mml:math id="M141" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>.</p><list list-type="simple"><list-item><p>(2) Matching two completely orthogonal plane features;</p></list-item></list><p>Assume that only two mutually orthogonal plane features are detected in frame <inline-formula id="pone.0330839.e142"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e142g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e142.jpg"/><mml:math id="M142" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, and the same two orthogonal planes are also detected in frame <inline-formula id="pone.0330839.e143"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e143g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e143.jpg"/><mml:math id="M143" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. However, the MF system established during initialization is inconsistent with the one currently detected&#8212;meaning that the Manhattan coordinate system in the current frame is not aligned with the world coordinate system. In this scenario, direct translation matrix decoupling becomes infeasible.</p><p>To resolve this issue, we propose a translation matrix decoupling method assisted by a hypothetical plane feature. As illustrated in <xref rid="pone.0330839.g011" ref-type="fig">Figs 11</xref> and <xref rid="pone.0330839.g012" ref-type="fig">12</xref>, the algorithm traverses frames <inline-formula id="pone.0330839.e144"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e144g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e144.jpg"/><mml:math id="M144" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e145"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e145g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e145.jpg"/><mml:math id="M145" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> to identify point features that are jointly observed. Assume that m such point features are observed by both frames. Among these, we select the most stable point feature, denoted as <inline-formula id="pone.0330839.e146"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e146g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e146.jpg"/><mml:math id="M146" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, based on the following criteria: <inline-formula id="pone.0330839.e147"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e147g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e147.jpg"/><mml:math id="M147" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is observed in the largest number of keyframes, and the distance from <inline-formula id="pone.0330839.e148"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e148g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e148.jpg"/><mml:math id="M148" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> to the camera center is less than 7 meters. The coordinates of this point feature in the camera coordinate system of frame <inline-formula id="pone.0330839.e149"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e149g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e149.jpg"/><mml:math id="M149" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> are denoted as <inline-formula id="pone.0330839.e150"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e150g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e150.jpg"/><mml:math id="M150" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, and in frame <inline-formula id="pone.0330839.e151"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e151g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e151.jpg"/><mml:math id="M151" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> as <inline-formula id="pone.0330839.e152"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e152g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e152.jpg"/><mml:math id="M152" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>.</p><fig position="float" id="pone.0330839.g011" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g011</object-id><label>Fig 11</label><caption><title>Constructing imaginary plane features using common points in frame.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g011.jpg"/></fig><fig position="float" id="pone.0330839.g012" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g012</object-id><label>Fig 12</label><caption><title>Constructing imaginary plane features using common points in frame.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g012.jpg"/></fig><p>Here, <inline-formula id="pone.0330839.e153"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e153g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e153.jpg"/><mml:math id="M153" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e154"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e154g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e154.jpg"/><mml:math id="M154" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> are a pair of orthogonal plane features detected in frame <inline-formula id="pone.0330839.e155"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e155g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e155.jpg"/><mml:math id="M155" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>; <inline-formula id="pone.0330839.e156"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e156g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e156.jpg"/><mml:math id="M156" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e157"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e157g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e157.jpg"/><mml:math id="M157" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> are a pair of orthogonal plane features detected in frame <inline-formula id="pone.0330839.e158"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e158g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e158.jpg"/><mml:math id="M158" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> that match <inline-formula id="pone.0330839.e159"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e159g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e159.jpg"/><mml:math id="M159" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e160"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e160g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e160.jpg"/><mml:math id="M160" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>; <inline-formula id="pone.0330839.e161"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e161g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e161.jpg"/><mml:math id="M161" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is the hypothetical plane feature that needs to be constructed in frame <inline-formula id="pone.0330839.e162"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e162g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e162.jpg"/><mml:math id="M162" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> to be orthogonal to <inline-formula id="pone.0330839.e163"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e163g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e163.jpg"/><mml:math id="M163" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e164"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e164g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e164.jpg"/><mml:math id="M164" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>; <inline-formula id="pone.0330839.e165"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e165g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e165.jpg"/><mml:math id="M165" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is the hypothetical plane feature that needs to be constructed in frame <inline-formula id="pone.0330839.e166"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e166g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e166.jpg"/><mml:math id="M166" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> to be orthogonal to <inline-formula id="pone.0330839.e167"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e167g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e167.jpg"/><mml:math id="M167" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e168"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e168g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e168.jpg"/><mml:math id="M168" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. The Hesse representation of <inline-formula id="pone.0330839.e169"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e169g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e169.jpg"/><mml:math id="M169" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> can be expressed as:</p><disp-formula id="pone.0330839.e170"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e170g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e170.jpg"/><mml:math id="M170" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">&#8214;</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">&#8214;</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives><label>(16)</label></disp-formula><p>where <inline-formula id="pone.0330839.e171"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e171g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e171.jpg"/><mml:math id="M171" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>&#8855;</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>; <inline-formula id="pone.0330839.e172"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e172g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e172.jpg"/><mml:math id="M172" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e173"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e173g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e173.jpg"/><mml:math id="M173" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> are the normal vectors of the plane features <inline-formula id="pone.0330839.e174"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e174g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e174.jpg"/><mml:math id="M174" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e175"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e175g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e175.jpg"/><mml:math id="M175" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, respectively.</p><p>The Hesse representation of <inline-formula id="pone.0330839.e176"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e176g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e176.jpg"/><mml:math id="M176" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> can be expressed as:</p><disp-formula id="pone.0330839.e177"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e177g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e177.jpg"/><mml:math id="M177" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">&#8214;</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">&#8214;</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives><label>(17)</label></disp-formula><p>where <inline-formula id="pone.0330839.e178"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e178g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e178.jpg"/><mml:math id="M178" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>&#8855;</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>; <inline-formula id="pone.0330839.e179"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e179g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e179.jpg"/><mml:math id="M179" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e180"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e180g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e180.jpg"/><mml:math id="M180" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> are the normal vectors of the plane features <inline-formula id="pone.0330839.e181"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e181g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e181.jpg"/><mml:math id="M181" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e182"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e182g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e182.jpg"/><mml:math id="M182" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, respectively.</p><p>After constructing the hypothetical plane feature, the three orthogonal plane features from the historical and current frames are completely matched. Therefore, the translation matrix can be decoupled using the scheme in step (1).</p><list list-type="simple"><list-item><p>(3) Matching orthogonal plane features that are parallel to each other.</p></list-item></list><p>For example, when only parallel orthogonal plane features can be matched, it becomes impossible to determine the distance relationship between the camera optical center and the three orthogonal plane features in the current and historical frames. As a result, only the rotation matrix can be decoupled, while the translation matrix cannot. In this case, the translation matrix is solved using nonlinear optimization with the cooperation of points, lines, and planes.</p></sec></sec><sec id="sec012"><title>3.3 Pose estimation model based on joint optimization of points, lines and planes and vanishing point constraints</title><p>After local map tracking, when more than two mutually orthogonal planes are detected and matched, the rotation matrix is first decoupled, followed by decoupling of the translation matrix using the hypothetical plane-assisted method. In cases where only parallel orthogonal planes are detected and matched, the rotation matrix is still decoupled first, and then nonlinear optimization is applied to the current frame using point-plane feature constraints and structural relationships to solve for the translation matrix. If fewer than two mutually orthogonal planes can be detected and matched, the system directly employs point-line-plane features and structural constraints for local nonlinear pose optimization to jointly estimate both the rotation and translation matrices, as illustrated in <xref rid="pone.0330839.g013" ref-type="fig">Fig 13</xref>.</p><fig position="float" id="pone.0330839.g013" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g013</object-id><label>Fig 13</label><caption><title>Pose estimation model based on joint optimization of points, lines and planes and vanishing point constraints.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g013.jpg"/></fig><p>This paper proposes a joint optimization model based on point, line, and plane (PLP) features, which simultaneously minimizes both the matching errors of homogeneous features and the association errors of heterogeneous features. To enhance the accuracy of multi-feature SLAM systems and better utilize the strengths of line and plane features during tracking, we adopt a unified parameter representation using point features for all feature types during parameter estimation and nonlinear optimization. Following the method in [<xref rid="pone.0330839.ref043" ref-type="bibr">43</xref>], line features are represented by the start endpoint of the line segment, while plane features are represented by two coplanar line segments. Referencing [<xref rid="pone.0330839.ref015" ref-type="bibr">15</xref>] and [<xref rid="pone.0330839.ref018" ref-type="bibr">18</xref>], all state variables are optimized by minimizing the total cost from all measurement residuals, as expressed in Eq. (18):</p><disp-formula id="pone.0330839.e183"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e183g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e183.jpg"/><mml:math id="M183" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:munder><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mo>&#8712;</mml:mo><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mi>&#961;</mml:mi></mml:mrow><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">&#8214;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mrow><mml:mi>&#967;</mml:mi></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">&#8214;</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>&#931;</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:munder><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mo>&#8712;</mml:mo><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mi>&#961;</mml:mi></mml:mrow><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">&#8214;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mrow><mml:mi>&#967;</mml:mi></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">&#8214;</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>&#931;</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:munder><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mo>&#8712;</mml:mo><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mi>&#961;</mml:mi></mml:mrow><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">&#8214;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mrow><mml:mi>&#967;</mml:mi></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">&#8214;</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>&#931;</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>&#8712;</mml:mo><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mo>&#8712;</mml:mo><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mrow><mml:mi>&#961;</mml:mi></mml:mrow><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">&#8214;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mrow><mml:mi>&#967;</mml:mi></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">&#8214;</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>&#931;</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>&#931;</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>&#8712;</mml:mo><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mo>&#8712;</mml:mo><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mrow><mml:mi>&#961;</mml:mi></mml:mrow><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">&#8214;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mrow><mml:mi>&#967;</mml:mi></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">&#8214;</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>&#931;</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>&#931;</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mo>&#8712;</mml:mo><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>&#8712;</mml:mo><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mrow><mml:mi>&#961;</mml:mi></mml:mrow><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">&#8214;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mrow><mml:mi>&#967;</mml:mi></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">&#8214;</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>&#931;</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives><label>(18)</label></disp-formula><p>where <inline-formula id="pone.0330839.e184"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e184g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e184.jpg"/><mml:math id="M184" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#967;</mml:mi></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is the camera state vector that needs to be estimated in the <inline-formula id="pone.0330839.e185"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e185g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e185.jpg"/><mml:math id="M185" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> frame. <inline-formula id="pone.0330839.e186"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e186g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e186.jpg"/><mml:math id="M186" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mrow><mml:mi>&#967;</mml:mi></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0330839.e187"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e187g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e187.jpg"/><mml:math id="M187" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mrow><mml:mi>&#967;</mml:mi></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, and <inline-formula id="pone.0330839.e188"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e188g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e188.jpg"/><mml:math id="M188" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mrow><mml:mi>&#967;</mml:mi></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> are the point feature re-projection residual, the line feature re-projection residual and the plane feature re-projection residual, respectively. <italic toggle="yes">F</italic>, <italic toggle="yes">L</italic> and <italic toggle="yes">P</italic> are the sets of point features, line features and plane features observed by camera frames, respectively. <inline-formula id="pone.0330839.e189"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e189g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e189.jpg"/><mml:math id="M189" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mrow><mml:mi>&#967;</mml:mi></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e190"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e190g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e190.jpg"/><mml:math id="M190" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mrow><mml:mi>&#967;</mml:mi></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> are the reprojection errors of point-to-plane distance and line-to-plane distance, respectively; <inline-formula id="pone.0330839.e191"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e191g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e191.jpg"/><mml:math id="M191" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mrow><mml:mi>&#967;</mml:mi></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is the reprojection error based on the vanishing point constraint. The error equations for homogeneous features (point-point, line-line, and plane-plane) follow formulations presented in [<xref rid="pone.0330839.ref034" ref-type="bibr">34</xref>] and [<xref rid="pone.0330839.ref043" ref-type="bibr">43</xref>], and are not elaborated here due to space constraints. The remainder of this section focuses on the construction of vanishing point-based constraints and heterogeneous feature association residuals.</p><p>Previous works commonly used geometric or deep learning-based methods to extract vanishing points. However, both approaches are computationally intensive and often inaccurate in complex environments. For example, in narrow corridor scenes, only a single vanishing point is typically extractable, and extraction in other directions tends to be unstable, as illustrated in <xref rid="pone.0330839.g014" ref-type="fig">Fig 14</xref>.</p><fig position="float" id="pone.0330839.g014" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g014</object-id><label>Fig 14</label><caption><title>Scene of long corridor.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g014.jpg"/></fig><p>To address this, we propose a vanishing point extraction method based on the normal vectors of orthogonal plane features. It is assumed that two or three orthogonal planes have already been detected. Let <inline-formula id="pone.0330839.e192"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e192g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e192.jpg"/><mml:math id="M192" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mtext>1</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0330839.e193"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e193g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e193.jpg"/><mml:math id="M193" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mtext>2</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e194"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e194g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e194.jpg"/><mml:math id="M194" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mtext>3</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> denote the three mutually orthogonal prior vanishing point directions, corresponding to the X, Y, and Z axes of the Manhattan coordinate system. Observed line features are classified according to their directional alignment with these vanishing points. As shown in <xref rid="pone.0330839.g015" ref-type="fig">Fig 15</xref>, let <inline-formula id="pone.0330839.e195"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e195g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e195.jpg"/><mml:math id="M195" display="inline" overflow="scroll"><mml:mrow><mml:mtext>a</mml:mtext></mml:mrow></mml:math></alternatives></inline-formula> be the angle between a line feature <inline-formula id="pone.0330839.e196"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e196g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e196.jpg"/><mml:math id="M196" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and the X-axis. When <inline-formula id="pone.0330839.e197"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e197g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e197.jpg"/><mml:math id="M197" display="inline" overflow="scroll"><mml:mrow><mml:mtext>a</mml:mtext></mml:mrow></mml:math></alternatives></inline-formula> is less than 10&#8201;degrees, the line feature <inline-formula id="pone.0330839.e198"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e198g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e198.jpg"/><mml:math id="M198" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is considered to be aligned with the X-axis direction.</p><fig position="float" id="pone.0330839.g015" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g015</object-id><label>Fig 15</label><caption><title>Line feature classification based on vanishing points.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g015.jpg"/></fig><p>To simplify the computation, we first calculate the vector cross product between the direction vector of each line feature and the direction of a vanishing point. Line features that are approximately parallel to <inline-formula id="pone.0330839.e199"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e199g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e199.jpg"/><mml:math id="M199" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>&#12289;<inline-formula id="pone.0330839.e200"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e200g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e200.jpg"/><mml:math id="M200" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e201"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e201g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e201.jpg"/><mml:math id="M201" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> are then assigned to corresponding directional categories by Eq. (19):</p><disp-formula id="pone.0330839.e202"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e202g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e202.jpg"/><mml:math id="M202" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#948;</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>&#8855;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives><label>(19)</label></disp-formula><p>where <inline-formula id="pone.0330839.e203"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e203g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e203.jpg"/><mml:math id="M203" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is the direction vector of the kth line feature, and <inline-formula id="pone.0330839.e204"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e204g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e204.jpg"/><mml:math id="M204" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> denotes the direction of the mth vanishing point. Ideally, <inline-formula id="pone.0330839.e205"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e205g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e205.jpg"/><mml:math id="M205" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#948;</mml:mi></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> should equal zero when the vectors are exactly parallel. However, due to noise and error propagation, <inline-formula id="pone.0330839.e206"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e206g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e206.jpg"/><mml:math id="M206" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#948;</mml:mi></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is typically non-zero in practice. Therefore, a threshold is introduced: when <inline-formula id="pone.0330839.e207"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e207g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e207.jpg"/><mml:math id="M207" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#948;</mml:mi></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>&#8804;0.05, the line feature <inline-formula id="pone.0330839.e208"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e208g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e208.jpg"/><mml:math id="M208" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is considered to belong to the vanishing point category <inline-formula id="pone.0330839.e209"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e209g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e209.jpg"/><mml:math id="M209" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>.</p><p>When multiple orthogonal plane features are detected in the scene, a statistical analysis is performed to count how many line features are assigned to each candidate vanishing point. The vanishing point direction with the largest number of associated line features is retained as the final dominant vanishing point direction. The complete procedure is illustrated in <xref rid="pone.0330839.g016" ref-type="fig">Fig 16</xref>.</p><fig position="float" id="pone.0330839.g016" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g016</object-id><label>Fig 16</label><caption><title>Iteration between Manhattan coordinate system and vanishing point.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g016.jpg"/></fig><p>Following the method in [<xref rid="pone.0330839.ref022" ref-type="bibr">22</xref>], the structure-constrained residual equation based on vanishing points is defined as:</p><disp-formula id="pone.0330839.e210"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e210g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e210.jpg"/><mml:math id="M210" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mrow><mml:mi>&#967;</mml:mi></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>&#8721;</mml:mo><mml:msubsup><mml:mi>\nolimits</mml:mi><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">&#8214;</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>&#8855;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo fence="true" form="postfix" stretchy="true">&#8214;</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives><label>(20)</label></disp-formula><p>Since <inline-formula id="pone.0330839.e211"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e211g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e211.jpg"/><mml:math id="M211" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mrow><mml:mi>&#967;</mml:mi></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is solely dependent on the rotation matrix <inline-formula id="pone.0330839.e212"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e212g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e212.jpg"/><mml:math id="M212" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, this matrix can be estimated through nonlinear optimization using Eq. (20). The translation matrix <inline-formula id="pone.0330839.e213"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e213g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e213.jpg"/><mml:math id="M213" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is subsequently obtained through additional geometric constraints. This approach effectively decouples the rotation and translation matrices, facilitating faster convergence of the optimization process and reducing the risk of convergence to local minima. To ensure consistency with point feature residual optimization, we adopt a two-endpoint representation for line features. As referenced in [<xref rid="pone.0330839.ref016" ref-type="bibr">16</xref>], a line feature can be represented using its two endpoints in the world coordinate system, as show in Eq. (21):</p><disp-formula id="pone.0330839.e214"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e214g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e214.jpg"/><mml:math id="M214" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives><label>(21)</label></disp-formula><p>The error equation based on the vanishing point constraint can be rewritten as:</p><disp-formula id="pone.0330839.e215"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e215g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e215.jpg"/><mml:math id="M215" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>&#947;</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>W</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>&#8855;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives><label>(22)</label></disp-formula><p>The Jacobian matrix of <inline-formula id="pone.0330839.e216"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e216g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e216.jpg"/><mml:math id="M216" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>&#947;</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> with respect to the state vector <inline-formula id="pone.0330839.e217"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e217g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e217.jpg"/><mml:math id="M217" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#967;</mml:mi></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> can be written as:</p><disp-formula id="pone.0330839.e218"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e218g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e218.jpg"/><mml:math id="M218" display="block" overflow="scroll"><mml:mrow><mml:mfrac><mml:mrow><mml:mo>&#8706;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>&#947;</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>&#8706;</mml:mo><mml:mrow><mml:mi>&#967;</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#8706;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>&#947;</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>&#8706;</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#8706;</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mo>&#8706;</mml:mo><mml:mrow><mml:mi>&#948;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#958;</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#8706;</mml:mo><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#8706;</mml:mo><mml:mrow><mml:mi>&#948;</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#8706;</mml:mo><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#8706;</mml:mo><mml:mrow><mml:mi>&#948;</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#8706;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>&#947;</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>&#8706;</mml:mo><mml:mrow><mml:mi>&#948;</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>&#8722;</mml:mo><mml:msup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">[</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo fence="true" form="postfix" stretchy="true">]</mml:mo></mml:mrow><mml:mrow><mml:mi>&#215;</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#8706;</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mo>&#8706;</mml:mo><mml:mrow><mml:mi>&#948;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#958;</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#8706;</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mo>&#8706;</mml:mo><mml:mrow><mml:mi>&#948;</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>&#8722;</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#8706;</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mo>&#8706;</mml:mo><mml:mrow><mml:mi>&#948;</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives><label>(23)</label></disp-formula><p>where <inline-formula id="pone.0330839.e219"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e219g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e219.jpg"/><mml:math id="M219" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is a constant, <inline-formula id="pone.0330839.e220"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e220g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e220.jpg"/><mml:math id="M220" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mrow><mml:mo>&#8706;</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>&#947;</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>&#8706;</mml:mo><mml:mrow><mml:mi>&#948;</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>=0. The perturbation model can be used to solve <inline-formula id="pone.0330839.e221"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e221g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e221.jpg"/><mml:math id="M221" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mrow><mml:mo>&#8706;</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mo>&#8706;</mml:mo><mml:mrow><mml:mi>&#948;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#958;</mml:mi></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>:</p><disp-formula id="pone.0330839.e222"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e222g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e222.jpg"/><mml:math id="M222" display="block" overflow="scroll"><mml:mrow><mml:mfrac><mml:mrow><mml:mo>&#8706;</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mo>&#8706;</mml:mo><mml:mrow><mml:mi>&#948;</mml:mi></mml:mrow><mml:mrow><mml:mi>&#958;</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">[</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mo fence="true" form="prefix" stretchy="true">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo fence="true" form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mo fence="true" form="postfix" stretchy="true">]</mml:mo></mml:mrow><mml:mrow><mml:mi>&#215;</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives><label>(24)</label></disp-formula><p>where <inline-formula id="pone.0330839.e223"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e223g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e223.jpg"/><mml:math id="M223" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e224"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e224g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e224.jpg"/><mml:math id="M224" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> are the endpoints of the line <inline-formula id="pone.0330839.e225"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e225g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e225.jpg"/><mml:math id="M225" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> in the world coordinate system. Let <inline-formula id="pone.0330839.e226"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e226g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e226.jpg"/><mml:math id="M226" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#958;</mml:mi></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> represent the Lie algebra corresponding to the transformation from the camera frame <inline-formula id="pone.0330839.e227"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e227g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e227.jpg"/><mml:math id="M227" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> to the world frame. The matrices <inline-formula id="pone.0330839.e228"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e228g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e228.jpg"/><mml:math id="M228" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0330839.e229"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e229g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e229.jpg"/><mml:math id="M229" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> denote the rotation and translation from the camera coordinate system to the world coordinate system, respectively. The symbol <inline-formula id="pone.0330839.e230"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.e230g" position="anchor" orientation="portrait" xlink:href="pone.0330839.e230.jpg"/><mml:math id="M230" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mrow><mml:mi>&#215;</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> denotes the skew-symmetric matrix operator.</p></sec></sec><sec id="sec013"><title>4 Experimental verification and evaluation</title><p>This study introduces PLPM-SLAM, a novel tightly coupled RGB-D SLAM system that integrates point-line-plane collaborative optimization with Manhattan plane feature constraints. To address scenarios where only two orthogonal Manhattan plane features are detected&#8212;rendering translation matrix decoupling infeasible&#8212;we propose a translation matrix decoupling algorithm assisted by hypothetical planes. During feature tracking, both homogeneous (point-point, line-line, plane-plane) and heterogeneous (point-line, point-plane, line-plane) feature associations are considered. Plane feature matching is performed using a descriptor constructed from the distances between nnn (where n&#8201;&gt;&#8201;3n&#8201;&gt;&#8201;3n&#8201;&gt;&#8201;3) non-collinear shared keypoints and planar features in both the current and reference frames. In unstructured environments, we jointly optimize homogeneous feature matching errors and heterogeneous feature association errors, and propose a SLAM model that integrates vanishing point constraints with point-line-plane collaborative optimization.</p><p>To evaluate the effectiveness of the proposed system, we conducted experiments using both public datasets&#8212;TUM RGB-D and ICL-NUIM&#8212;and real-world data collected with a ZED2i RGB-D camera. The TUM RGB-D dataset is a widely used benchmark for evaluating visual SLAM and visual odometry (VO) systems. It provides synchronized RGB and depth images at a resolution of 640&#8201;&#215;&#8201;480 and a frame rate of 30 Hz, along with high-precision ground truth camera trajectories. We selected sequences with prominent planar structures to assess our system&#8217;s performance. The ICL-NUIM dataset offers synthetic indoor environments, such as living rooms and office spaces, which are ideal for evaluating point-plane SLAM frameworks. It also includes ground truth trajectories, enabling detailed quantitative analysis.</p><p>All experiments were conducted on a laptop equipped with an Intel i7 CPU, 8 GB RAM, and no dedicated GPU. We compared our proposed SLAM system against several state-of-the-art RGB-D SLAM frameworks: ORB-SLAM3 is a classical point-feature-based SLAM system that supports monocular, stereo, and RGB-D inputs. Its stable performance and high accuracy have made it a standard baseline in SLAM research; MSC-VO is a visual SLAM system that integrates point and line features, as well as structural constraints. The use of line features improves robustness in low-texture environments, and Manhattan coordinate constraints help reduce long-term error accumulation; Planar-SLAM enhances tracking and mapping accuracy by leveraging geometric primitives such as points, lines, and planes. It employs a decoupled optimization strategy and introduces an additional pose optimization module based on Manhattan relationships. However, its performance degrades in scenes where reliable Manhattan structures cannot be detected; Manhattan-SLAM estimates orthogonal planes to recover Manhattan frames and supports real-time pose estimation in both Manhattan and non-Manhattan environments.</p><p>A module-level comparison of these representative systems is provided in <xref rid="pone.0330839.t001" ref-type="table">Table 1</xref>. In the <xref rid="pone.0330839.t001" ref-type="table">Table 1</xref>, &#8220;Heterogeneous feature distance&#8221; refers to constraints involving cross-feature associations (e.g., point-to-plane, line-to-plane), while &#8220;Homogeneous structural constraints&#8221; describe spatial relationships among same-type features (e.g., line-line, plane-plane). To evaluate SLAM performance, we use the Root Mean Square Error (RMSE) of the Absolute Trajectory Error (ATE) as the primary accuracy metric.</p><table-wrap position="float" id="pone.0330839.t001" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.t001</object-id><label>Table 1</label><caption><title>The module comparison of related classical algorithms.</title></caption><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.t001g" position="float" orientation="portrait" xlink:href="pone.0330839.t001.jpg"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Function\Model</th><th align="left" rowspan="1" colspan="1">ORB-SLAM3 [<xref rid="pone.0330839.ref015" ref-type="bibr">15</xref>]</th><th align="left" rowspan="1" colspan="1">MSC-VO [<xref rid="pone.0330839.ref016" ref-type="bibr">16</xref>]</th><th align="left" rowspan="1" colspan="1">Planar-SLAM [<xref rid="pone.0330839.ref017" ref-type="bibr">17</xref>]</th><th align="left" rowspan="1" colspan="1">Manhattan-SLAM [<xref rid="pone.0330839.ref018" ref-type="bibr">18</xref>]</th><th align="left" rowspan="1" colspan="1">UPLP-SLAM [<xref rid="pone.0330839.ref035" ref-type="bibr">35</xref>]</th><th align="left" rowspan="1" colspan="1">PLPM-SLAM</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Point</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Line</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Plane</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Heterogeneous feature distance constraints</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Homogeneous feature structure constraints</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Able to handle both unstructured and structured scenarios</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Decoupled Rotation Matrix</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Decoupled Translation Matrix</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">
<bold>&#8730;</bold>
</td></tr></tbody></table></alternatives></table-wrap><sec id="sec014"><title>4.1 A public dataset validation (TUM and ICL-NUIM)</title><p>We first tested using the public datasets ICL-NUIM and TUM. For the ICL-NUIM dataset, the paper only used the bedroom scene. <xref rid="pone.0330839.t002" ref-type="table">Table 2</xref> compares the results of several RGB-D SLAM methods on these two datasets. PLPM-SLAM is the algorithm proposed in this paper. Compared with PLPM-SLAM, PLP-SLAM removes the vanishing point constraint in the backend optimization. The RMSE results for several ICL-NUIM datasets are presented in <xref rid="pone.0330839.g017" ref-type="fig">Figs 17</xref> and <xref rid="pone.0330839.g018" ref-type="fig">18</xref>, while the trajectory comparisons for these datasets are illustrated in <xref rid="pone.0330839.g019" ref-type="fig">Figs 19</xref> and <xref rid="pone.0330839.g020" ref-type="fig">20</xref>.</p><table-wrap position="float" id="pone.0330839.t002" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.t002</object-id><label>Table 2</label><caption><title>Evaluation results of translation ATE RMSE (unit: m) on ICL-NUIM and TUM datasets. Bold numbers represent the best performances. &#8216;<italic toggle="yes">&#215;</italic>&#8217; represents tracking lost.</title></caption><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.t002g" position="float" orientation="portrait" xlink:href="pone.0330839.t002.jpg"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="2" colspan="1">Type</th><th align="left" rowspan="2" colspan="1">Dataset name</th><th align="left" rowspan="2" colspan="1">ORB-SLAM3 [<xref rid="pone.0330839.ref015" ref-type="bibr">15</xref>]</th><th align="left" rowspan="2" colspan="1">Manhattan-SLAM [<xref rid="pone.0330839.ref018" ref-type="bibr">18</xref>]</th><th align="left" rowspan="2" colspan="1">Planar-SLAM [<xref rid="pone.0330839.ref017" ref-type="bibr">17</xref>]</th><th align="left" rowspan="2" colspan="1">MSC-VO [<xref rid="pone.0330839.ref016" ref-type="bibr">16</xref>]</th><th align="left" colspan="3" rowspan="1">Ours</th></tr><tr><th align="left" rowspan="1" colspan="1">PLP-SLAM</th><th align="left" rowspan="1" colspan="1">PLPM-SLAM</th><th align="left" rowspan="1" colspan="1">Increase (%)</th></tr></thead><tbody><tr><td align="left" rowspan="10" colspan="1">TUM</td><td align="left" rowspan="1" colspan="1">1_desk</td><td align="left" rowspan="1" colspan="1">0.0224</td><td align="left" rowspan="1" colspan="1">0.0271</td><td align="left" rowspan="1" colspan="1">
<italic toggle="yes">&#215;</italic>
</td><td align="left" rowspan="1" colspan="1">0.0220</td><td align="left" rowspan="1" colspan="1">0.0167</td><td align="left" rowspan="1" colspan="1">
<bold>0.0139</bold>
</td><td align="left" rowspan="1" colspan="1">37.95</td></tr><tr><td align="left" rowspan="1" colspan="1">1_floor</td><td align="left" rowspan="1" colspan="1">0.0194</td><td align="left" rowspan="1" colspan="1">0.0351</td><td align="left" rowspan="1" colspan="1">0.0962</td><td align="left" rowspan="1" colspan="1">0.0449</td><td align="left" rowspan="1" colspan="1">0.0135</td><td align="left" rowspan="1" colspan="1">
<bold>0.0114</bold>
</td><td align="left" rowspan="1" colspan="1">41.24</td></tr><tr><td align="left" rowspan="1" colspan="1">1_rpy</td><td align="left" rowspan="1" colspan="1">0.0204</td><td align="left" rowspan="1" colspan="1">0.0176</td><td align="left" rowspan="1" colspan="1">
<italic toggle="yes">&#215;</italic>
</td><td align="left" rowspan="1" colspan="1">0.0244</td><td align="left" rowspan="1" colspan="1">0.0158</td><td align="left" rowspan="1" colspan="1">
<bold>0.0132</bold>
</td><td align="left" rowspan="1" colspan="1">35.29</td></tr><tr><td align="left" rowspan="1" colspan="1">1_xyz</td><td align="left" rowspan="1" colspan="1">0.0114</td><td align="left" rowspan="1" colspan="1">0.0118</td><td align="left" rowspan="1" colspan="1">0.0172</td><td align="left" rowspan="1" colspan="1">0.0131</td><td align="left" rowspan="1" colspan="1">0.0144</td><td align="left" rowspan="1" colspan="1">
<bold>0.0103</bold>
</td><td align="left" rowspan="1" colspan="1">9.65</td></tr><tr><td align="left" rowspan="1" colspan="1">2_desk_with_person</td><td align="left" rowspan="1" colspan="1">0.0229</td><td align="left" rowspan="1" colspan="1">0.0107</td><td align="left" rowspan="1" colspan="1">
<italic toggle="yes">&#215;</italic>
</td><td align="left" rowspan="1" colspan="1">0.0214</td><td align="left" rowspan="1" colspan="1">0.0154</td><td align="left" rowspan="1" colspan="1">
<bold>0.0091</bold>
</td><td align="left" rowspan="1" colspan="1">60.26</td></tr><tr><td align="left" rowspan="1" colspan="1">2_pioneer_slam3</td><td align="left" rowspan="1" colspan="1">0.0290</td><td align="left" rowspan="1" colspan="1">0.0853</td><td align="left" rowspan="1" colspan="1">0.8662</td><td align="left" rowspan="1" colspan="1">
<italic toggle="yes">&#215;</italic>
</td><td align="left" rowspan="1" colspan="1">0.0239</td><td align="left" rowspan="1" colspan="1">
<bold>0.0216</bold>
</td><td align="left" rowspan="1" colspan="1">25.52</td></tr><tr><td align="left" rowspan="1" colspan="1">2_xyz</td><td align="left" rowspan="1" colspan="1">0.0101</td><td align="left" rowspan="1" colspan="1">0.0100</td><td align="left" rowspan="1" colspan="1">0.0086</td><td align="left" rowspan="1" colspan="1">0.0166</td><td align="left" rowspan="1" colspan="1">0.0079</td><td align="left" rowspan="1" colspan="1">
<bold>0.0042</bold>
</td><td align="left" rowspan="1" colspan="1">58.42</td></tr><tr><td align="left" rowspan="1" colspan="1">3_long_office_household</td><td align="left" rowspan="1" colspan="1">0.0139</td><td align="left" rowspan="1" colspan="1">0.0223</td><td align="left" rowspan="1" colspan="1">0.0363</td><td align="left" rowspan="1" colspan="1">0.0172</td><td align="left" rowspan="1" colspan="1">0.0163</td><td align="left" rowspan="1" colspan="1">
<bold>0.0135</bold>
</td><td align="left" rowspan="1" colspan="1">2.88</td></tr><tr><td align="left" rowspan="1" colspan="1">3_structure_texture_far</td><td align="left" rowspan="1" colspan="1">0.0104</td><td align="left" rowspan="1" colspan="1">0.0138</td><td align="left" rowspan="1" colspan="1">0.0142</td><td align="left" rowspan="1" colspan="1">0.0143</td><td align="left" rowspan="1" colspan="1">0.0098</td><td align="left" rowspan="1" colspan="1">
<bold>0.0087</bold>
</td><td align="left" rowspan="1" colspan="1">16.35</td></tr><tr><td align="left" rowspan="1" colspan="1">3_structure_texture_near</td><td align="left" rowspan="1" colspan="1">0.0112</td><td align="left" rowspan="1" colspan="1">0.0120</td><td align="left" rowspan="1" colspan="1">0.0202</td><td align="left" rowspan="1" colspan="1">0.0162</td><td align="left" rowspan="1" colspan="1">0.0107</td><td align="left" rowspan="1" colspan="1">
<bold>0.0097</bold>
</td><td align="left" rowspan="1" colspan="1">13.39</td></tr><tr><td align="left" rowspan="3" colspan="1">ICL</td><td align="left" rowspan="1" colspan="1">living_room_traj1_frei</td><td align="left" rowspan="1" colspan="1">0.0447</td><td align="left" rowspan="1" colspan="1">0.0102</td><td align="left" rowspan="1" colspan="1">0.0123</td><td align="left" rowspan="1" colspan="1">0.0141</td><td align="left" rowspan="1" colspan="1">0.0102</td><td align="left" rowspan="1" colspan="1">
<bold>0.0077</bold>
</td><td align="left" rowspan="1" colspan="1">82.77</td></tr><tr><td align="left" rowspan="1" colspan="1">living_room_traj2_frei</td><td align="left" rowspan="1" colspan="1">0.0160</td><td align="left" rowspan="1" colspan="1">0.0191</td><td align="left" rowspan="1" colspan="1">0.0115</td><td align="left" rowspan="1" colspan="1">0.0146</td><td align="left" rowspan="1" colspan="1">0.0113</td><td align="left" rowspan="1" colspan="1">
<bold>0.0094</bold>
</td><td align="left" rowspan="1" colspan="1">41.25</td></tr><tr><td align="left" rowspan="1" colspan="1">living_room_traj3_frei</td><td align="left" rowspan="1" colspan="1">0.0109</td><td align="left" rowspan="1" colspan="1">0.0154</td><td align="left" rowspan="1" colspan="1">
<bold>0.0061</bold>
</td><td align="left" rowspan="1" colspan="1">0.0397</td><td align="left" rowspan="1" colspan="1">0.0099</td><td align="left" rowspan="1" colspan="1">0.0073</td><td align="left" rowspan="1" colspan="1">33.03</td></tr></tbody></table></alternatives></table-wrap><fig position="float" id="pone.0330839.g017" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g017</object-id><label>Fig 17</label><caption><title>RMSE comparison of different algorithms in the ICL dataset living_room_traj1_frei.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g017.jpg"/></fig><fig position="float" id="pone.0330839.g018" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g018</object-id><label>Fig 18</label><caption><title>RMSE comparison of different algorithms in the ICL dataset living_room_traj2_frei.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g018.jpg"/></fig><fig position="float" id="pone.0330839.g019" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g019</object-id><label>Fig 19</label><caption><title>Trajectory comparison of different algorithms in the ICL dataset living_room_traj1_frei.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g019.jpg"/></fig><fig position="float" id="pone.0330839.g020" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g020</object-id><label>Fig 20</label><caption><title>Trajectory comparison of different algorithms in the ICL dataset living_room_traj2_frei.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g020.jpg"/></fig><p>In the ICL-NUIM dataset, the living room sequences feature relatively small scenes with clear and regular structural characteristics. The main directions of the MF remain consistently stable. Since this scene strictly adheres to the MF, Planar-SLAM demonstrates superior performance compared to other algorithms. Notably, in the living_room_traj3_frei sequence, Planar-SLAM achieves the best results among all tested algorithms. In the living_room_traj1_frei and living_room_traj2_frei sequences, Planar-SLAM also exhibits commendable performance.</p><p>As shown in the table, in the living_room_traj1_frei sequence, where the structural features of the scene are prominent but texture features are not, the RMSE of ORB-SLAM3, which relies on point features, is significantly higher than the RMSE of other algorithms based on structural constraints. Across these three sequences, the RMSE of Manhattan-SLAM is slightly higher than that of Planar-SLAM. PLPM-SLAM, however, demonstrates outstanding performance, achieving the best results in the living_room_traj1_frei and living_room_traj2_frei sequences and the second-best result in the living_room_traj3_frei sequence. Next, we analyze the TUM dataset. The trajectory results for several TUM datasets are presented in <xref rid="pone.0330839.g021" ref-type="fig">Figs 21&#8211;</xref><xref rid="pone.0330839.g024" ref-type="fig">24</xref>, while the RMSE comparisons for these datasets are illustrated in <xref rid="pone.0330839.g025" ref-type="fig">Figs 25</xref>&#8211;<xref rid="pone.0330839.g028" ref-type="fig">28</xref>.</p><fig position="float" id="pone.0330839.g021" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g021</object-id><label>Fig 21</label><caption><title>Trajectory comparison of different algorithms in the TUM dataset 2_desk_with_person.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g021.jpg"/></fig><fig position="float" id="pone.0330839.g022" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g022</object-id><label>Fig 22</label><caption><title>Trajectory comparison of different algorithms in the TUM dataset 2_xyz.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g022.jpg"/></fig><fig position="float" id="pone.0330839.g023" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g023</object-id><label>Fig 23</label><caption><title>Trajectory comparison of different algorithms in the TUM dataset 3_long_office_household.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g023.jpg"/></fig><fig position="float" id="pone.0330839.g024" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g024</object-id><label>Fig 24</label><caption><title>Trajectory comparison of different algorithms in the TUM dataset 3_structure_texture_near.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g024.jpg"/></fig><fig position="float" id="pone.0330839.g025" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g025</object-id><label>Fig 25</label><caption><title>RMSE comparison of different algorithms in the TUM dataset 2_desk_with_person.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g025.jpg"/></fig><fig position="float" id="pone.0330839.g026" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g026</object-id><label>Fig 26</label><caption><title>RMSE comparison of different algorithms s in the TUM dataset 2_xyz.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g026.jpg"/></fig><fig position="float" id="pone.0330839.g027" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g027</object-id><label>Fig 27</label><caption><title>RMSE comparison of different algorithms in the TUM dataset 3_long_office_household.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g027.jpg"/></fig><fig position="float" id="pone.0330839.g028" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g028</object-id><label>Fig 28</label><caption><title>RMSE comparison of different algorithms in the TUM dataset 3_structure_texture_near.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g028.jpg"/></fig><p>Based on the RMSE comparison across the TUM dataset, PLPM-SLAM consistently outperforms all other methods. Whether in structurally rich sequences such as 3_structure_texture_far and 3_structure_texture_near, or in low-texture scenarios like 1_xyz, PLPM-SLAM demonstrates stable and reliable performance, as shown in <xref rid="pone.0330839.t002" ref-type="table">Table 2</xref>. Notably, in the 2_desk_with_person and 2_xyz sequences, PLPM-SLAM reduces RMSE by nearly 60% compared to ORB-SLAM3. For Planar-SLAM, the results indicate weaker performance across most sequences, with the exception of 2_xyz, where it performs relatively well. However, tracking failures are observed in the 1_desk and 1_rpy sequences. In contrast, Manhattan-SLAM shows robust performance in the majority of sequences, except for 2_pioneer_slam3, where its performance slightly declines. Importantly, Manhattan-SLAM does not exhibit tracking loss in any of the evaluated sequences.</p><p>The RMSE of MSC-VO is generally comparable to that of ORB-SLAM3, though slightly higher in most cases, except for 2_desk_with_person and 1_desk, where it achieves marginal improvements. As shown in <xref rid="pone.0330839.t002" ref-type="table">Table 2</xref>, the proposed PLPM-SLAM achieves the best overall performance across the TUM dataset. While its advantage is less pronounced in sequences such as 2_pioneer_slam3 and 3_long_office_household, it demonstrates significant superiority in most other cases.</p><p>In sequences with strong structural and texture features, such as living_room_traj3_frei, structure_texture_far, and structure_texture_near, all methods perform well. In low-structure, high-texture scenes (e.g., 2_pioneer_slam3), PLPM-SLAM and ORB-SLAM3 excel. However, due to chaotic line features in such scenes, MSC-VO, which relies heavily on line features for structural constraints, suffers from tracking loss. In high-structure, low-texture environments, all methods except ORB-SLAM3 maintain strong performance&#8212;for instance, in living_room_traj1_frei. In dynamic environments, feature-point-based systems like ORB-SLAM3 are more vulnerable to dynamic object interference, while line- and plane-feature&#8211;based systems, including PLPM-SLAM, show greater robustness (e.g., in 2_desk_with_person).</p><p><xref rid="pone.0330839.t003" ref-type="table">Table 3</xref> reports the number of frames in which Manhattan Frames (MF) were successfully extracted in the experimental datasets. &#8220;MF&#8221; refers to the classical approach relying on the detection of three mutually orthogonal planes. &#8220;SMF&#8221; denotes the method proposed in this study, where the third orthogonal plane is constructed with the assistance of shared feature points between the current and previous frames when only two orthogonal planes are initially detected.</p><table-wrap position="float" id="pone.0330839.t003" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.t003</object-id><label>Table 3</label><caption><title>Frame counts for MF extraction in the experimental datasets.</title></caption><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.t003g" position="float" orientation="portrait" xlink:href="pone.0330839.t003.jpg"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="2" colspan="1">Type</th><th align="left" rowspan="2" colspan="1">Dataset name</th><th align="left" rowspan="2" colspan="1">Is the structure obvious?</th><th align="left" colspan="3" rowspan="1">Frame count</th></tr><tr><th align="left" rowspan="1" colspan="1">MF</th><th align="left" rowspan="1" colspan="1">SMF</th><th align="left" rowspan="1" colspan="1">Total frame</th></tr></thead><tbody><tr><td align="left" rowspan="10" colspan="1">TUM</td><td align="left" rowspan="1" colspan="1">1_desk</td><td align="left" rowspan="1" colspan="1">Not obvious</td><td align="left" rowspan="1" colspan="1">21</td><td align="left" rowspan="1" colspan="1">63</td><td align="left" rowspan="1" colspan="1">829</td></tr><tr><td align="left" rowspan="1" colspan="1">1_floor</td><td align="left" rowspan="1" colspan="1">Not obvious</td><td align="left" rowspan="1" colspan="1">38</td><td align="left" rowspan="1" colspan="1">221</td><td align="left" rowspan="1" colspan="1">1437</td></tr><tr><td align="left" rowspan="1" colspan="1">1_rpy</td><td align="left" rowspan="1" colspan="1">Not obvious</td><td align="left" rowspan="1" colspan="1">12</td><td align="left" rowspan="1" colspan="1">108</td><td align="left" rowspan="1" colspan="1">977</td></tr><tr><td align="left" rowspan="1" colspan="1">1_xyz</td><td align="left" rowspan="1" colspan="1">Not obvious</td><td align="left" rowspan="1" colspan="1">3</td><td align="left" rowspan="1" colspan="1">122</td><td align="left" rowspan="1" colspan="1">899</td></tr><tr><td align="left" rowspan="1" colspan="1">2_desk_with_person</td><td align="left" rowspan="1" colspan="1">Not obvious</td><td align="left" rowspan="1" colspan="1">67</td><td align="left" rowspan="1" colspan="1">1882</td><td align="left" rowspan="1" colspan="1">4854</td></tr><tr><td align="left" rowspan="1" colspan="1">2_pioneer_slam3</td><td align="left" rowspan="1" colspan="1">Not obvious</td><td align="left" rowspan="1" colspan="1">108</td><td align="left" rowspan="1" colspan="1">212</td><td align="left" rowspan="1" colspan="1">1867</td></tr><tr><td align="left" rowspan="1" colspan="1">2_xyz</td><td align="left" rowspan="1" colspan="1">Not obvious</td><td align="left" rowspan="1" colspan="1">121</td><td align="left" rowspan="1" colspan="1">1706</td><td align="left" rowspan="1" colspan="1">4374</td></tr><tr><td align="left" rowspan="1" colspan="1">3_long_office_household</td><td align="left" rowspan="1" colspan="1">Not obvious</td><td align="left" rowspan="1" colspan="1">54</td><td align="left" rowspan="1" colspan="1">692</td><td align="left" rowspan="1" colspan="1">2507</td></tr><tr><td align="left" rowspan="1" colspan="1">3_structure_texture_far</td><td align="left" rowspan="1" colspan="1">Obvious</td><td align="left" rowspan="1" colspan="1">604</td><td align="left" rowspan="1" colspan="1">810</td><td align="left" rowspan="1" colspan="1">906</td></tr><tr><td align="left" rowspan="1" colspan="1">3_structure_texture_near</td><td align="left" rowspan="1" colspan="1">Obvious</td><td align="left" rowspan="1" colspan="1">572</td><td align="left" rowspan="1" colspan="1">803</td><td align="left" rowspan="1" colspan="1">1044</td></tr><tr><td align="left" rowspan="3" colspan="1">ICL</td><td align="left" rowspan="1" colspan="1">living_room_traj1_frei</td><td align="left" rowspan="1" colspan="1">Obvious</td><td align="left" rowspan="1" colspan="1">681</td><td align="left" rowspan="1" colspan="1">865</td><td align="left" rowspan="1" colspan="1">966</td></tr><tr><td align="left" rowspan="1" colspan="1">living_room_traj2_frei</td><td align="left" rowspan="1" colspan="1">Obvious</td><td align="left" rowspan="1" colspan="1">770</td><td align="left" rowspan="1" colspan="1">832</td><td align="left" rowspan="1" colspan="1">881</td></tr><tr><td align="left" rowspan="1" colspan="1">living_room_traj3_frei</td><td align="left" rowspan="1" colspan="1">Obvious</td><td align="left" rowspan="1" colspan="1">1041</td><td align="left" rowspan="1" colspan="1">1134</td><td align="left" rowspan="1" colspan="1">1241</td></tr></tbody></table></alternatives></table-wrap><p>Given that a greater number of MFs introduces more geometric constraints, the effectiveness of backend optimization can be significantly enhanced. As shown in <xref rid="pone.0330839.t003" ref-type="table">Table 3</xref>, when the scene exhibits strong structural features, both the classical method and the proposed method generate a comparable number of MFs. However, in environments with less obvious structural characteristics, the proposed method detects significantly more MFs than the classical approach. For instance, in the 1_xyz sequence, the desktop computer and the desk are nearly perpendicular. The classical method identifies only two mutually perpendicular MPs, which is insufficient to construct a complete MF. Consequently, it is able to decouple only the rotation matrix, while the translation matrix remains entangled. In contrast, the proposed method leverages shared keypoints across frames to construct a virtual auxiliary plane, enabling the extraction of three orthogonal MPs. This allows for complete MF construction and the decoupling of both the rotation and translation matrices. A similar improvement is observed in the 2_desk_with_person sequence. <xref rid="pone.0330839.g029" ref-type="fig">Figs 29</xref> and <xref rid="pone.0330839.g030" ref-type="fig">30</xref> present box plots of the Absolute Trajectory Error (ATE) for different algorithms on the 1_rpy and living_room_traj1_frei datasets, further illustrating the performance advantage of the proposed method. The 1_rpy sequence contains weak structural cues, whereas living_room_traj1_frei exhibits more distinct structural features. As shown in <xref rid="pone.0330839.g029" ref-type="fig">Figs 29</xref> and <xref rid="pone.0330839.g030" ref-type="fig">30</xref>, PLPM-SLAM consistently achieves the lowest median ATE and the smallest variance across both scenarios, demonstrating superior accuracy and robustness. Manhattan-SLAM ranks second, with a moderate error spread and fewer outliers. In contrast, ORB-SLAM3 yields the poorest performance, characterized by large error fluctuations and numerous outliers, indicating reduced stability under varying conditions.</p><fig position="float" id="pone.0330839.g029" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g029</object-id><label>Fig 29</label><caption><title>Box plot of ATE of 1_rpy for different algorithms.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g029.jpg"/></fig><fig position="float" id="pone.0330839.g030" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g030</object-id><label>Fig 30</label><caption><title>Box plot of ATE of living_room_traj1_frei for different algorithms.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g030.jpg"/></fig><p><xref rid="pone.0330839.g031" ref-type="fig">Fig 31</xref> presents a radar chart comparing the average ATE of each SLAM algorithm across the TUM and ICL datasets. The chart highlights the overall performance of six visual SLAM systems, where smaller values represent better accuracy. On the TUM dataset, PLPM-SLAM significantly outperforms all other methods, followed by PLP-SLAM, demonstrating strong adaptability to dynamic and low-structure environments. Similarly, on the ICL dataset, PLPM-SLAM achieves the lowest average ATE, confirming its robust and consistent performance across a wide range of sequences.</p><fig position="float" id="pone.0330839.g031" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g031</object-id><label>Fig 31</label><caption><title>Average ATE Comparison of SLAM Algorithms on TUM and ICL Datasets.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g031.jpg"/></fig><p>The consistent best performance of PLPM-SLAM in both datasets indicates its strong generalization capability and trajectory accuracy in both structured and unstructured indoor scenes. As shown in the <xref rid="pone.0330839.g032" ref-type="fig">Figs 32</xref> and <xref rid="pone.0330839.g033" ref-type="fig">33</xref> below, compared to the AHC algorithm, the proposed method can extract richer plane features, which provide more constraints during backend nonlinear optimization and offer more MP features.</p><fig position="float" id="pone.0330839.g032" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g032</object-id><label>Fig 32</label><caption><title>Comparison of the number of plane feature extractions between scenarios in structure_texture_far.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g032.jpg"/></fig><fig position="float" id="pone.0330839.g033" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g033</object-id><label>Fig 33</label><caption><title>Comparison of the number of plane feature extractions between scenarios in structure_texture_near.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g033.jpg"/></fig><p><xref rid="pone.0330839.g034" ref-type="fig">Figs 34</xref> and <xref rid="pone.0330839.g035" ref-type="fig">35</xref> present the extracted line features and their classification based on vanishing point estimation. As shown in <xref rid="pone.0330839.g035" ref-type="fig">Fig 35</xref>, the proposed method for vanishing point estimation using orthogonal plane features proves to be effective and reliable. <xref rid="pone.0330839.g036" ref-type="fig">Figs 36</xref> and <xref rid="pone.0330839.g037" ref-type="fig">37</xref> illustrate the orthogonal plane features extracted from the current frame, along with those matched from the historical frames. The image index of the current frame is 230, and the matched historical frame is indexed at 101. This indicates that the pose estimation of the current frame depends solely on the pose accuracy of frame 101, rather than the accumulated accuracy of all intermediate frames. As a result, pose estimation errors between the current and historical frames do not propagate or accumulate, enhancing the system&#8217;s robustness to drift over time.</p><fig position="float" id="pone.0330839.g034" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g034</object-id><label>Fig 34</label><caption><title>Extraction of line features in the structure_texture_far sequence.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g034.jpg"/></fig><fig position="float" id="pone.0330839.g035" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g035</object-id><label>Fig 35</label><caption><title>Classification based on vanishing points in the structure_texture_far sequence.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g035.jpg"/></fig><fig position="float" id="pone.0330839.g036" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g036</object-id><label>Fig 36</label><caption><title>Orthogonal plane features extracted from the current frame in the structure_texture_far sequence.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g036.jpg"/></fig><fig position="float" id="pone.0330839.g037" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g037</object-id><label>Fig 37</label><caption><title>Orthogonal plane features extracted from orthogonal plane features matched in the historical frame in the structure_texture_far sequence.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g037.jpg"/></fig></sec><sec id="sec015"><title>4.2 Verification of Actual Test Scenes Based on Zed2i Camera</title><p>To further evaluate the effectiveness of the proposed model&#8212;based on Manhattan plane feature constraints and point&#8211;plane collaborative optimization&#8212;we constructed a custom experimental platform equipped with a ZED2i RGB-D camera and a 3D LiDAR sensor. The extrinsic parameters between the two sensors were carefully calibrated, as illustrated in <xref rid="pone.0330839.g038" ref-type="fig">Fig 38</xref>. The 3D LiDAR localization results were used as ground truth for evaluation. Using this setup, we conducted experiments in two real-world environments at Changzhou University: the third-floor corridor and the basement-level parking garage of the Ligong Building, as illustrated in <xref rid="pone.0330839.g039" ref-type="fig">Figs 39</xref> and <xref rid="pone.0330839.g040" ref-type="fig">40</xref>.</p><fig position="float" id="pone.0330839.g038" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g038</object-id><label>Fig 38</label><caption><title>ZED2i camera-based test equipment.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g038.jpg"/></fig><fig position="float" id="pone.0330839.g039" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g039</object-id><label>Fig 39</label><caption><title>Scene of long corridor scene.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g039.jpg"/></fig><fig position="float" id="pone.0330839.g040" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g040</object-id><label>Fig 40</label><caption><title>Scene of underground parking scene.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g040.jpg"/></fig><list list-type="order"><list-item><p>Dataset s 1-1, 1-2, and 1-3 were collected in the long corridor on the third floor of Ligong Building at Changzhou University.</p></list-item><list-item><p>Dataset s 2-1, 2-2, and 2-3 were collected in the basement level one parking garage of Ligong Building at Changzhou University.</p></list-item></list><p><xref rid="pone.0330839.g041" ref-type="fig">Figs 41&#8211;</xref><xref rid="pone.0330839.g043" ref-type="fig">43</xref> show the trajectory comparisons, and <xref rid="pone.0330839.g044" ref-type="fig">Figs 44&#8211;</xref><xref rid="pone.0330839.g046" ref-type="fig">46</xref> show the corresponding RMSE results, for selected cases in the long corridor and underground garage scenes. The detailed comparison results are shown in <xref rid="pone.0330839.t004" ref-type="table">Table 4</xref>.</p><table-wrap position="float" id="pone.0330839.t004" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.t004</object-id><label>Table 4</label><caption><title>Evaluation results of translation ATE RMSE (unit: m) on long corridor scene and the underground garage scene. Bold numbers represent the best performances.</title></caption><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="pone.0330839.t004g" position="float" orientation="portrait" xlink:href="pone.0330839.t004.jpg"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Type</th><th align="left" rowspan="1" colspan="1">Dataset</th><th align="left" rowspan="1" colspan="1">Distance (m)</th><th align="left" rowspan="1" colspan="1">ORB-SLAM3</th><th align="left" rowspan="1" colspan="1">Manhattan-SLAM</th><th align="left" rowspan="1" colspan="1">Planar-SLAM</th><th align="left" rowspan="1" colspan="1">MSC-VO</th><th align="left" rowspan="1" colspan="1">PLP-SLAM</th><th align="left" rowspan="1" colspan="1">PLPM-SLAM</th><th align="left" rowspan="1" colspan="1">Increase (%)</th></tr></thead><tbody><tr><td align="left" rowspan="3" colspan="1">Scene 1 (Long corridor)</td><td align="left" rowspan="1" colspan="1">Data_1-1</td><td align="left" rowspan="1" colspan="1">26.5</td><td align="left" rowspan="1" colspan="1">0.1150</td><td align="left" rowspan="1" colspan="1">0.2801</td><td align="left" rowspan="1" colspan="1">5.5996</td><td align="left" rowspan="1" colspan="1">0.3951</td><td align="left" rowspan="1" colspan="1">0.0956</td><td align="left" rowspan="1" colspan="1">
<bold>0.0693</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>39.74</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Data_1-2</td><td align="left" rowspan="1" colspan="1">26.9</td><td align="left" rowspan="1" colspan="1">0.5886</td><td align="left" rowspan="1" colspan="1">0.8636</td><td align="left" rowspan="1" colspan="1">2.6594</td><td align="left" rowspan="1" colspan="1">0.4974</td><td align="left" rowspan="1" colspan="1">0.4438</td><td align="left" rowspan="1" colspan="1">
<bold>0.4032</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>31.50</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Data_1-3</td><td align="left" rowspan="1" colspan="1">46.4</td><td align="left" rowspan="1" colspan="1">1.4650</td><td align="left" rowspan="1" colspan="1">10.6689</td><td align="left" rowspan="1" colspan="1">11.2587</td><td align="left" rowspan="1" colspan="1">4.2955</td><td align="left" rowspan="1" colspan="1">0.3012</td><td align="left" rowspan="1" colspan="1">
<bold>0.1148</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>92.16</bold>
</td></tr><tr><td align="left" rowspan="3" colspan="1">Scene 2 (Underground parking lot)</td><td align="left" rowspan="1" colspan="1">Data_2-1</td><td align="left" rowspan="1" colspan="1">61.1</td><td align="left" rowspan="1" colspan="1">1.6295</td><td align="left" rowspan="1" colspan="1">2.4229</td><td align="left" rowspan="1" colspan="1">7.2819</td><td align="left" rowspan="1" colspan="1">2.5906</td><td align="left" rowspan="1" colspan="1">1.4457</td><td align="left" rowspan="1" colspan="1">
<bold>1.2209</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>25.08</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Data_2-2</td><td align="left" rowspan="1" colspan="1">54.8</td><td align="left" rowspan="1" colspan="1">1.4802</td><td align="left" rowspan="1" colspan="1">2.2011</td><td align="left" rowspan="1" colspan="1">7.0624</td><td align="left" rowspan="1" colspan="1">1.2348</td><td align="left" rowspan="1" colspan="1">1.3346</td><td align="left" rowspan="1" colspan="1">
<bold>1.1246</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>24.02</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Data_2-3</td><td align="left" rowspan="1" colspan="1">240.2</td><td align="left" rowspan="1" colspan="1">7.3907</td><td align="left" rowspan="1" colspan="1">13.6787</td><td align="left" rowspan="1" colspan="1">
<italic toggle="yes">&#215;</italic>
</td><td align="left" rowspan="1" colspan="1">4.8358</td><td align="left" rowspan="1" colspan="1">3.6521</td><td align="left" rowspan="1" colspan="1">
<bold>2.3096</bold>
</td><td align="left" rowspan="1" colspan="1">
<bold>68.75</bold>
</td></tr></tbody></table></alternatives></table-wrap><fig position="float" id="pone.0330839.g041" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g041</object-id><label>Fig 41</label><caption><title>Trajectory comparison of Data_1-1 based on the actual scene measured by ZED2i camera.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g041.jpg"/></fig><fig position="float" id="pone.0330839.g042" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g042</object-id><label>Fig 42</label><caption><title>Trajectory comparison of Data_2-2 based on the actual scene measured by ZED2i camera.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g042.jpg"/></fig><fig position="float" id="pone.0330839.g043" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g043</object-id><label>Fig 43</label><caption><title>Trajectory comparison of Data_2-3 based on the actual scene measured by ZED2i camera.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g043.jpg"/></fig><fig position="float" id="pone.0330839.g044" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g044</object-id><label>Fig 44</label><caption><title>RMSE comparison of Data_1-1 based on the actual scene measured by ZED2i camera.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g044.jpg"/></fig><fig position="float" id="pone.0330839.g045" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g045</object-id><label>Fig 45</label><caption><title>RMSE comparison of Data_2-2 based on the actual scene measured by ZED2i camera.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g045.jpg"/></fig><fig position="float" id="pone.0330839.g046" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g046</object-id><label>Fig 46</label><caption><title>RMSE comparison of Data_2-3 based on the actual scene measured by ZED2i camera.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g046.jpg"/></fig><p>From the comparison in the <xref rid="pone.0330839.t004" ref-type="table">Table 4</xref>, it can be observed that among the various methods compared, Planar-SLAM performs the worst in terms of both performance and stability in real-world scenarios, regardless of long corridor or underground parking lot, because it cannot be applied to non-MF environments. When the duration and distance of the scene are short, ORB-SLAM3 can maintain relatively stable accuracy. However, as the distance and time increase, the accuracy of ORB-SLAM3 gradually decreases due to error accumulation.</p><p>MSC-VO primarily relies on line features for MF extraction. Overall, it exhibits relatively stable performance, particularly in the Data_1&#8211;2 and Data_2&#8211;2 sequences. However, in Data_2&#8211;1, which includes dynamic elements in certain frames, the performance of all compared methods&#8212;except for the proposed algorithm&#8212;deteriorates, even though the sequence length in Data_2&#8211;2 is comparatively shorter. While MSC-VO, Manhattan-SLAM, and the proposed method are all capable of handling both structured and unstructured environments, MSC-VO is limited to scenes containing a single dominant MF. In cases where multiple dominant directions exist, the structural constraint module in MSC-VO becomes ineffective. For example, in Data_1&#8211;1 and Data_1&#8211;2, since the dominant MF direction remains consistent, MSC-VO performs relatively well. However, Manhattan-SLAM, due to the absence of a Local Bundle Adjustment (BA) module, suffers from higher RMSE in larger-scale scenes&#8212;particularly in frames with sparse orthogonal plane feature observations. In the three datasets from Scene 2, representing an underground parking garage, the proposed algorithm achieves the best performance, though RMSE still exceeds 1 meter. Scene 2 is characterized by dim lighting, irregular structural geometry, and numerous parked vehicles, which contribute to disorganized and fragmented line features. While some planes are detected, few satisfy orthogonality constraints, complicating accurate MF extraction.</p><p>Both Manhattan-SLAM and Planar-SLAM utilize point cloud clustering to extract plane features and employ angular and distance constraints between plane normals for matching. However, these methods struggle in irregular environments where reliable and consistent plane features cannot be extracted&#8212;especially across widely separated frames. In such cases, error accumulation makes these coarse constraints insufficient for accurate plane association. To mitigate this, the proposed algorithm augments point cloud clustering with coplanar line features to construct additional plane hypotheses, thereby introducing more geometric constraints into the backend optimization. While Manhattan-SLAM typically fails under such irregular conditions, the proposed model maintains stable performance. By comparing results from public datasets with those from real-world experiments described in this section, it becomes evident that Manhattan-SLAM and Planar-SLAM are highly dependent on scene-specific structural characteristics. Planar-SLAM, in particular, performs well in environments with strong planar geometry (e.g., living_room_traj1_frei) but exhibits reduced robustness under more diverse real-world conditions. In contrast, ORB-SLAM3 and MSC-VO, although not always achieving the best accuracy, maintain relatively stable performance with minimal error fluctuations and no observed tracking failures.</p><p>In summary, PLPM-SLAM consistently achieves the highest accuracy and robustness across both benchmark and real-world datasets, with especially pronounced advantages in real-world experimental scenarios. The number of plane features extracted by the AHC model and the proposed algorithm is compared in <xref rid="pone.0330839.g047" ref-type="fig">Figs 47</xref>&#8211;<xref rid="pone.0330839.g048" ref-type="fig">48</xref> for Scene 1 and in <xref rid="pone.0330839.g049" ref-type="fig">Figs 49</xref>&#8211;<xref rid="pone.0330839.g050" ref-type="fig">50</xref> for Scene 2. It is evident that the proposed method extracts a significantly larger number of plane features, particularly in complex regions such as corners (highlighted areas). Compared with the AHC model, the proposed approach provides more abundant planar constraints, thereby enhancing backend pose optimization. By analyzing <xref rid="pone.0330839.g047" ref-type="fig">Figs 47</xref>&#8211;<xref rid="pone.0330839.g050" ref-type="fig">50</xref>, it is also observed that both the AHC model and the proposed method extract more plane features in long corridors (Scene 1) than in underground parking lots (Scene 2), due to better-defined structural regularities in corridor environments.</p><fig position="float" id="pone.0330839.g047" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g047</object-id><label>Fig 47</label><caption><title>Comparison of the number of extracted plane features in scenes Data_1-1.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g047.jpg"/></fig><fig position="float" id="pone.0330839.g048" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g048</object-id><label>Fig 48</label><caption><title>Comparison of the number of extracted plane features in scenes Data_1-2.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g048.jpg"/></fig><fig position="float" id="pone.0330839.g049" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g049</object-id><label>Fig 49</label><caption><title>Comparison of the number of extracted plane features in scenes Data_2-1.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g049.jpg"/></fig><fig position="float" id="pone.0330839.g050" orientation="portrait"><object-id pub-id-type="doi">10.1371/journal.pone.0330839.g050</object-id><label>Fig 50</label><caption><title>Comparison of the number of extracted plane features in scenes Data_2-2.</title></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="pone.0330839.g050.jpg"/></fig></sec></sec><sec sec-type="conclusions" id="sec016"><title>5 Conclusion</title><p>This paper introduces PLPM-SLAM, an RGB-D SLAM system that integrates virtual-plane&#8211;assisted MF constraints with point-line-plane joint optimization to mitigate localization degradation and global drift in complex indoor environments. By incorporating both homogeneous and heterogeneous geometric relationships, the proposed system significantly enhances tracking robustness and pose estimation accuracy. Extensive evaluations on public benchmark datasets (TUM, ICL-NUIM) and real-world indoor scenes captured using a ZED2i RGB-D camera demonstrate that PLPM-SLAM consistently outperforms baseline methods, particularly in environments characterized by structural regularity or low texture.</p><p>Nevertheless, in highly cluttered or weakly structured scenes, the system&#8217;s performance may be constrained by limited plane feature availability. Future research will focus on leveraging deep learning&#8211;based structural plane detection and robust feature matching strategies to improve adaptability and accuracy in such challenging environments.</p></sec></body><back><ref-list><title>References</title><ref id="pone.0330839.ref001"><label>1</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Usenko</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Demmel</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Schubert</surname><given-names>D</given-names></name>, <name name-style="western"><surname>St&#252;ckler</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Cremers</surname><given-names>D</given-names></name>. <article-title>Visual-inertial mapping with non-linear factor recovery</article-title>. <source>IEEE Robotics and Automation Letters</source>. <year>2020</year>;<volume>5</volume>(<issue>2</issue>):<fpage>422</fpage>&#8211;<lpage>9</lpage>.</mixed-citation></ref><ref id="pone.0330839.ref002"><label>2</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Liu</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Liang</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Zhao</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Jiang</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Jin</surname><given-names>Y</given-names></name>. <article-title>Design of a Virtual Multi-Interaction Operation System for Hand&#8211;Eye Coordination of Grape Harvesting Robots</article-title>. <source>Agronomy</source>. <year>2023</year>;<volume>13</volume>(<issue>3</issue>):<fpage>829</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3390/agronomy13030829</pub-id></mixed-citation></ref><ref id="pone.0330839.ref003"><label>3</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Mur-Artal</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Tardos</surname><given-names>JD</given-names></name>. <article-title>ORB-SLAM2: An Open-Source SLAM System for Monocular, Stereo, and RGB-D Cameras</article-title>. <source>IEEE Trans Robot</source>. <year>2017</year>;<volume>33</volume>(<issue>5</issue>):<fpage>1255</fpage>&#8211;<lpage>62</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/tro.2017.2705103</pub-id></mixed-citation></ref><ref id="pone.0330839.ref004"><label>4</label><mixed-citation publication-type="confproc"><name name-style="western"><surname>Liu</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Zhou</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>H</given-names></name>. <article-title>A hierarchical framework for coordinating large-scale robot networks.</article-title> In: <conf-name>2019 International Conference on Robotics and Automation (ICRA)</conf-name>. <year>2019</year>; p. <fpage>6672</fpage>&#8211;<lpage>7</lpage>.</mixed-citation></ref><ref id="pone.0330839.ref005"><label>5</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Gomez-Ojeda</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Moreno</surname><given-names>F-A</given-names></name>, <name name-style="western"><surname>Zuniga-Noel</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Scaramuzza</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Gonzalez-Jimenez</surname><given-names>J</given-names></name>. <article-title>PL-SLAM: A Stereo SLAM System Through the Combination of Points and Line Segments</article-title>. <source>IEEE Trans Robot</source>. <year>2019</year>;<volume>35</volume>(<issue>3</issue>):<fpage>734</fpage>&#8211;<lpage>46</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/tro.2019.2899783</pub-id></mixed-citation></ref><ref id="pone.0330839.ref006"><label>6</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Wang</surname><given-names>Q</given-names></name>, <name name-style="western"><surname>Yan</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Xue</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Ma</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Zha</surname><given-names>H</given-names></name>. <article-title>Line Flow Based Simultaneous Localization and Mapping</article-title>. <source>IEEE Trans Robot</source>. <year>2021</year>;<volume>37</volume>(<issue>5</issue>):<fpage>1416</fpage>&#8211;<lpage>32</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/tro.2021.3061403</pub-id></mixed-citation></ref><ref id="pone.0330839.ref007"><label>7</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Yang</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Scherer</surname><given-names>S</given-names></name>. <article-title>Monocular Object and Plane SLAM in Structured Environments</article-title>. <source>IEEE Robot Autom Lett</source>. <year>2019</year>;<volume>4</volume>(<issue>4</issue>):<fpage>3145</fpage>&#8211;<lpage>52</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/lra.2019.2924848</pub-id></mixed-citation></ref><ref id="pone.0330839.ref008"><label>8</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Guo</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Peng</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Fan</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Zhai</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>Y</given-names></name>. <article-title>RGB-D SLAM Using Point-Plane Constraints for Indoor Environments</article-title>. <source>Sensors (Basel)</source>. <year>2019</year>;<volume>19</volume>(<issue>12</issue>):<fpage>2721</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3390/s19122721</pub-id><pub-id pub-id-type="pmid">31213001</pub-id><pub-id pub-id-type="pmcid">PMC6630892</pub-id></mixed-citation></ref><ref id="pone.0330839.ref009"><label>9</label><mixed-citation publication-type="confproc"><name name-style="western"><surname>Li</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Yao</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Bazin</surname><given-names>JC</given-names></name>, <name name-style="western"><surname>Lu</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Xing</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>K</given-names></name>. <conf-name>A</conf-name><article-title> monocular SLAM system leveraging structural regularity in Manhattan world.</article-title> In: <conf-name>Proceedings of the IEEE International Conference on Robotics and Automation.</conf-name><year>2018</year>, p. <fpage>2518</fpage>&#8211;<lpage>25</lpage>.</mixed-citation></ref><ref id="pone.0330839.ref010"><label>10</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Ma</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Yang</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Qi</surname><given-names>J</given-names></name>. <article-title>Research on SLAM Localization Algorithm for Orchard Dynamic Vision Based on YOLOD-SLAM2</article-title>. <source>Agriculture</source>. <year>2024</year>;<volume>14</volume>(<issue>9</issue>):<fpage>1622</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3390/agriculture14091622</pub-id></mixed-citation></ref><ref id="pone.0330839.ref011"><label>11</label><mixed-citation publication-type="confproc"><name name-style="western"><surname>Gao</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Yuille</surname><given-names>AL</given-names></name>. <article-title>Exploiting Symmetry and/or Manhattan Properties for 3D Object Structure Estimation from Single and Multiple Images.</article-title> In: <conf-name>2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</conf-name>. <year>2017</year>, p. <fpage>6718</fpage>&#8211;<lpage>27</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/cvpr.2017.711</pub-id></mixed-citation></ref><ref id="pone.0330839.ref012"><label>12</label><mixed-citation publication-type="confproc"><name name-style="western"><surname>Li</surname><given-names>H</given-names></name>, <etal>et al</etal>. <article-title>Learning icosahedral spherical probability map based on Bingham mixture model for vanishing point estimation.</article-title> In: <conf-name>Proc. IEEE Int. Conf. Comput. Vis</conf-name>. <year>2021</year>, p. <fpage>5641</fpage>&#8211;<lpage>50</lpage>.</mixed-citation></ref><ref id="pone.0330839.ref013"><label>13</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Zhou</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Gao</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Xu</surname><given-names>J</given-names></name>. <article-title>Tracking by Detection: Robust Indoor RGB-D Odometry Leveraging Key Local Manhattan World</article-title>. <source>IEEE Robot Autom Lett</source>. <year>2024</year>.</mixed-citation></ref><ref id="pone.0330839.ref014"><label>14</label><mixed-citation publication-type="confproc"><name name-style="western"><surname>Flint</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Murray</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Reid</surname><given-names>I</given-names></name>. <article-title>Manhattan scene understanding using monocular stereo and 3D features.</article-title> In: <conf-name>Proceedings of the IEEE International Conference on Computer Vision</conf-name>. <year>2011</year>, p. <fpage>2228</fpage>&#8211;<lpage>35</lpage>.</mixed-citation></ref><ref id="pone.0330839.ref015"><label>15</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Campos</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Elvira</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Rodriguez</surname><given-names>JJG</given-names></name>, <name name-style="western"><surname>Montiel</surname><given-names>JMM</given-names></name>, <name name-style="western"><surname>Tardos</surname><given-names>JD</given-names></name>. <article-title>ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual&#8211;Inertial, and Multimap SLAM</article-title>. <source>IEEE Trans Robot</source>. <year>2021</year>;<volume>37</volume>(<issue>6</issue>):<fpage>1874</fpage>&#8211;<lpage>90</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/tro.2021.3075644</pub-id></mixed-citation></ref><ref id="pone.0330839.ref016"><label>16</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Company-Corcoles</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Garcia-Fidalgo</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Ortiz</surname><given-names>A</given-names></name>. <article-title>MSC-VO: Exploiting Manhattan and Structural Constraints for Visual Odometry</article-title>. <source>IEEE Robot Autom Lett</source>. <year>2022</year>;<volume>7</volume>(<issue>2</issue>):<fpage>2803</fpage>&#8211;<lpage>10</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/lra.2022.3142900</pub-id></mixed-citation></ref><ref id="pone.0330839.ref017"><label>17</label><mixed-citation publication-type="confproc"><name name-style="western"><surname>Li</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Yunus</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Brasch</surname><given-names>N</given-names></name>. <article-title>RGB-D SLAM with structural regularities.</article-title> In: <conf-name>2021 IEEE International Conference on Robotics and Automation (ICRA)</conf-name>. <publisher-name>IEEE</publisher-name>; <year>2021</year>, p. <fpage>11581</fpage>&#8211;<lpage>7</lpage>.</mixed-citation></ref><ref id="pone.0330839.ref018"><label>18</label><mixed-citation publication-type="confproc"><name name-style="western"><surname>Yunus</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Tombari</surname><given-names>F</given-names></name>. <article-title>Manhattan-slam: Robust planar tracking and mapping leveraging mixture of manhattan frames</article-title>. <conf-name>2021 IEEE International Conference on Robotics and Automation (ICRA)</conf-name>. <publisher-name>IEEE</publisher-name>; <year>2021</year>, p. <fpage>6687</fpage>&#8211;<lpage>93</lpage>.</mixed-citation></ref><ref id="pone.0330839.ref019"><label>19</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Zhao</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Sun</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Zhang</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Xiong</surname><given-names>Y</given-names></name>. <article-title>Visual SLAM Combining Lines and Structural Regularities: Towards Robust Localization</article-title>. <source>IEEE Trans Intell Veh</source>. <year>2024</year>;<volume>9</volume>(<issue>6</issue>):<fpage>5047</fpage>&#8211;<lpage>64</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/tiv.2023.3311511</pub-id></mixed-citation></ref><ref id="pone.0330839.ref020"><label>20</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Zhang</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Yang</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Ma</surname><given-names>J</given-names></name>. <article-title>Monocular visual-inertial odometry leveraging point-line features with structural constraints</article-title>. <source>Vis Comput</source>. <year>2023</year>;<volume>40</volume>(<issue>2</issue>):<fpage>647</fpage>&#8211;<lpage>61</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s00371-023-02807-z</pub-id></mixed-citation></ref><ref id="pone.0330839.ref021"><label>21</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Jiang</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Qian</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Du</surname><given-names>L</given-names></name>, <etal>et al</etal>. <article-title>UL-SLAM: A universal monocular line-based slam via unifying structural and non-structural constraints</article-title>. <source>IEEE Trans Autom Sci Eng</source>. <year>2024</year>.</mixed-citation></ref><ref id="pone.0330839.ref022"><label>22</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Lim</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Jeon</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Myung</surname><given-names>H</given-names></name>. <article-title>UV-SLAM: Unconstrained Line-Based SLAM Using Vanishing Points for Structural Mapping</article-title>. <source>IEEE Robot Autom Lett</source>. <year>2022</year>;<volume>7</volume>(<issue>2</issue>):<fpage>1518</fpage>&#8211;<lpage>25</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/lra.2022.3140816</pub-id></mixed-citation></ref><ref id="pone.0330839.ref023"><label>23</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Chen</surname><given-names>Q</given-names></name>, <name name-style="western"><surname>Cao</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Hou</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Qiu</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>B</given-names></name>, <etal>et al</etal>. <article-title>VPL-SLAM: A Vertical Line Supported Point Line Monocular SLAM System</article-title>. <source>IEEE Trans Intell Transport Syst</source>. <year>2024</year>;<volume>25</volume>(<issue>8</issue>):<fpage>9749</fpage>&#8211;<lpage>61</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/tits.2024.3369168</pub-id></mixed-citation></ref><ref id="pone.0330839.ref024"><label>24</label><mixed-citation publication-type="confproc"><name name-style="western"><surname>Li</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Zhao</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Bazin</surname><given-names>J-C</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>Y-H</given-names></name>. <article-title>Line-based absolute and relative camera pose estimation in structured environments.</article-title> In: <conf-name>Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems</conf-name>. <year>2019</year>, p. <fpage>6914</fpage>&#8211;<lpage>20</lpage>.</mixed-citation></ref><ref id="pone.0330839.ref025"><label>25</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Xu</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Yin</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Shi</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Jiang</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Huang</surname><given-names>B</given-names></name>. <article-title>EPLF-VINS: Real-Time Monocular Visual-Inertial SLAM With Efficient Point-Line Flow Features</article-title>. <source>IEEE Robot Autom Lett</source>. <year>2023</year>;<volume>8</volume>(<issue>2</issue>):<fpage>752</fpage>&#8211;<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/lra.2022.3231983</pub-id></mixed-citation></ref><ref id="pone.0330839.ref026"><label>26</label><mixed-citation publication-type="confproc"><name name-style="western"><surname>Kim</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Coltin</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Kim</surname><given-names>HJ</given-names></name>. <article-title>Low-drift visual odometry in structured environments by decoupling rotational and translational motion.</article-title> In: <conf-name>2018 IEEE International Conference on Robotics and Automation (ICRA)</conf-name>. <publisher-name>IEEE</publisher-name>; <year>2018</year>, p. <fpage>7247</fpage>&#8211;<lpage>53</lpage>.</mixed-citation></ref><ref id="pone.0330839.ref027"><label>27</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Straub</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Freifeld</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Rosman</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Leonard</surname><given-names>JJ</given-names></name>, <name name-style="western"><surname>Fisher</surname><given-names>JW</given-names></name>. <article-title>The Manhattan Frame Model-Manhattan World Inference in the Space of Surface Normals</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source>. <year>2018</year>;<volume>40</volume>(<issue>1</issue>):<fpage>235</fpage>&#8211;<lpage>49</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TPAMI.2017.2662686</pub-id><pub-id pub-id-type="pmid">28166490</pub-id></mixed-citation></ref><ref id="pone.0330839.ref028"><label>28</label><mixed-citation publication-type="confproc"><name name-style="western"><surname>Chen</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Xie</surname><given-names>W</given-names></name>. <conf-name>Vip-slam: An efficient tightly-coupled RGB-D visual inertial planar slam</conf-name>. In: <conf-name>2022 International Conference on Robotics and Automation (ICRA)</conf-name>. <publisher-name>IEEE</publisher-name>; <year>2022</year>, p. <fpage>5615</fpage>&#8211;<lpage>21</lpage>.</mixed-citation></ref><ref id="pone.0330839.ref029"><label>29</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Hu</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Wu</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Zhao</surname><given-names>M</given-names></name>. <article-title>PAS-SLAM: A Visual SLAM System for Planar-Ambiguous Scenes</article-title>. <source>IEEE Trans Circuits Syst Video Technol</source>. <year>2024</year>.</mixed-citation></ref><ref id="pone.0330839.ref030"><label>30</label><mixed-citation publication-type="confproc"><name name-style="western"><surname>Shu</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Pagani</surname><given-names>A</given-names></name>. <article-title>Structure PLP-SLAM: Efficient sparse mapping and localization using point, line and plane for monocular, RGB-D and stereo cameras.</article-title> In: <conf-name>2023 IEEE International Conference on Robotics and Automation (ICRA)</conf-name>. <publisher-name>IEEE</publisher-name>; <year>2023</year>, p. <fpage>2105</fpage>&#8211;<lpage>12</lpage>.</mixed-citation></ref><ref id="pone.0330839.ref031"><label>31</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Zhang</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Qi</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Liao</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Wei</surname><given-names>R</given-names></name>. <article-title>Point-Plane SLAM Using Supposed Planes for Indoor Environments</article-title>. <source>Sensors (Basel)</source>. <year>2019</year>;<volume>19</volume>(<issue>17</issue>):<fpage>3795</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3390/s19173795</pub-id><pub-id pub-id-type="pmid">31480722</pub-id><pub-id pub-id-type="pmcid">PMC6749271</pub-id></mixed-citation></ref><ref id="pone.0330839.ref032"><label>32</label><mixed-citation publication-type="confproc"><name name-style="western"><surname>Li</surname><given-names>X</given-names></name>, <name name-style="western"><surname>He</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Lin</surname><given-names>J</given-names></name>. <article-title>Leveraging planar regularities for point line visual-inertial odometry.</article-title> In: <conf-name>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</conf-name>. <publisher-name>IEEE</publisher-name>; <year>2020</year>, p. <fpage>5120</fpage>&#8211;<lpage>7</lpage>.</mixed-citation></ref><ref id="pone.0330839.ref033"><label>33</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Li</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Brasch</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Navab</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Tombari</surname><given-names>F</given-names></name>. <article-title>Structure-SLAM: Low-Drift Monocular SLAM in Indoor Environments</article-title>. <source>IEEE Robot Autom Lett</source>. <year>2020</year>;<volume>5</volume>(<issue>4</issue>):<fpage>6583</fpage>&#8211;<lpage>90</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/lra.2020.3015456</pub-id></mixed-citation></ref><ref id="pone.0330839.ref034"><label>34</label><mixed-citation publication-type="confproc"><name name-style="western"><surname>Dong</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Lu</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>C</given-names></name>, <etal>et al</etal>. <article-title>STL-SLAM: A Structured-Constrained RGB-D SLAM Approach to Texture-Limited Environments</article-title>. <conf-name>2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</conf-name>. <publisher-name>IEEE</publisher-name>; <year>2024</year>, p. <fpage>10850</fpage>&#8211;<lpage>5</lpage>.</mixed-citation></ref><ref id="pone.0330839.ref035"><label>35</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Yang</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Yuan</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Gao</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Sun</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Zhang</surname><given-names>X</given-names></name>. <article-title>UPLP-SLAM: Unified point-line-plane feature fusion for RGB-D visual SLAM</article-title>. <source>Information Fusion</source>. <year>2023</year>;<volume>96</volume>:<fpage>51</fpage>&#8211;<lpage>65</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.inffus.2023.03.006</pub-id></mixed-citation></ref><ref id="pone.0330839.ref036"><label>36</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Li</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Zhao</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Bazin</surname><given-names>J-C</given-names></name>, <name name-style="western"><surname>Kim</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Joo</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Zhao</surname><given-names>Z</given-names></name>, <etal>et al</etal>. <article-title>Hong Kong World: Leveraging Structural Regularity for Line-Based SLAM</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source>. <year>2023</year>;<volume>45</volume>(<issue>11</issue>):<fpage>13035</fpage>&#8211;<lpage>53</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TPAMI.2023.3276204</pub-id><pub-id pub-id-type="pmid">37186524</pub-id></mixed-citation></ref><ref id="pone.0330839.ref037"><label>37</label><mixed-citation publication-type="confproc"><name name-style="western"><surname>Li</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Xing</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Zhao</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Bazin</surname><given-names>JC</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>YH</given-names></name>. <article-title>Leveraging structural regularity of Atlanta world for monocular SLAM.</article-title> In: <conf-name>Proceedings of the IEEE International Conference on Robotics and Automation.</conf-name><year>2019</year>, p. <fpage>2412</fpage>&#8211;<lpage>8</lpage>.</mixed-citation></ref><ref id="pone.0330839.ref038"><label>38</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Zou</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Wu</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Pei</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Ling</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Yu</surname><given-names>W</given-names></name>. <article-title>StructVIO: Visual-Inertial Odometry With Structural Regularity of Man-Made Environments</article-title>. <source>IEEE Trans Robot</source>. <year>2019</year>;<volume>35</volume>(<issue>4</issue>):<fpage>999</fpage>&#8211;<lpage>1013</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/tro.2019.2915140</pub-id></mixed-citation></ref><ref id="pone.0330839.ref039"><label>39</label><mixed-citation publication-type="journal"><name name-style="western"><surname>Li</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Zhao</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Bazin</surname><given-names>J-C</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>Y-H</given-names></name>. <article-title>Quasi-Globally Optimal and Near/True Real-Time Vanishing Point Estimation in Manhattan World</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source>. <year>2022</year>;<volume>44</volume>(<issue>3</issue>):<fpage>1503</fpage>&#8211;<lpage>18</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TPAMI.2020.3023183</pub-id><pub-id pub-id-type="pmid">32915727</pub-id></mixed-citation></ref><ref id="pone.0330839.ref040"><label>40</label><mixed-citation publication-type="confproc"><name name-style="western"><surname>Holz</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Holzer</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Rusu RB o g d a</surname><given-names>n</given-names></name>, <name name-style="western"><surname>Behnke</surname><given-names>S</given-names></name>. <article-title>Real-time plane segmentation using RGB-D cameras.</article-title> In: <conf-name>Robot Soccer World Cup</conf-name>. <year>2011</year>, p. <fpage>306</fpage>&#8211;<lpage>17</lpage>.</mixed-citation></ref><ref id="pone.0330839.ref041"><label>41</label><mixed-citation publication-type="confproc"><name name-style="western"><surname>Feng</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Taguchi</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Kamat</surname><given-names>VR</given-names></name>. <article-title>Fast plane extraction in organized point clouds using agglomerative hierarchical clustering</article-title>. <conf-name>2014 IEEE International Conference on Robotics and Automation (ICRA)</conf-name>. <publisher-name>IEEE</publisher-name>, <year>2014</year>, p. <fpage>6218</fpage>&#8211;<lpage>25</lpage>.</mixed-citation></ref><ref id="pone.0330839.ref042"><label>42</label><mixed-citation publication-type="confproc"><name name-style="western"><surname>Zhang</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Qi</surname><given-names>X</given-names></name>, <etal>et al</etal>. <article-title>Stereo Plane SLAM Based on Intersecting Lines</article-title>. <conf-name>2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</conf-name>. <publisher-loc>Prague, Czech Republic</publisher-loc>: <publisher-name>IEEE</publisher-name>; <year>2021</year>, p. <fpage>6566</fpage>&#8211;<lpage>72</lpage>.</mixed-citation></ref><ref id="pone.0330839.ref043"><label>43</label><mixed-citation publication-type="confproc"><name name-style="western"><surname>Gomez-Ojeda</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Briales</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Gonzalez-Jimenez</surname><given-names>J</given-names></name>. <conf-name>PL-SVO: Semi-direct monocular visual odometry by combining points and line segments</conf-name>. In: <conf-name>2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</conf-name>. <publisher-name>IEEE</publisher-name>; <year>2016</year>, p. <fpage>4211</fpage>&#8211;<lpage>6</lpage>.</mixed-citation></ref></ref-list></back></article></pmc-articleset>