<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" article-type="research-article" xml:lang="en" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Nat Commun</journal-id><journal-id journal-id-type="iso-abbrev">Nat Commun</journal-id><journal-id journal-id-type="pmc-domain-id">2873</journal-id><journal-id journal-id-type="pmc-domain">ncomms</journal-id><journal-title-group><journal-title>Nature Communications</journal-title></journal-title-group><issn pub-type="epub">2041-1723</issn><publisher><publisher-name>Nature Publishing Group</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12475282</article-id><article-id pub-id-type="pmcid-ver">PMC12475282.1</article-id><article-id pub-id-type="pmcaid">12475282</article-id><article-id pub-id-type="pmcaiid">12475282</article-id><article-id pub-id-type="pmid">41006270</article-id><article-id pub-id-type="doi">10.1038/s41467-025-63261-0</article-id><article-id pub-id-type="publisher-id">63261</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Spurious precision in meta-analysis of observational research</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-0753-8124</contrib-id><name name-style="western"><surname>Irsova</surname><given-names initials="Z">Zuzana</given-names></name><address><email>zuzana.irsova@fsv.cuni.cz</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Bom</surname><given-names initials="PRD">Pedro R. D.</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-3158-2539</contrib-id><name name-style="western"><surname>Havranek</surname><given-names initials="T">Tomas</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Rachinger</surname><given-names initials="H">Heiko</given-names></name><xref ref-type="aff" rid="Aff5">5</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/024d6js02</institution-id><institution-id institution-id-type="GRID">grid.4491.8</institution-id><institution-id institution-id-type="ISNI">0000 0004 1937 116X</institution-id><institution>Institute of Economic Studies, Faculty of Social Sciences, </institution><institution>Charles University, </institution></institution-wrap>Prague, Czech Republic </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00f54p054</institution-id><institution-id institution-id-type="GRID">grid.168010.e</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 8956</institution-id><institution>Meta-Research Innovation Center at Stanford, </institution><institution>Stanford University, </institution></institution-wrap>Stanford, CA USA </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00ne6sr39</institution-id><institution-id institution-id-type="GRID">grid.14724.34</institution-id><institution-id institution-id-type="ISNI">0000 0001 0941 7046</institution-id><institution>University of Deusto, </institution></institution-wrap>Bilbao, Spain </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04jzmdh37</institution-id><institution-id institution-id-type="GRID">grid.410315.2</institution-id><institution-id institution-id-type="ISNI">0000 0001 1954 7426</institution-id><institution>Centre for Economic Policy Research, </institution></institution-wrap>London, UK </aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/03e10x626</institution-id><institution-id institution-id-type="GRID">grid.9563.9</institution-id><institution-id institution-id-type="ISNI">0000 0001 1940 4767</institution-id><institution>University of the Balearic Islands, </institution></institution-wrap>Palma, Spain </aff></contrib-group><pub-date pub-type="epub"><day>26</day><month>9</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2025</year></pub-date><volume>16</volume><issue-id pub-id-type="pmc-issue-id">478256</issue-id><elocation-id>8454</elocation-id><history><date date-type="received"><day>12</day><month>2</month><year>2025</year></date><date date-type="accepted"><day>14</day><month>8</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>26</day><month>09</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>28</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-28 17:25:21.950"><day>28</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; The Author(s) 2025</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#8217;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#8217;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="41467_2025_Article_63261.pdf"/><abstract id="Abs1"><p id="Par1">Meta-analysis assigns more weight to studies with smaller standard errors to maximize the precision of the overall estimate. In observational settings, however, standard errors are shaped by methodological decisions. These decisions can interact with publication bias and <italic toggle="yes">p</italic>-hacking, potentially leading to spuriously precise results reported by primary studies. Here we show that such spurious precision undermines standard meta-analytic techniques, including inverse-variance weighting and bias corrections based on the funnel plot. Through simulations and large-scale empirical applications, we find that selection models do not resolve the issue. In some cases, a simple unweighted mean of reported estimates outperforms widely used correction methods. We introduce MAIVE (Meta-Analysis Instrumental Variable Estimator), an approach that reduces bias by using sample size as an instrument for reported precision. MAIVE offers a simple and robust solution for improving the reliability of meta-analyses in the presence of spurious precision.</p></abstract><abstract id="Abs2" abstract-type="web-summary"><p id="Par2">Meta-analyses often rely on reported precision to weigh studies. Here, the authors show that such precision can be overstated, and introduce a method that reduces the resulting bias, using sample size as an instrument for reported precision.</p></abstract><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Scientific community</kwd><kwd>Social sciences</kwd></kwd-group><funding-group><award-group><funding-source><institution>Czech Science Foundation (grant no.\ 23-05227M)</institution></funding-source></award-group></funding-group><funding-group><award-group><funding-source><institution>Czech Science Foundation (grant no.\ 23-05227M). Basque Government Department of Education (grant no.\ IT1429-22). Grant PID2023-152916NB-I00 financed by MCIN/AEI/10.13039/</institution></funding-source></award-group></funding-group><funding-group><award-group><funding-source><institution>Czech Science Foundation (grant no.\ 24-11583S) and the Institute for Research on the Socioeconomic Impact of Diseases and Systemic Risks (grant no.\ LX22NPO5101), funded by the European Union--Next Generation EU.</institution></funding-source></award-group></funding-group><funding-group><award-group><funding-source><institution>Czech Science Foundation (grant no.\ 23-05227M). Spanish Ministry of Science and Innovation (grant no.\ PID2020-114646RB-C43), PID2023-152916NB-I00 financed by MCIN/AEI/10.13039/</institution></funding-source></award-group></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#169; Springer Nature Limited 2025</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par3">Inverse-variance weighting reigns in meta-analysis<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. More precise studies, or rather those seemingly more precise based on lower reported standard errors, get a greater weight explicitly or implicitly. The weight is explicit in traditional summaries, such as the fixed-effect model (assuming a common effect) and the random-effects model (allowing for heterogeneity)<sup><xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR3">3</xref></sup>. They are weighted averages, with the weight diluted in random effects by a heterogeneity term.</p><p id="Par4">The weight is also explicit in publication bias correction models based on the funnel plot<sup><xref ref-type="bibr" rid="CR4">4</xref>&#8211;<xref ref-type="bibr" rid="CR9">9</xref></sup>. In funnel-based models, reported precision is especially crucial because the weighted average gets reinforced by assigning more importance to supposedly less biased (nominally more precise) studies. The weight is implicit in selection models estimated with maximum likelihood<sup><xref ref-type="bibr" rid="CR10">10</xref>&#8211;<xref ref-type="bibr" rid="CR15">15</xref></sup>, which, in the absence of publication bias, often reduce to the random-effects model.</p><p id="Par5">The tacit assumption behind these techniques is that the reported precision accurately reflects the study&#8217;s uncertainty. In other words: the standard error is given to the researcher by her data and methods. It is fixed and cannot be manipulated, consciously or unconsciously. The assumption is perhaps plausible in experimental research, for which most meta-analysis methods were developed. But in observational research, which comprises the vast majority of the scientific literature<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR17">17</xref></sup> and on which thousands of meta-analyses are conducted each year, the derivation of the standard error is often a key part of the empirical exercise.</p><p id="Par6">Consider, for example, a regression analysis with longitudinal data: explaining the educational outcomes of children taught by different teachers and observed over several years. Individual observations are not independent, and standard errors in the regression need to be clustered<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>. But how? At the level of teachers, classes, schools, children, or years? Should one use double clustering<sup><xref ref-type="bibr" rid="CR19">19</xref></sup> or perhaps wild bootstrap<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>? It is complicated<sup><xref ref-type="bibr" rid="CR21">21</xref>,<xref ref-type="bibr" rid="CR22">22</xref></sup>, and with a different clustering/bootstrapping choice the researcher will report different precision.</p><p id="Par7">Spurious precision can arise in many contexts other than longitudinal data analysis. Ordinary least squares, the workhorse of observational research, assumes homoskedasticity of errors. The assumption is often violated, and researchers should use robust standard errors<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>, typically larger than unadjusted ones. If researchers ignore heteroskedasticity, they report spuriously precise estimates. Moreover, heteroskedasticity- and cluster-robust standard errors are often downward biased in small- and medium-sized samples<sup><xref ref-type="bibr" rid="CR24">24</xref>,<xref ref-type="bibr" rid="CR25">25</xref></sup>, and the same problem applies to classical standard errors in instrumental-variable and difference-in-differences models, even with large samples<sup><xref ref-type="bibr" rid="CR26">26</xref>,<xref ref-type="bibr" rid="CR27">27</xref></sup>. Reported standard errors may also be underestimated in experiments due to violations of randomization assumptions, finite sample issues, or model misspecifications<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>. When a study with spurious precision enters meta-analysis, it wields exaggerated impact due to inverse-variance weighting.</p><p id="Par8">In this paper we use simulations and large-scale applications to show that spurious precision can create serious problems for meta-analysis. We offer a solution that removes most of the resulting bias by adjusting the reported precision to more closely reflect the sample size used in the primary study. The proposed approach uses two-stage least squares and we call it Meta-Analysis Instrumental Variable Estimator (MAIVE).</p></sec><sec id="Sec2" sec-type="results"><title>Results</title><sec id="Sec3"><title>Mechanisms of spurious precision</title><p id="Par9">Spurious precision could potentially emerge due to manipulation of data or reported standard errors. For economics journals, quasi-experimental evidence shows that the introduction of obligatory data sharing reduced the reported <italic toggle="yes">t</italic>-statistics<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>. These results imply that, before data sharing was mandated, some authors may have manipulated data or results to some extent&#8212;perhaps by removing &#8220;outliers&#8221; and thereby decreasing reported uncertainty. But a more realistic source of spurious precision is <italic toggle="yes">p</italic>-hacking, in which the researcher can sometimes adjust the entire model (e.g., by changing control variables in a regression setting) to produce statistically significant results. After adjusting the model, both the effect size and standard error change, and both changes can jointly contribute to statistical significance. We examine, by employing Monte Carlo simulations and empirical applications, the mechanisms and importance of spurious precision.</p><p id="Par10">Figure&#160;<xref rid="Fig1" ref-type="fig">1</xref> gives intuition on a simulation scenario inspired by potential clustering/heteroskedasticity/manipulation context discussed above. For brevity we call it a stylized scenario. Here researchers crave statistical significance and to this end change reported effect sizes or standard errors, but not both at the same time. The scenario is simplistic and meant to illustrate the concept of spurious precision, not capture the real behavior of researchers. We start with it because it allows for a transparent separation of selection on estimates (conventional in the literature) and selection on standard errors (our focus). The separation is less clean in the more realistic <italic toggle="yes">p</italic>-hacking scenario but can be mapped back to the stylized scenario. Note that both differ from the standard scenario of publication bias, where different studies have different probabilities of publication but are not manipulated or <italic toggle="yes">p</italic>-hacked.<fig id="Fig1" position="float" orientation="portrait"><label>Fig. 1</label><caption><title>Two flavors of selection and repercussions for meta-analysis.</title><p>Notes:&#160;Blue-filled circles (lighter in grayscale) denote estimates statistically significant at the 5% level; these are reported. Hollow circles denote insignificant estimates, which are not reported in their original form but <italic toggle="yes">p</italic>-hacked to yield statistical significance (black-filled circles). In panel (<bold>a</bold>) the resulting mean of reported estimates is biased upwards, and inverse-variance weighting helps mitigate the bias. In panel (<bold>b</bold>) the resulting mean is unbiased, and inverse-variance weighting introduces a bias. A realistic scenario of <italic toggle="yes">p</italic>-hacking combines both types of selection, so the <italic toggle="yes">p</italic>-hacked estimates move not strictly east or north (as in the figure) but northeast.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="d33e347" position="float" orientation="portrait" xlink:href="41467_2025_63261_Fig1_HTML.jpg"/></fig></p><p id="Par11">The mechanism of the left-hand panel of Fig.&#160;<xref rid="Fig1" ref-type="fig">1</xref> is analogous to the Lombard effect in psychoacoustics<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>: speakers increase their vocal effort in response to noise. Here researchers increase their selection effort in response to noise in data or methods, noise that produces insignificance. When selection works on effect sizes, the results are consistent with funnel-based models of publication bias: funnel asymmetry arises, the most precise estimates are close to the true effect, and inverse-variance weighting helps mitigate the bias.</p><p id="Par12">By contrast, the mechanism of the right-hand panel of Fig.&#160;<xref rid="Fig1" ref-type="fig">1</xref> is analogous to Taylor&#8217;s law in ecology<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>: variance can decrease in response to a smaller mean. When researchers achieve significance by lowering the standard error to compensate for a small estimated effect size, we again observe funnel asymmetry. But this time no bias arises in the reported effect sizes. The simple unweighted mean of reported estimates is unbiased, and it is inverse-variance weighting that creates a bias. The bias increases when we use a correction based on the funnel plot: that is, when we estimate the effect size of a hypothetical infinitely precise study.</p><p id="Par13">In practice, as noted, selection on estimates and standard errors likely arises simultaneously. We generate this quality in simulations by allowing researchers to replace control variables in a regression context. Control variables are correlated with the main regressor of interest, and their replacement affects both the estimated effect in question and the corresponding precision. Then <italic toggle="yes">p</italic>-hacked estimates move not strictly east or north, as in the figure, but northeast. Spuriously large estimates can then be also spuriously precise. Our simulations and applications suggest that an upward bias arises in conventional meta-analysis estimators, including those that try to correct for publication bias.</p></sec><sec id="Sec4"><title>Formalization and conceptual framework</title><p id="Par14">Suppose that the object of meta-analysis is <italic toggle="yes">&#945;</italic><sub>1</sub>, the slope coefficient of a regression of an outcome variable <italic toggle="yes">Y</italic> on a predictor <italic toggle="yes">X</italic><sub>1</sub>, after controlling for covariates <italic toggle="yes">X</italic><sub>2</sub>, &#8230;, <italic toggle="yes">X</italic><sub><italic toggle="yes">p</italic></sub>:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="d33e397">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${Y}_{j}={\alpha }_{0}+{\alpha }_{1}{X}_{1j}+{\alpha }_{2}{X}_{2j}+\ldots+{\alpha }_{p}{X}_{pj}+{u}_{j},$$\end{document}</tex-math><mml:math id="d33e403"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo>&#8230;</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:math><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="anchor" orientation="portrait" xlink:href="41467_2025_63261_Article_Equ1.gif"/></alternatives></disp-formula>where <italic toggle="yes">j</italic> denotes individual observations and <italic toggle="yes">u</italic> is an error term with zero mean conditional on <italic toggle="yes">X</italic><sub>1</sub>, &#8230;, <italic toggle="yes">X</italic><sub><italic toggle="yes">p</italic></sub>. For example, if the interest lies in the effect of teacher experience on the academic performance of pupils, <italic toggle="yes">Y</italic> would measure the pupil&#8217;s test score, <italic toggle="yes">X</italic><sub>1</sub> would measure the teacher&#8217;s experience, and it would be necessary to control for confounding factors such as socioeconomic background (children from families with higher socioeconomic status may simultaneously show better test scores and attend schools where teachers have more experience).</p><p id="Par15">Assume that primary studies estimate a form of (<xref rid="Equ1" ref-type="disp-formula">1</xref>), always featuring <italic toggle="yes">Y</italic> and <italic toggle="yes">X</italic><sub>1</sub>, but potentially omitting some or all covariates <italic toggle="yes">X</italic><sub>2</sub>, &#8230;, <italic toggle="yes">X</italic><sub><italic toggle="yes">p</italic></sub>. The estimates of <italic toggle="yes">&#945;</italic><sub>1</sub> and the corresponding standard errors reported in these studies provide the data for meta-analysis. The precision of an estimate is the inverse of its reported standard error. For simplicity, we assume that all primary studies define <italic toggle="yes">Y</italic> and <italic toggle="yes">X</italic><sub>1</sub> on the same scale, so that no rescaling is necessary at the meta-analysis level. Note that while we work with comparable regression coefficients to avoid the mechanical correlation between estimates and standard errors that arises with standardized effect sizes, MAIVE can be applied in settings involving standardized effect sizes. In fact, this mechanical correlation is another reason why MAIVE is particularly useful in such cases.</p><p id="Par16">The ordinary least squares (OLS) estimator provides an unbiased and consistent estimate of <italic toggle="yes">&#945;</italic><sub>1</sub> in model (1). The corresponding standard error is given by:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="d33e527">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\mbox{SE}}}\,({\hat{\alpha }}_{1})=\sqrt{\frac{{s}^{2}}{(N-1)\,{{\mbox{Var}}}\,({X}_{1})(1-{R}_{1}^{2})}},$$\end{document}</tex-math><mml:math id="d33e533"><mml:mstyle><mml:mtext>SE</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>Var</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:msqrt><mml:mo>,</mml:mo></mml:math><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="anchor" orientation="portrait" xlink:href="41467_2025_63261_Article_Equ2.gif"/></alternatives></disp-formula>which depends on the estimated variance of <italic toggle="yes">u</italic> (<italic toggle="yes">s</italic><sup>2</sup>), the sample size (<italic toggle="yes">N</italic>), the variance of <italic toggle="yes">X</italic><sub>1</sub>, and the correlation between <italic toggle="yes">X</italic><sub>1</sub> and the other regressors (measured by <inline-formula id="IEq1"><alternatives><tex-math id="d33e616">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${R}_{1}^{2}$$\end{document}</tex-math><mml:math id="d33e621"><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq1.gif"/></alternatives></inline-formula>).</p><p id="Par17">Equation (<xref rid="Equ2" ref-type="disp-formula">2</xref>) hinges on the absence of heteroskedasticity and autocorrelation. If the error term is heteroskedastic or exhibits a clustered structure of correlation, (<xref rid="Equ2" ref-type="disp-formula">2</xref>) usually underestimates the true standard error of <italic toggle="yes">&#945;</italic><sub>1</sub>. This misspecification of the statistical properties of the error term is one potential cause of spurious precision. Another potential cause is the misspecification of the functional form of the regression, a mechanism we focus on in simulations. Suppose, for example, that one or more of the control variables <italic toggle="yes">X</italic><sub>2</sub>, &#8230;, <italic toggle="yes">X</italic><sub><italic toggle="yes">p</italic></sub> are correlated with <italic toggle="yes">X</italic><sub>1</sub> but are excluded from (<xref rid="Equ1" ref-type="disp-formula">1</xref>), causing omitted-variable bias. Then <inline-formula id="IEq2"><alternatives><tex-math id="d33e661">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${R}_{1}^{2}$$\end{document}</tex-math><mml:math id="d33e666"><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq1.gif"/></alternatives></inline-formula> decreases and <italic toggle="yes">s</italic><sup>2</sup> increases, affecting both the numerator and denominator of (<xref rid="Equ2" ref-type="disp-formula">2</xref>). We focus on the more intuitive case in which the former effect dominates, so the resulting standard error is smaller than the one obtained from the well-specified model (<xref rid="Equ1" ref-type="disp-formula">1</xref>).</p><p id="Par18">Reported precision is defined as spurious if it exceeds that in a correctly specified model with proper functional form and error term properties. Correct precision, by contrast, requires that the model yields an unbiased and consistent estimate of <italic toggle="yes">&#945;</italic><sub>1</sub> and that the computation of the standard error accounts for clustering or small-sample issues when present. Spurious precision thus defined is relevant at the meta-analysis level because it undermines the effectiveness of conventional methods, which use the standard error as inverse weight and also as a regressor in Egger-type regression, to identify the true mean effect beyond publication bias.</p><p id="Par19">Spurious precision by itself does not bias meta-analysis if it is unrelated to the size of the estimated effect; in that case, it only reduces efficiency and distorts inference. But it becomes a more serious problem when some authors crave statistical significance and adjust the computation of precision in response to the estimated effect size&#8212;even if the corresponding estimate reported in the primary study remains unbiased (as we will see in the stylized simulation scenario). Spurious precision is particularly detrimental to meta-analysis when it co-occurs with a biased estimate (as we will see in the <italic toggle="yes">p</italic>-hacking simulation scenario). Note that the standard error of a biased estimate of <italic toggle="yes">&#945;</italic><sub>1</sub> from a misspecified model may be regarded as correct for that particular model. However, at the meta-analysis level, cross-study comparison of precision matters, and in this case a biased estimate would be paired with higher precision&#8212;and thus greater weight&#8212;than if it were unbiased.</p></sec><sec id="Sec5"><title>Conventional meta-analysis models</title><p id="Par20">We focus on minimizing bias in meta-analysis, though in the Supplementary Information (<xref rid="MOESM1" ref-type="media">S1</xref>, <xref rid="MOESM1" ref-type="media">S6</xref>) we also report and discuss results for MSE and coverage rates. Does any meta-analysis technique work well in the case of panel B of Fig.&#160;<xref rid="Fig1" ref-type="fig">1</xref>, or at least with a small amount of spurious precision? We examine seven current estimators: simple unweighted mean, fixed-effect&#160;model (weighted least squares, FE/WLS)<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>, precision-effect test and precision-effect estimate with standard errors (PET-PEESE)<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>, endogenous kink (EK)<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>, weighted average of adequately powered estimates (WAAP)<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>, the model by Andrews and Kasy<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, and <italic toggle="yes">p</italic>-uniform<sup>*</sup><sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. Note that the unweighted mean can be seen as a limiting case of a random-effects model, where between-study variance is assumed to be infinite and all estimates are weighted equally.</p><p id="Par21">The first two are summary statistics, the next three are corrections based on the funnel plot, and the last two are selection models. The three funnel-based techniques are commonly used in observational research<sup><xref ref-type="bibr" rid="CR33">33</xref>&#8211;<xref ref-type="bibr" rid="CR38">38</xref></sup>. The two selection models, based on random-effects specifications, are also used often<sup><xref ref-type="bibr" rid="CR39">39</xref>&#8211;<xref ref-type="bibr" rid="CR45">45</xref></sup> and represent the latest incarnations of models in the tradition of Hedges<sup><xref ref-type="bibr" rid="CR10">10</xref>&#8211;<xref ref-type="bibr" rid="CR13">13</xref></sup> and their simplifications<sup><xref ref-type="bibr" rid="CR46">46</xref>&#8211;<xref ref-type="bibr" rid="CR51">51</xref></sup>.</p><p id="Par22">The importance of reported precision for these estimators is summarized in Table&#160;<xref rid="Tab1" ref-type="table">1</xref>. In most of them precision has two roles: weight and identification. Identification, the unique determination of the mean true effect in meta-analysis based on observed primary studies, can be achieved through Egger-type regression (where the standard error or a function thereof is included as a regressor), selection model, or a combination of both&#8212;such as the EK model.<table-wrap id="Tab1" position="float" orientation="portrait"><label>Table 1</label><caption><p>The role of the standard error in 7 benchmark estimators</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1">Estimator</th><th colspan="1" rowspan="1">Weight</th><th colspan="1" rowspan="1">Regressor</th><th colspan="1" rowspan="1">Identification</th></tr></thead><tbody><tr><td colspan="1" rowspan="1">Simple average</td><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1"/></tr><tr><td colspan="1" rowspan="1">FE/WLS</td><td colspan="1" rowspan="1"><italic toggle="yes">&#10003;</italic></td><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1"/></tr><tr><td colspan="1" rowspan="1">PET-PEESE</td><td colspan="1" rowspan="1"><italic toggle="yes">&#10003;</italic></td><td colspan="1" rowspan="1"><italic toggle="yes">&#10003;</italic></td><td colspan="1" rowspan="1"/></tr><tr><td colspan="1" rowspan="1">EK</td><td colspan="1" rowspan="1"><italic toggle="yes">&#10003;</italic></td><td colspan="1" rowspan="1"><italic toggle="yes">&#10003;</italic></td><td colspan="1" rowspan="1"><italic toggle="yes">&#10003;</italic></td></tr><tr><td colspan="1" rowspan="1">WAAP</td><td colspan="1" rowspan="1"><italic toggle="yes">&#10003;</italic></td><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1"><italic toggle="yes">&#10003;</italic></td></tr><tr><td colspan="1" rowspan="1">Andrews &amp; Kasy</td><td colspan="1" rowspan="1"><italic toggle="yes">&#10003;</italic></td><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1"><italic toggle="yes">&#10003;</italic></td></tr><tr><td colspan="1" rowspan="1"><italic toggle="yes">p</italic>-uniform<sup>*</sup></td><td colspan="1" rowspan="1"><italic toggle="yes">&#10003;</italic></td><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1"><italic toggle="yes">&#10003;</italic></td></tr></tbody></table><table-wrap-foot><p>Notes: Simple average = unweighted mean. FE/WLS = fixed effect/weighted least squares: mean weighted by inverse variance<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>. PET-PEESE = precision-effect test and precision-effect estimate with standard errors: selection is a quadratic function of SE when true effect &#160;&#8800;&#160;0<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>. EK = endogenous kink: selection is a linear function of SE for imprecise estimates, no selection for precise ones<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>. WAAP = weighted average of adequately powered estimates: only estimates with at least 80% power included<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>. Andrews &amp; Kasy = a selection model in the tradition of Hedges<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. <italic toggle="yes">p</italic>-uniform<sup>*</sup> = a simplified selection model based on the principle that <italic toggle="yes">p</italic>-values should be uniformly distributed at the true effect size<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>.</p></table-wrap-foot></table-wrap></p><p id="Par23">None of these estimators perform well with even modest spurious precision working through selection on standard errors. The reader might expect selection models to beat funnel-based models, because of the latter&#8217;s heavier reliance on precision. This is not always the case, and even selection models are sometimes defeated by the unweighted mean when selection on standard errors is modest (about 1:3 compared to selection on estimates). The bias in meta-analysis due to spurious precision can be more important than the classical publication bias.</p></sec><sec id="Sec6"><title>Meta-analysis instrumental variable estimator</title><p id="Par24">We propose a straightforward adjustment of current meta-analysis techniques, the meta-analysis instrumental variable estimator (MAIVE), which corrects most of the bias and restores valid coverage rates. MAIVE replaces, in all meta-analytic contexts, the reported variance with the portion that can be explained by the inverse of the total sample size used in the primary study, regardless of the model specification in the original studies (e.g., whether they use multilevel or clustered designs). MAIVE relies on the following regression:<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="d33e924">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SE{(\hat{\alpha })}_{i}^{2}={\psi }_{0}+{\psi }_{1}(1/{N}_{i})+{\nu }_{i},$$\end{document}</tex-math><mml:math id="d33e930"><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:msubsup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>&#968;</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>&#968;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>&#957;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:math><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="anchor" orientation="portrait" xlink:href="41467_2025_63261_Article_Equ3.gif"/></alternatives></disp-formula>where <inline-formula id="IEq3"><alternatives><tex-math id="d33e980">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{\alpha }$$\end{document}</tex-math><mml:math id="d33e985"><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq3.gif"/></alternatives></inline-formula> is the effect size reported in a primary study, <italic toggle="yes">S</italic><italic toggle="yes">E</italic> is its standard error, <italic toggle="yes">&#968;</italic><sub>0</sub> is a constant, <italic toggle="yes">N</italic><sub><italic toggle="yes">i</italic></sub> is the sample size of the primary study, and <italic toggle="yes">&#957;</italic><sub><italic toggle="yes">i</italic></sub> is an error term that soaks up, among other things, the spurious elements of the reported standard error related to <italic toggle="yes">p</italic>-hacking. We explain the intuition behind MAIVE by starting with a version of the Egger regression<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>:<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="d33e1022">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{\alpha }}_{i}={\alpha }_{0}+\beta SE{(\hat{\alpha })}_{i}^{2}+{v}_{i}.$$\end{document}</tex-math><mml:math id="d33e1028"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>&#946;</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:msubsup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:math><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="anchor" orientation="portrait" xlink:href="41467_2025_63261_Article_Equ4.gif"/></alternatives></disp-formula>This is the PEESE model, but for simplicity without additional inverse-variance weights&#8212;since the model searches for the effect conditional on maximum precision (<italic toggle="yes">&#945;</italic><sub>0</sub>), it already features an implicit, built-in weight.</p><p id="Par25">In panel A of Fig.&#160;<xref rid="Fig1" ref-type="fig">1</xref>, the quadratic regression (PEESE, Eq. (<xref rid="Equ4" ref-type="disp-formula">4</xref>)) would fit the data quite well<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>, and estimated <italic toggle="yes">&#945;</italic><sub>0</sub> would lie close to the mean underlying effect. In panel B, however, PEESE fails to recover the underlying coefficients. PEESE fails because it assumes a causal effect of the standard error on the estimate: a good description of panel A (Lombard effect), but not panel B (Taylor&#8217;s law). In panel B, the standard error sometimes depends on the estimated effect size and is thus correlated with the error term, <italic toggle="yes">v</italic><sub><italic toggle="yes">i</italic></sub>. In other words, spurious precision breaks the exogeneity assumption in (<xref rid="Equ4" ref-type="disp-formula">4</xref>) that is necessary for ordinary least squares to correctly identify regression parameters. The resulting estimates of <italic toggle="yes">&#945;</italic><sub>0</sub> (true effect) and <italic toggle="yes">&#946;</italic> (intensity of selection) are biased.</p><p id="Par26">The problem is the correlation between <italic toggle="yes">S</italic><italic toggle="yes">E</italic> and <italic toggle="yes">v</italic><sub><italic toggle="yes">i</italic></sub>, which can potentially arise for four reasons: First, selective reporting based on standard errors, which we simulate. Second, measurement error in <italic toggle="yes">S</italic><italic toggle="yes">E</italic><sup><xref ref-type="bibr" rid="CR52">52</xref></sup>. Third, mechanical relation between estimates and standard errors in standardized effect sizes<sup><xref ref-type="bibr" rid="CR37">37</xref>,<xref ref-type="bibr" rid="CR53">53</xref>,<xref ref-type="bibr" rid="CR54">54</xref></sup>. We do not consider these two sources of correlation in simulations. Fourth, unobserved heterogeneity: some method choices can affect both estimates and standard errors in the same direction. Our <italic toggle="yes">p</italic>-hacking simulation only partly addresses this mechanism by allowing researchers to change control variables, which can affect both estimates and standard errors. So we model only some of the mechanisms which create problems with inverse-variance weighting and Egger regression in meta-analysis.</p><p id="Par27">The intuitive statistical solution to this problem, often called endogeneity, is to find an instrument for the standard error. A valid instrument is strongly correlated with the standard error, but uncorrelated with the error term in (<xref rid="Equ4" ref-type="disp-formula">4</xref>)&#8212;and thus unrelated to the four sources of endogeneity mentioned above. These are the two assumptions that MAIVE needs in order to relax the crucial exogeneity assumption of meta-analysis models.</p><p id="Par28">The answer beckons. As is evident from Eq. (<xref rid="Equ2" ref-type="disp-formula">2</xref>), reported variance is a linear function of the inverse of the sample size used in the primary study. The sample size is plausibly robust to selection, or at least it is often harder to collect more data than to <italic toggle="yes">p</italic>-hack the standard error to achieve significance. In observational research, authors typically use as much data as available from the start. The sample size is not estimated, and so it does not suffer from measurement error. The sample size is often not systematically affected by changing methodology and not mechanically related to standardized effect sizes. Indeed, the sample size, unlike the standard error, is often given to the researcher: the very word data means &#8220;things given.&#8221;</p><p id="Par29">We regress the squared reported standard errors on the inverse sample size (Eq. (<xref rid="Equ3" ref-type="disp-formula">3</xref>)) and plug the fitted values [<inline-formula id="IEq4"><alternatives><tex-math id="d33e1163">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{{\psi }_{0}}+\hat{{\psi }_{1}}(1/{N}_{i})$$\end{document}</tex-math><mml:math id="d33e1168"><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>&#968;</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>&#968;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq4.gif"/></alternatives></inline-formula>] instead of the variance into the right-hand side of Eq. (<xref rid="Equ4" ref-type="disp-formula">4</xref>). Thence we obtain the baseline MAIVE estimator. For the baseline MAIVE we choose the instrumented version of PET-PEESE without inverse-variance weights because it works well in simulations and applications. The version with adjusted weights (again, using fitted instead of reported precision) often performs similarly but is more complex. Any meta-analysis technique can be adjusted by the procedure, using <inline-formula id="IEq5"><alternatives><tex-math id="d33e1204">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sqrt{\hat{{\psi }_{0}}+\hat{{\psi }_{1}}(1/{N}_{i})}$$\end{document}</tex-math><mml:math id="d33e1209"><mml:msqrt><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>&#968;</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>&#968;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq5.gif"/></alternatives></inline-formula> instead of reported standard errors. Adjusted standard errors can be retrieved using our maive package in R.</p></sec><sec id="Sec7"><title>Simulations</title><p id="Par30">Table&#160;<xref rid="Tab2" ref-type="table">2</xref> shows the variants of individual estimators we consider. We always start with the unadjusted variant. Where possible, we consider the adjustment of weights and identification devices separately. So, for PET-PEESE and EK we have 5 different variants: 1) unadjusted, 2) adjusted weights, 3) instrumented SEs, 4) adjusted weights and instrumented SEs, and 5) instrumented SEs and no weights. In variant 3, only the regressor is MAIVE-adjusted, not the weights. In variant 5, weights are dropped altogether for parsimony&#8212;note that doing so brings MAIVE closer to a random-effects model that accounts for extreme heterogeneity than to a fixed-effect model. The separation into these five variants is not straightforward for selection models, and we do not pursue it here.<table-wrap id="Tab2" position="float" orientation="portrait"><label>Table 2</label><caption><p>Estimators and their MAIVE variants considered in simulations</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1">Estimator</th><th colspan="1" rowspan="1">Variants</th></tr></thead><tbody><tr><td colspan="1" rowspan="1">Simple average</td><td colspan="1" rowspan="1">(1) Unadjusted</td></tr><tr><td colspan="1" rowspan="1">FE/WLS</td><td colspan="1" rowspan="1">(1) Unadjusted</td></tr><tr><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1">(2) Adjusted weights</td></tr><tr><td colspan="1" rowspan="1">PET-PEESE</td><td colspan="1" rowspan="1">(1) Unadjusted</td></tr><tr><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1">(2) Adjusted weights</td></tr><tr><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1">(3) Instrumented SEs</td></tr><tr><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1">(4) Adjusted weights and instrumented SEs</td></tr><tr><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1">(5) Instrumented SEs and no weights&#160;(MAIVE baseline)</td></tr><tr><td colspan="1" rowspan="1">EK</td><td colspan="1" rowspan="1">(1) Unadjusted</td></tr><tr><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1">(2) Adjusted weights</td></tr><tr><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1">(3) Instrumented SEs</td></tr><tr><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1">(4) Adjusted weights and instrumented SEs</td></tr><tr><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1">(5) Instrumented SEs and no weights</td></tr><tr><td colspan="1" rowspan="1">WAAP</td><td colspan="1" rowspan="1">(1) Unadjusted</td></tr><tr><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1">(2) Adjusted weights and SEs</td></tr><tr><td colspan="1" rowspan="1">Andrews &amp; Kasy</td><td colspan="1" rowspan="1">(1) Unadjusted</td></tr><tr><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1">(2) Adjusted SEs</td></tr><tr><td colspan="1" rowspan="1"><italic toggle="yes">p</italic>-uniform<sup>*</sup></td><td colspan="1" rowspan="1">(1) Unadjusted</td></tr><tr><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1">(2) Adjusted SEs</td></tr></tbody></table><table-wrap-foot><p>Notes: See notes to Table&#160;<xref rid="Tab1" ref-type="table">1</xref>.</p></table-wrap-foot></table-wrap></p><p id="Par31">In Fig.&#160;<xref rid="Fig2" ref-type="fig">2</xref> we report one set of simulation results: the case of the <italic toggle="yes">p</italic>-hacking scenario with a positive underlying effect size. Here the authors of primary studies run regressions with two variables on the right-hand side and are interested in the slope coefficient on the first variable. A meta-analyst collects the slope coefficients. The vertical axis in Fig.&#160;<xref rid="Fig2" ref-type="fig">2</xref> measures the bias of meta-analysis estimators relative to the true value of the slope coefficient (<italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;1). The bottom horizontal axis measures the correlation between the regression variable of interest and a control variable that should be included&#8212;but can be replaced by some researchers with a less relevant control, a practice that affects both estimates and their standard errors. The top horizontal axis captures the corresponding importance of selection on standard errors relative to selection on estimates. Technical details are available in the Methods part.<fig id="Fig2" position="float" orientation="portrait"><label>Fig. 2</label><caption><title>Bias: <italic toggle="yes">p</italic>-hacking selection; MAIVE denotes the estimator&#8217;s unweighted version.</title><p>Notes: The true effect in the simulation is set to 1. The vertical axis shows the bias of meta-analysis estimators. A higher correlation (on the bottom horizontal axis) between the main and control regression variables is associated with more relative importance of spurious precision (top horizontal axis). In the Methods section and the Supplementary Information (<xref rid="MOESM1" ref-type="media">S1</xref>) we provide details on the simulations. The dashed line shows the performance of the simple mean of published estimates. Panels show (<bold>a</bold>) a comparison of biases for all unadjusted estimators; bias for (<bold>b</bold>) the fixed effect or weighted least squares estimator with adjustment, (<bold>c</bold>) the adjusted precision-effect test and precision-effect estimate with standard errors, (<bold>d</bold>) the adjusted endogenous kink estimator, (<bold>e</bold>) the adjusted weighted average of adequately powered, (<bold>f</bold>) the adjusted Andrews and Kasy estimator, (<bold>g</bold>) the adjusted p-uniform* method; and (<bold>h</bold>) a comparison of biases for all adjusted estimators. All estimators in panel (<bold>h</bold>) use MAIVE-adjusted standard errors; the default is the MAIVE version of PET-PEESE without weights.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="d33e1421" position="float" orientation="portrait" xlink:href="41467_2025_63261_Fig2_HTML.jpg"/></fig></p><p id="Par32">The higher the correlation, the more potential for <italic toggle="yes">p</italic>-hacking via the replacement of the control variable. Replacing the control variable with a less relevant proxy creates an upward omitted-variable bias if, as we assume in the simulation, the signs of <italic toggle="yes">&#945;</italic><sub>2</sub> and the correlation are the same. A higher correlation causes collinearity and thus increases the potential for selection on standard errors more than proportionally compared to selection on estimates. With a higher correlation and thus more <italic toggle="yes">p</italic>-hacking and also more relative selection on standard errors, the bias of standard meta-analysis estimators increases. Note that even a large correlation still corresponds to a relatively small ratio of selection on standard errors (spurious precision, Taylor&#8217;s law) relative to selection on estimates (Lombard effect). In the Supplementary Information (Supplementary Table&#160;<xref rid="MOESM1" ref-type="media">S5</xref>) we compute and tabulate this correspondence for different values of the true effect and the correlation.</p><p id="Par33">Eventually, the bias of the unadjusted techniques gets even larger than the bias of the simple unweighted mean. That is, with enough selection on standard errors the simple mean of reported estimates defeats the current estimators that are meant to correct the important bias in the simple mean. Spurious precision can therefore reduce the effectiveness of conventional bias-correction methods, sometimes making them less reliable than the simple mean they are intended to improve upon. MAIVE corrects most of this bias (see panels B-G in Fig.&#160;<xref rid="Fig2" ref-type="fig">2</xref> and compare panel A to panel H), and the MAIVE versions with adjusted or omitted weights work similarly well. In this scenario, the MAIVE version of EK works even better than the MAIVE version of PEESE (default MAIVE), but this is not the case in other simulations. MAIVE performs comparably to conventional estimators if spurious precision is negligible, and dominates unadjusted estimators if spurious precision is important.</p><p id="Par34">In the Supplementary Information (<xref rid="MOESM1" ref-type="media">S1</xref>, <xref rid="MOESM1" ref-type="media">S3</xref>&#8211;<xref rid="MOESM1" ref-type="media">S6</xref>) we report the results of more simulation scenarios, both stylized and <italic toggle="yes">p</italic>-hacking, for bias, MSE, and coverage rates&#8212;with comparable results in qualitative terms. Even a modest dose of spurious precision can make inverse-variance weighting unreliable and warrants a MAIVE treatment. Note that our simulations allow for substantial heterogeneity among primary studies. By inducing biases in the reported estimates, <italic toggle="yes">p</italic>-hacking causes excess variation in the reported findings (i.e., heterogeneity&#8212;<italic toggle="yes">I</italic><sup>2</sup> of 40&#8211;70% depending on simulation context). When additionally allowing for true effect heterogeneity via traditional random effects, <italic toggle="yes">I</italic><sup>2</sup> surpasses 80% in all contexts. Doing so in the Supplementary Information (<xref rid="MOESM1" ref-type="media">S3</xref>) does not affect our main results but slightly improves the performance of selection models relative to funnel-based ones.</p></sec><sec id="Sec8"><title>Applications</title><p id="Par35">We complement simulations with empirical applications. Our strategy is based on Kvarven et al.<sup><xref ref-type="bibr" rid="CR55">55</xref></sup>, who compare meta-analysis results to later preregistered multiple-laboratory replications of the same effect. Kvarven et al. find that common meta-analysis techniques, including those that explicitly correct for publication bias, yield estimates substantially larger than those of replications. The finding has two implications: First, publication bias and <italic toggle="yes">p</italic>-hacking are important on average, create an upward bias in the mean reported results, and should be taken into account by meta-analysts. Second, existing meta-analysis techniques fail to correct enough for these problems. If MAIVE helps reduce meta-analysis estimates and thus bring them closer to replications, it solves a part of the puzzle identified by Kvarven et al. and, at the same time, establishes the empirical relevance of spurious precision.</p><p id="Par36">In the first application we use the dataset of Kvarven et al. focusing on psychology research. However, the dataset does not include sample sizes for individual primary studies, and we need sample sizes for MAIVE correction. Kvarven et al. provide us with additional, previously unpublished data on sample sizes for some meta-analyses. The rest of the required sample sizes we collect manually or obtain by e-mail from the authors of meta-analyses or primary studies. In the end we succeed in collecting sample sizes for all replication&#8211;meta-analysis pairs.</p><p id="Par37">Kvarven et al. find that, among meta-analysis estimators, PET-PEESE yields results closest to those of preregistered multiple-laboratory replications. So in our applications, consistently with the previous simulations, we use PET-PEESE as the benchmark and employ its MAIVE version (again, without inverse-variance weights) as the default MAIVE estimator. We find that, when conditions for instrumental variable estimation are met (strong instrument, at least modest sample size), MAIVE further reduces the bias of PET-PEESE in 75% of the cases. More details on estimation and inference are available in the Methods part and in the Supplementary Information (<xref rid="MOESM1" ref-type="media">S1</xref>).</p><p id="Par38">But the sample of replication&#8211;meta-analysis pairs is limited due to the costs of multilab replications. So in the second, more important application we turn to a large dataset of meta-analyses (especially in economics, but also education, finance, business, political science, and sociology) used in Bartos et al.<sup><xref ref-type="bibr" rid="CR56">56</xref></sup>. These meta-analyses typically focus on observational research. As in the previous case, we need sample sizes for individual primary studies (or estimates), and these are often not included in the dataset. We collect as many missing sample sizes as possible manually or obtain them by e-mail from the authors of meta-analyses or primary studies. Technical details are available in the Methods part and in the Supplementary Information (<xref rid="MOESM1" ref-type="media">S2</xref>).</p><p id="Par39">Our results suggest that, when conditions for instrumental variable estimation are strongly met (239 meta-analyses), MAIVE further reduces the PET-PEESE estimates in more than 70% of the cases. Table&#160;<xref rid="Tab3" ref-type="table">3</xref> shows that the reduction is even stronger if we consider only meta-analyses for which PET-PEESE delivers an estimate statistically significant at the 5% level (two-sided). The reduction also tends to be stronger when the correlation between reported variance and inverse sample size is stronger. Figure&#160;<xref rid="Fig3" ref-type="fig">3</xref> shows the main outcome of empirical applications visually: though the pattern is by no means perfect, reductions in PET-PEESE-corrected effects due to MAIVE predominate in meta-analyses of observational research.<table-wrap id="Tab3" position="float" orientation="portrait"><label>Table 3</label><caption><p>MAIVE estimates tend to be closer to 0 than PET-PEESE in meta-analyses</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="1" rowspan="1"/><th colspan="2" rowspan="1">All effect sizes</th><th colspan="2" rowspan="1">PET-PEESE significant</th></tr><tr><th colspan="1" rowspan="1"/><th colspan="1" rowspan="1">Absolute</th><th colspan="1" rowspan="1">%</th><th colspan="1" rowspan="1">Absolute</th><th colspan="1" rowspan="1">%</th></tr></thead><tbody><tr><td colspan="1" rowspan="1"><italic toggle="yes">(a) All meta-analyses</italic></td><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1"/></tr><tr><td colspan="1" rowspan="1">&#8739;MAIVE&#8739;&#160;&gt;&#160;&#8739;PET-PEESE&#8739;</td><td colspan="1" rowspan="1">111</td><td colspan="1" rowspan="1">35.8</td><td colspan="1" rowspan="1">63</td><td colspan="1" rowspan="1">29.9</td></tr><tr><td colspan="1" rowspan="1">&#8739;MAIVE&#8739;&#160;&lt;&#160;&#8739;PET-PEESE&#8739;</td><td colspan="1" rowspan="1">199</td><td colspan="1" rowspan="1">64.2</td><td colspan="1" rowspan="1">148</td><td colspan="1" rowspan="1">70.1</td></tr><tr><td colspan="1" rowspan="1">Total</td><td colspan="1" rowspan="1">310</td><td colspan="1" rowspan="1">100</td><td colspan="1" rowspan="1">193</td><td colspan="1" rowspan="1">100</td></tr><tr><td colspan="1" rowspan="1"><italic toggle="yes">(b) Meta-analyses with&#160;</italic><italic toggle="yes">F</italic>&#160;&gt;&#160;10</td><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1"/></tr><tr><td colspan="1" rowspan="1">&#8739;MAIVE&#8739;&#160;&gt;&#160;&#8739;PET-PEESE&#8739;</td><td colspan="1" rowspan="1">87</td><td colspan="1" rowspan="1">32.6</td><td colspan="1" rowspan="1">44</td><td colspan="1" rowspan="1">24.6</td></tr><tr><td colspan="1" rowspan="1">&#8739;MAIVE&#8739;&#160;&lt;&#160;&#8739;PET-PEESE&#8739;</td><td colspan="1" rowspan="1">180</td><td colspan="1" rowspan="1">67.4</td><td colspan="1" rowspan="1">135</td><td colspan="1" rowspan="1">75.4</td></tr><tr><td colspan="1" rowspan="1">Total</td><td colspan="1" rowspan="1">267</td><td colspan="1" rowspan="1">100</td><td colspan="1" rowspan="1">172</td><td colspan="1" rowspan="1">100</td></tr><tr><td colspan="1" rowspan="1"><italic toggle="yes">(c) Meta-analyses with&#160;</italic><italic toggle="yes">F</italic>&#160;&gt;&#160;100</td><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1"/><td colspan="1" rowspan="1"/></tr><tr><td colspan="1" rowspan="1">&#8739;MAIVE&#8739;&#160;&gt;&#160;&#8739;PET-PEESE&#8739;</td><td colspan="1" rowspan="1">70</td><td colspan="1" rowspan="1">29.2</td><td colspan="1" rowspan="1">36</td><td colspan="1" rowspan="1">22.4</td></tr><tr><td colspan="1" rowspan="1">&#8739;MAIVE&#8739;&#160;&lt;&#160;&#8739;PET-PEESE&#8739;</td><td colspan="1" rowspan="1">169</td><td colspan="1" rowspan="1">70.7</td><td colspan="1" rowspan="1">125</td><td colspan="1" rowspan="1">77.6</td></tr><tr><td colspan="1" rowspan="1">Total</td><td colspan="1" rowspan="1">239</td><td colspan="1" rowspan="1">100</td><td colspan="1" rowspan="1">151</td><td colspan="1" rowspan="1">100</td></tr></tbody></table><table-wrap-foot><p>Notes: The table compares the results of MAIVE and PET-PEESE for the sample of economics meta-analyses<sup><xref ref-type="bibr" rid="CR56">56</xref></sup>. The table separates the cases in which the estimated underlying effect in PET-PEESE is statistically significant at the 5% level (right) and when all PET-PEESE estimates are considered (left). In both cases, MAIVE estimates are typically closer to zero (that is, smaller in absolute value) than PET-PEESE estimates. The difference is larger for statistically significant effects and for meta-analyses with a large <italic toggle="yes">F</italic>-statistic in the first-stage regression of MAIVE; the <italic toggle="yes">F</italic>-statistic therefore measures the strength of the MAIVE instrument. The larger the <italic toggle="yes">F</italic>-statistic, the more reliable MAIVE is, althought the difference in performance is not large.&#160;</p></table-wrap-foot></table-wrap><fig id="Fig3" position="float" orientation="portrait"><label>Fig. 3</label><caption><title>Histogram of the percentage change of MAIVE relative to PET-PEESE.</title><p>Notes: The figure compares the results, in absolute value, of MAIVE and PET-PEESE for the sample of economics meta-analyses<sup><xref ref-type="bibr" rid="CR56">56</xref></sup>. Only meta-analyses with the <italic toggle="yes">F</italic>&#160;&gt;&#160;100 from the first-stage regression of MAIVE are included. In most cases, MAIVE adjustment moves PET-PEESE estimates closer to zero.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="d33e1699" position="float" orientation="portrait" xlink:href="41467_2025_63261_Fig3_HTML.jpg"/></fig></p></sec></sec><sec id="Sec9" sec-type="discussion"><title>Discussion</title><p id="Par40">Simulations reveal three stylized facts. First, spurious precision can plausibly arise in observational research, for example through <italic toggle="yes">p</italic>-hacking. Second, even a modest degree of spurious precision&#8212;introduced in our simulations via selection on standard errors&#8212;can create formidable challenges for existing meta-analysis models based on inverse-variance weighting, including those designed to correct for publication bias. Third, the Meta-Analysis Instrumental Variable Estimator (MAIVE) we introduce significantly reduces the resulting bias in meta-analysis.</p><p id="Par41">Empirical applications reveal that spurious precision matters in practice: (i) MAIVE produces results that systematically differ from those of unadjusted meta-analysis models, and (ii) it helps explain the discrepancy identified by Kvarven et al.<sup><xref ref-type="bibr" rid="CR55">55</xref></sup>, between meta-analytic estimates and replication results, as MAIVE typically reduces meta-analytic effects. These applications are crucial for corroborating the presence of spurious precision, since no simulation, however comprehensive, can fully capture the complexity of real-world research. Controlled but necessarily stylized simulations are thus complemented by empirical applications that use real data from published studies. Together, they provide converging evidence that spurious precision is an important issue in observational research.</p><p id="Par42">Our results imply that the default use of inverse-variance weights in meta-analysis is problematic. Under classical assumptions, these weights increase the precision of the overall estimate. But when spurious precision is present, inverse-variance weighting can distort inference or even introduce bias. In fact, with enough spurious precision and publication selection, a simple unweighted mean of reported estimates can be less biased than sophisticated inverse-variance-weighted models designed to correct the very bias affecting the mean. In other words, spurious precision can produce more bias than classical publication bias. Our simulations and empirical applications show that dropping inverse-variance weights often does not harm, and can sometimes improve, the performance of meta-analytic estimators.</p><p id="Par43">The estimator we recommend, MAIVE, builds on PET-PEESE (a variant of Egger regression), but drops inverse-variance weights and replaces the reported variance with the portion explainable by inverse sample size, using an instrumental variables approach. MAIVE has three limitations. First, the instrument should be strong: the correlation between inverse sample size and reported variance needs to be substantial. Our empirical applications show that MAIVE&#8217;s performance improves with instrument strength. Caution is warranted if the <italic toggle="yes">F</italic>-statistic from the first-stage regression of reported variance on inverse sample size falls below 10. The weak-instrument-robust Anderson-Rubin confidence interval, computed by our maive package, should be reported. Second, because MAIVE uses a two-stage estimator, it is relatively imprecise and performs better in larger meta-analyses. Third, MAIVE assumes that sample size is not subject to selection. If meta-analysts suspect that authors systematically choose sample sizes based on expected effect sizes, MAIVE may not offer an advantage over conventional estimators.</p><p id="Par44">When inverse sample size is strongly correlated with reported variance, the number of estimates is at least in the double digits, and sample size is not itself likely to be selected upon, MAIVE can be applied with minimal cost in virtually any meta-analysis. In practice, meta-analysts only need to collect sample sizes from primary studies, a step many already take. Our results show that while MAIVE does not eliminate bias entirely, it outperforms traditional bias-correction estimators when spurious precision is substantial. When spurious precision is negligible, MAIVE performs similarly to standard techniques. It thus serves as a valuable robustness check, even when spurious precision is not initially suspected.</p><p id="Par45">Why not simply replace reported variance with inverse sample size, as proposed in earlier work<sup><xref ref-type="bibr" rid="CR37">37</xref>,<xref ref-type="bibr" rid="CR57">57</xref>&#8211;<xref ref-type="bibr" rid="CR59">59</xref></sup>? While such a substitution also addresses spurious precision, the instrumental variable approach offers several advantages, as detailed in Supplementary Information (<xref rid="MOESM1" ref-type="media">S1</xref>). One key advantage is flexibility: the instrumental approach can incorporate other aspects of study design, beyond sample size, that affect precision. Because sample size is rarely a perfect proxy for true variance, MAIVE accounts for this imperfection through Anderson-Rubin confidence intervals. The method can also be extended with additional instruments, such as variables related to clustering, heteroskedasticity adjustment, or identification strategy in primary studies, to improve fit and robustness.</p><p id="Par46">Spurious precision can also be addressed by using the original data from primary studies, as done in individual participant data meta-analysis, the emerging gold standard in medicine<sup><xref ref-type="bibr" rid="CR60">60</xref></sup>. This approach, however, remains infeasible in most observational research due to limited availability of data and code, as well as substantial methodological heterogeneity. In contrast, MAIVE is feasible in most contexts. By dropping inverse-variance weights, MAIVE is conceptually closer to a random-effects&#160;meta-analysis model that accounts for extreme heterogeneity than to a fixed-effect model. Given its minimal data requirements and strong performance in the presence of spurious precision, we recommend that MAIVE be routinely reported alongside conventional meta-analysis estimators. The maive R package and web interface (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="http://spuriousprecision.com">spuriousprecision.com</ext-link>) provide accessible tools for implementation.</p></sec><sec id="Sec10"><title>Methods</title><sec id="Sec11"><title>Stylized selection simulation</title><p id="Par47">This scenario allows us to cleanly separate selection on estimates from selection on standard errors, and the separation forms a useful benchmark and starting point for the more realistic <italic toggle="yes">p</italic>-hacking scenario. All codes and data used in this study are available in GitHub and Zenodo<sup><xref ref-type="bibr" rid="CR61">61</xref></sup>.</p><sec id="Sec12"><title>Generation of primary data</title><p id="Par48">The primary data in the stylized scenario are generated according to<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="d33e1770">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Y={\alpha }_{0}+{\alpha }_{1}X+u,$$\end{document}</tex-math><mml:math id="d33e1776"><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>X</mml:mi><mml:mo>+</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo></mml:math><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="anchor" orientation="portrait" xlink:href="41467_2025_63261_Article_Equ5.gif"/></alternatives></disp-formula>where <italic toggle="yes">&#945;</italic><sub>0</sub>&#160;=&#160;0 (without loss of generality), <italic toggle="yes">X</italic>&#160;~&#160;<italic toggle="yes">U</italic>(0,&#160;1) and <inline-formula id="IEq6"><alternatives><tex-math id="d33e1806">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$u \sim N(0,{\sigma }_{u}^{2})$$\end{document}</tex-math><mml:math id="d33e1811"><mml:mi>u</mml:mi><mml:mo>~</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq6.gif"/></alternatives></inline-formula>. The parameter of interest to meta-analysis is <italic toggle="yes">&#945;</italic><sub>1</sub>. Let <italic toggle="yes">i</italic> index each primary study and let there be <italic toggle="yes">M</italic> such primary studies, so that <italic toggle="yes">i</italic>&#160;=&#160;1,&#160;2,&#160;&#8230;,&#160;<italic toggle="yes">M</italic>. Each primary study obtains random samples of size <italic toggle="yes">N</italic><sub><italic toggle="yes">i</italic></sub> for variables <italic toggle="yes">Y</italic> and <italic toggle="yes">X</italic>, estimates the regression model specified by Eq. (<xref rid="Equ5" ref-type="disp-formula">5</xref>), and reports the OLS estimate of <italic toggle="yes">&#945;</italic><sub>1</sub> and the corresponding standard error.</p></sec><sec id="Sec13"><title>Selection</title><p id="Par49">We simulate a case in which some researchers prefer positive and statistically significant estimates of <italic toggle="yes">&#945;</italic><sub>1</sub>. In the stylized scenario, a fraction <italic toggle="yes">&#960;</italic> of the researchers engage in questionable research practices and are willing to change, by any means necessary, either the reported estimates (E-selection) or the standard errors (SE-selection) in order to inflate the statistical significance of their findings. They do so only when obtaining a positive but statistically insignificant estimate. Hence, when the obtained estimate is either negative or positive but statistically significant, the results are reported without any change. If, on the contrary, the obtained estimate is positive but statistically insignificant, the researcher changes the originally obtained findings with probability <italic toggle="yes">&#960;</italic>.</p><p id="Par50">With probability <italic toggle="yes">&#981;</italic>, a researcher willing to engage in questionable research practices chooses SE-selection, replacing the obtained standard error by a value that is just enough to achieve statistical significance at the 5% level (two-sided); that is, the reported standard error is <inline-formula id="IEq7"><alternatives><tex-math id="d33e1886">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{\alpha }}_{1}/1.96$$\end{document}</tex-math><mml:math id="d33e1891"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:mn>1.96</mml:mn></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq7.gif"/></alternatives></inline-formula>. With probability 1-<italic toggle="yes">&#981;</italic> the researcher chooses instead E-selection, replacing the obtained estimate by a value that is just enough to achieve statistical significance at the 5% level; that is, the reported estimate is <inline-formula id="IEq8"><alternatives><tex-math id="d33e1908">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$SE({\hat{\alpha }}_{1})\times 1.96$$\end{document}</tex-math><mml:math id="d33e1913"><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#215;</mml:mo><mml:mn>1.96</mml:mn></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq8.gif"/></alternatives></inline-formula>.</p><p id="Par51">In this environment, therefore, the overall magnitude of publication selection is measured by <italic toggle="yes">&#960;,</italic> and the relative importance of SE-selection versus E-selection is measured by <italic toggle="yes">&#981;</italic>. Note that, to keep perfect control on <italic toggle="yes">&#981;</italic> as measuring the relative importance of the two types of selection, we assume that researchers do not engage in both types simultaneously. This is also the reason why we assume that negative estimates are not subject to selection; otherwise, a negative estimate would have to become positive, which would necessarily involve E-selection. This restriction will be removed in the <italic toggle="yes">p</italic>-hacking scenario.</p></sec><sec id="Sec14"><title>Parameter values and distributions</title><p id="Par52">We implement this type of selection by means of the parameter values and distributions summarized in Supplementary Table <xref rid="MOESM1" ref-type="media">S3</xref> in the&#160;<xref rid="MOESM1" ref-type="media">Supplementary Information</xref>. The number of studies in a meta-analysis is <italic toggle="yes">M</italic>&#160;=&#160;80 in line with previous related simulations<sup><xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR9">9</xref></sup>. In Supplementary Information (<xref rid="MOESM1" ref-type="media">S4</xref>) we also consider simulations with <italic toggle="yes">M</italic>&#160;=&#160;30. We assume that primary sample sizes are drawn from a uniform distribution over (30, 1000); in the next section we will calibrate the sample size distribution based on 436 published meta-analyses. We consider three alternative values of <italic toggle="yes">&#945;</italic><sub>1</sub>: zero, one, and two. We interpret these values as representing no effect, a moderate effect, and a large effect, respectively. We assume that the probability of potentially engaging in questionable research practices is <italic toggle="yes">&#960;</italic>&#160;=&#160;0.5 and let <italic toggle="yes">&#981;</italic> vary from 0 to 1 in steps of 0.25. Note that <italic toggle="yes">&#981;</italic>&#160;=&#160;0 corresponds to pure E-selection, whereas <italic toggle="yes">&#981;</italic>&#160;=&#160;1 corresponds to pure SE-selection. Finally, we calibrate <inline-formula id="IEq9"><alternatives><tex-math id="d33e1991">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sigma }_{u}^{2}=3.3$$\end{document}</tex-math><mml:math id="d33e1996"><mml:msubsup><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>3.3</mml:mn></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq9.gif"/></alternatives></inline-formula> in order to generate similar effective incidences of selection for <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;0 and <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;2, which is about 24% in both cases; for <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;1 it is a bit larger, at about 32%. (The effective incidence of selection is the overall fraction of findings subject to selection. Note that, in this scenario, effective selection incidence has a hump-shaped profile when graphed against <italic toggle="yes">&#945;</italic><sub>1</sub>. This is because of the assumption of no selection on negative findings. Hence, when <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;0, selection incidence is not very high because approximately half of the estimates are negative. It gets higher for <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;1, because less estimates are then negative. And it gets lower again for <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;2 because more estimates become significantly positive naturally, even without selection.)</p></sec><sec id="Sec15"><title>Replications and statistics</title><p id="Par53">To study the performance of the 7 baseline estimators and their MAIVE variants, we set the number of replications to <italic toggle="yes">R</italic>&#160;=&#160;2000. We compute the bias and the mean squared error (MSE) of each estimator by averaging the estimation errors and the squared estimation errors over <italic toggle="yes">R</italic>. Hence, for a generic estimator <italic toggle="yes">z</italic>, the two statistics are given by:<disp-formula id="Equa"><alternatives><tex-math id="d33e2051">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{rcl}\,{{\mbox{Bias}}}\,(z)&amp;=&amp;\frac{1}{R}{\sum }_{i=1}^{R}\left({z}_{i}-{\alpha }_{1}\right)\\ \,{{\mbox{MSE}}}\,(z)&amp;=&amp;\frac{1}{R}{\sum }_{i=1}^{R}{\left({z}_{i}-{\alpha }_{1}\right)}^{2}\end{array}$$\end{document}</tex-math><mml:math id="d33e2056"><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>Bias</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msubsup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>MSE</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mo mathsize="big">&#8721;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="anchor" orientation="portrait" xlink:href="41467_2025_63261_Article_Equa.gif"/></alternatives></disp-formula>In addition, we also compute the coverage rates of each estimator by counting the number of confidence intervals that contain the true value of <italic toggle="yes">&#945;</italic><sub>1</sub> as a fraction of the total number of replications. All the results of the simple stylized scenario are discussed in the Supplementary Information (<xref rid="MOESM1" ref-type="media">S1</xref>).</p></sec></sec><sec id="Sec16"><title><italic toggle="yes">P</italic>-hacking simulation</title><sec id="Sec17"><title>Generation of primary data</title><p id="Par54">In the more realistic <italic toggle="yes">p</italic>-hacking simulation the data generating process for primary studies includes not one but two regressors, <italic toggle="yes">X</italic><sub>1</sub> and <italic toggle="yes">X</italic><sub>2</sub>:<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="d33e2176">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Y={\alpha }_{0}+{\alpha }_{1}{X}_{1}+{\alpha }_{2}{X}_{2}+u,$$\end{document}</tex-math><mml:math id="d33e2182"><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo></mml:math><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="anchor" orientation="portrait" xlink:href="41467_2025_63261_Article_Equ6.gif"/></alternatives></disp-formula>where, again, <italic toggle="yes">&#945;</italic><sub>0</sub>&#160;=&#160;0 (without loss of generality), <italic toggle="yes">X</italic><sub>1</sub>&#160;~&#160;<italic toggle="yes">U</italic>(0,&#160;1), and <inline-formula id="IEq10"><alternatives><tex-math id="d33e2230">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$u \sim N(0,{\sigma }_{u}^{2})$$\end{document}</tex-math><mml:math id="d33e2235"><mml:mi>u</mml:mi><mml:mo>~</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq6.gif"/></alternatives></inline-formula>. The second regressor, <italic toggle="yes">X</italic><sub>2</sub>, is a convex combination of <italic toggle="yes">X</italic><sub>1</sub> and an independent random term <italic toggle="yes">&#1013;</italic>&#160;~&#160;<italic toggle="yes">N</italic>(0,&#160;1); i.e., <italic toggle="yes">X</italic><sub>2</sub>&#160;=&#160;<italic toggle="yes">&#968;</italic><italic toggle="yes">X</italic><sub>1</sub>&#160;+&#160;(1&#160;&#8722;&#160;<italic toggle="yes">&#968;</italic>)<italic toggle="yes">&#1013;</italic>, where <italic toggle="yes">&#968;</italic>&#160;&#8712;&#160;(0,&#160;1). Hence, <italic toggle="yes">X</italic><sub>1</sub> and <italic toggle="yes">X</italic><sub>2</sub> are positively correlated by construction, this correlation being governed by <italic toggle="yes">&#968;</italic>. The parameter of interest to meta-analysis is <italic toggle="yes">&#945;</italic><sub>1</sub>. In some simulations in the Supplementary Information (<xref rid="MOESM1" ref-type="media">S3</xref>), this parameter is allowed to be random. In this case, <italic toggle="yes">&#945;</italic><sub>1</sub> refers to its mean and <inline-formula id="IEq11"><alternatives><tex-math id="d33e2313">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sigma }_{{\alpha }_{1}}^{2}$$\end{document}</tex-math><mml:math id="d33e2318"><mml:msubsup><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq11.gif"/></alternatives></inline-formula> is its variance. The <italic toggle="yes">M</italic> primary studies each report an OLS estimate and a corresponding standard error of <italic toggle="yes">&#945;</italic><sub>1</sub> using a sample of size <italic toggle="yes">N</italic><sub><italic toggle="yes">i</italic></sub>. The numerical values of the parameters depend on the selection mechanism assumed and are discussed below.</p></sec><sec id="Sec18"><title>Selection</title><p id="Par55">In this selection scenario, some researchers engage in questionable research practices by manipulating the specification of the model. In particular, we assume that primary studies start by estimating the correctly specified model (Eq. (<xref rid="Equ6" ref-type="disp-formula">6</xref>)). If the obtained estimate of <italic toggle="yes">&#945;</italic><sub>1</sub> is not positive and statistically significant in the correctly specified model, then, with probability <italic toggle="yes">&#960;</italic>, the dissatisfied authors of such a primary study replace the true control variable <italic toggle="yes">X</italic><sub>2</sub> by a different control variable, <italic toggle="yes">X</italic><sub>3</sub>. They try many such variables until they find one that &#8216;works,&#8217; in the sense of turning the estimate of <italic toggle="yes">&#945;</italic><sub>1</sub> positive and statistically significant. (We implement this idea by first uniformly drawing a correlation coefficient between <italic toggle="yes">X</italic><sub>2</sub> and <italic toggle="yes">X</italic><sub>3</sub>, constrained to be positive and less than 0.8. We then generate variable <italic toggle="yes">X</italic><sub>3</sub> to match this correlation with <italic toggle="yes">X</italic><sub>2</sub>. The maximum correlation of 0.8 is imposed just to save on computing time, since very high correlations do not help the cause of getting statistical significance.)</p><p id="Par56">Replacing <italic toggle="yes">X</italic><sub>2</sub> by a related but weaker control variable <italic toggle="yes">X</italic><sub>3</sub> helps achieving statistical significance through both E-selection and SE-selection. E-selection works through the bias it causes on the estimate of <italic toggle="yes">&#945;</italic><sub>1</sub>. Because <italic toggle="yes">X</italic><sub>1</sub> and <italic toggle="yes">X</italic><sub>2</sub> are positively correlated, dropping <italic toggle="yes">X</italic><sub>2</sub> in fact biases the estimate of <italic toggle="yes">&#945;</italic><sub>1</sub> upwards (omitted-variable bias), making statistical significance more likely. The bias increases with the correlation between <italic toggle="yes">X</italic><sub>1</sub> and <italic toggle="yes">X</italic><sub>2</sub> and with the value of <italic toggle="yes">&#945;</italic><sub>2</sub>. The bias is somewhat mitigated by the inclusion of <italic toggle="yes">X</italic><sub>3</sub>. Note that, by inducing biases in the reported estimates, <italic toggle="yes">p</italic>-hacking causes not only publication selection but also excess variation in the reported findings (i.e., heterogeneity), a feature that characterizes most meta-analyses in observational research. In economics, for example, heterogeneity&#8212;rather than the unconditional mean&#8212;is often the focus of applied meta-analyses.</p><p id="Par57">The <italic toggle="yes">p</italic>-hacking process also causes SE-selection: replacing <italic toggle="yes">X</italic><sub>2</sub> by a weaker control decreases collinearity, thus artificially decreasing the SE of the estimate of <italic toggle="yes">&#945;</italic><sub>1</sub> relative to the SE in the correctly specified model. SE-selection increases with the correlation between <italic toggle="yes">X</italic><sub>1</sub> and <italic toggle="yes">X</italic><sub>2</sub>, governed by <italic toggle="yes">&#968;</italic>, but proportionally more so than E-selection. (To see this, note that E-selection depends on the bias of the estimate of <italic toggle="yes">&#945;</italic><sub>1</sub>. At most, in case <italic toggle="yes">X</italic><sub>2</sub> is dropped or replaced by an irrelevant control, this bias is given by <italic toggle="yes">&#968;</italic><italic toggle="yes">&#945;</italic><sub>2</sub>, and thus increases linearly with <italic toggle="yes">&#968;</italic>. But SE-selection increases more than linearly with <italic toggle="yes">&#968;</italic>. This is because the SE of <inline-formula id="IEq12"><alternatives><tex-math id="d33e2488">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{\alpha }}_{1}$$\end{document}</tex-math><mml:math id="d33e2493"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq12.gif"/></alternatives></inline-formula> in a model where <italic toggle="yes">X</italic><sub>2</sub> is included can be written as <inline-formula id="IEq13"><alternatives><tex-math id="d33e2510">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c\sqrt{1/(1-{\psi }^{2})}$$\end{document}</tex-math><mml:math id="d33e2515"><mml:mi>c</mml:mi><mml:msqrt><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:msup><mml:mrow><mml:mi>&#968;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq13.gif"/></alternatives></inline-formula>, where <italic toggle="yes">c</italic> depends on the variances of <italic toggle="yes">Y</italic> and <italic toggle="yes">X</italic><sub>1</sub>, on the <italic toggle="yes">R</italic><sup>2</sup> of the regression, and the sample size, but is invariant to <italic toggle="yes">&#968;</italic>. So the SE increases more than linearly with <italic toggle="yes">&#968;</italic>, approaching infinity as <italic toggle="yes">&#968;</italic> approaches one.) Thus this scenario still allows us to control the relative magnitude of SE-selection versus E-selection, albeit indirectly and imperfectly. It is not possible to fully decouple the two flavors of selection in this simulation environment, unlike in the stylized scenario.</p><p id="Par58">On a technical note, we limit the number of control variables attempted by <italic toggle="yes">p</italic>-hackers to <italic toggle="yes">H</italic>. If, at the <italic toggle="yes">H</italic>-th attempt, the estimate of <italic toggle="yes">&#945;</italic><sub>1</sub> remains negative or statistically insignificant, the <italic toggle="yes">p</italic>-hacker gives up the <italic toggle="yes">p</italic>-hacking search and resorts instead to an entirely new dataset, starting the process all over again. We do so because it may be extremely difficult (and time-consuming, from a computational perspective) in some cases to <italic toggle="yes">p</italic>-hack a very negative estimate into a significantly positive one. This is especially the case when <italic toggle="yes">&#945;</italic><sub>1</sub> is very small, which, by sampling error alone, may generate substantially negative estimates in some datasets.</p></sec><sec id="Sec19"><title>Parameter values and distributions</title><p id="Par59">We implement <italic toggle="yes">p</italic>-hacking selection using the parameter values and distributions summarized in Table S4 in the&#160;<xref rid="MOESM1" ref-type="media">Supplementary Information</xref>. A key parameter in the simulations is <italic toggle="yes">&#968;</italic>, the correlation between <italic toggle="yes">X</italic><sub>1</sub> and <italic toggle="yes">X</italic><sub>2</sub>, since it governs the relative degree of SE-selection versus E-selection. The higher its values, the larger the relative degree of SE-selection. (We can quantify, for each value of <italic toggle="yes">&#968;</italic>, the relative importance of SE-selection that would correspond to parameter <italic toggle="yes">&#981;</italic> in the stylized scenario; see below.) We let <italic toggle="yes">&#968;</italic> take on values from 0.5 to 0.9 in steps of 0.1, using the middle value of 0.7 as the baseline value for the calibration of other parameters. In line with related simulation studies<sup><xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR9">9</xref></sup>, we assume a meta-analysis of <italic toggle="yes">M</italic>&#160;=&#160;80 studies (<italic toggle="yes">M</italic>&#160;=&#160;30 in the Supplementary Information&#160;<xref rid="MOESM1" ref-type="media">S3</xref>) and a probability of engaging in publication selection (in this context, the fraction of potential <italic toggle="yes">p</italic>-hackers) of <italic toggle="yes">&#960;</italic>&#160;=&#160;50%. The maximum number of <italic toggle="yes">p</italic>-hacking attempts before drawing new data is set at <italic toggle="yes">H</italic>&#160;=&#160;50.</p><p id="Par60">Regarding the true effect, we consider the cases where it is nil (<italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;0) and where it is positive (<italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;1). We do not separately consider a case of a large effect as in the stylized scenario, because once again the results would be qualitatively comparable to <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;1, so we have just one value for the positive effect. We set the remaining parameters (especially <inline-formula id="IEq14"><alternatives><tex-math id="d33e2661">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sigma }_{u}^{2}$$\end{document}</tex-math><mml:math id="d33e2666"><mml:msubsup><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq14.gif"/></alternatives></inline-formula>) so that <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;1 is neither too small nor too large an effect. If <inline-formula id="IEq15"><alternatives><tex-math id="d33e2681">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sigma }_{u}^{2}$$\end{document}</tex-math><mml:math id="d33e2686"><mml:msubsup><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq14.gif"/></alternatives></inline-formula> is too large, <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;1 effectively represents a small effect. Conversely, when <inline-formula id="IEq16"><alternatives><tex-math id="d33e2700">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sigma }_{u}^{2}$$\end{document}</tex-math><mml:math id="d33e2705"><mml:msubsup><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq14.gif"/></alternatives></inline-formula> is too small, <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;1 effectively represents a large effect. Moreover, the larger the effective size of <italic toggle="yes">&#945;</italic><sub>1</sub>, the smaller the effective incidence of publication selection, eventually dropping to zero. For <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;0, the effective incidence of selection is about 49%. (This assumes that primary studies test the null hypothesis that <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;0 using a two-sided test at the 5% level. Hence, the probability of not finding a significantly positive value is 97.5%. Because only half of the studies engage in publication selection, the effective selection incidence is half of this rate, that is, 48.75%.) We then choose <inline-formula id="IEq17"><alternatives><tex-math id="d33e2733">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sigma }_{u}^{2}$$\end{document}</tex-math><mml:math id="d33e2738"><mml:msubsup><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq14.gif"/></alternatives></inline-formula> so that the effective selection incidence for <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;1 is half of the incidence for <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;0&#8212;that is, 24%. (With <italic toggle="yes">&#968;</italic>&#160;=&#160;0.6, it is about 21%; with <italic toggle="yes">&#968;</italic>&#160;=&#160;0.8, it is about 30%). The implied value of <inline-formula id="IEq18"><alternatives><tex-math id="d33e2763">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sigma }_{u}^{2}$$\end{document}</tex-math><mml:math id="d33e2768"><mml:msubsup><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq14.gif"/></alternatives></inline-formula> is 5.06.</p><p id="Par61">Note that we focus on non-standardized effect sizes, regression coefficients. If we focused on a standardized effect size, such as standardized mean difference, we would inevitably introduce a mechanical correlation between estimates and standard errors. This correlation would obscure our simulations because our goal in this paper is to model spurious precision that arises due to selection on standard errors, not other sources of endogeneity of the standard error. The interpretation of the effect size is not important for our simulation as long as the values fall within a range that matters for publication selection. For simplicity, we chose true effect values of 0 a 1 and calibrate the variance of the error term for publication bias to matter for these values. However, in standardized terms, given that the standard deviation of <italic toggle="yes">Y</italic> is about 2.35 and that of <italic toggle="yes">X</italic><sub>1</sub> is about 0.29, <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;1 implies that one standard deviation increase in <italic toggle="yes">X</italic><sub>1</sub> increases <italic toggle="yes">Y</italic> by about 0.29/2.35&#8201;=&#8201;0.12 standard deviations. That is, the partial correlation coefficient is about 0.12. While the value may seem low, it is consistent with common meta-analyses in our second empirical application: across hundreds of meta-analyses and 170,900 partial correlations, the mean is 0.16 and the median 0.08. For <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;2, the standard deviation of <italic toggle="yes">Y</italic> increases slightly to about 2.52, so that the standardized effect is 2*0.29/2.52&#8201;=&#8201;0.23&#8212;i.e., one standard deviation of <italic toggle="yes">X</italic><sub>1</sub> increases <italic toggle="yes">Y</italic> by about 0.23 standard deviations&#8212;almost twice as large as for <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;1.</p><p id="Par62">The <italic toggle="yes">p</italic>-hacking scenario generates heterogeneity. Given <inline-formula id="IEq19"><alternatives><tex-math id="d33e2823">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sigma }_{u}^{2}$$\end{document}</tex-math><mml:math id="d33e2828"><mml:msubsup><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq14.gif"/></alternatives></inline-formula>, <italic toggle="yes">&#945;</italic><sub>1</sub>, and <italic toggle="yes">&#968;</italic>, the main parameter determining the degree of heterogeneity is <italic toggle="yes">&#945;</italic><sub>2</sub>. Based on the findings of applied meta-analyses, simulation studies<sup><xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR9">9</xref></sup> often assume values of <italic toggle="yes">I</italic><sup>2</sup> of at least 70%. By setting <italic toggle="yes">&#945;</italic><sub>2</sub>&#160;=&#160;2, we arrive at an <italic toggle="yes">I</italic><sup>2</sup> of about 73% for <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;0 (for <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;1, the <italic toggle="yes">I</italic><sup>2</sup> is about half). When allowing for true effect heterogeneity (Supplementary Information&#160;<xref rid="MOESM1" ref-type="media">S3</xref>), we set <inline-formula id="IEq20"><alternatives><tex-math id="d33e2886">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sigma }_{{\alpha }_{1}}^{2}$$\end{document}</tex-math><mml:math id="d33e2891"><mml:msubsup><mml:mrow><mml:mi>&#963;</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq11.gif"/></alternatives></inline-formula> at 0.64. This further increases the <italic toggle="yes">I</italic><sup>2</sup> by about 9 percentage points when <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;0; and by about 40 percentage points when <italic toggle="yes">&#945;</italic><sub>1</sub>&#160;=&#160;1. The sample size of a primary study, <italic toggle="yes">N</italic><sub><italic toggle="yes">i</italic></sub>, is drawn from a truncated gamma distribution &#915;(<italic toggle="yes">a</italic>,&#160;<italic toggle="yes">b</italic>). Note that the mean of this distribution is given by <italic toggle="yes">a</italic><italic toggle="yes">b</italic> and the variance by <italic toggle="yes">a</italic><italic toggle="yes">b</italic><sup>2</sup>. We choose the values of <italic toggle="yes">a</italic> and <italic toggle="yes">b</italic> to match the research record. Using a database of 436 meta-analyses in economics and related fields compiled by Chris Doucouliagos<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>, we find the medians of the mean and variance of the sample sizes within the individual meta-analyses to be 473 and 588<sup>2</sup>, respectively; using these as target values, we find the required gamma parameters to be <italic toggle="yes">a</italic>&#160;=&#160;0.65 and <italic toggle="yes">b</italic>&#160;=&#160;731. We truncate the distribution from below, so that a sample size is never smaller than 30.</p></sec><sec id="Sec20"><title>Implied relative degree of SE-selection</title><p id="Par63">As mentioned above, we control the relative degrees of selection on estimates and selection on standard errors indirectly through the parameter <italic toggle="yes">&#968;</italic>. In the stylized scenario, this relative degree was controlled directly through <italic toggle="yes">&#981;</italic>. Although we cannot control <italic toggle="yes">&#981;</italic> directly here, we can nevertheless infer its size for each value of <italic toggle="yes">&#968;</italic>. To do so, start by denoting, for the set of selected estimates, the observed (post-selection, hacked) <italic toggle="yes">t</italic>-statistic of <inline-formula id="IEq21"><alternatives><tex-math id="d33e2981">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{\alpha }}_{1}$$\end{document}</tex-math><mml:math id="d33e2986"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq12.gif"/></alternatives></inline-formula> by <inline-formula id="IEq22"><alternatives><tex-math id="d33e2998">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t={\hat{\alpha }}_{1}/\,{\mbox{SE}}\,({\hat{\alpha }}_{1})$$\end{document}</tex-math><mml:math id="d33e3003"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>SE</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq22.gif"/></alternatives></inline-formula> and the original (pre-selection, unhacked) <italic toggle="yes">t</italic>-statistic by <inline-formula id="IEq23"><alternatives><tex-math id="d33e3038">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${t}^{ * }={\hat{\alpha }}_{1}^{ * }/\,{\mbox{SE}}\,{({\hat{\alpha }}_{1})}^{ * }$$\end{document}</tex-math><mml:math id="d33e3043"><mml:msup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup><mml:mo>/</mml:mo><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>SE</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq23.gif"/></alternatives></inline-formula>. Of course, the objective of selection is to increase the size of the <italic toggle="yes">t</italic>-statistic, so <italic toggle="yes">t</italic>&#160;&gt;&#160;<italic toggle="yes">t</italic>*. E-selection implies <inline-formula id="IEq24"><alternatives><tex-math id="d33e3095">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{\alpha }}_{1} &gt; {\hat{\alpha }}_{1}^{ * }$$\end{document}</tex-math><mml:math id="d33e3100"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq24.gif"/></alternatives></inline-formula> and SE-selection implies <inline-formula id="IEq25"><alternatives><tex-math id="d33e3124">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\,{\mbox{SE}}\,({\hat{\alpha }}_{1}) &lt; \,{\mbox{SE}}\,{({\hat{\alpha }}_{1})}^{ * }$$\end{document}</tex-math><mml:math id="d33e3129"><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>SE</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>SE</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq25.gif"/></alternatives></inline-formula>. In the <italic toggle="yes">p</italic>-hacking scenario, however, both types usually occur simultaneously and <italic toggle="yes">&#981;</italic> measures the relative importance of each. Because <inline-formula id="IEq26"><alternatives><tex-math id="d33e3177">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t/{t}^{ * }=({\hat{\alpha }}_{1}/{\hat{\alpha }}_{1}^{ * })\times (\,{\mbox{SE}}\,{({\hat{\alpha }}_{1})}^{ * }/\,{\mbox{SE}}\,({\hat{\alpha }}_{1}))$$\end{document}</tex-math><mml:math id="d33e3182"><mml:mi>t</mml:mi><mml:mo>/</mml:mo><mml:msup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#215;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>SE</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup><mml:mo>/</mml:mo><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>SE</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq26.gif"/></alternatives></inline-formula>, it follows that<disp-formula id="Equb"><alternatives><tex-math id="d33e3263">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\ln \left(\frac{t}{{t}^{ * }}\right)=\ln \left(\frac{{\hat{\alpha }}_{1}}{{\hat{\alpha }}_{1}^{ * }}\right)+\ln \left(\frac{\,{\mbox{SE}}\,{({\hat{\alpha }}_{1})}^{ * }}{\,{\mbox{SE}}\,({\hat{\alpha }}_{1})}\right),$$\end{document}</tex-math><mml:math id="d33e3268"><mml:mo>ln</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mfrac><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo>ln</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mo>ln</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mfrac><mml:mrow><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>SE</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>SE</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="anchor" orientation="portrait" xlink:href="41467_2025_63261_Article_Equb.gif"/></alternatives></disp-formula>which decomposes the amount of publication selection in selected estimates (percent change of the <italic toggle="yes">t</italic>-statistic) into its E-selection component (given by the first term, the percent increase of <inline-formula id="IEq27"><alternatives><tex-math id="d33e3359">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{\alpha }}_{1}$$\end{document}</tex-math><mml:math id="d33e3364"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq12.gif"/></alternatives></inline-formula> after selection) and its SE-selection component (given by the second term, the percent decrease in <inline-formula id="IEq28"><alternatives><tex-math id="d33e3376">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\,{\mbox{SE}}\,({\hat{\alpha }}_{1})$$\end{document}</tex-math><mml:math id="d33e3381"><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>SE</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq28.gif"/></alternatives></inline-formula> after selection). Hence, the relative importance of SE-selection can be approximated by the relative size of the second term:<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="d33e3401">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi=\frac{\ln (\,{\mbox{SE}}\,{({\hat{\alpha }}_{1})}^{ * }/\,{\mbox{SE}}\,({\hat{\alpha }}_{1}))}{\ln (t/{t}^{ * })}.$$\end{document}</tex-math><mml:math id="d33e3407"><mml:mi>&#981;</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>ln</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>SE</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup><mml:mo>/</mml:mo><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>SE</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>ln</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>/</mml:mo><mml:msup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="anchor" orientation="portrait" xlink:href="41467_2025_63261_Article_Equ7.gif"/></alternatives></disp-formula>On a technical note, we need to impose some restrictions to ensure that 0&#8201;&#8804;&#8201;<italic toggle="yes">&#981;</italic>&#8201;&#8804;&#8201;1. If, for a particular selected estimate, <inline-formula id="IEq29"><alternatives><tex-math id="d33e3476">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\,{\mbox{SE}}\,({\hat{\alpha }}_{1}) &gt; \,{\mbox{SE}}\,{({\hat{\alpha }}_{1})}^{ * }$$\end{document}</tex-math><mml:math id="d33e3481"><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>SE</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mspace width="0.25em"/><mml:mstyle><mml:mtext>SE</mml:mtext></mml:mstyle><mml:mspace width="0.25em"/><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq29.gif"/></alternatives></inline-formula>, then selection must have occurred entirely through the estimates and we set <italic toggle="yes">&#981;</italic>&#160;=&#160;0. If, on the other hand, <inline-formula id="IEq30"><alternatives><tex-math id="d33e3526">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{\alpha }}_{1} &lt; {\hat{\alpha }}_{1}^{ * }$$\end{document}</tex-math><mml:math id="d33e3531"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_Article_IEq30.gif"/></alternatives></inline-formula>, then selection must have occurred through the standard errors, and we set <italic toggle="yes">&#981;</italic>&#160;=&#160;1.&#160;<xref rid="MOESM1" ref-type="media">Supplementary Information</xref> shows the values of <italic toggle="yes">&#981;</italic> corresponding to the various values of <italic toggle="yes">&#968;</italic> (Supplementary Table&#160;<xref rid="MOESM1" ref-type="media">S5</xref>). Clearly, the relative importance of SE-selection increases with <italic toggle="yes">&#968;</italic>. All the additional results of the <italic toggle="yes">p</italic>-hacking scenario, on top of those presented in the main text, are discussed in the Supplementary Information (<xref rid="MOESM1" ref-type="media">S1</xref>).</p></sec></sec><sec id="Sec21"><title>Application based on Kvarven et al.</title><p id="Par64">We follow the approach of Kvarven et al.<sup><xref ref-type="bibr" rid="CR55">55</xref></sup>, who use three meta-analysis estimators: PET-PEESE (as an example of a widely used funnel-based Egger-type technique), 3PSM (a widely used selection model&#160;similar to the Andrews-Kasy model used in our simulations), and Trim &amp; Fill (one of the simplest existing correction techniques). We extend the analysis of Kvarven et al. by including the MAIVE version of each of those three estimators. We are most interested in the comparison of PET-PEESE, which was found by Kvarven et al. to have the smallest bias, with the MAIVE version of PET-PEESE without any weights (the version of MAIVE that we have preferred throughout the manuscript).</p><p id="Par65">We recommend to use the MAIVE adjustment if minimal conditions for normal inference in regression analysis are met and, at the same time, if inverse sample size is a reliably strong instrument for reported variance. Regarding the former, for MAIVE we require each meta-analysis to use at least 30 estimates from primary studies (which, among other things, gives the meta-analyst hope that the regression confidence interval can be reliable). Regarding the latter, to be on the safe side in this application we require that the <italic toggle="yes">F</italic>-statistic from the first-stage regression, regressing reported variance on inverse sample size, is larger than 100. Keane and Neal<sup><xref ref-type="bibr" rid="CR27">27</xref></sup> argue that the commonly used threshold of 10 is often not enough to ensure a strong instrument and valid inference. They recommend researchers use the Anderson-Rubin confidence interval, which is robust to weak instruments and ensures valid inference. In our R package maive we allow researchers to obtain this substantially more robust confidence interval so that they can use MAIVE with lower values of the <italic toggle="yes">F</italic>-statistics as well.</p><p id="Par66">All the details on the results are reported in the Supplementary Information (<xref rid="MOESM1" ref-type="media">S2</xref>). In 8 out of the 15 meta-analyses, both conditions for MAIVE (sample size and instrument strength) are met. Out of these 8 meta-analyses, in 6 cases (75%) is the MAIVE version of PET-PEESE with no weights closer to the replication result than unadjusted PET-PEESE is. The MAIVE versions of Trim &amp; Fill and 3PSM do not behave so well, though: in both cases, the majority of MAIVE estimates are farther from the replication values than the standard estimates are. The <italic toggle="yes">F</italic> statistics from the first-stage regressions are generally pretty large, being larger than 10 in all cases, larger than 100 in all but 2, and larger than 1000 in more than half (8) of them. The meta-analyses are not always large, however: for instance, 5 of them use fewer than 30 estimates.</p><p id="Par67">The Supplementary Information (<xref rid="MOESM1" ref-type="media">S2</xref>) also reports the mean absolute deviations of each estimator, with and without the MAIVE adjustment, from the baseline (and arguably unbiased) preregistered multilab replication result. Across all meta-analyses, the MAIVE version of PET-PEESE is, on average, slightly farther from the replication value than the standard version. This finding holds for both weighted and unweighted MAIVE variants. However, if we confine the comparison to meta-analyses with <italic toggle="yes">F</italic>&#160;&gt;&#160;100, with sample sizes satisfying <italic toggle="yes">M</italic>&#160;&gt;&#160;30, or both, then the MAIVE versions of PET-PEESE, weighted or unweighted, are closer to the replication values than the standard PET-PEESE version is. Again, in this application the MAIVE adjustment does not improve the performance of Trim &amp; Fill and 3PSM.</p></sec><sec id="Sec22"><title>Application based on Bartos et al.</title><p id="Par68">The second MAIVE application is performed on a large dataset compiled by Chris Doucouliagos and used in Bartos et al.<sup><xref ref-type="bibr" rid="CR56">56</xref></sup>. The dataset comprises 613 meta-analyses (especially in economics, but also psychology, education, finance, business, political science, and sociology) and includes 209,766 estimates in total, almost exclusively those from observational studies. This unpublished dataset, which we acquired from the authors, includes estimates and standard errors, also with sample sizes in some cases. Because sample sizes are crucial for the MAIVE adjustment, we attempt to collect them for as many primary studies as possible.</p><p id="Par69">We restrict our analysis to (1) meta-analyses with at least 30 estimates (<italic toggle="yes">M</italic>&#160;&gt;&#160;30), (2) estimates based on at least 10 observations, (3) estimates with available sample sizes. Doing so reduces the set of usable meta-analyses to 348. We further censor the data at the 1% and 99% percentiles to limit the influence of extreme outliers. For each of the 348 meta-analyses we apply PET-PEESE and its MAIVE version. In 38 meta-analyses, a negative slope estimate appears in the first-stage regression; these meta-analyses are also discarded, resulting in a final set of 310 meta-analyses.</p><p id="Par70">If SE-selection is present, based on our previous <italic toggle="yes">p</italic>-hacking simulations we expect MAIVE to reduce the estimates of PET-PEESE: MAIVE should be less negative than PET-PEESE when PET-PEESE is negative, and less positive when PET-PEESE is positive. This is what we find and report in the main text (Table&#160;<xref rid="Tab3" ref-type="table">3</xref>). MAIVE corrects down PET-PEESE more strongly when the first-stage <italic toggle="yes">F</italic>-statistic is large. When <italic toggle="yes">F</italic>&#160;&gt;&#160;100, MAIVE estimates are smaller in absolute value than PET-PEESE estimates in 70.7% of the meta-analyses. It is also important to emphasize how likely it is that sample size is a strong instrument for standard errors: in 267 of the 310 meta-analyses for which a first-stage regression is computed (i.e., 86%), the first-stage <italic toggle="yes">F</italic> statistic exceeds 10. And in 239 of those (i.e., 77%), the <italic toggle="yes">F</italic> statistic is larger than 100.</p><p id="Par71">Finally, Fig.&#160;<xref rid="Fig3" ref-type="fig">3</xref> in the main body of the paper plots the histogram of the percentage change of MAIVE relative to PET-PEESE. Dark blue bars indicate negative changes, i.e. meta-analyses for which MAIVE is smaller than a positive PET-PEESE estimate or higher than a negative PET-PEESE estimate. The dark bars should dominate if MAIVE is to correct down PET-PEESE estimates. Light blue bars, in contrast, correspond to meta-analyses for which MAIVE exacerbates the PET-PEESE estimate. Clearly, and consistent with the results in Table&#160;<xref rid="Tab3" ref-type="table">3</xref>, MAIVE corrects down most PET-PEESE estimates.</p></sec><sec id="Sec23"><title>Reporting summary</title><p id="Par72">Further information on research design is available in the&#160;<xref rid="MOESM2" ref-type="media">Nature Portfolio Reporting Summary</xref> linked to this article.</p></sec></sec><sec id="Sec24" sec-type="supplementary-material"><title>Supplementary information</title><p>
<supplementary-material content-type="local-data" id="MOESM1" position="float" orientation="portrait"><media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_MOESM1_ESM.pdf" position="float" orientation="portrait"><caption><p>Supplementary Information</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM2" position="float" orientation="portrait"><media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_MOESM2_ESM.pdf" position="float" orientation="portrait"><caption><p>Reporting Summary</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM3" position="float" orientation="portrait"><media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="41467_2025_63261_MOESM3_ESM.pdf" position="float" orientation="portrait"><caption><p>Transparent Peer Review file</p></caption></media></supplementary-material>
</p></sec></body><back><fn-group><fn><p><bold>Publisher&#8217;s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><sec><title>Supplementary information</title><p>The online version contains supplementary material available at 10.1038/s41467-025-63261-0.</p></sec><ack><title>Acknowledgements</title><p>We are grateful to Frantisek Bartos, Stephan Bruns, Steven Goodman, John Ioannidis, Stepan Jurajda, Maya Mathur, Shinichi Nakagawa, Bob Reed, Tom Stanley, and Elizabeth Tipton for useful comments that helped us improve the paper. We thank Amanda Kvarven, Josh May, David Rand, and Chris Doucouliagos for sending us additional data on top of their published datasets. Z.I., P.R.D.B., and H.R. acknowledge support from the Czech Science Foundation (grant no. 23-05227M). P.R.D.B. also acknowledges support from the Basque Government Department of Education (grant no. IT1429-22). H.R. also acknowledges support from the Spanish Ministry of Science and Innovation (grant no. PID2020-114646RB-C43). P.R.D.B. and H.R. acknowledge support under grant PID2023-152916NB-I00 financed by MCIN/AEI/10.13039/ 501100011033. T.H. acknowledges support from the Czech Science Foundation (grant no. 24-11583S) and from the Institute for Research on the Socioeconomic Impact of Diseases and Systemic Risks (grant no. LX22NPO5101), funded by the European Union&#8211;Next Generation EU.</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p>Z.I. and T.H. proposed the research idea; P.R.D.B. and H.R. designed the simulations; Z.I. and T.H. collected data for applications; P.R.D.B. and H.R. coded the study and executed the simulations and applications; Z.I. interpreted the results, with assistance from T.H., P.R.D.B., and H.R.; Z.I. and T.H. wrote the main text, with assistance from P.R.D.B. and H.R. Finally, P.R.D.B. and H.R. wrote the&#160;<xref rid="MOESM1" ref-type="media">Supplementary Information</xref>, with assistance from T.H.</p></notes><notes notes-type="peer-review"><title>Peer review</title><sec id="FPar1"><title>Peer review information</title><p id="Par73"><italic toggle="yes">Nature Communications</italic> thanks the anonymous reviewers for their contribution to the peer review of this work. A peer review file is available.</p></sec></notes><notes notes-type="data-availability"><title>Data availability</title><p>All data used in this study have been deposited in the meta-analysis.cz database at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="http://www.meta-analysis.cz/maive">meta-analysis.cz/maive</ext-link> and archived at 10.5281/zenodo.15425605. These are raw data.</p></notes><notes notes-type="data-availability"><title>Code availability</title><p>All codes used in this study have been deposited in the GitHub database at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://github.com/meta-analysis-es/maive">github.com/meta-analysis-es/maive</ext-link> and archived at 10.5281/zenodo.15425605. The maive R package and an interactive web application are available at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://spuriousprecision.com">spuriousprecision.com</ext-link>.</p></notes><notes id="FPar2" notes-type="COI-statement"><title>Competing interests</title><p id="Par74">The authors declare no competing interests.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gurevitch</surname><given-names>J</given-names></name><name name-style="western"><surname>Koricheva</surname><given-names>J</given-names></name><name name-style="western"><surname>Nakagawa</surname><given-names>S</given-names></name><name name-style="western"><surname>Stewart</surname><given-names>G</given-names></name></person-group><article-title>Meta-analysis and the science of research synthesis</article-title><source>Nature</source><year>2018</year><volume>555</volume><fpage>175</fpage><lpage>182</lpage><pub-id pub-id-type="doi">10.1038/nature25753</pub-id><pub-id pub-id-type="pmid">29517004</pub-id></element-citation><mixed-citation id="mc-CR1" publication-type="journal">Gurevitch, J., Koricheva, J., Nakagawa, S. &amp; Stewart, G. Meta-analysis and the science of research synthesis. <italic toggle="yes">Nature</italic><bold>555</bold>, 175&#8211;182 (2018).<pub-id pub-id-type="pmid">29517004</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/nature25753</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Borenstein</surname><given-names>M</given-names></name><name name-style="western"><surname>Hedges</surname><given-names>L</given-names></name><name name-style="western"><surname>Higgins</surname><given-names>J</given-names></name><name name-style="western"><surname>Rothstein</surname><given-names>H</given-names></name></person-group><article-title>A basic introduction to fixed-effect and random-effects models for meta-analysis</article-title><source>Res. Synth. Methods</source><year>2010</year><volume>1</volume><fpage>97</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.1002/jrsm.12</pub-id><pub-id pub-id-type="pmid">26061376</pub-id></element-citation><mixed-citation id="mc-CR2" publication-type="journal">Borenstein, M., Hedges, L., Higgins, J. &amp; Rothstein, H. A basic introduction to fixed-effect and random-effects models for meta-analysis. <italic toggle="yes">Res. Synth. Methods</italic><bold>1</bold>, 97&#8211;111 (2010).<pub-id pub-id-type="pmid">26061376</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/jrsm.12</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR3"><label>3.</label><citation-alternatives><element-citation id="ec-CR3" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stanley</surname><given-names>TD</given-names></name><name name-style="western"><surname>Doucouliagos</surname><given-names>H</given-names></name></person-group><article-title>Neither fixed nor random: weighted least squares meta-analysis</article-title><source>Stat. Med.</source><year>2015</year><volume>34</volume><fpage>2116</fpage><lpage>2127</lpage><pub-id pub-id-type="doi">10.1002/sim.6481</pub-id><pub-id pub-id-type="pmid">25809462</pub-id></element-citation><mixed-citation id="mc-CR3" publication-type="journal">Stanley, T. D. &amp; Doucouliagos, H. Neither fixed nor random: weighted least squares meta-analysis. <italic toggle="yes">Stat. Med.</italic><bold>34</bold>, 2116&#8211;2127 (2015).<pub-id pub-id-type="pmid">25809462</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/sim.6481</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Egger</surname><given-names>M</given-names></name><name name-style="western"><surname>Smith</surname><given-names>GD</given-names></name><name name-style="western"><surname>Schneider</surname><given-names>M</given-names></name><name name-style="western"><surname>Minder</surname><given-names>C</given-names></name></person-group><article-title>Bias in meta-analysis detected by a, simple, graphical test</article-title><source>Br. Med. J.</source><year>1997</year><volume>315</volume><fpage>629</fpage><lpage>634</lpage><pub-id pub-id-type="doi">10.1136/bmj.315.7109.629</pub-id><pub-id pub-id-type="pmid">9310563</pub-id><pub-id pub-id-type="pmcid">PMC2127453</pub-id></element-citation><mixed-citation id="mc-CR4" publication-type="journal">Egger, M., Smith, G. D., Schneider, M. &amp; Minder, C. Bias in meta-analysis detected by a, simple, graphical test. <italic toggle="yes">Br. Med. J.</italic><bold>315</bold>, 629&#8211;634 (1997).<pub-id pub-id-type="pmid">9310563</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1136/bmj.315.7109.629</pub-id><pub-id pub-id-type="pmcid">PMC2127453</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Duval</surname><given-names>S</given-names></name><name name-style="western"><surname>Tweedie</surname><given-names>R</given-names></name></person-group><article-title>Trim and fill: a simple funnel-plot&#8211;based method of testing and adjusting for publication bias in meta-analysis</article-title><source>Biometrics</source><year>2000</year><volume>56</volume><fpage>455</fpage><lpage>463</lpage><pub-id pub-id-type="doi">10.1111/j.0006-341X.2000.00455.x</pub-id><pub-id pub-id-type="pmid">10877304</pub-id></element-citation><mixed-citation id="mc-CR5" publication-type="journal">Duval, S. &amp; Tweedie, R. Trim and fill: a simple funnel-plot&#8211;based method of testing and adjusting for publication bias in meta-analysis. <italic toggle="yes">Biometrics</italic><bold>56</bold>, 455&#8211;463 (2000).<pub-id pub-id-type="pmid">10877304</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1111/j.0006-341x.2000.00455.x</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="other">Stanley, T. D. &amp; Doucouliagos, H. <italic toggle="yes">Meta-regression analysis in economics and business</italic> (Routledge, 2012).</mixed-citation></ref><ref id="CR7"><label>7.</label><citation-alternatives><element-citation id="ec-CR7" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stanley</surname><given-names>TD</given-names></name><name name-style="western"><surname>Doucouliagos</surname><given-names>H</given-names></name></person-group><article-title>Meta-regression approximations to reduce publication selection bias</article-title><source>Res. Synth. Methods</source><year>2014</year><volume>5</volume><fpage>60</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1002/jrsm.1095</pub-id><pub-id pub-id-type="pmid">26054026</pub-id></element-citation><mixed-citation id="mc-CR7" publication-type="journal">Stanley, T. D. &amp; Doucouliagos, H. Meta-regression approximations to reduce publication selection bias. <italic toggle="yes">Res. Synth. Methods</italic><bold>5</bold>, 60&#8211;78 (2014).<pub-id pub-id-type="pmid">26054026</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/jrsm.1095</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR8"><label>8.</label><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ioannidis</surname><given-names>JP</given-names></name><name name-style="western"><surname>Stanley</surname><given-names>TD</given-names></name><name name-style="western"><surname>Doucouliagos</surname><given-names>H</given-names></name></person-group><article-title>The power of bias in economics research</article-title><source>Econ. J.</source><year>2017</year><volume>127</volume><fpage>F236</fpage><lpage>F265</lpage><pub-id pub-id-type="doi">10.1111/ecoj.12461</pub-id></element-citation><mixed-citation id="mc-CR8" publication-type="journal">Ioannidis, J. P., Stanley, T. D. &amp; Doucouliagos, H. The power of bias in economics research. <italic toggle="yes">Econ. J.</italic><bold>127</bold>, F236&#8211;F265 (2017).</mixed-citation></citation-alternatives></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bom</surname><given-names>PRD</given-names></name><name name-style="western"><surname>Rachinger</surname><given-names>H</given-names></name></person-group><article-title>A kinked meta-regression model for publication bias correction</article-title><source>Res. Synth. Methods</source><year>2019</year><volume>10</volume><fpage>497</fpage><lpage>514</lpage><pub-id pub-id-type="doi">10.1002/jrsm.1352</pub-id><pub-id pub-id-type="pmid">31039283</pub-id></element-citation><mixed-citation id="mc-CR9" publication-type="journal">Bom, P. R. D. &amp; Rachinger, H. A kinked meta-regression model for publication bias correction. <italic toggle="yes">Res. Synth. Methods</italic><bold>10</bold>, 497&#8211;514 (2019).<pub-id pub-id-type="pmid">31039283</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/jrsm.1352</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hedges</surname><given-names>L</given-names></name></person-group><article-title>Estimation of effect size under nonrandom sampling: The effects of censoring studies yielding statistically insignificant mean differences</article-title><source>J. Educ. Stat.</source><year>1984</year><volume>9</volume><fpage>61</fpage><lpage>85</lpage><pub-id pub-id-type="doi">10.3102/10769986009001061</pub-id></element-citation><mixed-citation id="mc-CR10" publication-type="journal">Hedges, L. Estimation of effect size under nonrandom sampling: The effects of censoring studies yielding statistically insignificant mean differences. <italic toggle="yes">J. Educ. Stat.</italic><bold>9</bold>, 61&#8211;85 (1984).</mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Iyengar</surname><given-names>S</given-names></name><name name-style="western"><surname>Greenhouse</surname><given-names>JB</given-names></name></person-group><article-title>Selection models and the file drawer problem</article-title><source>Stat. Sci.</source><year>1988</year><volume>3</volume><fpage>109</fpage><lpage>117</lpage></element-citation><mixed-citation id="mc-CR11" publication-type="journal">Iyengar, S. &amp; Greenhouse, J. B. Selection models and the file drawer problem. <italic toggle="yes">Stat. Sci.</italic><bold>3</bold>, 109&#8211;117 (1988).</mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><citation-alternatives><element-citation id="ec-CR12" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hedges</surname><given-names>LV</given-names></name></person-group><article-title>Modeling publication selection effects in meta-analysis</article-title><source>Stat. Sci.</source><year>1992</year><volume>72</volume><fpage>246</fpage><lpage>255</lpage></element-citation><mixed-citation id="mc-CR12" publication-type="journal">Hedges, L. V. Modeling publication selection effects in meta-analysis. <italic toggle="yes">Stat. Sci.</italic><bold>72</bold>, 246&#8211;255 (1992).</mixed-citation></citation-alternatives></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vevea</surname><given-names>J</given-names></name><name name-style="western"><surname>Hedges</surname><given-names>LV</given-names></name></person-group><article-title>A general linear model for estimating effect size in the presence of publication bias</article-title><source>Psychometrika</source><year>1995</year><volume>60</volume><fpage>419</fpage><lpage>435</lpage><pub-id pub-id-type="doi">10.1007/BF02294384</pub-id></element-citation><mixed-citation id="mc-CR13" publication-type="journal">Vevea, J. &amp; Hedges, L. V. A general linear model for estimating effect size in the presence of publication bias. <italic toggle="yes">Psychometrika</italic><bold>60</bold>, 419&#8211;435 (1995).</mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Andrews</surname><given-names>I</given-names></name><name name-style="western"><surname>Kasy</surname><given-names>M</given-names></name></person-group><article-title>Identification of and correction for publication bias</article-title><source>Am. Econ. Rev.</source><year>2019</year><volume>109</volume><fpage>2766</fpage><lpage>2794</lpage><pub-id pub-id-type="doi">10.1257/aer.20180310</pub-id></element-citation><mixed-citation id="mc-CR14" publication-type="journal">Andrews, I. &amp; Kasy, M. Identification of and correction for publication bias. <italic toggle="yes">Am. Econ. Rev.</italic><bold>109</bold>, 2766&#8211;2794 (2019).</mixed-citation></citation-alternatives></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="other">van Aert, R. C. &amp; van Assen, M. Correcting for publication bias in a meta-analysis with the p-uniform* method. <italic toggle="yes">Psychonomic Bull. Rev.</italic> (2025), in press.</mixed-citation></ref><ref id="CR16"><label>16.</label><mixed-citation publication-type="other">Dal-Re, R. et al. Making prospective registration of observational research a reality. <italic toggle="yes">Sci. Transl. Med.</italic><bold>6</bold>, 224 (2014).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1126/scitranslmed.3007513</pub-id><pub-id pub-id-type="pmid">24553383</pub-id></mixed-citation></ref><ref id="CR17"><label>17.</label><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bruns</surname><given-names>SB</given-names></name><name name-style="western"><surname>Ioannidis</surname><given-names>JP</given-names></name></person-group><article-title>p-Curve and p-hacking in observational research</article-title><source>PloS ONE</source><year>2016</year><volume>11</volume><fpage>e0149144</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0149144</pub-id><pub-id pub-id-type="pmid">26886098</pub-id><pub-id pub-id-type="pmcid">PMC4757561</pub-id></element-citation><mixed-citation id="mc-CR17" publication-type="journal">Bruns, S. B. &amp; Ioannidis, J. P. p-Curve and p-hacking in observational research. <italic toggle="yes">PloS ONE</italic><bold>11</bold>, e0149144 (2016).<pub-id pub-id-type="pmid">26886098</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1371/journal.pone.0149144</pub-id><pub-id pub-id-type="pmcid">PMC4757561</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR18"><label>18.</label><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Abadie</surname><given-names>A</given-names></name><name name-style="western"><surname>Athey</surname><given-names>S</given-names></name><name name-style="western"><surname>Imbens</surname><given-names>GW</given-names></name><name name-style="western"><surname>Wooldridge</surname><given-names>JM</given-names></name></person-group><article-title>When should you adjust standard errors for clustering?</article-title><source>Q. J. Econ.</source><year>2023</year><volume>138</volume><fpage>1</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1093/qje/qjac038</pub-id></element-citation><mixed-citation id="mc-CR18" publication-type="journal">Abadie, A., Athey, S., Imbens, G. W. &amp; Wooldridge, J. M. When should you adjust standard errors for clustering? <italic toggle="yes">Q. J. Econ.</italic><bold>138</bold>, 1&#8211;35 (2023).</mixed-citation></citation-alternatives></ref><ref id="CR19"><label>19.</label><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cameron</surname><given-names>AC</given-names></name><name name-style="western"><surname>Miller</surname><given-names>DL</given-names></name></person-group><article-title>A practitioner&#8217;s guide to cluster-robust inference</article-title><source>J. Hum. Resour.</source><year>2015</year><volume>50</volume><fpage>317</fpage><lpage>372</lpage><pub-id pub-id-type="doi">10.3368/jhr.50.2.317</pub-id></element-citation><mixed-citation id="mc-CR19" publication-type="journal">Cameron, A. C. &amp; Miller, D. L. A practitioner&#8217;s guide to cluster-robust inference. <italic toggle="yes">J. Hum. Resour.</italic><bold>50</bold>, 317&#8211;372 (2015).</mixed-citation></citation-alternatives></ref><ref id="CR20"><label>20.</label><citation-alternatives><element-citation id="ec-CR20" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Roodman</surname><given-names>D</given-names></name><name name-style="western"><surname>Nielsen</surname><given-names>M&#216;</given-names></name><name name-style="western"><surname>MacKinnon</surname><given-names>JG</given-names></name><name name-style="western"><surname>Webb</surname><given-names>MD</given-names></name></person-group><article-title>Fast and wild: bootstrap inference in stata using boottest</article-title><source>Stata J.</source><year>2019</year><volume>19</volume><fpage>4</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1177/1536867X19830877</pub-id></element-citation><mixed-citation id="mc-CR20" publication-type="journal">Roodman, D., Nielsen, M. &#216;., MacKinnon, J. G. &amp; Webb, M. D. Fast and wild: bootstrap inference in stata using boottest. <italic toggle="yes">Stata J.</italic><bold>19</bold>, 4&#8211;60 (2019).</mixed-citation></citation-alternatives></ref><ref id="CR21"><label>21.</label><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>de Chaisemartin</surname><given-names>C</given-names></name><name name-style="western"><surname>Ramirez-Cuellar</surname><given-names>J</given-names></name></person-group><article-title>At what level should one cluster standard errors in paired and small-strata experiments?</article-title><source>Am. Econ. J. Appl. Econ.</source><year>2024</year><volume>16</volume><fpage>193</fpage><lpage>212</lpage><pub-id pub-id-type="doi">10.1257/app.20210252</pub-id></element-citation><mixed-citation id="mc-CR21" publication-type="journal">de Chaisemartin, C. &amp; Ramirez-Cuellar, J. At what level should one cluster standard errors in paired and small-strata experiments? <italic toggle="yes">Am. Econ. J. Appl. Econ.</italic><bold>16</bold>, 193&#8211;212 (2024).</mixed-citation></citation-alternatives></ref><ref id="CR22"><label>22.</label><citation-alternatives><element-citation id="ec-CR22" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>MacKinnon</surname><given-names>JG</given-names></name><name name-style="western"><surname>Nielsen</surname><given-names>MO</given-names></name><name name-style="western"><surname>Webb</surname><given-names>MD</given-names></name></person-group><article-title>Cluster-robust inference: a guide to empirical practice</article-title><source>J. Econ.</source><year>2023</year><volume>232</volume><fpage>272</fpage><lpage>299</lpage><pub-id pub-id-type="doi">10.1016/j.jeconom.2022.04.001</pub-id></element-citation><mixed-citation id="mc-CR22" publication-type="journal">MacKinnon, J. G., Nielsen, M. O. &amp; Webb, M. D. Cluster-robust inference: a guide to empirical practice. <italic toggle="yes">J. Econ.</italic><bold>232</bold>, 272&#8211;299 (2023).</mixed-citation></citation-alternatives></ref><ref id="CR23"><label>23.</label><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>White</surname><given-names>H</given-names></name></person-group><article-title>A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity</article-title><source>Econometrica</source><year>1980</year><volume>48</volume><fpage>817</fpage><lpage>838</lpage><pub-id pub-id-type="doi">10.2307/1912934</pub-id></element-citation><mixed-citation id="mc-CR23" publication-type="journal">White, H. A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity. <italic toggle="yes">Econometrica</italic><bold>48</bold>, 817&#8211;838 (1980).</mixed-citation></citation-alternatives></ref><ref id="CR24"><label>24.</label><citation-alternatives><element-citation id="ec-CR24" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chesher</surname><given-names>A</given-names></name><name name-style="western"><surname>Jewitt</surname><given-names>I</given-names></name></person-group><article-title>The bias of a heteroskedasticity consistent covariance matrix estimator</article-title><source>Econometrica</source><year>1987</year><volume>55</volume><fpage>1217</fpage><lpage>1222</lpage><pub-id pub-id-type="doi">10.2307/1911269</pub-id></element-citation><mixed-citation id="mc-CR24" publication-type="journal">Chesher, A. &amp; Jewitt, I. The bias of a heteroskedasticity consistent covariance matrix estimator. <italic toggle="yes">Econometrica</italic><bold>55</bold>, 1217&#8211;1222 (1987).</mixed-citation></citation-alternatives></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="other">Lang, K. How credible is the credibility revolution? <italic toggle="yes">J. Labor Econ.</italic><bold>43</bold>, 635&#8211;663 (2025).</mixed-citation></ref><ref id="CR26"><label>26.</label><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Roth</surname><given-names>J</given-names></name></person-group><article-title>Pretest with caution: event-study estimates after testing for parallel trends</article-title><source>Am. Econ. Rev. Insights</source><year>2022</year><volume>4</volume><fpage>305</fpage><lpage>322</lpage><pub-id pub-id-type="doi">10.1257/aeri.20210236</pub-id></element-citation><mixed-citation id="mc-CR26" publication-type="journal">Roth, J. Pretest with caution: event-study estimates after testing for parallel trends. <italic toggle="yes">Am. Econ. Rev. Insights</italic><bold>4</bold>, 305&#8211;322 (2022).</mixed-citation></citation-alternatives></ref><ref id="CR27"><label>27.</label><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Keane</surname><given-names>M</given-names></name><name name-style="western"><surname>Neal</surname><given-names>T</given-names></name></person-group><article-title>Instrument strength in IV estimation and inference: a guide to theory and practice</article-title><source>J. Econ.</source><year>2023</year><volume>235</volume><fpage>1625</fpage><lpage>1653</lpage><pub-id pub-id-type="doi">10.1016/j.jeconom.2022.12.009</pub-id></element-citation><mixed-citation id="mc-CR27" publication-type="journal">Keane, M. &amp; Neal, T. Instrument strength in IV estimation and inference: a guide to theory and practice. <italic toggle="yes">J. Econ.</italic><bold>235</bold>, 1625&#8211;1653 (2023).</mixed-citation></citation-alternatives></ref><ref id="CR28"><label>28.</label><citation-alternatives><element-citation id="ec-CR28" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Young</surname><given-names>A</given-names></name></person-group><article-title>Channeling fisher: randomization tests and the statistical insignificance of seemingly significant experimental results</article-title><source>Q. J. Econ.</source><year>2019</year><volume>134</volume><fpage>557</fpage><lpage>598</lpage><pub-id pub-id-type="doi">10.1093/qje/qjy029</pub-id></element-citation><mixed-citation id="mc-CR28" publication-type="journal">Young, A. Channeling fisher: randomization tests and the statistical insignificance of seemingly significant experimental results. <italic toggle="yes">Q. J. Econ.</italic><bold>134</bold>, 557&#8211;598 (2019).</mixed-citation></citation-alternatives></ref><ref id="CR29"><label>29.</label><citation-alternatives><element-citation id="ec-CR29" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Askarov</surname><given-names>Z</given-names></name><name name-style="western"><surname>Doucouliagos</surname><given-names>A</given-names></name><name name-style="western"><surname>Doucouliagos</surname><given-names>H</given-names></name><name name-style="western"><surname>Stanley</surname><given-names>TD</given-names></name></person-group><article-title>The significance of data-sharing policy</article-title><source>J. Eur. Econ. Assoc.</source><year>2023</year><volume>21</volume><fpage>1191</fpage><lpage>1226</lpage><pub-id pub-id-type="doi">10.1093/jeea/jvac053</pub-id></element-citation><mixed-citation id="mc-CR29" publication-type="journal">Askarov, Z., Doucouliagos, A., Doucouliagos, H. &amp; Stanley, T. D. The significance of data-sharing policy. <italic toggle="yes">J. Eur. Econ. Assoc.</italic><bold>21</bold>, 1191&#8211;1226 (2023).</mixed-citation></citation-alternatives></ref><ref id="CR30"><label>30.</label><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lane</surname><given-names>H</given-names></name><name name-style="western"><surname>Tranel</surname><given-names>B</given-names></name></person-group><article-title>The Lombard sign and the role of hearing in speech</article-title><source>J. Speech Hearing Res.</source><year>1971</year><volume>14</volume><fpage>677</fpage><lpage>709</lpage><pub-id pub-id-type="doi">10.1044/jshr.1404.677</pub-id></element-citation><mixed-citation id="mc-CR30" publication-type="journal">Lane, H. &amp; Tranel, B. The Lombard sign and the role of hearing in speech. <italic toggle="yes">J. Speech Hearing Res.</italic><bold>14</bold>, 677&#8211;709 (1971).</mixed-citation></citation-alternatives></ref><ref id="CR31"><label>31.</label><citation-alternatives><element-citation id="ec-CR31" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Taylor</surname><given-names>LR</given-names></name></person-group><article-title>Aggregation, variance and the mean</article-title><source>Nature</source><year>1961</year><volume>189</volume><fpage>732</fpage><lpage>735</lpage><pub-id pub-id-type="doi">10.1038/189732a0</pub-id></element-citation><mixed-citation id="mc-CR31" publication-type="journal">Taylor, L. R. Aggregation, variance and the mean. <italic toggle="yes">Nature</italic><bold>189</bold>, 732&#8211;735 (1961).</mixed-citation></citation-alternatives></ref><ref id="CR32"><label>32.</label><citation-alternatives><element-citation id="ec-CR32" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stanley</surname><given-names>TD</given-names></name><name name-style="western"><surname>Doucouliagos</surname><given-names>H</given-names></name></person-group><article-title>Neither fixed nor random: weighted least squares meta-regression</article-title><source>Res. Synth. Methods</source><year>2017</year><volume>8</volume><fpage>19</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1002/jrsm.1211</pub-id><pub-id pub-id-type="pmid">27322495</pub-id></element-citation><mixed-citation id="mc-CR32" publication-type="journal">Stanley, T. D. &amp; Doucouliagos, H. Neither fixed nor random: weighted least squares meta-regression. <italic toggle="yes">Res. Synth. Methods</italic><bold>8</bold>, 19&#8211;42 (2017).<pub-id pub-id-type="pmid">27322495</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/jrsm.1211</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR33"><label>33.</label><citation-alternatives><element-citation id="ec-CR33" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Havranek</surname><given-names>T</given-names></name><etal/></person-group><article-title>Reporting guidelines for meta-analysis in economics</article-title><source>J. Econ. Surv.</source><year>2020</year><volume>34</volume><fpage>469</fpage><lpage>475</lpage><pub-id pub-id-type="doi">10.1111/joes.12363</pub-id></element-citation><mixed-citation id="mc-CR33" publication-type="journal">Havranek, T. et al. Reporting guidelines for meta-analysis in economics. <italic toggle="yes">J. Econ. Surv.</italic><bold>34</bold>, 469&#8211;475 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR34"><label>34.</label><citation-alternatives><element-citation id="ec-CR34" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ugur</surname><given-names>M</given-names></name><name name-style="western"><surname>Awaworyi Churchill</surname><given-names>S</given-names></name><name name-style="western"><surname>Luong</surname><given-names>H</given-names></name></person-group><article-title>What do we know about R&amp;D spillovers and productivity? Meta-analysis evidence on heterogeneity and statistical power</article-title><source>Res. Policy</source><year>2020</year><volume>49</volume><fpage>103866</fpage><pub-id pub-id-type="doi">10.1016/j.respol.2019.103866</pub-id></element-citation><mixed-citation id="mc-CR34" publication-type="journal">Ugur, M., Awaworyi Churchill, S. &amp; Luong, H. What do we know about R&amp;D spillovers and productivity? Meta-analysis evidence on heterogeneity and statistical power. <italic toggle="yes">Res. Policy</italic><bold>49</bold>, 103866 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR35"><label>35.</label><citation-alternatives><element-citation id="ec-CR35" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Xue</surname><given-names>X</given-names></name><name name-style="western"><surname>Reed</surname><given-names>WR</given-names></name><name name-style="western"><surname>Menclova</surname><given-names>A</given-names></name></person-group><article-title>Social capital and health: a meta-analysis</article-title><source>J. Health Econ.</source><year>2020</year><volume>72</volume><fpage>102317</fpage><pub-id pub-id-type="doi">10.1016/j.jhealeco.2020.102317</pub-id><pub-id pub-id-type="pmid">32497954</pub-id></element-citation><mixed-citation id="mc-CR35" publication-type="journal">Xue, X., Reed, W. R. &amp; Menclova, A. Social capital and health: a meta-analysis. <italic toggle="yes">J. Health Econ.</italic><bold>72</bold>, 102317 (2020).<pub-id pub-id-type="pmid">32497954</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.jhealeco.2020.102317</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR36"><label>36.</label><citation-alternatives><element-citation id="ec-CR36" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Neisser</surname><given-names>C</given-names></name></person-group><article-title>The elasticity of taxable income: a meta-regression analysis</article-title><source>Econ. J.</source><year>2021</year><volume>131</volume><fpage>3365</fpage><lpage>3391</lpage><pub-id pub-id-type="doi">10.1093/ej/ueab038</pub-id></element-citation><mixed-citation id="mc-CR36" publication-type="journal">Neisser, C. The elasticity of taxable income: a meta-regression analysis. <italic toggle="yes">Econ. J.</italic><bold>131</bold>, 3365&#8211;3391 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR37"><label>37.</label><citation-alternatives><element-citation id="ec-CR37" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nakagawa</surname><given-names>S</given-names></name><name name-style="western"><surname>Lagisz</surname><given-names>M</given-names></name><name name-style="western"><surname>Jennions</surname><given-names>MD</given-names></name><etal/></person-group><article-title>Methods for testing publication bias in ecological and evolutionary meta-analyses</article-title><source>Methods Ecol. Evol.</source><year>2022</year><volume>13</volume><fpage>4</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1111/2041-210X.13724</pub-id></element-citation><mixed-citation id="mc-CR37" publication-type="journal">Nakagawa, S., Lagisz, M. &amp; Jennions, M. D. et al. Methods for testing publication bias in ecological and evolutionary meta-analyses. <italic toggle="yes">Methods Ecol. Evol.</italic><bold>13</bold>, 4&#8211;21 (2022).</mixed-citation></citation-alternatives></ref><ref id="CR38"><label>38.</label><citation-alternatives><element-citation id="ec-CR38" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Brown</surname><given-names>AL</given-names></name><name name-style="western"><surname>Imai</surname><given-names>T</given-names></name><name name-style="western"><surname>Vieider</surname><given-names>F</given-names></name><name name-style="western"><surname>Camerer</surname><given-names>C</given-names></name></person-group><article-title>Meta-analysis of empirical estimates of loss-aversion</article-title><source>J. Econ. Lit.</source><year>2024</year><volume>62</volume><fpage>485</fpage><lpage>516</lpage><pub-id pub-id-type="doi">10.1257/jel.20221698</pub-id></element-citation><mixed-citation id="mc-CR38" publication-type="journal">Brown, A. L., Imai, T., Vieider, F. &amp; Camerer, C. Meta-analysis of empirical estimates of loss-aversion. <italic toggle="yes">J. Econ. Lit.</italic><bold>62</bold>, 485&#8211;516 (2024).</mixed-citation></citation-alternatives></ref><ref id="CR39"><label>39.</label><citation-alternatives><element-citation id="ec-CR39" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Carter</surname><given-names>EC</given-names></name><name name-style="western"><surname>Sch nbrodt</surname><given-names>FD</given-names></name><name name-style="western"><surname>Gervais</surname><given-names>WM</given-names></name><name name-style="western"><surname>Hilgard</surname><given-names>J</given-names></name></person-group><article-title>Correcting for bias in psychology: a comparison of meta-analytic methods</article-title><source>Adv. Methods Pract. Psychological Sci.</source><year>2019</year><volume>2</volume><fpage>115</fpage><lpage>144</lpage><pub-id pub-id-type="doi">10.1177/2515245919847196</pub-id></element-citation><mixed-citation id="mc-CR39" publication-type="journal">Carter, E. C., Schonbrodt, F. D., Gervais, W. M. &amp; Hilgard, J. Correcting for bias in psychology: a comparison of meta-analytic methods. <italic toggle="yes">Adv. Methods Pract. Psychological Sci.</italic><bold>2</bold>, 115&#8211;144 (2019).</mixed-citation></citation-alternatives></ref><ref id="CR40"><label>40.</label><citation-alternatives><element-citation id="ec-CR40" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Brodeur</surname><given-names>A</given-names></name><name name-style="western"><surname>Cook</surname><given-names>N</given-names></name><name name-style="western"><surname>Heyes</surname><given-names>A</given-names></name></person-group><article-title>Methods matter: P-hacking and causal inference in economics</article-title><source>Am. Econ. Rev.</source><year>2020</year><volume>110</volume><fpage>3634</fpage><lpage>3660</lpage><pub-id pub-id-type="doi">10.1257/aer.20190687</pub-id></element-citation><mixed-citation id="mc-CR40" publication-type="journal">Brodeur, A., Cook, N. &amp; Heyes, A. Methods matter: P-hacking and causal inference in economics. <italic toggle="yes">Am. Econ. Rev.</italic><bold>110</bold>, 3634&#8211;3660 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR41"><label>41.</label><citation-alternatives><element-citation id="ec-CR41" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>DellaVigna</surname><given-names>S</given-names></name><name name-style="western"><surname>Linos</surname><given-names>E</given-names></name></person-group><article-title>RCTs to scale: comprehensive evidence from two nudge units</article-title><source>Econometrica</source><year>2022</year><volume>90</volume><fpage>81</fpage><lpage>116</lpage><pub-id pub-id-type="doi">10.3982/ECTA18709</pub-id></element-citation><mixed-citation id="mc-CR41" publication-type="journal">DellaVigna, S. &amp; Linos, E. RCTs to scale: comprehensive evidence from two nudge units. <italic toggle="yes">Econometrica</italic><bold>90</bold>, 81&#8211;116 (2022).</mixed-citation></citation-alternatives></ref><ref id="CR42"><label>42.</label><citation-alternatives><element-citation id="ec-CR42" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Imai</surname><given-names>T</given-names></name><name name-style="western"><surname>Rutter</surname><given-names>TA</given-names></name><name name-style="western"><surname>Camerer</surname><given-names>CF</given-names></name></person-group><article-title>Meta-analysis of present-bias estimation using convex time budgets</article-title><source>Econ. J.</source><year>2021</year><volume>131</volume><fpage>1788</fpage><lpage>1814</lpage><pub-id pub-id-type="doi">10.1093/ej/ueaa115</pub-id></element-citation><mixed-citation id="mc-CR42" publication-type="journal">Imai, T., Rutter, T. A. &amp; Camerer, C. F. Meta-analysis of present-bias estimation using convex time budgets. <italic toggle="yes">Econ. J.</italic><bold>131</bold>, 1788&#8211;1814 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR43"><label>43.</label><citation-alternatives><element-citation id="ec-CR43" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gechert</surname><given-names>S</given-names></name><name name-style="western"><surname>Heimberger</surname><given-names>P</given-names></name></person-group><article-title>Do corporate tax cuts boost economic growth?</article-title><source>Eur. Econ. Rev.</source><year>2022</year><volume>147</volume><fpage>104157</fpage><pub-id pub-id-type="doi">10.1016/j.euroecorev.2022.104157</pub-id></element-citation><mixed-citation id="mc-CR43" publication-type="journal">Gechert, S. &amp; Heimberger, P. Do corporate tax cuts boost economic growth? <italic toggle="yes">Eur. Econ. Rev.</italic><bold>147</bold>, 104157 (2022).</mixed-citation></citation-alternatives></ref><ref id="CR44"><label>44.</label><citation-alternatives><element-citation id="ec-CR44" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Havranek</surname><given-names>T</given-names></name><name name-style="western"><surname>Irsova</surname><given-names>Z</given-names></name><name name-style="western"><surname>Laslopova</surname><given-names>L</given-names></name><name name-style="western"><surname>Zeynalova</surname><given-names>O</given-names></name></person-group><article-title>Publication and attenuation biases in measuring skill substitution</article-title><source>Rev. Econ. Stat.</source><year>2024</year><volume>106</volume><fpage>1187</fpage><lpage>1200</lpage><pub-id pub-id-type="doi">10.1162/rest_a_01227</pub-id></element-citation><mixed-citation id="mc-CR44" publication-type="journal">Havranek, T., Irsova, Z., Laslopova, L. &amp; Zeynalova, O. Publication and attenuation biases in measuring skill substitution. <italic toggle="yes">Rev. Econ. Stat.</italic><bold>106</bold>, 1187&#8211;1200 (2024).</mixed-citation></citation-alternatives></ref><ref id="CR45"><label>45.</label><citation-alternatives><element-citation id="ec-CR45" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Matousek</surname><given-names>J</given-names></name><name name-style="western"><surname>Havranek</surname><given-names>T</given-names></name><name name-style="western"><surname>Irsova</surname><given-names>Z</given-names></name></person-group><article-title>Individual discount rates: a meta-analysis of experimental evidence</article-title><source>Exp. Econ.</source><year>2022</year><volume>25</volume><fpage>318</fpage><lpage>358</lpage><pub-id pub-id-type="doi">10.1007/s10683-021-09716-9</pub-id></element-citation><mixed-citation id="mc-CR45" publication-type="journal">Matousek, J., Havranek, T. &amp; Irsova, Z. Individual discount rates: a meta-analysis of experimental evidence. <italic toggle="yes">Exp. Econ.</italic><bold>25</bold>, 318&#8211;358 (2022).</mixed-citation></citation-alternatives></ref><ref id="CR46"><label>46.</label><citation-alternatives><element-citation id="ec-CR46" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Simonsohn</surname><given-names>U</given-names></name><name name-style="western"><surname>Nelson</surname><given-names>LD</given-names></name><name name-style="western"><surname>Simmons</surname><given-names>JP</given-names></name></person-group><article-title>p-Curve: a key to the file-drawer</article-title><source>J. Exp. Psychol. Gen.</source><year>2014</year><volume>143</volume><fpage>534</fpage><lpage>547</lpage><pub-id pub-id-type="doi">10.1037/a0033242</pub-id><pub-id pub-id-type="pmid">23855496</pub-id></element-citation><mixed-citation id="mc-CR46" publication-type="journal">Simonsohn, U., Nelson, L. D. &amp; Simmons, J. P. p-Curve: a key to the file-drawer. <italic toggle="yes">J. Exp. Psychol. Gen.</italic><bold>143</bold>, 534&#8211;547 (2014).<pub-id pub-id-type="pmid">23855496</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1037/a0033242</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR47"><label>47.</label><citation-alternatives><element-citation id="ec-CR47" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Simonsohn</surname><given-names>U</given-names></name><name name-style="western"><surname>Nelson</surname><given-names>LD</given-names></name><name name-style="western"><surname>Simmons</surname><given-names>JP</given-names></name></person-group><article-title>p-Curve and effect size: correcting for publication bias using only significant results</article-title><source>Perspect. Psychological Sci.</source><year>2014</year><volume>9</volume><fpage>666</fpage><lpage>681</lpage><pub-id pub-id-type="doi">10.1177/1745691614553988</pub-id><pub-id pub-id-type="pmid">26186117</pub-id></element-citation><mixed-citation id="mc-CR47" publication-type="journal">Simonsohn, U., Nelson, L. D. &amp; Simmons, J. P. p-Curve and effect size: correcting for publication bias using only significant results. <italic toggle="yes">Perspect. Psychological Sci.</italic><bold>9</bold>, 666&#8211;681 (2014).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1177/1745691614553988</pub-id><pub-id pub-id-type="pmid">26186117</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR48"><label>48.</label><citation-alternatives><element-citation id="ec-CR48" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Assen</surname><given-names>VM</given-names></name><name name-style="western"><surname>Aert</surname><given-names>VRC</given-names></name><name name-style="western"><surname>Wicherts</surname><given-names>JM</given-names></name></person-group><article-title>Meta-analysis using effect size distributions of only statistically significant studies</article-title><source>Psychological Methods</source><year>2015</year><volume>20</volume><fpage>293</fpage><lpage>309</lpage><pub-id pub-id-type="doi">10.1037/met0000025</pub-id><pub-id pub-id-type="pmid">25401773</pub-id></element-citation><mixed-citation id="mc-CR48" publication-type="journal">Assen, V. M., Aert, V. R. C. &amp; Wicherts, J. M. Meta-analysis using effect size distributions of only statistically significant studies. <italic toggle="yes">Psychological Methods</italic><bold>20</bold>, 293&#8211;309 (2015).<pub-id pub-id-type="pmid">25401773</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1037/met0000025</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR49"><label>49.</label><citation-alternatives><element-citation id="ec-CR49" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Simonsohn</surname><given-names>U</given-names></name><name name-style="western"><surname>Simmons</surname><given-names>JP</given-names></name><name name-style="western"><surname>Nelson</surname><given-names>LD</given-names></name></person-group><article-title>Better P-curves: making P-curve analysis more robust to, errors, fraud, and ambitious P-hacking, a Reply to Ulrich and Miller</article-title><source>J. Exp. Psychol. Gen.</source><year>2015</year><volume>144</volume><fpage>1146</fpage><lpage>1152</lpage><pub-id pub-id-type="doi">10.1037/xge0000104</pub-id><pub-id pub-id-type="pmid">26595842</pub-id></element-citation><mixed-citation id="mc-CR49" publication-type="journal">Simonsohn, U., Simmons, J. P. &amp; Nelson, L. D. Better P-curves: making P-curve analysis more robust to, errors, fraud, and ambitious P-hacking, a Reply to Ulrich and Miller <italic toggle="yes">J. Exp. Psychol. Gen.</italic><bold>144</bold>, 1146&#8211;1152 (2015).<pub-id pub-id-type="pmid">26595842</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1037/xge0000104</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR50"><label>50.</label><citation-alternatives><element-citation id="ec-CR50" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Aert</surname><given-names>VRC</given-names></name><name name-style="western"><surname>Assen</surname><given-names>VM</given-names></name></person-group><article-title>Bayesian evaluation of effect size after replicating an original study</article-title><source>Plos ONE</source><year>2017</year><volume>12</volume><fpage>e0175302</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0175302</pub-id><pub-id pub-id-type="pmid">28388646</pub-id><pub-id pub-id-type="pmcid">PMC5384677</pub-id></element-citation><mixed-citation id="mc-CR50" publication-type="journal">Aert, V. R. C. &amp; Assen, V. M. Bayesian evaluation of effect size after replicating an original study. <italic toggle="yes">Plos ONE</italic><bold>12</bold>, e0175302 (2017).<pub-id pub-id-type="pmid">28388646</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1371/journal.pone.0175302</pub-id><pub-id pub-id-type="pmcid">PMC5384677</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR51"><label>51.</label><citation-alternatives><element-citation id="ec-CR51" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Aert</surname><given-names>VRC</given-names></name><name name-style="western"><surname>Assen</surname><given-names>VM</given-names></name></person-group><article-title>Examining reproducibility in psychology: a hybrid method for combining a statistically significant original study and a replication</article-title><source>Behav. Res. Methods</source><year>2018</year><volume>50</volume><fpage>1515</fpage><lpage>1539</lpage><pub-id pub-id-type="doi">10.3758/s13428-017-0967-6</pub-id><pub-id pub-id-type="pmid">28936638</pub-id><pub-id pub-id-type="pmcid">PMC6096648</pub-id></element-citation><mixed-citation id="mc-CR51" publication-type="journal">Aert, V. R. C. &amp; Assen, V. M. Examining reproducibility in psychology: a hybrid method for combining a statistically significant original study and a replication. <italic toggle="yes">Behav. Res. Methods</italic><bold>50</bold>, 1515&#8211;1539 (2018).<pub-id pub-id-type="pmid">28936638</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3758/s13428-017-0967-6</pub-id><pub-id pub-id-type="pmcid">PMC6096648</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR52"><label>52.</label><citation-alternatives><element-citation id="ec-CR52" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stanley</surname><given-names>TD</given-names></name></person-group><article-title>Beyond publication bias</article-title><source>J. Econ. Surv.</source><year>2005</year><volume>19</volume><fpage>309</fpage><lpage>345</lpage><pub-id pub-id-type="doi">10.1111/j.0950-0804.2005.00250.x</pub-id></element-citation><mixed-citation id="mc-CR52" publication-type="journal">Stanley, T. D. Beyond publication bias. <italic toggle="yes">J. Econ. Surv.</italic><bold>19</bold>, 309&#8211;345 (2005).</mixed-citation></citation-alternatives></ref><ref id="CR53"><label>53.</label><citation-alternatives><element-citation id="ec-CR53" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pustejovsky</surname><given-names>JE</given-names></name><name name-style="western"><surname>Rodgers</surname><given-names>MA</given-names></name></person-group><article-title>Testing for funnel plot asymmetry of standardized mean differences</article-title><source>Res. Synth. Methods</source><year>2019</year><volume>10</volume><fpage>57</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1002/jrsm.1332</pub-id><pub-id pub-id-type="pmid">30506832</pub-id></element-citation><mixed-citation id="mc-CR53" publication-type="journal">Pustejovsky, J. E. &amp; Rodgers, M. A. Testing for funnel plot asymmetry of standardized mean differences. <italic toggle="yes">Res. Synth. Methods</italic><bold>10</bold>, 57&#8211;71 (2019).<pub-id pub-id-type="pmid">30506832</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/jrsm.1332</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR54"><label>54.</label><citation-alternatives><element-citation id="ec-CR54" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stanley</surname><given-names>TD</given-names></name><name name-style="western"><surname>Doucouliagos</surname><given-names>H</given-names></name><name name-style="western"><surname>Havranek</surname><given-names>T</given-names></name></person-group><article-title>Meta-analyses of partial correlations are biased: detection and solutions</article-title><source>Res. Synth. Methods</source><year>2024</year><volume>15</volume><fpage>313</fpage><lpage>325</lpage><pub-id pub-id-type="doi">10.1002/jrsm.1704</pub-id><pub-id pub-id-type="pmid">38342768</pub-id></element-citation><mixed-citation id="mc-CR54" publication-type="journal">Stanley, T. D., Doucouliagos, H. &amp; Havranek, T. Meta-analyses of partial correlations are biased: detection and solutions. <italic toggle="yes">Res. Synth. Methods</italic><bold>15</bold>, 313&#8211;325 (2024).<pub-id pub-id-type="pmid">38342768</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/jrsm.1704</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR55"><label>55.</label><citation-alternatives><element-citation id="ec-CR55" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kvarven</surname><given-names>A</given-names></name><name name-style="western"><surname>Stromland</surname><given-names>E</given-names></name><name name-style="western"><surname>Johannesson</surname><given-names>M</given-names></name></person-group><article-title>Comparing meta-analyses and preregistered multiple-laboratory replication projects</article-title><source>Nat. Hum. Behav.</source><year>2020</year><volume>4</volume><fpage>423</fpage><lpage>434</lpage><pub-id pub-id-type="doi">10.1038/s41562-019-0787-z</pub-id><pub-id pub-id-type="pmid">31873200</pub-id></element-citation><mixed-citation id="mc-CR55" publication-type="journal">Kvarven, A., Stromland, E. &amp; Johannesson, M. Comparing meta-analyses and preregistered multiple-laboratory replication projects. <italic toggle="yes">Nat. Hum. Behav.</italic><bold>4</bold>, 423&#8211;434 (2020).<pub-id pub-id-type="pmid">31873200</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41562-019-0787-z</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR56"><label>56.</label><citation-alternatives><element-citation id="ec-CR56" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bartos</surname><given-names>F</given-names></name><etal/></person-group><article-title>Footprint of publication selection bias on meta-analyses in medicine, environmental sciences, psychology, and economics</article-title><source>Res. Synth. Methods</source><year>2024</year><volume>15</volume><fpage>500</fpage><lpage>511</lpage><pub-id pub-id-type="doi">10.1002/jrsm.1703</pub-id><pub-id pub-id-type="pmid">38327122</pub-id></element-citation><mixed-citation id="mc-CR56" publication-type="journal">Bartos, F. et al. Footprint of publication selection bias on meta-analyses in medicine, environmental sciences, psychology, and economics. <italic toggle="yes">Res. Synth. Methods</italic><bold>15</bold>, 500&#8211;511 (2024).<pub-id pub-id-type="pmid">38327122</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/jrsm.1703</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR57"><label>57.</label><citation-alternatives><element-citation id="ec-CR57" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sanchez-Meca</surname><given-names>J</given-names></name><name name-style="western"><surname>Martin-Martinez</surname><given-names>F</given-names></name></person-group><article-title>Weighting by inverse variance or by sample size in meta-analysis: a simulation study</article-title><source>Educ. Psychological Meas.</source><year>1998</year><volume>58</volume><fpage>211</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1177/0013164498058002005</pub-id></element-citation><mixed-citation id="mc-CR57" publication-type="journal">Sanchez-Meca, J. &amp; Martin-Martinez, F. Weighting by inverse variance or by sample size in meta-analysis: a simulation study. <italic toggle="yes">Educ. Psychological Meas.</italic><bold>58</bold>, 211&#8211;220 (1998).</mixed-citation></citation-alternatives></ref><ref id="CR58"><label>58.</label><citation-alternatives><element-citation id="ec-CR58" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Deeks</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Macaskill</surname><given-names>P</given-names></name><name name-style="western"><surname>Irwig</surname><given-names>L</given-names></name></person-group><article-title>The performance of tests of publication bias and other sample size effects in systematic reviews</article-title><source>J. Clin. Epidemiol.</source><year>2005</year><volume>58</volume><fpage>882</fpage><lpage>893</lpage><pub-id pub-id-type="doi">10.1016/j.jclinepi.2005.01.016</pub-id><pub-id pub-id-type="pmid">16085191</pub-id></element-citation><mixed-citation id="mc-CR58" publication-type="journal">Deeks, J. J., Macaskill, P. &amp; Irwig, L. The performance of tests of publication bias and other sample size effects in systematic reviews. <italic toggle="yes">J. Clin. Epidemiol.</italic><bold>58</bold>, 882&#8211;893 (2005).<pub-id pub-id-type="pmid">16085191</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.jclinepi.2005.01.016</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR59"><label>59.</label><citation-alternatives><element-citation id="ec-CR59" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Peters</surname><given-names>JL</given-names></name><name name-style="western"><surname>Sutton</surname><given-names>AJ</given-names></name><name name-style="western"><surname>Jones</surname><given-names>DR</given-names></name><name name-style="western"><surname>Abrams</surname><given-names>KR</given-names></name><name name-style="western"><surname>Rushton</surname><given-names>L</given-names></name></person-group><article-title>Comparison of Two Methods to Detect Publication Bias in Meta-analysis</article-title><source>JAMA</source><year>2006</year><volume>295</volume><fpage>676</fpage><lpage>680</lpage><pub-id pub-id-type="doi">10.1001/jama.295.6.676</pub-id><pub-id pub-id-type="pmid">16467236</pub-id></element-citation><mixed-citation id="mc-CR59" publication-type="journal">Peters, J. L., Sutton, A. J., Jones, D. R., Abrams, K. R. &amp; Rushton, L. Comparison of Two Methods to Detect Publication Bias in Meta-analysis. <italic toggle="yes">JAMA</italic><bold>295</bold>, 676&#8211;680 (2006).<pub-id pub-id-type="pmid">16467236</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1001/jama.295.6.676</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR60"><label>60.</label><mixed-citation publication-type="other">Richard, D. &amp; Riley, L. A. S. <italic toggle="yes">Individual participant data meta-analysis: a handbook for healthcare research</italic> (John Wiley &amp; Sons Ltd., 2021).</mixed-citation></ref><ref id="CR61"><label>61.</label><mixed-citation publication-type="other">Irsova, Z., Bom, P. R. D., Havranek, T. &amp; Rachinger, H. Replication materials for &#8220;Spurious precision in meta-analysis of observational research&#8221;. <italic toggle="yes">Zenodo</italic>, 10.5281/zenodo.15425605 (2025).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41467-025-63261-0</pub-id><pub-id pub-id-type="pmcid">PMC12475282</pub-id><pub-id pub-id-type="pmid">41006270</pub-id></mixed-citation></ref></ref-list></back></article></pmc-articleset>