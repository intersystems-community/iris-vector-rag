<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xml:lang="en" article-type="research-article" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Nucleic Acids Res</journal-id><journal-id journal-id-type="iso-abbrev">Nucleic Acids Res</journal-id><journal-id journal-id-type="pmc-domain-id">4</journal-id><journal-id journal-id-type="pmc-domain">nar</journal-id><journal-id journal-id-type="publisher-id">nar</journal-id><journal-title-group><journal-title>Nucleic Acids Research</journal-title></journal-title-group><issn pub-type="ppub">0305-1048</issn><issn pub-type="epub">1362-4962</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12476229</article-id><article-id pub-id-type="pmcid-ver">PMC12476229.1</article-id><article-id pub-id-type="pmcaid">12476229</article-id><article-id pub-id-type="pmcaiid">12476229</article-id><article-id pub-id-type="doi">10.1093/nar/gkaf921</article-id><article-id pub-id-type="publisher-id">gkaf921</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="category-taxonomy-collection"><subject>AcademicSubjects/SCI00010</subject></subj-group><subj-group subj-group-type="category-taxonomy-collection"><subject>Narese/47</subject></subj-group><subj-group subj-group-type="heading"><subject>Methods</subject></subj-group></article-categories><title-group><article-title>On metrics for subpopulation detection in single-cell and spatial omics data</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0009-0007-6404-3244</contrib-id><name name-style="western"><surname>Luo</surname><given-names initials="S">Siyuan</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization" degree-contribution="lead" vocab-term="Conceptualization">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation" degree-contribution="equal" vocab-term="Data curation">Data curation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="lead" vocab-term="Formal analysis">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation" degree-contribution="lead" vocab-term="Investigation">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology" degree-contribution="equal" vocab-term="Methodology">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/resources" degree-contribution="equal" vocab-term="Resources">Resources</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/software" degree-contribution="equal" vocab-term="Software">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization" degree-contribution="equal" vocab-term="Visualization">Visualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="equal" vocab-term="Writing - original draft">Writing - original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="equal" vocab-term="Writing - review &amp; editing">Writing - review &amp; editing</role><aff>
<institution>Laboratory of Nutrition and Metabolic Epigenetics, Department of Health Sciences and Technology</institution>, <addr-line>ETH Zurich, 8603, Zurich</addr-line>, <country country="CH">Switzerland</country></aff><aff>Department of Molecular Life Sciences, <institution>University of Zurich</institution>, 8057,&#160;<addr-line>Zurich</addr-line>, <country country="CH">Switzerland</country></aff><xref rid="FN1" ref-type="author-notes"/></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-3418-4218</contrib-id><name name-style="western"><surname>Germain</surname><given-names initials="PL">Pierre-Luc</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization" degree-contribution="equal" vocab-term="Conceptualization">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="equal" vocab-term="Formal analysis">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation" degree-contribution="equal" vocab-term="Investigation">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology" degree-contribution="equal" vocab-term="Methodology">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/resources" degree-contribution="equal" vocab-term="Resources">Resources</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/software" degree-contribution="equal" vocab-term="Software">Software</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation" degree-contribution="equal" vocab-term="Validation">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization" degree-contribution="equal" vocab-term="Visualization">Visualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="equal" vocab-term="Writing - original draft">Writing - original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="equal" vocab-term="Writing - review &amp; editing">Writing - review &amp; editing</role><aff>Department of Molecular Life Sciences, <institution>University of Zurich</institution>, 8057,&#160;<addr-line>Zurich</addr-line>, <country country="CH">Switzerland</country></aff><aff>
<institution>SIB Swiss Institute of Bioinformatics, University of Zurich</institution>, 8057,&#160;<addr-line>Zurich</addr-line>, <country country="CH">Switzerland</country></aff><aff>
<institution>Institute for Neuroscience</institution>, Department of Health Sciences and Technology, ETH Zurich, 8092,&#160;<addr-line>Zurich</addr-line>, <country country="CH">Switzerland</country></aff><xref rid="FN1" ref-type="author-notes"/></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-9920-3075</contrib-id><name name-style="western"><surname>von&#160;Meyenn</surname><given-names initials="F">Ferdinand</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation" degree-contribution="equal" vocab-term="Investigation">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration" degree-contribution="equal" vocab-term="Project administration">Project administration</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision" degree-contribution="equal" vocab-term="Supervision">Supervision</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="equal" vocab-term="Writing - review &amp; editing">Writing - review &amp; editing</role><aff>
<institution>Laboratory of Nutrition and Metabolic Epigenetics</institution>, Department of Health Sciences and Technology, <addr-line>ETH Zurich, 8603, Zurich</addr-line>, <country country="CH">Switzerland</country></aff></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-3048-5518</contrib-id><name name-style="western"><surname>Robinson</surname><given-names initials="M">Mark&#160;D</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization" degree-contribution="equal" vocab-term="Conceptualization">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation" degree-contribution="equal" vocab-term="Investigation">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology" degree-contribution="equal" vocab-term="Methodology">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration" degree-contribution="equal" vocab-term="Project administration">Project administration</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision" degree-contribution="equal" vocab-term="Supervision">Supervision</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="equal" vocab-term="Writing - original draft">Writing - original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="equal" vocab-term="Writing - review &amp; editing">Writing - review &amp; editing</role><aff>Department of Molecular Life Sciences, <institution>University of Zurich</institution>, 8057,&#160;<addr-line>Zurich</addr-line>, <country country="CH">Switzerland</country></aff><aff>
<institution>SIB Swiss Institute of Bioinformatics, University of Zurich</institution>, 8057,&#160;<addr-line>Zurich</addr-line>, <country country="CH">Switzerland</country></aff><xref rid="COR1" ref-type="corresp"/></contrib></contrib-group><author-notes><corresp id="COR1">To whom correspondence should be addressed. Email: <email>mark.robinson@mls.uzh.ch</email></corresp><fn id="FN1"><p>Siyuan Luo and Pierre-Luc Germain contributed equally to this work.</p></fn></author-notes><pub-date pub-type="collection"><day>14</day><month>10</month><year>2025</year></pub-date><pub-date pub-type="epub" iso-8601-date="2025-09-27"><day>27</day><month>9</month><year>2025</year></pub-date><volume>53</volume><issue>18</issue><issue-id pub-id-type="pmc-issue-id">497355</issue-id><elocation-id>gkaf921</elocation-id><history><date date-type="accepted"><day>13</day><month>8</month><year>2025</year></date><date date-type="rev-recd"><day>18</day><month>7</month><year>2025</year></date><date date-type="received"><day>06</day><month>3</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>27</day><month>09</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>28</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-28 21:25:17.150"><day>28</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; The Author(s) 2025. Published by Oxford University Press.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="gkaf921.pdf"/><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="gkaf921.pdf"/><abstract><title>Abstract</title><p>Benchmarks are crucial to understanding the strengths and weaknesses of the growing number of tools for single-cell and spatial omics analysis. A key task is to distinguish subpopulations within complex tissues, where evaluation typically relies on external&#160;clustering validation metrics. Different metrics often lead to inconsistencies between rankings, highlighting the importance of understanding the behavior and biological implications of each metric. In this work, we provide a framework for systematically understanding and selecting validation metrics for single-cell data analysis, addressing tasks such as creating cell embeddings, constructing graphs, clustering, and spatial domain detection. Our discussion centers on the desirable properties of metrics, focusing on biological relevance and potential biases. Using this framework, we not only analyze existing metrics but also develop novel ones. Delving into domain detection in spatial omics data, we develop new external metrics tailored to spatially&#160;aware measurements. Additionally, a Bioconductor R package, <monospace>poem</monospace>, implements all the metrics discussed. While we focus on single-cell omics, much of the discussion is of broader relevance to other types of high-dimensional data.</p></abstract><abstract abstract-type="graphical"><title>Graphical Abstract</title><p>
<fig position="float" id="ga1" orientation="portrait"><label>Graphical Abstract</label><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="gkaf921figgra1.jpg"/></fig>
</p></abstract><funding-group><award-group award-type="grant"><funding-source><institution-wrap><institution>Swiss National Science Foundation</institution><institution-id institution-id-type="DOI">10.13039/501100001711</institution-id></institution-wrap></funding-source><award-id>200021_212940</award-id><award-id>310030_204869</award-id></award-group><award-group award-type="grant"><funding-source><institution-wrap><institution>swissuniversities P5 Phase B</institution></institution-wrap></funding-source><award-id>23-36_14</award-id></award-group><award-group award-type="grant"><funding-source><institution-wrap><institution>European Research Council</institution><institution-id institution-id-type="DOI">10.13039/100010663</institution-id></institution-wrap></funding-source><award-id>803491</award-id></award-group></funding-group><counts><page-count count="22"/></counts><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="SEC1"><title>Introduction</title><p>A critical feature of single-cell omics data is its ability to elucidate heterogeneous cell subpopulations within complex tissues. Identifying and distinguishing these subpopulations is a fundamental task in single-cell analysis, often involving clustering cells into meaningful groups based on the similarity of their measurements. This process is typically preceded by several preprocessing steps, including normalization, feature selection, dimensional reduction, and batch correction, and the results of clustering serve as an entry point for assessing the performance of these upstream computational tasks [<xref rid="B1" ref-type="bibr">1&#8211;5</xref>]. Thus, evaluating the effectiveness of cell subpopulation identification is crucial for informing current methodological progress in single-cell data analysis.</p><p>When assessing the performance of cell subpopulation identification, researchers usually rely on external labels (the so-called ground truth) derived either from orthogonal experimental approaches (such as fluorescence-activated cell sorting&#160;or additional data modalities in multiomics data) or from simulation. Validation metrics are then employed to quantify the degree of concordance between the clustering outcomes and these labels (also known as external clustering metrics). These metrics define the criteria for the quality of cell subpopulation identification, and therefore shape the field&#8217;s methodological development.</p><p>However, conducting reliable and biologically meaningful performance evaluation remains challenging. First, despite extensive discussions on external validation indices for general clustering tasks [<xref rid="B6" ref-type="bibr">6&#8211;8</xref>], there are no specific guidelines for choosing metrics in the context of single-cell biology. Researchers often follow established practices from the literature that, as we will show, may not always be optimal or well-justified. Second, while using multiple metrics for benchmarking is generally advisable, it can lead to inconsistent rankings of methods [<xref rid="B3" ref-type="bibr">3</xref>], making it difficult to draw clear conclusions. Finally, cellular heterogeneity in biology is often organized into complex hierarchical structures, but the ground-truth labels we use typically represent only one level of this hierarchy. As we will show, evaluations that expect a match strictly at this single level, without allowing for differences in resolution, can introduce bias that misrepresents the actual biological interest.</p><p>Inspired by previous research efforts to define formal constraints, or &#8220;desirable properties,&#8221; for external clustering metrics [<xref rid="B6" ref-type="bibr">6</xref>, <xref rid="B7" ref-type="bibr">7</xref>, <xref rid="B9" ref-type="bibr">9</xref>], we structure our discussion of various metrics around the key properties most relevant for single-cell biology. We seek to provide not only guidelines for selecting metrics and interpreting benchmarking results but also a framework for developing guidelines applicable to new metrics and related computational tasks.</p><p>In the final section, we demonstrate how desirable properties and corresponding metrics can be adapted for spatial domain detection. Moreover, we show that the insights gained from clustering tasks can be applied as heuristics, and, when combined with spatial considerations, can inform the development of new desirable properties and metrics. Overall, it highlights how our framework can generate valuable guidelines not only for choosing appropriate metrics but also for developing novel metrics that can better serve the research questions.</p></sec><sec sec-type="materials|methods" id="SEC2"><title>Materials and methods</title><sec id="SEC2-1"><title>Datasets</title><sec id="SEC2-1-1"><title>The 10XPBMC dataset used in Fig.&#160;<xref rid="F2" ref-type="fig">2</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref></title><p>This dataset is the scATAC-seq part of the 10XPBMC multiomics datasets used in [<xref rid="B4" ref-type="bibr">4</xref>], and the details about its generation, quality control (QC), and preprocessing steps can be found there. The clusterings in Fig.&#160;<xref rid="F2" ref-type="fig">2</xref> is done using the pipeline SnapATAC, and the clusterings in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S3</xref> is done using the pipeline aggregation. See [<xref rid="B4" ref-type="bibr">4</xref>] for the pipeline details.</p><fig position="float" id="F1" orientation="portrait"><label>Figure 1.</label><caption><p>Desirable properties and how partition-based metrics reflect each property. Here in&#160;panel&#160;(<bold>A</bold>), <italic toggle="yes">C</italic> represents ground truth partitions, while <italic toggle="yes">P</italic><sub>1</sub> and <italic toggle="yes">P</italic><sub>2</sub> are two hypothetical clustering results. In the first and second columns, <italic toggle="yes">P</italic><sub>2</sub> should be preferred to <italic toggle="yes">P</italic><sub>1</sub> according to the desirable properties of cluster homogeneity and class completeness, respectively. In the third column, if errors in smaller classes should be penalized more than errors in larger classes, then <italic toggle="yes">P</italic><sub>2</sub> should be preferred over <italic toggle="yes">P</italic><sub>1</sub>, and vice versa. In the last column, <italic toggle="yes">P</italic><sub>1</sub> and <italic toggle="yes">P</italic><sub>2</sub> are two random partitions into different number of clusters. According to the property of chance agreement neutrality, neither <italic toggle="yes">P</italic><sub>1</sub> nor <italic toggle="yes">P</italic><sub>2</sub> should be preferred over the other. Panel&#160;(<bold>B</bold>) illustrates the effectiveness of each metric in comparing <italic toggle="yes">P</italic><sub>1</sub> to <italic toggle="yes">P</italic><sub>2</sub> with respect to the corresponding properties. The values are calculated using the toy examples in panel&#160;(A). Panels&#160;(<bold>C</bold>&#8211;<bold>F</bold>) summarize the comparisons from a property-centric perspective.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="gkaf921fig1.jpg"/></fig><fig position="float" id="F2" orientation="portrait"><label>Figure 2.</label><caption><p>Real-world examples of partitions with different rankings across metrics. As an example, we use the 10x&#160;multi-omic PBMC dataset in Luo <italic toggle="yes">et&#160;al.</italic> [<xref rid="B4" ref-type="bibr">4</xref>], comparing three ATAC-seq clustering solutions against RNA-seq annotations (treated as ground truth). The <italic toggle="yes">x</italic>-axis represents the predicted clusters; <italic toggle="yes">y</italic>-axis is the ground truth classes. The tile colors indicate the proportion of cells from the corresponding true class (each row sums up to one). A clearer diagonal structure indicates better agreement. AWH, AWC, and ARI values are shown. The barplot on top shows cluster-wise AWHs (homogeneity); the barplot on the right shows class-specific AWCs (completeness). Bar color represents the proportion of cells in each cluster/class.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="gkaf921fig2.jpg"/></fig></sec><sec id="SEC2-1-2"><title>The Atlas2 dataset used in Fig.&#160;<xref rid="F4" ref-type="fig">4</xref></title><p>See section &#8220;Exploration of the LSI embeddings for the Atlas2 scATAC-seq dataset.&#8221;</p><fig position="float" id="F3" orientation="portrait"><label>Figure 3.</label><caption><p>Examples of how class shape affects the embedding-based metrics. In panel&#160;(<bold>A</bold>), both scenarios contain two classes sampled from 2D Gaussian distributions. Class A in Scenario 1 forms an elongated shape, while in Scenario 2, it is more globular. Silhouette scores for these two scenarios reveal similar distributions, despite the visually poorer separation of the two classes in Scenario 2. Panel&#160;(<bold>B</bold>) illustrates how embedding-based metrics compare Scenario 1 to Scenario 2. In panel (<bold>C</bold>), Scenario 3 and 4 highlight a moon-shaped dataset colored by clustering predictions from <italic toggle="yes">k</italic>-means clustering and HDBSCAN clustering, respectively. Panel (<bold>D</bold>)&#160;illustrates how embedding-based metrics compare Scenarios 3 and 4.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="gkaf921fig3.jpg"/></fig><fig position="float" id="F4" orientation="portrait"><label>Figure 4.</label><caption><p>Real-world example of misleading Silhouette scores and Euclidean distances. Using the Atlas2 dataset from Luo <italic toggle="yes">et&#160;al.</italic> [<xref rid="B4" ref-type="bibr">4</xref>], UMAP embeddings (<bold>A</bold>) show well-separated classes. However, Silhouette scores using Euclidean distance in the LSI space (upper panel of <bold>B</bold>) show many cells with low scores; using Cosine distance strongly mitigates this effect ( lower panel of B). Cells in (<bold>B</bold>) are colored with the identity of its own class if its silhouette width is positive and that of the closest other class if the width is negative. The LSI embedding in panel (<bold>C</bold>), focusing on two LSI dimensions that best distinguish vascular smooth muscle cells&#8212;those with the highest proportion of negative Silhouettes in panel&#160;(A)&#8212;exhibits a star-shaped distribution (C). Panel&#160;(D) shows library size for each cell, where higher values increase divergence between cell types and amplify within-class distances, collectively contributing to negative Silhouette scores (<bold>E</bold>).</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="gkaf921fig4.jpg"/></fig></sec><sec id="SEC2-1-3"><title>The 10x Visium dataset</title><p>We use the LIBD 10x Visium dataset (slice 151673) from Maynard <italic toggle="yes">et&#160;al.</italic> [<xref rid="B10" ref-type="bibr">10</xref>], with manual annotations from the original publication serving as the ground truth. Domain detection is performed using BayesSpace, CellCharter, GraphST, precast, and SEDR with default parameters and specifying the true number of classes. Then, the Hungarian algorithm is applied to match the predicted clusters with the annotated classes.</p></sec></sec><sec id="SEC2-2"><title>Exploration of the LSI embeddings for the Atlas2 scATAC-seq dataset</title><p>This is related to Fig.&#160;<xref rid="F4" ref-type="fig">4</xref>. The dataset is the scATAC-seq Atlas2 dataset used in [<xref rid="B4" ref-type="bibr">4</xref>], and the details about its generation, QC, and preprocessing steps can be found there. After QC and filtering, the pipeline ArchR_tiles from [<xref rid="B4" ref-type="bibr">4</xref>] is used for dimensional reduction, which generates the latent semantic indexing (LSI)-based embeddings for each cell. Following ArchR&#8217;s documentation, the first LSI component is removed due to its above 0.75 Pearson&#8217;s correlation with the library size. The UMAP in Fig.&#160;<xref rid="F4" ref-type="fig">4A</xref> and the Silhouette width in Fig.&#160;<xref rid="F4" ref-type="fig">4</xref>B&#160;are calculated based on the 2nd to 16th LSI components.</p></sec><sec id="SEC2-3"><title>Composed density between and within clusters</title><p>Let <italic toggle="yes">C</italic><sub><italic toggle="yes">K</italic></sub> denotes a clustering to be evaluated. First, a number of representative points are selected for each cluster in <italic toggle="yes">C</italic><sub><italic toggle="yes">K</italic></sub> using a furthest-first technique to cover the geometry of the cluster effectively. The Composed density between and within clusters (CDbw) index is defined as:</p><disp-formula id="M1"><label>(1)</label><tex-math id="TM0001" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{eqnarray*}
CDbw(C_K) = {\rm Cohesion}(C_K) \cdot {\rm Compactness}(C_K) \cdot {\rm Sep}(C_K)\nonumber\\
\end{eqnarray*}\end{document}</tex-math></disp-formula><p>where,</p><disp-formula id="M2"><label>(2)</label><tex-math id="TM0001a" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{eqnarray*}
{\rm Cohesion}(C_K) = \frac{{\rm Compactness}(C_K)}{1+{\rm Intra}\_{\rm change}(C_K)}
\end{eqnarray*}\end{document}</tex-math></disp-formula><disp-formula id="M3"><label>(3)</label><tex-math id="TM0002" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{eqnarray*}
{\rm Compactness}(C_K) = \frac{\sum ^{n_s}_{i=1}{\rm Intra}\_{\rm dens}(C_K, s_i)}{n_s}
\end{eqnarray*}\end{document}</tex-math></disp-formula><disp-formula id="M4"><label>(4)</label><tex-math id="TM0003" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{eqnarray*}
{\rm Sep}(C_K) = \frac{\frac{1}{K}\sum _i\text{min}_j\lbrace {\rm Dist}(C_i, C_j)\rbrace }{1+{\rm Inter}\_{\rm dens}(C_K)}
\end{eqnarray*}\end{document}</tex-math></disp-formula><p>
<inline-formula>
<tex-math id="TM0004" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${\rm Intra}\_{\rm dens}(C_K , s_i)$\end{document}</tex-math>
</inline-formula>&#160;is the intra-cluster density, and <italic toggle="yes">s</italic><sub><italic toggle="yes">i</italic></sub>, <italic toggle="yes">i</italic> &#8712; {1, ..., <italic toggle="yes">n</italic><sub><italic toggle="yes">s</italic></sub>} is a sequence of shrinking factors &#8712; [0, 1] that is used to move the representative points closer to the cluster center. For a given <italic toggle="yes">s</italic><sub><italic toggle="yes">i</italic></sub>, <inline-formula><tex-math id="TM0005" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${\rm Intra}\_{\rm dens}(C_K, s_i)$\end{document}</tex-math></inline-formula> calculates the average density around all the representative points, normalized by the standard deviation of the cluster. <inline-formula><tex-math id="TM0006" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${\rm Intra}\_{\rm change}(C_K)$\end{document}</tex-math></inline-formula> is the changes in the within-cluster densities over changes in <italic toggle="yes">s</italic><sub><italic toggle="yes">i</italic></sub>, which averages the difference between values of <inline-formula><tex-math id="TM0007" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${\rm Intra}\_{\rm dens}(C_K, s_i)$\end{document}</tex-math></inline-formula> for adjacent values of <italic toggle="yes">s</italic><sub><italic toggle="yes">i</italic></sub>. To calculate <italic toggle="yes">Sep</italic>(<italic toggle="yes">C</italic><sub><italic toggle="yes">K</italic></sub>), each representative of a cluster is paired with the closest representatives of any other cluster. <italic toggle="yes">Dist</italic>(<italic toggle="yes">C</italic><sub><italic toggle="yes">i</italic></sub>, <italic toggle="yes">C</italic><sub><italic toggle="yes">j</italic></sub>), the distance between clusters <italic toggle="yes">C</italic><sub><italic toggle="yes">i</italic></sub>, <italic toggle="yes">C</italic><sub><italic toggle="yes">j</italic></sub>, is calculated as the average of distances between the pairwise closest representatives; <italic toggle="yes">Dens</italic>(<italic toggle="yes">C</italic><sub><italic toggle="yes">i</italic></sub>, <italic toggle="yes">C</italic><sub><italic toggle="yes">j</italic></sub>), the density between clusters <italic toggle="yes">C</italic><sub><italic toggle="yes">i</italic></sub> and <italic toggle="yes">C</italic><sub><italic toggle="yes">j</italic></sub>, is an average standardized number of points in the neighborhood of the midpoint of the line between each pair of representatives.&#160;The density between clusters in the clustering, <inline-formula><tex-math id="TM0008" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
${\rm Inter}\_{\rm dens}(C_K)$\end{document}</tex-math></inline-formula>, is the average of maximum <italic toggle="yes">Dens</italic>(<italic toggle="yes">C</italic><sub><italic toggle="yes">i</italic></sub>, <italic toggle="yes">C</italic><sub><italic toggle="yes">j</italic></sub>) for every pair of clusters <italic toggle="yes">C</italic><sub><italic toggle="yes">i</italic></sub> and <italic toggle="yes">C</italic><sub><italic toggle="yes">j</italic></sub>.</p></sec><sec id="SEC2-4"><title>Density-Based Clustering Validation index</title><p>For a clustering solution <italic toggle="yes">C</italic>, the Density-Based Clustering Validation (DBCV) index is the weighted average of the validity indices of all clusters:</p><disp-formula id="M5"><label>(5)</label><tex-math id="TM0009" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{eqnarray*}
\text{DBCV}(C) = \sum _{i=1}^{l} \frac{|C_i|}{|O|} VC(C_i)
\end{eqnarray*}\end{document}</tex-math></disp-formula><p>where, <italic toggle="yes">l</italic> is the number of clusters, and |<italic toggle="yes">O</italic>| is the total number of objects. The validity index for a cluster <italic toggle="yes">C</italic><sub><italic toggle="yes">i</italic></sub> is calculated as the following:</p><disp-formula id="M6"><label>(6)</label><tex-math id="TM00010" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{eqnarray*}
VC(C_i) = \frac{{\rm min}_{j \ne i} \left( \text{DSPC}(C_i, C_j) \right) - \text{DSC}(C_i)}{\max \left( {\rm min}_{j \ne i} \left( \text{DSPC}(C_i, C_j) \right), \text{DSC}(C_i) \right)}
\end{eqnarray*}\end{document}</tex-math></disp-formula><p>DSPC(<italic toggle="yes">C</italic><sub><italic toggle="yes">i</italic></sub>, <italic toggle="yes">C</italic><sub><italic toggle="yes">j</italic></sub>) is the density separation between two clusters <italic toggle="yes">C</italic><sub><italic toggle="yes">i</italic></sub> and <italic toggle="yes">C</italic><sub><italic toggle="yes">j</italic></sub>, which is defined as the minimum mutual reachability distance between their internal nodes:</p><disp-formula id="M7"><label>(7)</label><tex-math id="TM00011" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{eqnarray*}
\text{DSPC}(C_i, C_j) = {\rm min}\left( d_{\text{mreach}}(o_i, o_j) \text{ where } o_i \in C_i \text{ and } o_j \in C_j \right)\nonumber\\
\end{eqnarray*}\end{document}</tex-math></disp-formula><p>whereas DSC(<italic toggle="yes">C</italic><sub><italic toggle="yes">i</italic></sub>) is the density sparseness of a cluster <italic toggle="yes">C</italic><sub><italic toggle="yes">i</italic></sub>, being the maximum edge weight (largest distance) of the internal edges in the Minimum Spanning Tree (MST) of the cluster. The MST is constructed using the mutual reachability distance considering the objects in <italic toggle="yes">C</italic><sub><italic toggle="yes">i</italic></sub>.</p><p>
<italic toggle="yes">d</italic>
<sub>mreach</sub>(<italic toggle="yes">o</italic><sub><italic toggle="yes">i</italic></sub>, <italic toggle="yes">o</italic><sub><italic toggle="yes">j</italic></sub>) is the mutual reachability distance for two objects <italic toggle="yes">o</italic><sub><italic toggle="yes">i</italic></sub> and <italic toggle="yes">o</italic><sub><italic toggle="yes">j</italic></sub>, and is defined as:</p><disp-formula id="M8"><label>(8)</label><tex-math id="TM00012" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{eqnarray*}
d_{\text{mreach}}(o_i, o_j) &amp;=&amp; \max \big( \text{aptscoredist}(o_i), \text{aptscoredist}(o_j),\nonumber\\ &amp;&amp; d(o_i, o_j) \big)
\end{eqnarray*}\end{document}</tex-math></disp-formula><p>where, <italic toggle="yes">d</italic>(<italic toggle="yes">o</italic><sub><italic toggle="yes">i</italic></sub>, <italic toggle="yes">o</italic><sub><italic toggle="yes">j</italic></sub>) is the pairwise distance between objects <italic toggle="yes">o</italic><sub><italic toggle="yes">i</italic></sub> and <italic toggle="yes">o</italic><sub><italic toggle="yes">j</italic></sub>, and aptscoredist(<italic toggle="yes">o</italic><sub><italic toggle="yes">i</italic></sub>) is the core distance of object <italic toggle="yes">o</italic><sub><italic toggle="yes">i</italic></sub>. For an object <italic toggle="yes">o</italic> in a cluster <italic toggle="yes">C</italic><sub><italic toggle="yes">i</italic></sub>, its core distance with respect to all other objects in the same cluster is calculated by:</p><disp-formula id="M9"><label>(9)</label><tex-math id="TM00013" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{eqnarray*}
\text{aptscoredist}(o) = \left( \frac{1}{n_i - 1} \sum _{j=2}^{n_i} \left( \frac{1}{\text{KNN}(o, j)} \right)^d \right)^{-\frac{1}{d}}
\end{eqnarray*}\end{document}</tex-math></disp-formula><p>where, <italic toggle="yes">n</italic><sub><italic toggle="yes">i</italic></sub> = |<italic toggle="yes">C</italic><sub><italic toggle="yes">i</italic></sub>|, KNN(<italic toggle="yes">o</italic>, <italic toggle="yes">j</italic>) is the distance to the <italic toggle="yes">j</italic>-th nearest neighbor of object <italic toggle="yes">o</italic> within the same cluster, and <italic toggle="yes">d</italic> is the dimensionality of the feature space.</p></sec><sec id="SEC2-5"><title>Entropy-based Local indicator of Spatial Association</title><p>For a site <italic toggle="yes">i</italic>, the Entropy-based Local indicator of Spatial Association (ELSA) score is the product of two terms:</p><disp-formula id="M10"><label>(10)</label><tex-math id="TM00014" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{eqnarray*}
E_i = E_{ai} \times E_{ci}
\end{eqnarray*}\end{document}</tex-math></disp-formula><p>where, <italic toggle="yes">E</italic><sub><italic toggle="yes">ai</italic></sub> summarizes the dissimilarity between site <italic toggle="yes">i</italic> and the neighboring sites and is calculated as:</p><disp-formula id="M11"><label>(11)</label><tex-math id="TM00015" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{eqnarray*}
E_{ai} = \frac{\sum _j \omega _{ij} d_{ij}}{\max \lbrace d\rbrace \sum _j \omega _{ij}}, \quad j \ne i
\end{eqnarray*}\end{document}</tex-math></disp-formula><p>&#969;<sub><italic toggle="yes">ij</italic></sub> is a binary weight that specifies whether the site <italic toggle="yes">j</italic> is within the neighborhood of site <italic toggle="yes">i</italic>, and <italic toggle="yes">d</italic><sub><italic toggle="yes">ij</italic></sub> describes the dissimilarity between the categories at sites <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic>, which is calculated as the absolute difference of the ranks assigned to the categories at sites <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic>.</p><p>
<italic toggle="yes">E</italic>
<sub>
<italic toggle="yes">ci</italic>
</sub> on the other hand quantifies diversity of the categories within the neighborhood of site <italic toggle="yes">i</italic>:</p><disp-formula id="M12"><label>(12)</label><tex-math id="TM00016" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{eqnarray*}
E_{ci} = -\frac{\sum _{k=1}^{m_\omega } p_k \log _2 (p_k)}{\log _2 m_i}, \quad j \ne i
\end{eqnarray*}\end{document}</tex-math></disp-formula><p>where <italic toggle="yes">m</italic> are the total number of categories, <italic toggle="yes">p</italic><sub><italic toggle="yes">k</italic></sub> is the probability of <italic toggle="yes">k</italic>th category from the <italic toggle="yes">m</italic><sub>&#969;</sub> categories within the neighborhood of site <italic toggle="yes">i</italic>, and <inline-formula><tex-math id="TM00017" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$m_i = \left\lbrace \begin{array}{@{}l@{\quad }l@{}}m \text{ if } \sum _j \omega _{ij} &gt;m \\ \sum _j \omega _{ij}, \text{ otherwise} \end{array}\right.$\end{document}</tex-math></inline-formula>.</p></sec><sec id="SEC2-6"><title>Simulations</title><p>This is related to <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S5</xref>. To explore in a mostly unbiased way the behavior of metrics, we generate a number of simulated 2- and 3-dimensional datasets with 3 to 4 classes of varying abundances (some equal, some highly skewed), variability, and differences between classes. This is implemented in the <monospace>mockData</monospace> function of the <monospace>poem</monospace> package. Briefly, we first use multi-dimensional scaling to obtain centroids for each class that approximate the desired pairwise class differences (determined by the settings), and then generate the desired number of points around them using a normal or log-normal distribution with a given variability parameter. To create further non-Gaussian spread in some classes, we concatenate points from multiple such distributions symmetrically shifted from the centroid. Each simulation was further performed with 2 seeds (see the GitHub repository for the exact sets of parameters used), yielding 2240 simulations. For each, we then take the simulated data to be embedding-like structures and calculate embedding-level metrics as well as graph metrics on a kNN graph with <italic toggle="yes">k</italic>&#160;=&#160;5. To compute partition-level metrics, we run <italic toggle="yes">k-</italic>means clustering with <italic toggle="yes">k</italic> ranging from 2 to 6, as well as Louvain clustering on the kNN graph with resolutions of 0.5, 1, and 2. Node- and class-specific metrics are averaged to yield global metrics. To enable a comparison of the metrics results with interpretable dimensions of the simulation parameters, we define &#8220;size imbalance&#8221;&#160;as the Simpson diversity index of the class abundances, the &#8220;signal-to-noise&#8221; as the ratio between the mean pairwise class differences and the mean class variability (i.e. standard deviation), and the &#8220;spread&#8221; as the mean class spread parameter. We then perform a linear regression of each metric on these three parameters across simulations, and for partition-level metrics we additionally include the number of clusters as a covariate.</p></sec><sec id="SEC2-7"><title>Fuzzy pair-counting metrics</title><p>We use Hullermeier&#8217;s Normalized Degree of Concordance (NDC, see Hullermeier <italic toggle="yes">et&#160;al.</italic> [<xref rid="B11" ref-type="bibr">11</xref>]) as a fuzzy version of the RI&#160;and d&#8217;Ambrosio&#8217;s Adjusted Concordance Index (ACI, see D&#8217;Ambrosio <italic toggle="yes">et&#160;al.</italic> [<xref rid="B12" ref-type="bibr">12</xref>]) as fuzzy ARI. The ACI adjusts the NDC for chance based on permutation of the membership probability vectors. Based on this logic, we further implemented fuzzy Wallace indices (i.e. Wallace Homogeneity and Wallace Completeness and their chance-adjusted versions). Briefly, Wallace Completeness of a class is originally defined in the nonfuzzy setting as the proportion of all the pairs of elements of that class that are also in the same cluster. In the fuzzy setting, this pair concordance is understood as the similarity in membership agreements for pairs of elements between the two fuzzy partitionings. Specifically, the agreement between a pair of elements <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic> is given by <inline-formula><tex-math id="TM00018" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$A_{ij} = \frac{\Vert \boldsymbol{w}_i-\boldsymbol{w}_j\Vert _1}{2}$\end{document}</tex-math></inline-formula>, where <inline-formula><tex-math id="TM00019" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\boldsymbol{w}_i$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math id="TM00020" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\boldsymbol{w}_j$\end{document}</tex-math></inline-formula> represent their respective membership vectors. The concordance between two fuzzy partitionings <italic toggle="yes">Q</italic> and <italic toggle="yes">P</italic> for that pair is then given as <inline-formula><tex-math id="TM00021" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$C_{PQ}^{ij} = 1 - |A_{ij}^P - A_{ij}^Q|$\end{document}</tex-math></inline-formula>. Since class membership is fuzzy, the extent to which this concordance matters for the computation of the completeness of a class <italic toggle="yes">X</italic> depends on the extent to which the pair of elements are of that class, which can be computed using different <italic toggle="yes">t</italic>-norm operations for set membership. While multiple such functions are implemented in our package, by default we use the product <italic toggle="yes">t</italic>-norm, meaning that the degree of membership of a pair of element to the class <italic toggle="yes">X</italic> (denoted <inline-formula><tex-math id="TM00022" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$m_X^{ij}$\end{document}</tex-math></inline-formula>) is given by the product of the probability that each of the two element belongs to class <italic toggle="yes">X</italic>. The Wallace Completeness of class <italic toggle="yes">X</italic>, <italic toggle="yes">WC</italic><sub><italic toggle="yes">X</italic></sub>, can then be computed as <inline-formula><tex-math id="TM00023" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$WC_X = \frac{\sum {m_X^{ij}\times C_{PQ}^{ij}}}{\sum {m_X^{ij}}}$\end{document}</tex-math></inline-formula> across all possible pairs <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic>. To obtain a chance adjusted <italic toggle="yes">AWC</italic><sub><italic toggle="yes">X</italic></sub>, we compute the randomly expected <inline-formula><tex-math id="TM00024" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$WC_X^{\prime }$\end{document}</tex-math></inline-formula> across permutations of the predicted memberships, and then calculate <inline-formula><tex-math id="TM00025" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$AWC_X = \frac{WC_X-WC_X^{\prime }}{1-WC_X^{\prime }}$\end{document}</tex-math></inline-formula>. The same is done for Wallace Homogeneity.</p></sec><sec id="SEC2-8"><title>Spatial application of fuzzy metrics (neighborhood-smoothed pair sorting metrics)</title><p>To make hard labels fuzzy in a spatially&#160;dependent fashion, we first compute the domain composition of its spatial nearest neighbors (i.e. nearest neighbors based on the Euclidean distance between spots/cells). To make the neighborhood definition more comparable across areas, in particular at the border of a field of view (where there are fewer first-degree neighbors) or in areas of low-density for nonspot-based datasets, we compute the median distance to the desired <italic toggle="yes">k</italic>th nearest neighbor across spots/cells, and then consider for each spot/cell the neighbors that are within that range. The neighborhood domain membership (<inline-formula><tex-math id="TM00026" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\boldsymbol{w}_\text{n}$\end{document}</tex-math></inline-formula>) of a spot <italic toggle="yes">i</italic>, <inline-formula><tex-math id="TM00027" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\boldsymbol{w}_\text{n}^i$\end{document}</tex-math></inline-formula>, is then the number of its neighbors belonging to domain, divided by the number of neighbors. The domain membership of spot <italic toggle="yes">i</italic> itself, <inline-formula><tex-math id="TM00028" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\boldsymbol{w}_\text{s}^i$\end{document}</tex-math></inline-formula>, is 1 if the spot belongs to a domain, and zero otherwise. The fuzzy domain membership is then computed as <inline-formula><tex-math id="TM00029" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\boldsymbol{w}^i = (1-\alpha )\times \boldsymbol{w}_\text{n}^i + (\boldsymbol{w}_\text{s}^i \times \alpha )$\end{document}</tex-math></inline-formula>, where &#945; is a parameter controlling the relative weight of the spot versus it&#8217;s neighborhood (by default, we set &#945; = 0.5).</p><p>By comparing against a fuzzy truth, we decrease the concordance of a predicted partitioning that would be exactly like the original &#8220;hard&#8221; truth. For this reason, we developed a fuzzy-hard version of the metrics that compares (hard) clustering labels to both a &#8220;hard&#8221; and a fuzzy ground truth. For the purpose of computing within-pair agreements, the hard labels are expressed as a weight of 1 for the given label and 0 for other labels. Otherwise the procedure is exactly like described above, except that the concordance between the prediction <italic toggle="yes">P</italic> and the truth <italic toggle="yes">Q</italic> of a pair of elements <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic> is given by <inline-formula><tex-math id="TM00030" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$C_{PQ}^{ij} = 1 - {\rm min}(|A_{ij}^P - A_{ij}^Q|, |A_{ij}^P - A_{ij}^R|)$\end{document}</tex-math></inline-formula>, where <italic toggle="yes">Q</italic> and <italic toggle="yes">R</italic> are respectively the hard and fuzzy versions of the ground truth. In this context, for the purpose of computing completeness, pair membership is based on the hard ground truth labels.</p></sec><sec id="SEC2-9"><title>Spatial RI/ARI</title><p>Yan <italic toggle="yes">et&#160;al.</italic> [<xref rid="B13" ref-type="bibr">13</xref>] proposed a spatially&#160;aware version of the Rand Index (RI) and its adjusted ARI. In this context, concordant pairs (i.e. pairs that are either separated or grouped according to both partitions) retain a concordance score of 1, as in the classical RI. However, discordant pairs, which would score 0 in the classical RI, get assigned a certain value depending on the distance between the two spots/elements. How this value is set depends on the type of discordance. Specifically, if the elements are wrongly grouped in the clustering (i.e. but are separated in the ground truth), then this mistake is more tolerated if the elements are spatially close to each other, and the value is determined by the function <italic toggle="yes">f</italic>(<italic toggle="yes">d</italic>):</p><disp-formula id="M13"><label>(13)</label><tex-math id="TM00031" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{eqnarray*}
f(d) = \alpha \cdot {\rm exp}(-d^2)
\end{eqnarray*}\end{document}</tex-math></disp-formula><p>Instead, if the elements are wrongly separated in the clustering (i.e. but are grouped in the ground truth), then this mistake is more tolerated if the elements are spatially distant, and the value is determined by the function <italic toggle="yes">h</italic>(<italic toggle="yes">d</italic>):</p><disp-formula id="M14"><label>(14)</label><tex-math id="TM00032" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{eqnarray*}
h(d) = \alpha (1-{\rm exp}(-d^2))
\end{eqnarray*}\end{document}</tex-math></disp-formula><p>The distance, here, is computed on normalized (0&#8211;1) coordinates, and the authors set the &#945; to 0.8.</p><p>As shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S10D&#8211;F</xref>, we find these original decay functions to be insufficiently steep: wrongly grouped elements get tolerated even if they are quite distant, and vice versa. We therefore changed the decay functions to the following:</p><disp-formula id="M15"><label>(15)</label><tex-math id="TM00033" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{eqnarray*}
h(d) = \alpha (1-{\rm exp}(-{\beta _hd}))
\end{eqnarray*}\end{document}</tex-math></disp-formula><disp-formula id="M16"><label>(16)</label><tex-math id="TM00034" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{eqnarray*}
f(d) = \alpha ({\rm exp}(-{\beta _fd}))
\end{eqnarray*}\end{document}</tex-math></disp-formula><p>with the default values of &#946;<sub><italic toggle="yes">f</italic></sub> = 4 and &#946;<sub><italic toggle="yes">h</italic></sub> = 1. The modified decay can be visualized in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S10G&#8211;I</xref>. These parameters are modifiable arguments to the function, and users can decide to revert back to the original distance functions from Yan <italic toggle="yes">et&#160;al.</italic> [<xref rid="B13" ref-type="bibr">13</xref>].</p></sec><sec id="SEC2-10"><title>Scalability assessment</title><p>We used the Visium HD colon cancer dataset from Oliveira <italic toggle="yes">et&#160;al.</italic> [<xref rid="B14" ref-type="bibr">14</xref>] for benchmarking (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S11</xref> for dataset details). Metric calculations were performed using both the manual annotations provided in the original study and the predicted domain partitions or cell embeddings from CellCharter [<xref rid="B15" ref-type="bibr">15</xref>]. The <monospace>poem</monospace>&#160;version 1.1.2 was used. For spatial clustering evaluation, R package <monospace>spARI</monospace> (GitHub commit fb739c8, accessed on 2025.05.28, corresponding to version 1.0 in R) was used.</p><p>CPU time (cpu_time) and peak memory usage (max_rss, maximum resident set size) of metrics was assessed by using the Snakemake&#8217;s built-in benchmarking function. The benchmarking pipeline was executed on a computing cluster, with 8 CPU cores and 100&#160;GB of memory allocated per core (i.e.&#160;<monospace>sbatch -c 8 &#8211;mem-per-cpu=102400</monospace>), allowing up to 800&#160;GB of total memory across the workflow.</p></sec></sec><sec sec-type="results" id="SEC3"><title>Results</title><sec id="SEC3-1"><title>Understanding partition-based metrics to evaluate clustering</title><p>To distinguish from measurements at the upstream data representation level, we use the term &#8220;partition-based metrics&#8221;&#160;for external clustering metrics (see Glossary in Supplementary Information). For clarity, we refer to the predicted partition to be evaluated as &#8220;clusters&#8221;, and the ground-truth partition as &#8220;classes&#8221;. The principle for defining desirable properties of clustering metrics can be summarized as follows: Given any pair of partitions of the same set, denoted as (<italic toggle="yes">P</italic><sub>1</sub>, <italic toggle="yes">P</italic><sub>2</sub>), where <italic toggle="yes">P</italic><sub>2</sub> is assumed to be a better clustering option than <italic toggle="yes">P</italic><sub>1</sub> according to some intuition, a metric <italic toggle="yes">F</italic> should adhere to the constraint that <italic toggle="yes">F</italic>(<italic toggle="yes">P</italic><sub>1</sub>) &lt; <italic toggle="yes">F</italic>(<italic toggle="yes">P</italic><sub>2</sub>) (assuming that a higher value of <italic toggle="yes">F</italic> indicates a better clustering) [<xref rid="B7" ref-type="bibr">7</xref>]. Some of these constraints and intuitions are about features of the partition that should be reflected by the metric, while others can be about biases that should not influence the metric.</p><p>Rather than reviewing all desirable properties in the literature [<xref rid="B6" ref-type="bibr">6</xref>, <xref rid="B7" ref-type="bibr">7</xref>, <xref rid="B9" ref-type="bibr">9</xref>], we focus on properties that are most relevant to clustering molecular profiles of cells: cluster homogeneity, class completeness, class size sensitivity, and chance agreement neutrality. Cluster homogeneity states that clusters should not mix objects from different classes. Class completeness requires that all elements of a single class should not be distributed across different clusters. Class size sensitivity refers to how the misassignment of an element is evaluated relative to the size of the class it belongs to. We note that whether and what exact sensitivity to class size is desired depends on the context and research question. For instance, a metric might be considered desirable if it (i) is insensitive to class size [<xref rid="B16" ref-type="bibr">16</xref>], (ii) penalizes errors more in larger classes than in smaller ones, or (iii) penalizes errors more in smaller classes than in larger ones [<xref rid="B6" ref-type="bibr">6</xref>]. Lastly, chance agreement neutrality means that similarities between two partitions occurring purely by chance should not be given undue credit to inflate the final similarity score (see Glossary in Supplementary Information or Albatineh and Niewiadomska-Bugaj [<xref rid="B17" ref-type="bibr">17</xref>]).</p><p>Partition-based metrics can be categorized into three groups based on their calculation: pair-counting, information theoretic, and set matching measures. Extensive literature covers what they are and how they compare to each other [<xref rid="B6" ref-type="bibr">6&#8211;8</xref>, <xref rid="B16" ref-type="bibr">16</xref>, <xref rid="B18" ref-type="bibr">18&#8211;20</xref>]. Instead of reviewing them all here, we focus on key aspects from each category, as listed in Table&#160;<xref rid="tbl1" ref-type="table">1</xref> and examine how they capture the desirable properties (Fig.&#160;<xref rid="F1" ref-type="fig">1</xref>). Such an examination can be easily extended to additional metrics.</p><table-wrap position="float" id="tbl1" orientation="portrait"><label>Table 1.</label><caption><p>Partition-based metrics</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="4" align="center" rowspan="1">Category</th><th rowspan="1" colspan="1">Metric</th><th rowspan="1" colspan="1">Calculation</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">PB</td><td rowspan="1" colspan="1">AG</td><td rowspan="1" colspan="1">DL</td><td rowspan="1" colspan="1">Rand Index (RI)</td><td rowspan="1" colspan="1">
<inline-formula>
<tex-math id="TM00035" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\frac{a+d}{n(n-1)/2 \text{}}$\end{document}</tex-math>
</inline-formula>; the ratio of the sum of true positive and true negative pairs to the total number of object pairs [<xref rid="B21" ref-type="bibr">21</xref>]. 0 &#8804; RI &#8804;1.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">PB</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">CL</td><td rowspan="1" colspan="1">Wallace Homogeneity (WH)</td><td rowspan="1" colspan="1">
<inline-formula>
<tex-math id="TM00036" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\frac{a}{a+c}$\end{document}</tex-math>
</inline-formula>; the ratio of the true positive pairs to the total number of object pairs that are in the same cluster in <italic toggle="yes">P</italic> [<xref rid="B22" ref-type="bibr">22</xref>]. 0 &#8804; WH &#8804;1.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">PB</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">CL</td><td rowspan="1" colspan="1">Wallace Completeness (WC)</td><td rowspan="1" colspan="1">
<inline-formula>
<tex-math id="TM00037" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\frac{a}{a+b}$\end{document}</tex-math>
</inline-formula>; the ratio of the true positive pairs to the total number of object pairs that are in the same class in <italic toggle="yes">G</italic> [<xref rid="B22" ref-type="bibr">22</xref>]. 0 &#8804; WC &#8804;1.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">PB</td><td rowspan="1" colspan="1">AG</td><td rowspan="1" colspan="1">DL</td><td rowspan="1" colspan="1">Adjusted Rand Index (ARI)</td><td rowspan="1" colspan="1">
<inline-formula>
<tex-math id="TM00038" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\frac{\text{RI}-\mathrm{E}(\text{RI})}{1-\mathrm{E}(\text{RI})} = \frac{2(ad-bc)}{(a+b)(b+d)+(a+c)(c+d)}$\end{document}</tex-math>
</inline-formula>; adjusting RI by accounting for the expected similarity of all pairings due to chance using the Permutation Model for clusterings. ARI is the harmonic mean of AWH and AWC [<xref rid="B21" ref-type="bibr">21</xref>]. &#8722;1 &#8804; ARI &#8804;1.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">PB</td><td rowspan="1" colspan="1">AG</td><td rowspan="1" colspan="1">DL</td><td rowspan="1" colspan="1">Normalized Class Size Rand Index (NCR)</td><td rowspan="1" colspan="1">A normalized version of RI, where each concordance quantity is divided by the maximum possible concordance for their respective class [<xref rid="B6" ref-type="bibr">6</xref>]. 0 &#8804; NCR &#8804;1.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">PB</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">DL</td><td rowspan="1" colspan="1">Mutual Information (MI)</td><td rowspan="1" colspan="1">
<italic toggle="yes">H</italic>(<italic toggle="yes">G</italic>) &#8722; <italic toggle="yes">H</italic>(<italic toggle="yes">G</italic>|<italic toggle="yes">P</italic>); the difference between the Shannon entropy of <italic toggle="yes">G</italic> and the conditional entropy of <italic toggle="yes">G</italic> given <italic toggle="yes">P</italic>. 0 &#8804; MI &#8804;min(<italic toggle="yes">H</italic>(<italic toggle="yes">G</italic>), <italic toggle="yes">H</italic>(<italic toggle="yes">P</italic>)).</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">PB</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">CL</td><td rowspan="1" colspan="1">Adjusted Wallace Homogeneity (AWH), Adjusted Wallace Completeness (AWC), and Adjusted Mutual Information (AMI)</td><td rowspan="1" colspan="1">Chance adjusted version of WH, WC [<xref rid="B22" ref-type="bibr">22</xref>] and MI [<xref rid="B23" ref-type="bibr">23</xref>], respectively. For a metric <italic toggle="yes">M</italic>, the chance adjusted version of it is <inline-formula><tex-math id="TM00039" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\frac{{M}-{E}({M})}{1-{E}({M})}$\end{document}</tex-math></inline-formula>. &#8722;1 &#8804; AWH/AWC/AMI &#8804;1.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">PB</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">DL</td><td rowspan="1" colspan="1">(Entropy-based) Homogeneity (EH)</td><td rowspan="1" colspan="1">
<inline-formula>
<tex-math id="TM00040" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$1-\frac{H(G|P)}{H(G)}$\end{document}</tex-math>
</inline-formula> if <italic toggle="yes">H</italic>(<italic toggle="yes">G</italic>, <italic toggle="yes">P</italic>) &#8800; 0, 1 otherwise; the ratio of MI to the individual entropy of <italic toggle="yes">G</italic> [<xref rid="B24" ref-type="bibr">24</xref>]. 0 &#8804; EH &#8804;1.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">PB</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">DL</td><td rowspan="1" colspan="1">(Entropy-based) Completeness (EC)</td><td rowspan="1" colspan="1">
<inline-formula>
<tex-math id="TM00041" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$1-\frac{H(P|G)}{H(P)}$\end{document}</tex-math>
</inline-formula> if <italic toggle="yes">H</italic>(<italic toggle="yes">P</italic>, <italic toggle="yes">G</italic>) &#8800; 0, 1 otherwise; the ratio of MI to the individual entropy of <italic toggle="yes">P</italic> [<xref rid="B24" ref-type="bibr">24</xref>]. 0 &#8804; EC &#8804;1.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">PB</td><td rowspan="1" colspan="1">AG</td><td rowspan="1" colspan="1">DL</td><td rowspan="1" colspan="1">V Measure (VM)</td><td rowspan="1" colspan="1">
<inline-formula>
<tex-math id="TM00042" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\frac{(1+\beta )\times \text{EH}\times \text{EC}}{\beta \times \text{EH}+\text{EC}}$\end{document}</tex-math>
</inline-formula>; the harmonic mean between EH and EC. It is identical to normalized mutual information (NMI) when arithmetic mean is used for averaging in NMI calculation [<xref rid="B24" ref-type="bibr">24</xref>]. 0 &#8804; VM &#8804;1.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">PB</td><td rowspan="1" colspan="1">AG</td><td rowspan="1" colspan="1">DL</td><td rowspan="1" colspan="1">Normalized Mutual Information (NMI)</td><td rowspan="1" colspan="1">A normalization of the Mutual Information (MI) to scale the results between 0 (independent) and 1 (perfect correlation). The most common ways of normalization include using the geometric mean (<inline-formula><tex-math id="TM00043" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\frac{I(X;Y)}{\sqrt{H(X) \cdot H(Y)}}$\end{document}</tex-math></inline-formula>), arithmetic mean (<inline-formula><tex-math id="TM00044" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\frac{2 \cdot I(X;Y)}{H(X) + H(Y)}$\end{document}</tex-math></inline-formula>) or maximum (<inline-formula><tex-math id="TM00045" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\frac{I(X;Y)}{\text{max}(H(X),H(Y))}$\end{document}</tex-math></inline-formula>) [<xref rid="B23" ref-type="bibr">23</xref>]. This measure is not adjusted for chance. 0 &#8804; NMI &#8804;1.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">PB</td><td rowspan="1" colspan="1">AG</td><td rowspan="1" colspan="1">CL</td><td rowspan="1" colspan="1">(weighted average) F Measure (wFM)</td><td rowspan="1" colspan="1">Here we calculate weighted F1-score, where the weights are based on the sizes of classes [<xref rid="B16" ref-type="bibr">16</xref>]. 0 &#8804; wFM &#8804;1.</td></tr></tbody></table><table-wrap-foot><fn id="T1TFN1"><p>Metrics are categorized according to whether they are aggregated or track a specific desirable property, and the minimal unit of calculation (cell, class/cluster, or dataset). Metric categories are abbreviated as follows: PB (Partition-based metric), EB (Embedding-based metric), GB (Graph-based metric), and&#160;PB-S (Partition-based metric with spatial information); AG (Aggregated metric)&#160;and&#160;PR (Property-based metric); EL (Element-level evaluation), CL (Class/cluster-level evaluation), and DL (Dataset-level evaluation). In the first column, a &#8593; indicates that a higher metric value is better, while a &#8595; means that a lower value is preferred. The notation used is common throughout the table: consider comparing the predicted partition P to the ground-truth partition G; <italic toggle="yes">a</italic> is the number of pairs that are in the same group both in P and G; <italic toggle="yes">b</italic> is the number of pairs that are in the same class in G but in different clusters in P; <italic toggle="yes">c</italic> is the number of pairs that are in different classes in G but in the same cluster in P; <italic toggle="yes">d</italic> is the number of pairs that are in different groups both in P and G; <italic toggle="yes">n</italic> is the total number of objects; <italic toggle="yes">E</italic> is the expectation operator; <italic toggle="yes">H</italic>( &#183; ) is the Shannon entropy; <italic toggle="yes">I(X</italic>; <italic toggle="yes">Y</italic>) is the Mutual Information between X and Y; &#946; is the ratio of weight attributed to homogeneity versus completeness; the expectation values of RI, WH, and WC are calculated under a generalized hypergeometric model.</p></fn></table-wrap-foot></table-wrap><p>Based on how a metric reflects the properties of homogeneity and completeness, we categorize them into property-based metrics and aggregated metrics. Property-based metrics focus on a specific desirable property. Metrics that measure homogeneity include Wallace Homogeneity (WH), its adjusted version (AWH) [<xref rid="B22" ref-type="bibr">22</xref>], Mutual Information (MI), and Entropy-based Homogeneity (EH) [<xref rid="B24" ref-type="bibr">24</xref>]. Conversely, completeness metrics contain Wallace Completeness (WC), its adjusted version (AWC), and Entropy-based Completeness (EC). Aggregated metrics integrate both homogeneity and completeness. The RI and its adjusted forms (Adjusted Rand Index, ARI, and Normalized Class Size Rand Index, NCR) are classic examples, with RI representing the harmonic mean of WH and WC, ARI being the harmonic mean of AWH and AWC, and NCR [<xref rid="B6" ref-type="bibr">6</xref>] a variant of ARI using a different normalization method (Table&#160;<xref rid="tbl1" ref-type="table">1</xref>). Other key aggregated metrics include the V-measure (VM), which is the harmonic mean of EH and EC, and the (weighted average) F-measure (wFM) [<xref rid="B16" ref-type="bibr">16</xref>], which is the harmonic mean of precision and recall (the set-matching equivalents of homogeneity and completeness).</p><p>The use of toy examples in Fig.&#160;<xref rid="F1" ref-type="fig">1A</xref> demonstrates how <italic toggle="yes">P</italic><sub>1</sub> or <italic toggle="yes">P</italic><sub>2</sub> should be preferred over the other according to each of the desirable properties. Figure&#160;<xref rid="F1" ref-type="fig">1</xref>B&#8211;F&#160;shows the metric values for these examples, illustrating their behavior. As expected, RI, ARI, NCR, wFM, and VM effectively capture both homogeneity and completeness (Fig.&#160;<xref rid="F1" ref-type="fig">1B</xref>), while WH, AWH, MI, and&#160;EH reflect homogeneity independently of completeness changes. However, when MI is adjusted for chance (i.e. AMI), it can no longer be independent of completeness. WC, AWC, and EC primarily reflect completeness, with AWC also showing a slight preference for <italic toggle="yes">P</italic><sub>2</sub> in the homogeneity example due to its chance-adjusted nature (see Glossary in Supplementary Information), which accounts for the difficulty of achieving the same completeness with an increased number of clusters as in <italic toggle="yes">P</italic><sub>2</sub>. Similarly, EC does not assign identical values to <italic toggle="yes">P</italic><sub>1</sub> and <italic toggle="yes">P</italic><sub>2</sub> in the homogeneity scenario because it lacks chance adjustment, making it sensitive to the number of clusters, particularly when both the number of samples and clusters are small [<xref rid="B24" ref-type="bibr">24</xref>].</p><p>Regarding class size sensitivity, Fig.&#160;<xref rid="F1" ref-type="fig">1B</xref> and&#160;E&#160;illustrate that WH, AWH, MI, EH, and wFM are insensitive to class size. NCR [<xref rid="B6" ref-type="bibr">6</xref>] is unique in its tendency to penalize errors in smaller classes more heavily. The remaining metrics tend to prefer errors in smaller classes over larger ones.</p><p>When it comes to chance agreement neutrality, metrics adjusted for chance, such as ARI, NCR, AWH, AWC, and AMI (Fig.&#160;<xref rid="F1" ref-type="fig">1B</xref> and&#160;F), effectively neutralize the influence of random agreements. In contrast, their unadjusted counterparts&#8212;RI, WC, and MI&#8212;are biased, with the exception of WH. wFM seems to have some resilience to such bias. Other unadjusted metrics including EH, EC, and VM&#160;fail to remain neutral to random agreements. Interestingly, although both EC and WC measure completeness, they differ in their preference for <italic toggle="yes">P</italic><sub>1</sub> and <italic toggle="yes">P</italic><sub>2</sub>, indicating that they can be affected differently by random agreements.</p><p>Notably, there is an inherent contradiction between the chance adjustment in metrics and a class size sensitivity that would favor the same error rate in larger classes over smaller ones. As depicted in Fig.&#160;<xref rid="F1" ref-type="fig">1E</xref>, ARI gives greater advantage to <italic toggle="yes">P</italic><sub>1</sub> than <italic toggle="yes">P</italic><sub>2</sub> compared to RI, and similarly, AWC favors <italic toggle="yes">P</italic><sub>1</sub> over <italic toggle="yes">P</italic><sub>2</sub> more than WC does. Recall that both ARI and AWC are explicitly adjusted for chance. Such chance adjustment assumes that correct assignments in rare classes are more likely to happen by chance, so the adjusted score is reduced more for these cases (e.g. <italic toggle="yes">P</italic><sub>2</sub>). However, this assumption may not always be valid in single-cell analysis, where methods that focus on major components of variability (e.g. SVD, variable feature selection, etc.) naturally make it challenging to detect rare populations. While the uniform sampling assumption is often acceptable for simplicity, in studies where rare populations are highly relevant, the difficulty of characterizing smaller classes should not be ignored. Thus, although chance adjustment is generally recommended for meaningful comparisons, it can introduce bias and might not necessarily track the most desired partitioning. When the accurate identification of rare classes is crucial, metrics such as NCR should be considered.</p><p>Overall, we show here how different metrics vary in their capability to reflect various desirable properties. This sheds light on why, in many benchmark studies, rankings often vary depending on the metric (Fig.&#160;<xref rid="F2" ref-type="fig">2</xref>&#160;and&#160;[<xref rid="B3" ref-type="bibr">3</xref>, <xref rid="B4" ref-type="bibr">4</xref>]). The present discussion and example analyses can therefore help users understand what each metric measures, guide their usage, and lead to better benchmark interpretation.</p><p>Furthermore, we want to highlight the limitations and lack of transparency associated with using aggregated metrics including ARI [<xref rid="B25" ref-type="bibr">25</xref>] and VM as a universal standard for assessing clustering performance. Although ARI can provide a general sense of clustering effectiveness, it does not always correlate with the optimal clustering strategy, particularly in complex tasks. We observed that as clustering granularity increases, a noticeable trade-off emerges between homogeneity and completeness, with higher granularity favoring homogeneity at the expense of completeness (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S1</xref>). This phenomenon is critical in contexts such as disease-relevant cell state discovery (Fig.&#160;<xref rid="F2" ref-type="fig">2</xref>) or meta-cell identification (see Glossary in Supplementary Information). While VM provides some flexibility by allowing adjustments to the weights between EH and EC, it remains unclear how to optimally tune this weight to achieve an optimal solution.</p><p>Therefore, despite the widespread use of aggregated metrics such as ARI, we advocate for a more selective reliance on them. While such metrics are useful for broadly identifying low-performing methods, more fine-grained comparisons among top-performing methods should instead focus on property-based metrics such as MI, AWH, and AWC, as they offer clearer insights into specific aspects of clustering performance. These metrics provide an easily interpretable readout of strengths and weaknesses, allowing for a more targeted approach in method selection and evaluation.</p><sec id="SEC3-1-1"><title>Challenges with partition-level evaluation</title><p>Evaluating at the partition level is straightforward, but determining a partition requires selecting the number of clusters, <italic toggle="yes">k</italic>, or parameters that influence it, and the values of partition-based metrics vary as <italic toggle="yes">k</italic> varies ([<xref rid="B16" ref-type="bibr">16</xref>, <xref rid="B18" ref-type="bibr">18</xref>]; see also <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S1</xref>). Multiple strategies have been adopted to address this problem, including evaluating the metric at the &#8220;best-performing <italic toggle="yes">k</italic>&#8221; [<xref rid="B4" ref-type="bibr">4</xref>], the &#8220;true <italic toggle="yes">k</italic>&#8221; (based on the available ground truth labels) [<xref rid="B1" ref-type="bibr">1</xref>, <xref rid="B2" ref-type="bibr">2</xref>, <xref rid="B26" ref-type="bibr">26</xref>], the &#8220;detected <italic toggle="yes">k</italic>&#8221; (typically using default parameters) [<xref rid="B2" ref-type="bibr">2</xref>], or across a range of parameters that yield different <italic toggle="yes">k</italic> values [<xref rid="B4" ref-type="bibr">4</xref>]. Each of these approaches, however, can introduce potential biases. For example, Fig.&#160;<xref rid="F2" ref-type="fig">2A</xref>&#8211;<xref rid="F2" ref-type="fig">C</xref> show clusterings generated by the same pipeline with different <italic toggle="yes">k</italic>. When using the &#8220;true <italic toggle="yes">k</italic>&#8221; (Fig.&#160;<xref rid="F2" ref-type="fig">2C</xref>), the pipeline performance is underestimated, because certain populations, such as B-cell subtypes, are very similar and difficult to distinguish. Forcing the clustering to match the &#8220;true <italic toggle="yes">k</italic>&#8221; results in unnecessary segregation of correctly identified clusters (Fig.&#160;<xref rid="F2" ref-type="fig">2C</xref>), which significantly reduces AWC (completeness) without improving AWH (homogeneity). Thus, the clusterings based on the &#8220;true <italic toggle="yes">k</italic>&#8221; do not always represent the most relevant solution a pipeline can generate. Selecting the &#8220;best-performing <italic toggle="yes">k</italic>,&#8221; on the other hand, has the drawback that different metrics might not agree on the best <italic toggle="yes">k</italic>. This highlights the need for complementary evaluation approaches.</p><p>In addition, biological populations often exhibit a hierarchical structure [<xref rid="B27" ref-type="bibr">27</xref>], while the ground truth is typically available at a single resolution, which is not necessarily the only meaningful one. For example, within a population labeled as a single class by the ground truth, there may exist real and meaningful subpopulations. A method that identifies these subpopulations would be significantly penalized, because the partition itself does not carry any information regarding the relationships between the different classes or clusters. This issue has been discussed in Wu and Wu [<xref rid="B27" ref-type="bibr">27</xref>], where the authors proposed evaluation metrics for comparing a partition to a hierarchical ground-truth structure. As we will see, these issues can also be mitigated by evaluating at other levels of the analysis.</p></sec></sec><sec id="SEC3-2"><title>Evaluations on upstream data representations</title><p>To circumvent the shortcomings of partition-level evaluations or at least to complement it with other measures, a promising strategy is to evaluate upstream aspects of the data, such as low dimensional embeddings or graph representations. This removes the need to select a specific <italic toggle="yes">k</italic> or resolution to explicitly define clusters. Moreover, because these representations can preserve relationships between clusters across resolutions (i.e. two subpopulations of a class will nevertheless tend to be close to each other), evaluating graph or embedding structures helps to mitigate biases related to parameter choices and the resolution of the ground truth. As we will see and as shown in the literature [<xref rid="B28" ref-type="bibr">28</xref>];&#160;however, it is important that the assumptions underlying the representations and metrics be aligned to the relevant downstream tasks.</p><p>Below, we first extend the desirable properties of partitions to embeddings and graphs. While formulations of these properties can be found in the literature [<xref rid="B29" ref-type="bibr">29</xref>, <xref rid="B30" ref-type="bibr">30</xref>], they can be understood as adaptations of the general intuitions of homogeneity and completeness. At the embedding level, these include compactness and separation of the classes; at the graph level, they are neighborhood homogeneity and class compactness. The basic intuition is that elements of a given class should be close to each other (i.e. compact) on the embedding or graph, and not be close to elements of other classes (i.e. separation or local homogeneity). Their exact meanings will vary across contexts, and we explore how different metrics, some well-established and others novel, relate to these properties.</p><sec id="SEC3-2-1"><title>Embedding assessment</title><p>Embedding-based metrics are often internal metrics used to evaluate clustering quality but can also be used as external metrics using the true class labels. A cell embedding can be evaluated either directly using distance measures within the embedding space, or indirectly through secondary information derived from these distances, such as a nearest-neighbor graph. The latter will be discussed in the following section. We discuss three representative embedding metrics: the Silhouette score [<xref rid="B31" ref-type="bibr">31</xref>], the composed density between and within clusters index (CDbw) [<xref rid="B32" ref-type="bibr">32</xref>], and the Density-Based Clustering Validation index (DBCV) [<xref rid="B33" ref-type="bibr">33</xref>]; see Table&#160;<xref rid="tbl2" ref-type="table">2</xref> for details. They are all aggregated metrics aiming to balance compactness and separation. Notably, CDbw consists of three different components&#8212;CDbw cohesion, CDbw compactness, and CDbw separation&#8212;which can be used as property-based evaluations.</p><table-wrap position="float" id="tbl2" orientation="portrait"><label>Table 2.</label><caption><p>Embedding-based evaluation metrics</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="4" align="center" rowspan="1">Category</th><th rowspan="1" colspan="1">Metric</th><th rowspan="1" colspan="1">Calculation</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">EB</td><td rowspan="1" colspan="1">AG</td><td rowspan="1" colspan="1">DL</td><td rowspan="1" colspan="1">Silhouette score</td><td rowspan="1" colspan="1">
<inline-formula>
<tex-math id="TM00046" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\frac{n-m}{\text{max}(m, n)}$\end{document}</tex-math>
</inline-formula>, where <italic toggle="yes">n</italic> is the mean distance between a sample and the nearest class that the sample is not a part of, and <italic toggle="yes">m</italic> is the mean intra-class distance [<xref rid="B31" ref-type="bibr">31</xref>]. &#8722;1 &#8804; Silhouette &#8804;1.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">EB</td><td rowspan="1" colspan="1">AG</td><td rowspan="1" colspan="1">DL</td><td rowspan="1" colspan="1">Composed Density between and within Clusters (CDbw)</td><td rowspan="1" colspan="1">The CDbw index consists of three components: cohesion, compactness, and separation between clusters. It uses multiple representative points selected from each cluster to calculate intra-cluster density and between-cluster distances, reflecting the geometry of the clusters and capturing changes in intra-cluster density. See Supplementary Information 1: Methods &#8220;Composed Density between and within Clusters (CDbw)&#8221;&#160;for details [<xref rid="B32" ref-type="bibr">32</xref>]. 0 &#8804; CDbw &#8804;+&#8734;.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">EB</td><td rowspan="1" colspan="1">AG</td><td rowspan="1" colspan="1">DL</td><td rowspan="1" colspan="1">Density Based Clustering Validation index (DBCV)</td><td rowspan="1" colspan="1">A density-based index that computes the least dense region inside a cluster and the most dense region between the clusters, to measure the within and between cluster density connectedness of clusters. See Supplementary Information 1: Methods &#8220;Density Based Clustering Validation index (DBCV)&#8221; for details [<xref rid="B33" ref-type="bibr">33</xref>], &#8722;1 &#8804; DBCV &#8804;1.</td></tr></tbody></table><table-wrap-foot><fn id="T2TFN1"><p>Metrics are categorized according to whether they are aggregated or track a specific desirable property, and the minimal unit of calculation (cell, class/cluster, or dataset). Metric categories are abbreviated as follows: PB (Partition-based metric), EB (Embedding-based metric), GB (Graph-based metric), and&#160;PB-S (Partition-based metric with spatial information); AG (Aggregated metric) and&#160;PR (Property-based metric); EL (Element-level evaluation), CL (Class/cluster-level evaluation), and DL (Dataset-level evaluation). In the first column, a &#8593; indicates that a higher metric value is better, while a &#8595; means that a lower value is preferred.</p></fn></table-wrap-foot></table-wrap><p>The Silhouette score is frequently used to evaluate single cell embeddings [<xref rid="B3" ref-type="bibr">3</xref>]. At the dataset level, it is a ratio between the separation between classes, understood as the distance between their centroids, and the compactness of the classes, understood as variance around the centroids. As such, it implicitly assumes hyperspherical classes [<xref rid="B33" ref-type="bibr">33</xref>, <xref rid="B34" ref-type="bibr">34</xref>]. In contrast, both CDbw and DBCV indices are designed to handle arbitrarily-shaped clusters or classes. CDbw achieves this by representing each class with multiple points instead of a single one. It defines between-class separation through the minimum pairwise distance between representatives, normalized by inter-class density. Compactness, in this case, is defined based on intra-class density, which assesses how tightly the classes&#8217; points are packed around representative points. Additionally, it introduces cohesion to measure the uniformity of intra-class density changes across representatives. DBCV also employs a notion of density, with compactness referring to the density within a class, specifically the maximum distance within the MST&#160;of the class, while separation corresponds to the maximum density between two classes.</p><p>In Fig.&#160;<xref rid="F3" ref-type="fig">3</xref>, we use toy examples to explore how these three metrics behave on classes (clusters) of different shapes. In Fig.&#160;<xref rid="F3" ref-type="fig">3A</xref> and&#160;<xref rid="F3" ref-type="fig">B</xref>, both scenarios feature two classes sampled from 2D Gaussian distributions. By varying the covariance, the classes take on different shapes, with class A in Scenario 1 forming an elongated cluster, while in Scenario B, it is more globular. In Scenario 1, despite a clear separation between the two classes, many negative Silhouette scores appear due to the elongated shape of class A, resulting in an overall score similar to that of Scenario 2 (Fig.&#160;<xref rid="F3" ref-type="fig">3B</xref>), where the classes are visually not as well-separated. For CDbw, although the overall scores are similar between the two scenarios, its components clearly show that the class separation is better in Scenario 1, while compactness and cohesion are worse. This provides a more comprehensive comparison. From a density perspective, DBCV favors Scenario 1 (Fig.&#160;<xref rid="F3" ref-type="fig">3B</xref>), likely because the density separation in Scenario 1 is better.</p><p>In Fig.&#160;<xref rid="F3" ref-type="fig">3</xref>C&#160;and D, we highlight two scenarios with moon-shaped classes (i.e. representing nonconvex clusters). Here, density-based clustering methods such as HDBSCAN can correctly separate the two classes, while <italic toggle="yes">k</italic>-means clustering, which assumes globular clusters, does not perform well. This performance difference is clearly identified by DBCV and CDbw (Fig.&#160;<xref rid="F3" ref-type="fig">3D</xref>), whereas the Silhouette score fails to capture it. Notably, CDbw highlights the separation differences between the two predictions in Fig.&#160;<xref rid="F3" ref-type="fig">3C</xref>, but not their compactness differences (independently from the number of representative points used, see <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S2</xref>).</p><p>We note that the assumptions about the underlying data structure captured by cell embeddings can vary depending on the downstream applications [<xref rid="B35" ref-type="bibr">35</xref>, <xref rid="B36" ref-type="bibr">36</xref>]. For instance, when 2D embeddings are used for visual cluster validation or exploring class relationships&#8212;where the global relationships and distances in the embedding space are key [<xref rid="B35" ref-type="bibr">35</xref>]&#8212;the Silhouette, CDbw, and DBCV may provide valuable insights, as they all operate on the level of cluster relationships and incorporate the notion of distance. However, special caution is needed with the Silhouette score due to its sensitivity to class shapes, since shape can vary significantly between embeddings, and shape distortions introduced by nonlinear dimensional reduction methods in single-cell data are common [<xref rid="B36" ref-type="bibr">36</xref>].</p><p>For downstream applications such as clustering, the assumptions used depend on the analysis workflow. Current best practice for clustering single-cell omics data [<xref rid="B1" ref-type="bibr">1</xref>, <xref rid="B37" ref-type="bibr">37</xref>, <xref rid="B38" ref-type="bibr">38</xref>] often involves constructing a kNN/SNN graph and applying graph-based clustering (see Glossary in Supplementary Information). This assumes that the embedding space preserves distances in local neighborhoods&#160;but not necessarily global distances. Embedding-based metrics still rely on global distances, and because of this difference in assumptions, lower values from embedding-based metrics do not necessarily imply a poorer clustering outcome.&#160;Thus, we argue that metrics that focus on local neighborhood relationships, which we introduce in the next section, are better aligned with the clustering workflow. There might however be other downstream tasks for which obtaining more globular class representations would for instance be important, and in such a context the Silhouette score would still be valuable.</p><p>Given the demonstrated importance of local similarities in clustering, the most intuitive evaluation at the embedding level would be to examine how well the local neighborhood distances are preserved in the embedding space. However, there is typically no ground truth available for this. For instance, Euclidean distances in the high-dimensional &#8220;ambient&#8221;&#160;space (see Glossary in Supplementary Information) cannot be assumed to accurately represent the true relationships due to the curse of dimensionality [<xref rid="B36" ref-type="bibr">36</xref>, <xref rid="B39" ref-type="bibr">39</xref>, <xref rid="B40" ref-type="bibr">40</xref>].</p><p>Even in a low-dimensional embedding space, there are contexts in which Euclidean distances are inappropriate [<xref rid="B40" ref-type="bibr">40</xref>, <xref rid="B41" ref-type="bibr">41</xref>]. Figure&#160;<xref rid="F4" ref-type="fig">4</xref> shows a single-cell ATAC-seq dataset where a latent space was derived using LSI (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Information 1</xref>: Methods &#8220;Exploration of the LSI embeddings for the Atlas2 scATAC-seq dataset&#8221;). In Fig.&#160;<xref rid="F4" ref-type="fig">4A</xref>, Uniform Manifold Approximation and Projection (UMAP) was performed for visualization using the LSI embedding as input. Figure&#160;<xref rid="F4" ref-type="fig">4</xref>B&#160;shows Silhouette scores of true classes using either Euclidean or Cosine distances on the LSI space, colored by the class of the closest centroids. Our observations revealed that for certain cell types (e.g.&#160;vascular smooth muscle cells), despite UMAP&#8217;s capability to effectively identify and separate these cells by relying on local connectivity, the Silhouette score using Euclidean distance in the LSI embedding space often resulted in a large proportion of negative scores, while using Cosine distance greatly alleviates this problem. In the scATAC-seq example, this is chiefly because of technical library size variation across cells: the deeper they are sequenced, the more they distinguish themselves from other classes, and hence the more spread out in the embedding (Fig.&#160;<xref rid="F4" ref-type="fig">4C</xref>&#8211;<xref rid="F4" ref-type="fig">E</xref>), creating Euclidean (but not Cosine) distances between cells that represent the same pattern, but differ in information content.</p></sec><sec id="SEC3-2-2"><title>Graph structure assessment</title><p>Graph-based clustering has become increasingly popular across multiple fields due to its effectiveness in analyzing complex networks [<xref rid="B30" ref-type="bibr">30</xref>, <xref rid="B42" ref-type="bibr">42</xref>], including in single-cell omics data [<xref rid="B1" ref-type="bibr">1</xref>, <xref rid="B38" ref-type="bibr">38</xref>, <xref rid="B43" ref-type="bibr">43</xref>]. The general idea of graph-based metrics is to assess whether connections within communities are significantly denser than those with the rest of the network [<xref rid="B30" ref-type="bibr">30</xref>]. This assumes that the graph is locally homophilic, i.e. nodes with similar attributes are more likely to be connected [<xref rid="B42" ref-type="bibr">42</xref>, <xref rid="B44" ref-type="bibr">44</xref>], which is guaranteed by the construction of the kNN/SNN graph. In addition, the construction of such graphs only assumes that distances are preserved locally in the embedding space, mitigating problems related to non-Euclidean spaces.</p><p>The intuition underlying graph clustering can be linked to the desirable properties previously discussed, where homogeneity indicates that connections primarily occur between nodes of the same class, and compactness implies that any pair of nodes within a class exhibits expected similarity, reflecting the cohesiveness of the community (Table&#160;<xref rid="tbl3" ref-type="table">3</xref>). Metrics for homogeneity are typically computed for the neighborhood of each node, but can be aggregated for evaluation at varying levels of granularity&#8212;per class&#160;or across the entire graph. The simplest, most intuitive metric, which we call neighborhood purity (NP), computes the proportion of the neighborhood sharing the node&#8217;s class. A diversity metric commonly used in the single-cell field, the Local Inverse Simpson&#8217;s Index (LISI) [<xref rid="B46" ref-type="bibr">46</xref>, <xref rid="B47" ref-type="bibr">47</xref>], can also be inverted (i.e. the Simpson Index) to evaluate homogeneity. The Proportion of Weakly Connected (PWC) nodes [<xref rid="B4" ref-type="bibr">4</xref>] and modularity [<xref rid="B45" ref-type="bibr">45</xref>] have also been used (see Table&#160;<xref rid="tbl3" ref-type="table">3</xref>). Purity and LISI/SI operate at the node level [in the context of distinguishing populations (as opposed to measuring batch integration), the LISI/SI score of a node is less easy to interpret because it tracks dominance or diversity of the neighborhood independently of whether the neighborhood matches the node&#8217;s class], PWC at the class level, and modularity at the graph level. Figure&#160;<xref rid="F5" ref-type="fig">5</xref>A&#160;shows the behaviour of these metrics using toy examples. While NP effectively measures the difference between graph 1 and the other two, it fails to capture the nuances in homogeneity between graphs 2 and 3. Instead, the small increase in LISI from graphs 2 to 3 nicely tracks the increased class diversity (and hence decreased homogeneity) among neighborhoods of comparable purity. At the class level, PWC (known as Flake-ODF in Savic and Ivanovic [<xref rid="B30" ref-type="bibr">30</xref>]) serves as an indicator of class separability that is especially sensitive to nodes that are at risk of being misclassified, making it a valuable measure of homogeneity (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S3A</xref>). In a real dataset (from Luo <italic toggle="yes">et&#160;al.</italic> [<xref rid="B4" ref-type="bibr">4</xref>]), the &#8220;B memory&#8221; and &#8220;B intermediate&#8221; subpopulations are difficult to separate during clustering (UMAP in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S3B</xref> and heatmap in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S3C</xref>), which is reflected in their large PWC score (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S3D</xref>). Notably, PWC remains robust across different neighborhood sizes used for constructing the SNN graph (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S3D</xref>). Finally, modularity is a common way to track the relationship between intra- and inter-class edges at the graph level. Of note, modularity is not limited to tracking homogeneity: because the relative weights of the edges depend on the degree of their nodes, changes in compactness can influence the modularity score. In practice, however, its focus on existing edges (as opposed to &#8220;missing&#8221; edges between elements of the same class) means that the score is mostly driven by homogeneity (see Fig.&#160;<xref rid="F5" ref-type="fig">5B</xref>, &#8220;modularity&#8221;).</p><table-wrap position="float" id="tbl3" orientation="portrait"><label>Table 3.</label><caption><p>Graph-based evaluation metrics</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="4" align="center" rowspan="1">Category</th><th rowspan="1" colspan="1">Metric</th><th rowspan="1" colspan="1">Calculation</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">GB</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">DL</td><td rowspan="1" colspan="1">Modularity</td><td rowspan="1" colspan="1">For a given graph partition, it quantifies the number of edges within communities relative to what would be expected by chance. <inline-formula><tex-math id="TM00047" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$Q = \frac{1}{2m} \sum _{ij} \left( A_{ij} - \gamma \frac{k_i k_j}{2m} \right) \delta (c_i, c_j)$\end{document}</tex-math></inline-formula>, where <italic toggle="yes">m</italic> is the number of edges, <italic toggle="yes">A</italic> is the adjacency matrix of the graph, <italic toggle="yes">k</italic><sub><italic toggle="yes">i</italic></sub> is the (weighted) degree of <italic toggle="yes">i</italic>, &#947; is the resolution parameter, and &#948;(<italic toggle="yes">c</italic><sub><italic toggle="yes">i</italic></sub>, <italic toggle="yes">c</italic><sub><italic toggle="yes">j</italic></sub>) is 1 if <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic> are in the same community else 0 [<xref rid="B45" ref-type="bibr">45</xref>]. <inline-formula><tex-math id="TM00048" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$-\frac{1}{2}\le$\end{document}</tex-math></inline-formula> modularity &#8804;1 for unweighted and undirected graphs.</td></tr><tr><td rowspan="1" colspan="1">&#8595;</td><td rowspan="1" colspan="1">GB</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">EL</td><td rowspan="1" colspan="1">Local Inverse Simpson&#8217;s Index (LISI)</td><td rowspan="1" colspan="1">For a given node in a weighted kNN graph, the expected number of nodes needed to be sampled before two nodes are drawn from the same class within its neighborhood [<xref rid="B46" ref-type="bibr">46</xref>, <xref rid="B47" ref-type="bibr">47</xref>]. 1 &#8804; LISI &#8804;&#160;<italic toggle="yes">k</italic>, where 1 indicates perfect homogeneity and <italic toggle="yes">k</italic> means a completely random mixture.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">GB</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">EL</td><td rowspan="1" colspan="1">Neighborhood Purity (NP)</td><td rowspan="1" colspan="1">For each node in a graph, the proportion of its neighborhood that is of the same class. 0 &#8804; NP &#8804;1.</td></tr><tr><td rowspan="1" colspan="1">&#8595;</td><td rowspan="1" colspan="1">GB</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">EL</td><td rowspan="1" colspan="1">Proportion of Weakly Connected (PWC)</td><td rowspan="1" colspan="1">For a given community in a graph, the proportion of nodes that have more connections to the outside of the community than the inside of the community [<xref rid="B4" ref-type="bibr">4</xref>]. 0 &#8804; PWC &#8804;1.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">GB</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">EL</td><td rowspan="1" colspan="1">Cohesion</td><td rowspan="1" colspan="1">The minimum number of nodes that must be removed to split a graph [<xref rid="B48" ref-type="bibr">48</xref>]. 0 &#8804; cohesion &#8804;&#160;<italic toggle="yes">n</italic> &#8722; 1 where <italic toggle="yes">n</italic> is the total number of nodes in the graph (<italic toggle="yes">n</italic> &#8805; 2).</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">GB</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">CL</td><td rowspan="1" colspan="1">Adhesion</td><td rowspan="1" colspan="1">The minimum number of edges that must be removed to split a graph [<xref rid="B48" ref-type="bibr">48</xref>]. 0 &#8804; adhesion &#8804;&#160;<italic toggle="yes">n</italic> &#8722; 1 where <italic toggle="yes">n</italic> is the total number of nodes in the graph (<italic toggle="yes">n</italic> &#8805; 2).</td></tr><tr><td rowspan="1" colspan="1">&#8595;</td><td rowspan="1" colspan="1">GB</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">CL</td><td rowspan="1" colspan="1">Adjusted Mean Shortest Path (AMSP)</td><td rowspan="1" colspan="1">For a connected graph, the average shortest paths between all node pairs, normalized by the square root of the total number of nodes. The paths are calculated in steps for either weighted or unweighted graphs. For disconnected graphs, AMSP is calculated as <inline-formula><tex-math id="TM00049" notation="LaTeX">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\frac{\sum _{i} (1+m_i)}{\sqrt{N}}$\end{document}</tex-math></inline-formula>, where <italic toggle="yes">m</italic><sub><italic toggle="yes">i</italic></sub> is the mean shortest path of each maximal connected subgraph, and <italic toggle="yes">N</italic> is the number of nodes. This metric captures the disconnectivity and spread of a graph. Note that the normalization for size is approximate, and specifically applicable for kNN graphs. AMSP &#8805;1.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">GB</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">CL</td><td rowspan="1" colspan="1">Neighborhood Class Enrichment (NCE)</td><td rowspan="1" colspan="1">The log2 fold-enrichment of a node&#8217;s class among its nearest neighbors compared to the expected proportion given its relative abundance. NCE is not bounded.</td></tr></tbody></table><table-wrap-foot><fn id="T3TFN1"><p>Metrics are categorized according to whether they are aggregated or track a specific desirable property, and the minimal unit of calculation (cell, class/cluster, or dataset). Metric categories are abbreviated as follows: PB (Partition-based metric), EB (Embedding-based metric), GB (Graph-based metric), and&#160;PB-S (Partition-based metric with spatial information); AG (Aggregated metric) and&#160;PR (Property-based metric); EL (Element-level evaluation), CL (Class/cluster-level evaluation), and DL (Dataset-level evaluation). In the first column, a &#8593; indicates that a higher metric value is better, while a &#8595; means that a lower value is preferred.</p></fn></table-wrap-foot></table-wrap><fig position="float" id="F5" orientation="portrait"><label>Figure 5.</label><caption><p>Example graphs and metrics computed on them. (<bold>A</bold>) Graphs with varying levels of homogeneity and their corresponding values for different metrics. (<bold>B</bold>) Graphs differing in class compactness of class 1, and their corresponding values for different metrics.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="gkaf921fig5.jpg"/></fig><p>Compactness is typically assessed at the class level, with potential to aggregate to the graph level (Table&#160;<xref rid="tbl3" ref-type="table">3</xref>). Figure&#160;<xref rid="F5" ref-type="fig">5</xref>B&#160;illustrates various graphs that differ in the degree of compactness. While all graphs have a high neighborhood homogenity (as measured by LISI/SI, PWC, and NP), graph 4 captures the similarity between nodes of class 1 much better than graph 7 because the subgraph of class 1 is more &#8220;compact&#8221;; class 2 is identical across all examples. Existing metrics to quantify graph compactness include graph cohesion or adhesion [<xref rid="B48" ref-type="bibr">48</xref>];&#160;however, they are expensive to compute and therefore not scalable to large graphs. Additionally, they are limited to quantifying disconnected class subgraphs because they provide no further distinction once zero cohesion/adhesion is reached, thus making them easily influenced by a few nodes. We propose that a more robust and scalable approach is to look at the distribution of shortest paths between any two nodes for all connected components of the same class, and then aggregate over components. Here, we define a score called &#8220;adjusted mean shortest path&#8221; (AMSP), which calculates the average shortest paths between all pairs of nodes within each connected components of a class, add 1 to these values to penalize disconnectedness, and then sum across components. Since the mean shortest path in a kNN graph is linearly proportional to the number of vertices (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S4</xref>), we divide the value by the number of nodes to yield a metric that is less dependent on class size. This nicely captures the differences between graphs in Fig.&#160;<xref rid="F5" ref-type="fig">5B</xref>.</p><p>Local homogeneity is critical to the quality of clusterings based on nearest neighbors, making the corresponding metrics highly valuable for the evaluation of (single-cell) embeddings and derived graphs. Graph compactness is also important because discontinuities in the graph may cause improper class separation. However, beyond a certain level of compactness (i.e. assuming that the graph is sufficiently connected), there might not be impact anymore on downstream clustering. In practice, the relevance of compactness is further complicated by the issue of ground truth resolution: since real subpopulations may exist within what is labeled as a single class, it might not be desirable to penalize a reduced compactness. Nevertheless, class compactness may be highly relevant in tasks such as meta-cell identification [<xref rid="B49" ref-type="bibr">49</xref>, <xref rid="B50" ref-type="bibr">50</xref>], which aim at minimizing within-group variability.</p><p>Overall, graph-based metrics are particularly valuable because they avoid some of the biases that affect embedding-based metrics, including global assumptions about distances and class shape. Graph metrics instead focus on the local structure that is critical for common downstream tasks in the single-cell field. They are highly correlated to clustering homogeneity, while avoiding the problem of partition-based metrics that are highly dependent on the clustering resolution. Moreover, graph-based metrics have the advantage of being applicable, and more or less comparable, across various ways of constructing the underlying embedding and calculating distances between cells. Taken together, we believe they are the most useful to evaluate single-cell processing.</p></sec><sec id="SEC3-2-3"><title>Comparison of metrics across data representations</title><p>To compare the metrics in various realistic contexts, we simulated 2240 datasets in which the number, abundance, and differences between classes, as well as their spread are&#160;varied; we applied various clustering pipelines, and computed partition-, embedding- and graph-based metrics (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Information 1</xref>: Methods &#8220;Simulations&#8221;). The correlation, across simulations, between pairs of metrics, and their association with specific features of the simulations, are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S5</xref>). As expected, the major patterns of association between metrics are driven by the property they track, followed by adjustment for chance. Of note, even metrics that are adjusted for chance are significantly associated with the number of clusters called.</p></sec></sec><sec id="SEC3-3"><title>Domain detection in spatial (transcript)omics data</title><p>Spatially&#160;resolved molecular measurements enhance single-cell by retaining spatial context, allowing for a more refined examination of tissue heterogeneity and cell subpopulations within physical space. One main task in the various types of spatial omics data (SOD) is the isolation of spatial homogeneous regions defined by molecular, compositional, and functional similarities [<xref rid="B51" ref-type="bibr">51</xref>, <xref rid="B52" ref-type="bibr">52</xref>]. So-called spatial domain detection, an analog of clustering, results in partitions of cells or spots (we refer to &#8220;spots&#8221; and array-based examples for simplicity, but the discussion also apply to other types of SOD. These are often compared to manual annotations based on immunohistochemistry and pre-defined markers, which are often taken as &#8220;ground truth&#8221; [<xref rid="B53" ref-type="bibr">53&#8211;56</xref>]. In this context, the partition-based metrics discussed earlier can be directly applied to clustering outputs in a spatially&#160;agnostic way. We extend this by applying the same heuristics of desirable properties and propose new metrics that incorporate spatial information.</p><sec id="SEC3-3-1"><title>Nonspatially&#160;aware evaluation</title><p>Metrics such as ARI, MI, EH, and EC (Table&#160;<xref rid="tbl1" ref-type="table">1</xref>) have already been utilized for SOD data for domain detection [<xref rid="B53" ref-type="bibr">53</xref>]. Here, we focus our discussion on property-based domain-level metrics, including WC, AWC, WH, and AWH, highlighting their transparency and interpretability (&#8220;domain&#8221; could be either a manually&#160;annotated class or an algorithm-derived cluster). We also introduce an element-level metric, Spot-wise Pair Concordance (SPC), which adapts the pair-counting concept to the spot-level, enhancing interpretability, particularly for visualization purposes.</p><p>We apply these metrics to the LIBD human dorsolateral pre-frontal cortex spatial transcriptomics data generated with the 10x Visium platform [<xref rid="B10" ref-type="bibr">10</xref>]. Figure&#160;<xref rid="F6" ref-type="fig">6A</xref> shows domain detection results across five methods, along with manual annotations; all methods are set to return the &#8220;true <italic toggle="yes">k</italic>,&#8221; and clusters are matched to classes using the Hungarian algorithm [<xref rid="B58" ref-type="bibr">58</xref>]. Figure&#160;<xref rid="F6" ref-type="fig">6</xref>B&#160;presents several partition-based metrics comparing the clusters to the manual annotation. The ranking between methods are generally consistent across metrics, except for the differences between precast [<xref rid="B59" ref-type="bibr">59</xref>] and CellCharter [<xref rid="B15" ref-type="bibr">15</xref>]. The per-domain AWC and AWH in Fig.&#160;<xref rid="F6" ref-type="fig">6</xref>C&#160;provide deeper insights that are not captured by dataset-level metrics. For example, precast performs worse than CellCharter in preserving white matter (WM), while CellCharter struggles with preserving the layer-like structure in the L3, L4, and L5 classes.</p><fig position="float" id="F6" orientation="portrait"><label>Figure 6.</label><caption><p>Partition-level metrics can be used for spatial domain detection. The LIBD 10x Visium dataset (slice 151673, Maynard <italic toggle="yes">et&#160;al.</italic> [<xref rid="B10" ref-type="bibr">10</xref>]) is used for illustration. In panel&#160;(<bold>A</bold>), the last panel shows the manual annotations, while in the remaining panels, each spot is colored according to the prediction from a domain detection algorithm, with colors matched to the corresponding classes in manual annotation. The background is shaded with alternating grey and white regions, representing the annotated adjacent domains from the manual annotation. In panel&#160;(<bold>B</bold>), the values of partition-based metrics for each method are calculated. Panels&#160;(<bold>C</bold> and <bold>D</bold>) show the values of AWC (for each class) and AWH (for each cluster).</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="gkaf921fig6.jpg"/></fig><p>Furthermore, the domain-level metrics across methods collectively reveal patterns about the manual annotations themselves. For instance, WM, corresponding to cluster 1, consistently has high AWC and AWH scores, while class L3 shows low completeness scores. This aligns with Fig.&#160;<xref rid="F6" ref-type="fig">6A</xref>, where class L3 is frequently split into multiple clusters following the shapes of different cortex layers, suggesting that this domain might exhibit heterogeneity along the axis perpendicular to the cortex layers, possibly representing a gradient layer. Lastly, cluster 4 in Fig.&#160;<xref rid="F6" ref-type="fig">6</xref>D&#160;appears to be the least homogeneous, and none of the methods clearly identify class L4 of the annotation. Both precast and SEDR [<xref rid="B60" ref-type="bibr">60</xref>] treat cluster 4 as a miscellaneous group for spots that may be noisy or contain heterogeneous cell types, while BayesSpace [<xref rid="B61" ref-type="bibr">61</xref>], CellCharter, and GraphST [<xref rid="B62" ref-type="bibr">62</xref>] label cluster 4 as continuous areas, which are however a mixture of multiple classes based on the ground truth.</p></sec><sec id="SEC3-3-2"><title>Spatially&#160;aware evaluation</title><p>The metrics above do not use spatial information, which can be used to impose additional constraints. First, adjacent cells are more likely to share common ancestors during morphogenesis and are exposed to similar signaling environments, and therefore to be more similar (positive spatial autocorrelation). Second, tissue formation tends to yield continuous structures with relatively smooth boundaries (spatial continuity), although the extent of this continuity will vary across tissues. Third, a spot&#8217;s identity is shaped not only by its own internal state&#160;but also by its surrounding environment (spatial contextuality). Finally, manual annotations of spatial domains, often used as ground truth, can be uncertain [<xref rid="B63" ref-type="bibr">63</xref>], particularly near domain interfaces, where the transition between regions may be ambiguous due to spots exhibiting characteristics of multiple domains (interface uncertainty); this is especially the case for lower-resolution technologies.</p><p>Building on the four characteristics of SOD (above), we propose two pairs of desirable properties. The first pair is local homogeneity and domain continuity, which respectively estimate the degree of positive spatial autocorrelation and spatial continuity of SOD. They are internal evaluations, meaning they can be assessed without a ground truth. The second pair includes neighborhood concordance, which estimates the extent of concordance between a spot&#8217;s spatial context between the predicted and reference partitions, and interface tolerance, which tackles interface uncertainty. They are external evaluations, which relate to comparisons with a ground truth.</p><p>While somewhat intuitive, the notion of domain continuity can have different meanings. On the one hand, it can simply be a higher-level implication of local homogeneity: highly homogeneous local neighborhoods will lead to smooth, continuous domains. On the other hand, there can be continuity in a strict sense with low local heterogeneity (e.g.&#160;thin striped pattern). The Spatial Chaos Score (CHAOS) [<xref rid="B51" ref-type="bibr">51</xref>], computed at the domain level (Table&#160;<xref rid="tbl4" ref-type="table">4</xref>), aims to track the latter, more specific kind of domain continuity. In contrast, two metrics are more focused on local homogeneity: the ELSA&#160;[<xref rid="B57" ref-type="bibr">57</xref>] and the Percentage of Abnormal Spots (PAS) [<xref rid="B51" ref-type="bibr">51</xref>] (Table&#160;<xref rid="tbl4" ref-type="table">4</xref>). Inspired by Local Indicators of Spatial Association (LISA [<xref rid="B64" ref-type="bibr">64</xref>]), ELSA is evaluated at the spot level using categorical variables&#160;but can be aggregated at the domain or dataset level. PAS summarizes at the domain or dataset-level the proportion of spots that are sufficiently inconsistent with their neighborhood (as such, it is analogous to the PWC graph metric). As shown in Fig.&#160;<xref rid="F7" ref-type="fig">7B</xref>, such abnormal spots often highlight areas with nonsmooth domain boundaries. In contrast, ELSA assigns each spot a continuous value between 0 and 1, where 0 indicates a homogeneous neighborhood (Fig.&#160;<xref rid="F7" ref-type="fig">7D</xref>). ELSA highlights boundary regions, with higher values signifying higher diversity. Both PAS and ELSA can be computed across various neighborhood sizes&#160;but are rather robust to it (Fig.&#160;<xref rid="F7" ref-type="fig">7B</xref>&#8211;<xref rid="F7" ref-type="fig">D</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S6</xref>).</p><table-wrap position="float" id="tbl4" orientation="portrait"><label>Table 4.</label><caption><p>Evaluation metrics for spatial clusterings</p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="4" align="center" rowspan="1">Category</th><th rowspan="1" colspan="1">Metric</th><th rowspan="1" colspan="1">Calculation</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">&#8595;</td><td rowspan="1" colspan="1">PB-S</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">CL</td><td rowspan="1" colspan="1">Percentage of Abnormal Spots (PAS)</td><td rowspan="1" colspan="1">PAS measures the percentage of abnormal spots, which is defined as spots with a spatial domain label differing from more than half of its nearest neighbors [<xref rid="B51" ref-type="bibr">51</xref>]. 0 &#8804; PAS &#8804;1.</td></tr><tr><td rowspan="1" colspan="1">&#8595;</td><td rowspan="1" colspan="1">PB-S</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">CL</td><td rowspan="1" colspan="1">Spatial Chaos Score (CHAOS)</td><td rowspan="1" colspan="1">CHAOS is the mean length of the graph edges in the 1-nearest neighbor (1NN) graph for each domain averaged across domains [<xref rid="B51" ref-type="bibr">51</xref>]. 0 &#8804; CHAOS +&#8734;.</td></tr><tr><td rowspan="1" colspan="1">&#8595;</td><td rowspan="1" colspan="1">PB-S</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">EL</td><td rowspan="1" colspan="1">Entropy-based Local indicator of Spatial Association (ELSA)</td><td rowspan="1" colspan="1">For a site <italic toggle="yes">i</italic>, <italic toggle="yes">E</italic><sub><italic toggle="yes">i</italic></sub> = <italic toggle="yes">E</italic><sub><italic toggle="yes">ai</italic></sub> &#215; <italic toggle="yes">E</italic><sub><italic toggle="yes">ci</italic></sub>, where <italic toggle="yes">E</italic><sub><italic toggle="yes">ai</italic></sub> summarizes the dissimilarity between site <italic toggle="yes">i</italic> and the neighboring sites, and <italic toggle="yes">E</italic><sub><italic toggle="yes">ci</italic></sub> quantifies the diversity of the categories within the neighborhood of site <italic toggle="yes">i</italic> [<xref rid="B57" ref-type="bibr">57</xref>] . See <xref rid="sup1" ref-type="supplementary-material">Supplementary Information 1</xref>: Methods &#8220;Entropy-based Local indicator of Spatial Association (ELSA)&#8221;&#160;for more details. 0 &#8804; ELSA &#8804;1.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">PB-S</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">DL</td><td rowspan="1" colspan="1">Neighborhood Smoothed (ns) RI/ARI/WH/WC/ AWH/AWC</td><td rowspan="1" colspan="1">Spatial versions of the pair-sorting indices using a neighborhood smoothing strategy, based on fuzzy versions of the metrics. Specifically, we use the NDC (see Hullermeier <italic toggle="yes">et&#160;al.</italic> [<xref rid="B11" ref-type="bibr">11</xref>]) and the ACI, see D&#8217;Ambrosio <italic toggle="yes">et&#160;al.</italic> [<xref rid="B12" ref-type="bibr">12</xref>]) as fuzzy versions of RI and ARI, respectively, and extend this approach to develop fuzzy versions of other metrics. In the spatial context, we first make a fuzzy representation of the true labels based on the spatial neighborhood, and then track the maximum pair concordance between the predicted labels and either the hard or fuzzy ground truth. For details, see <xref rid="sup1" ref-type="supplementary-material">Supplementary Information 1</xref>: Methods &#8220;Fuzzy pair-counting metrics,&#8221; &#8220;Spatial application of fuzzy metrics (neighborhood-smoothed pair sorting metrics).&#8221; 0 &#8804; nsRI/nsWH/nsWC &#8804;1, &#8722;1 &#8804; nsARI/nsAWH/nsAWC &#8804;1.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">PB-S</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">DL</td><td rowspan="1" colspan="1">Spatial RI/ARI</td><td rowspan="1" colspan="1">Spatial versions of RI/ARI using a distance-weighting strategy, proposed by Yan <italic toggle="yes">et&#160;al.</italic> [<xref rid="B13" ref-type="bibr">13</xref>]. Unlike standard RI/ARI, where discordant pairs get zero concordance scores, these variants assign concordance scores to discordant pairs based on their spatial proximity, to penalize grouping errors less when elements are close and separation errors less when elements are far apart. For details, see <xref rid="sup1" ref-type="supplementary-material">Supplementary Information 1</xref>: Methods &#8220;Spatial RI/ARI.&#8221; 0 &#8804; SpatialRI &#8804;1, &#8722;1 &#8804; SpatialARI &#8804;1.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">PB</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">EL</td><td rowspan="1" colspan="1">Spot-wise Pair Concordance (SPC)</td><td rowspan="1" colspan="1">For each spot, the average concordance with all spot pairs involving that spot. This value is the same for spots sharing the same combination of cluster and class, and is especially useful for visualization. When averaged across the dataset, it corresponds to the RI. A variant can be computed by excluding negative pairs (pairs discordant in both clustering and ground truth). See <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S7A</xref> for a graphical illustration. 0 &#8804; SPC &#8804;1.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">PB-S</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">EL</td><td rowspan="1" colspan="1">Spatial SPC</td><td rowspan="1" colspan="1">Similar to the nonspatial SPC, but evaluates concordance in a &#8220;fuzzy&#8221; manner, following the approach used for spatial adaptations of other pair-sorting indices (see above).&#160;0 &#8804; Spatial SPC &#8804;1.</td></tr><tr><td rowspan="1" colspan="1">&#8593;</td><td rowspan="1" colspan="1">PB-S</td><td rowspan="1" colspan="1">PR</td><td rowspan="1" colspan="1">DL</td><td rowspan="1" colspan="1">Neighborhood Smoothed Set-matching Accuracy (nsAccuracy)</td><td rowspan="1" colspan="1">An accuracy that downweights misclassifications based on the spatial neighborhood. Instead of counting as zero in the accuracy computation, the misclassified node counts as the proportion of its spatial neighborhood that is of the node&#8217;s predicted class. 0 &#8804; nsAccuracy &#8804;1.</td></tr></tbody></table><table-wrap-foot><fn id="T4TFN1"><p>Metrics are categorized according to whether they are aggregated or track a specific desirable property, and the minimal unit of calculation (cell, class/cluster, or dataset). Metric categories are abbreviated as follows: PB (Partition-based metric), EB (Embedding-based metric), GB (Graph-based metric), and&#160;PB-S (Partition-based metric with spatial information); AG (Aggregated metric) and&#160;PR (Property-based metric); EL (Element-level evaluation), CL (Class/cluster-level evaluation), and DL (Dataset-level evaluation). In the first column, a &#8593; indicates that a higher metric value is better, while a &#8595; means that a lower value is preferred.</p></fn></table-wrap-foot></table-wrap><fig position="float" id="F7" orientation="portrait"><label>Figure 7.</label><caption><p>Metrics for spatial clustering evaluation and visualization. The same LIBD 10x&#160;Visium dataset as in Fig.&#160;<xref rid="F6" ref-type="fig">6</xref> is used. Panel&#160;(<bold>A</bold>) is identical to the BayesSpace subpanel in Fig.&#160;<xref rid="F6" ref-type="fig">6A</xref>, where the border is colored by the predicted domain, and the background is shaded using the ground truth. In panel&#160;(<bold>B</bold>), spot-level metric values related to PAS are shown, indicating whether a spot is classified as abnormal or not. Panel&#160;(<bold>C</bold>) displays how the dataset-level ELSA and PAS score change as the size of the neighborhood (<italic toggle="yes">k</italic>) varies. Panel&#160;(<bold>D</bold>) shows element-level ELSA values. The same visualization for larger <italic toggle="yes">k</italic> are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S6</xref>.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="gkaf921fig7.jpg"/></fig><p>We also generated toy examples in Fig.&#160;<xref rid="F8" ref-type="fig">8A</xref> to investigate further the various metrics. For internal evaluation (Fig.&#160;<xref rid="F8" ref-type="fig">8B</xref>), all three metrics correctly identify P3 and P4 as less smooth than P1 or P2, albeit with different dynamic ranges. While CHAOS gives the same scores to P1 and P2 due to the lack of discontinuity, PAS and ELSA consider P1 smoother, as expected. P3 and P4 differ only in the spacing between segments of the blue domain. This leads to a slight increase in CHAOS for P4, reflecting greater spatial discontinuity. From a local homogeneity perspective, ELSA shows a small decrease for P4, indicating a marginal gain in neighborhood consistency. PAS, however, remains unchanged between P3 and P4, as the number of boundary-disrupting spots stays similar. Because these metrics are ground-truth agnostic, the pattern is similar when comparing P5 and P6.</p><fig position="float" id="F8" orientation="portrait"><label>Figure 8.</label><caption><p>Examples of desirable properties for domain detection, and how different metrics reflect each property. In panel&#160;(<bold>A</bold>), the colors within each spot represent the ground truth labels, while the colors around the spot borders indicate the predicted labels. GT1 and GT2 denote two datasets colored by the ground truth domain partition, with P1&#8211;P4 showing hypothetical domain detection results based on GT1, and P5 and P6 based on GT2. The number of misclassified spots remains the same across P1 to P3, and also across P5 and P6, but their spatial distribution varies. Panel&#160;(<bold>B&#8211;</bold>
&#160;<bold>D</bold>) demonstrate how each metric compares P1 with P2 and P3, and compares P5 with P6, respectively. Panel&#160;(B) shows internal metrics (dashed lines indicate the values for GT1 and GT2), while (C) and (D) are external metrics. Nonspatial, distance-weighted, and neighborhood smoothed versions are computed for RI and ARI. For the other metrics, nonspatial and neighborhood smoothed variants are included.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="gkaf921fig8.jpg"/></fig><p>At the time of initial writing, there was no existing external partition-based metrics that take the spatial information into account. To include this spatial dimension into partition-based evaluation, we developed two strategies.</p><p>The first approach is based on set matching (see Glossary in Supplementary Information) and evaluates the agreement between a spot&#8217;s predicted label and the true labels of both the spot and its neighborhood, capturing spatial relationships. We refer to this as the neighborhood smoothed set-matching accuracy (nsAccuracy, see Table&#160;<xref rid="tbl4" ref-type="table">4</xref>). As shown in Fig.&#160;<xref rid="F8" ref-type="fig">8</xref>C&#160;and D, nsAccuracy correctly reflects the property of interface tolerance, as misclassified spots at the domain boundary are assigned to the adjacent domain, reducing the penalties for such spots. Since misclassifications in P1 are located more at the interface between domains that those of P2, P3, and P4, it has higher set-matching accuracy. P2, P3, and P4 further demonstrate that when the number of interface misclassifications is the same, nsAccuracy remains consistent, regardless of the distribution of other misclassifications within the domain. This confirms that nsAccuracy effectively captures interface tolerance in a desirable way, while not expecting more smoothness than is present in the ground truth (Fig.&#160;<xref rid="F8" ref-type="fig">8</xref>C&#160;and D). In contrast, internal metrics in Fig.&#160;<xref rid="F8" ref-type="fig">8</xref>B&#160;assign P5 a smoother score than P6, ignoring the nonsmooth nature of GT2. Despite being simple and easy to interpret, this nsAccuracy has two major limitations: it requires matching clusters to classes, which can be ambiguous, and it is not adjusted for chance (i.e. expected agreement based on random allocations).</p><p>Another strategy we propose is to make either or both the clustering and the ground truth fuzzy (see Glossary in Supplementary Information), by averaging a spot&#8217;s identity with that of its neighborhood, and then employ metrics for fuzzy clustering evaluation [<xref rid="B11" ref-type="bibr">11</xref>, <xref rid="B12" ref-type="bibr">12</xref>]. Building on the permutation-based fuzzy version of the ARI [<xref rid="B12" ref-type="bibr">12</xref>], we developed a fuzzy version of the (adjusted) Wallace indices (i.e. WH/AWH and WC/AWC (see Table&#160;<xref rid="tbl4" ref-type="table">4</xref>). Based on this, we defined &#8220;neighborhood smoothed&#8221;&#160;versions of the pair-counting metrics [Fig.&#160;<xref rid="F8" ref-type="fig">8C</xref> and&#160;<xref rid="F8" ref-type="fig">D</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Information 1</xref>: Methods &#8220;Spatial application of fuzzy metrics (Neighborhood-smoothed pair sorting metrics)&#8221;]. As shown in Fig.&#160;<xref rid="F8" ref-type="fig">8C</xref>, these spatially&#160;aware metrics all correctly prefer P1 to P2&#8211;P4, and P6&#8211;P5, thus displaying interface tolerance.</p><p>To better understand the metric behavior with fuzzy representations, let us look at domain-level metric values. When interpreting SpatialWC and SpatialAWC in Fig.&#160;<xref rid="F8" ref-type="fig">8</xref>, one should consider the values for each ground-truth domain (i.e. class), as shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S9</xref>. In Fig.&#160;<xref rid="F8" ref-type="fig">8A</xref>, for spots of the red class, although P1&#8211;P4 misclassify the same number of spots into the blue cluster, the completeness of the red class in P1 is higher than in P2&#8211;P4. Because there are more misclassified spots in P1 that are from the interface of red and blue classes that contain partial blue memberships, the error is considered less severe. On the contrary, when interpreting SpatialWH and SpatialAWH in Fig.&#160;<xref rid="F8" ref-type="fig">8</xref>, one should consider the values for each predicted domain (i.e.&#160;cluster), as shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S9</xref>. In Fig.&#160;<xref rid="F8" ref-type="fig">8A</xref>, for spots of the blue cluster, although P1&#8211;P4 incorrectly mix the same number of spots from the red class into the blue cluster, these red spots in P1 are all on the interface between the blue and red classes in GT1, and thus have partial membership of the blue class, making such errors less penalized than the errors in P2&#8211;P4. For P2&#8211;P4, the number of misclassified spots at the class interface are identical, and thus the spatial metrics have identical values (within the range of variation of the permutations for adjusted metrics).</p><p>During the writing of this research, Yan <italic toggle="yes">et&#160;al.</italic> [<xref rid="B13" ref-type="bibr">13</xref>] proposed a different set of spatially&#160;sensitive properties. They stipulated that&#160;(i) incorrectly grouping two elements (e.g. spots) into the same domain should be penalized less if the elements are close to each other,&#160;and,&#160;(ii) incorrectly separating two elements should be penalized less if they are distant from each other. Rather than tackling interface uncertainty, as do the aformentioned fuzzy metrics, these properties emphasize positive spatial autocorrelation and spatial continuity, both of which are expected in SOD. The authors developed a spatially&#160;aware version of the Rand Index (Spatial RI) by giving discordant pair a nonzero concordance value based on their spatial proximity. They additionally developed a version adjusted for chance (Spatial ARI). While the proposal and metrics are sound, we found that the original weight functions proposed by the authors do not change sufficiently with distance (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S10</xref>), and therefore adjusted them. These &#8220;distance-weighted&#8221;&#160;RI/ARI are shown for our toy example in (Fig.&#160;<xref rid="F8" ref-type="fig">8C</xref> and&#160;<xref rid="F8" ref-type="fig">D</xref>). Both the distance-weighted and neighborhood smoothed RI/ARI show a decrease in P2&#8211;P4 compared to P1, with the strongest decrease for the neighborhood smoothed scores (Fig.&#160;<xref rid="F8" ref-type="fig">8C</xref>). They differ, however, in whether P4 is worse than P2 and P3. Neighborhood smoothed RI/ARI stay invariant across P2 to P4, as they are sensitive only to the number of edge errors, not their spatial distribution. In contrast, distance-weighted RI/ARI further decrease in P4, reflecting the greater spatial separation between mislabeled spots and the true blue domain. Which behavior is more desirable depends on assumptions and downstream application. Similarly, the two spatially&#160;aware variants disagree on which of P5 and P6 is worse. The intuition of edge tolerance explains why the neighborhood smoothed RI/ARI assign a higher score to P6 than P5, while it is less intuitive why the distance-weighted approach would assign a higher score to P5.</p><p>Finally, for element-wise external evaluation and visualization, we developed the SPC&#160;(Table&#160;<xref rid="tbl4" ref-type="table">4</xref>). It can incorporate either hard-hard or fuzzy-hard representations of the truth and prediction, making it flexible for either nonspatially&#160;aware or spatially&#160;aware evaluation. This is useful to spatially visualize the different degrees of disagreement between a predicted domain partition and a ground truth without the need for set matching (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig.&#160;S7</xref>). To facilitate exploration of the aforementioned metrics, we developed a Shiny app, available at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://plger.shinyapps.io/poem/" ext-link-type="uri">https://plger.shinyapps.io/poem/</ext-link>, which allows users to visualize results interactively and interpret the behavior of the metrics on customizable toy examples.</p></sec></sec><sec id="SEC3-4"><title>Time and memory complexity</title><p>With the emergence of atlas-scale single-cell datasets, it is important to have evaluation metrics that are both time- and memory-efficient. For metrics newly proposed or implemented by our package <monospace>poem</monospace>, we monitored CPU time and peak memory usage across four dataset sizes by subsampling a large dataset (<xref rid="sup1" ref-type="supplementary-material">Supplementary Figs&#160;S11</xref> and <xref rid="sup1" ref-type="supplementary-material">S12</xref>). With the exception of DBCV, all tested partition-, embedding-, and graph-based metrics demonstrate high scalability. DBCV is computationally intensive in both time and memory due to the need to compute pairwise distance matrices and MSTs within each cluster.</p><p>Among spatial metrics using distance-weighting, the original implementation of SpatialARI [<xref rid="B13" ref-type="bibr">13</xref>] by Yan <italic toggle="yes">et&#160;al.</italic> consumes excessive memory and fails with an out-of-memory error for the dataset with 136&#160;870 cells. In contrast, our optimized version significantly reduces memory usage (by 10- to 100-fold) at comparable runtime. Spatial metrics using neighborhood smoothing are comparatively slow but remain memory efficient.</p></sec></sec><sec sec-type="discussion" id="SEC4"><title>Discussion</title><p>Evaluation metrics play a crucial role in shaping our understanding of the strengths and weaknesses of computational methods, guiding their development, and ultimately influencing our interpretation of biology. However, the current practice of selecting evaluation metrics in the single-cell omics field often lacks a clear and rational basis. In this work, we leverage the concept of desirable properties to gain a deeper understanding of the behavior of each metric, offering a structured guideline for rational metric selection.</p><p>To illustrate and explore these desirable properties, we make extensive use of carefully designed toy examples. These examples, while simple, offer clear insights that can be difficult to extract from real-world datasets, where multiple factors are often entangled. Despite their simplicity, these examples demonstrate what does or does not influence a metric, thereby helping the interpretation in a way that extends to real-world datasets.</p><p>In single-cell -omics, the identification of rare subpopulations is often most challenging, and some of the most widely used metrics, such as the ARI, are less sensitive to misclassification errors happening in smaller populations. They are also, we argue, less interpretable. Given that each metric captures different desirable properties and functions at different evaluation levels, we generally advocate the use of property-based metrics and those that operate at finer levels, such as class- or spot-level metrics, for fine-grained method comparison. As demonstrated in the clustering examples and domain detection examples, they offer greater transparency and interpretability compared to aggregated, dataset-level metrics.</p><p>We extend the most relevant desirable properties from partitions to embeddings to graphs, enabling a similar and structured evaluation across these levels, and emphasize that desirable properties should be carefully considered within the biological context of a study. By examining the relationships and trade-offs between different properties, we aim to help researchers select metrics tailored to their biological questions and the complexities of different datasets. This approach aids in developing useful metrics, as well as in addressing the challenge of interpreting benchmarking results that involve multiple metrics and datasets with inconsistent rankings of methods.</p><p>By understanding metrics from the perspective of desirable properties, researchers can more precisely assess the validity of the underlying assumptions. In our discussion, we advocate evaluating single-cell data from a connectivity standpoint at the graph level, as it requires fewer global assumptions than embedding-based evaluations, and has proven to be highly effective in capturing statistical patterns in single-cell datasets. In addition, it is preferable over partition-based evaluation because it mitigates issues caused by misaligned levels of biological granularity between the prediction and ground truth. To facilitate this practice, we introduce novel metrics&#8212;PWC and AMSP&#8212;that align with this perspective. In particular, we introduce AMSP as a measure of graph compactness: while compactness is not always crucial when evaluating the discrimination of cell populations (because the ground truth annotation typically does not exclude the existence of unknown sub-populations), it can be for other tasks. For example, compactness is critical to accurate trajectory inference, where discontinuities could lead to wrong inferences. An implementation of all of the metrics discussed here (and more), including the novel metrics and fuzzy adaptations, are available in our R package <monospace>poem</monospace> (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://bioconductor.org/packages/poem" ext-link-type="uri">https://bioconductor.org/packages/poem</ext-link>).</p><p>In addition, we extend our work to the problem of spatial domain detection in SOD. The evaluation of domain detection methods has often relied on internal metrics or external metrics that do not account for spatial relationships. To address this, we developed spatially&#160;aware metrics for external evaluation. While we tested our external metrics primarily on array-based SOD, in principle they are applicable to nonarray-based SRT datasets by defining neighborhood structures using physical distances between cell centers or boundaries.</p><p>Overall, our work emphasizes the contribution of a systematic approach to evaluation metrics grounded in desirable properties. This method prioritizes biological intuition and concerns, rather than uncritically adopting metrics from other fields. In our analysis of spatial domain detection, we demonstrate how different data modalities introduce additional biological considerations, from which we derive new desirable properties. This showcases the strength of our framework not only in providing guidelines but also in generating new principles and inspiring the development of novel metrics.</p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material id="sup1" position="float" content-type="local-data" orientation="portrait"><label>gkaf921_Supplemental_File</label><media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="gkaf921_supplemental_file.pdf" position="float" orientation="portrait"/></supplementary-material></sec></body><back><ack id="ACK1"><title>Acknowledgements</title><p>We wish to acknowledge Robinson Lab members for fruitful discussion and the core SpaceHack 2023 team (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://spatialhackathon.github.io/past.html" ext-link-type="uri">https://spatialhackathon.github.io/past.html</ext-link>), especially Jieran Sun, Peiying Cai, and Sarusan Kathirchelvan, for discussions and sharing partitions from methods run on the LIBD dataset.</p><p>
<italic toggle="yes">Author contributions:</italic> Siyuan Luo (Conceptualization [lead], Data curation [equal], Formal analysis [lead], Investigation [lead], Methodology [equal], Resources [equal], Software [equal], Visualization [equal], Writing&#8212;original draft [equal], Writing&#8212;review &amp; editing [equal]), Pierre-Luc Germain (Conceptualization [equal], Formal analysis [equal], Investigation [equal], Methodology [equal], Resources [equal], Software [equal], Validation [equal], Visualization [equal], Writing&#8212;original draft [equal], Writing&#8212;review &amp; editing [equal]), Ferdinand von Meyenn (Investigation [equal], Project administration [equal], Supervision [equal], Writing&#8212;review &amp; editing [equal]), and&#160;Mark D. Robinson (Conceptualization [equal], Investigation [equal], Methodology [equal], Project administration [equal], Supervision [equal], Writing&#8212;original draft [equal], Writing&#8212;review &amp; editing [equal]).</p></ack><sec id="SEC6"><title>Supplementary data</title><p>
<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://academic.oup.com/nar/article-lookup/doi/10.1093/nar/gkaf921#supplementary-data" ext-link-type="uri">Supplementary data</ext-link> is available at NAR online.</p></sec><sec sec-type="COI-statement" id="SEC7"><title>Conflict of interest</title><p>Authors declare that they have no conflict of interest.</p></sec><sec id="SEC8"><title>Funding</title><p>M.D.R. acknowledges funding from the Swiss National Science Foundation (grants 200021_212940 and 310030_204869) as well as support from swissuniversities P5 Phase B funding (project 23-36_14). F.v.M. acknowledges funding from the European Research Council Starting Grant (# 803491; BRITE). Funding to pay the Open Access publication charges for this article was provided by University funds.</p></sec><sec sec-type="data-availability" id="SEC9"><title>Data availability</title><p>All the metrics we mentioned are implemented in our R package <monospace>poem</monospace> (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://bioconductor.org/packages/poem" ext-link-type="uri">https://bioconductor.org/packages/poem</ext-link>, snapshot on Zenodo: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://doi.org/10.5281/zenodo.15853802" ext-link-type="uri">https://doi.org/10.5281/zenodo.15853802</ext-link>). Notebooks, R scripts, and supporting data used for reproducing the analysis and generating the visualizations in this manuscript are available at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/RoseYuan/metric_paper" ext-link-type="uri">https://github.com/RoseYuan/metric_paper</ext-link> (snapshot on Zenodo: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://doi.org/10.5281/zenodo.15853790" ext-link-type="uri">https://doi.org/10.5281/zenodo.15853790</ext-link>).</p></sec><ref-list id="REF1"><title>References</title><ref id="B1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Du&#242;</surname> &#160;<given-names>A</given-names></string-name>, <string-name name-style="western"><surname>Robinson</surname> &#160;<given-names>MD</given-names></string-name>, <string-name name-style="western"><surname>Soneson</surname> &#160;<given-names>C</given-names></string-name></person-group> &#160;<article-title>A systematic performance evaluation of clustering methods for single-cell RNA-seq data</article-title>. <source>F1000Research</source>. <year>2020</year>; <volume>7</volume>:<fpage>1141</fpage>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.12688/f1000research.15666.1</pub-id><pub-id pub-id-type="pmcid">PMC6134335</pub-id><pub-id pub-id-type="pmid">30271584</pub-id></mixed-citation></ref><ref id="B2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Germain</surname> &#160;<given-names>PL</given-names></string-name>, <string-name name-style="western"><surname>Sonrel</surname> &#160;<given-names>A</given-names></string-name>, <string-name name-style="western"><surname>Robinson</surname> &#160;<given-names>MD</given-names></string-name></person-group> &#160;<article-title>pipeComp, a general framework for the evaluation of computational pipelines, reveals performant single cell RNA-seq preprocessing tools</article-title>. <source>Genome Biol</source>. <year>2020</year>; <volume>21</volume>:<fpage>227</fpage><pub-id pub-id-type="doi">10.1186/s13059-020-02136-7</pub-id>.<pub-id pub-id-type="pmid">32873325</pub-id><pub-id pub-id-type="pmcid">PMC7465801</pub-id></mixed-citation></ref><ref id="B3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Luecken</surname> &#160;<given-names>MD</given-names></string-name>, <string-name name-style="western"><surname>B&#252;ttner</surname> &#160;<given-names>M</given-names></string-name>, <string-name name-style="western"><surname>Chaichoompu</surname> &#160;<given-names>K</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Benchmarking atlas-level data integration in single-cell genomics</article-title>. <source>Nat Methods</source>. <year>2022</year>; <volume>19</volume>:<fpage>41</fpage>&#8211;<lpage>50</lpage>.<pub-id pub-id-type="doi">10.1038/s41592-021-01336-8</pub-id>.<pub-id pub-id-type="pmid">34949812</pub-id><pub-id pub-id-type="pmcid">PMC8748196</pub-id></mixed-citation></ref><ref id="B4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Luo</surname> &#160;<given-names>S</given-names></string-name>, <string-name name-style="western"><surname>Germain</surname> &#160;<given-names>PL</given-names></string-name>, <string-name name-style="western"><surname>Robinson</surname> &#160;<given-names>MD</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Benchmarking computational methods for single-cell chromatin data analysis</article-title>. <source>Genome Biol</source>. <year>2024</year>; <volume>25</volume>:<fpage>225</fpage><pub-id pub-id-type="doi">10.1186/s13059-024-03356-x</pub-id>.<pub-id pub-id-type="pmid">39152456</pub-id><pub-id pub-id-type="pmcid">PMC11328424</pub-id></mixed-citation></ref><ref id="B5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Tran</surname> &#160;<given-names>HTN</given-names></string-name>, <string-name name-style="western"><surname>Ang</surname> &#160;<given-names>KS</given-names></string-name>, <string-name name-style="western"><surname>Chevrier</surname> &#160;<given-names>M</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>A benchmark of batch-effect correction methods for single-cell RNA sequencing data</article-title>. <source>Genome Biol</source>. <year>2020</year>; <volume>21</volume>:<fpage>12</fpage><pub-id pub-id-type="doi">10.1186/s13059-019-1850-9</pub-id>.<pub-id pub-id-type="pmid">31948481</pub-id><pub-id pub-id-type="pmcid">PMC6964114</pub-id></mixed-citation></ref><ref id="B6"><label>6.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name name-style="western"><surname>de&#160;Souto</surname> &#160;<given-names>MC</given-names></string-name>, <string-name name-style="western"><surname>Coelho</surname> &#160;<given-names>AL</given-names></string-name>, <string-name name-style="western"><surname>Faceli</surname> &#160;<given-names>K</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>A comparison of external clustering evaluation indices in the context of imbalanced data sets</article-title>. <source>2012 Brazilian symposium on neural networks</source>. <year>2012</year>; <publisher-loc>Piscataway, NJ, USA</publisher-loc><publisher-name>IEEE</publisher-name><fpage>49</fpage>&#8211;<lpage>54</lpage>.<pub-id pub-id-type="doi">10.1109/SBRN.2012.25</pub-id>.</mixed-citation></ref><ref id="B7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Amig&#243;</surname> &#160;<given-names>E</given-names></string-name>, <string-name name-style="western"><surname>Gonzalo</surname> &#160;<given-names>J</given-names></string-name>, <string-name name-style="western"><surname>Artiles</surname> &#160;<given-names>J</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>A comparison of extrinsic clustering evaluation metrics based on formal constraints</article-title>. <source>Inform Retrieval</source>. <year>2009</year>; <volume>12</volume>:<fpage>461</fpage>&#8211;<lpage>86</lpage>.<pub-id pub-id-type="doi">10.1007/s10791-008-9066-8</pub-id>.</mixed-citation></ref><ref id="B8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Wu</surname> &#160;<given-names>J</given-names></string-name>, <string-name name-style="western"><surname>Chen</surname> &#160;<given-names>J</given-names></string-name>, <string-name name-style="western"><surname>Xiong</surname> &#160;<given-names>H</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>External validation measures for <italic toggle="yes">K</italic>-means clustering: A data distribution perspective</article-title>. <source>Exp Syst Appl</source>. <year>2009</year>; <volume>36</volume>:<fpage>6050</fpage>&#8211;<lpage>61</lpage>.<pub-id pub-id-type="doi">10.1016/j.eswa.2008.06.093</pub-id>.<pub-id pub-id-type="pmid">19095536</pub-id></mixed-citation></ref><ref id="B9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Arinik</surname> &#160;<given-names>N</given-names></string-name>, <string-name name-style="western"><surname>Labatut</surname> &#160;<given-names>V</given-names></string-name>, <string-name name-style="western"><surname>Figueiredo</surname> &#160;<given-names>R</given-names></string-name></person-group> &#160;<article-title>Characterizing and comparing external measures for the assessment of cluster analysis and community detection</article-title>. <source>IEEE Access</source>. <year>2021</year>; <volume>9</volume>:<fpage>20255</fpage>&#8211;<lpage>76</lpage>.<pub-id pub-id-type="doi">10.1109/ACCESS.2021.3054621</pub-id>.</mixed-citation></ref><ref id="B10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Maynard</surname> &#160;<given-names>KR</given-names></string-name>, <string-name name-style="western"><surname>Collado-Torres</surname> &#160;<given-names>L</given-names></string-name>, <string-name name-style="western"><surname>Weber</surname> &#160;<given-names>LM</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Transcriptome-scale spatial gene expression in the human dorsolateral prefrontal cortex</article-title>. <source>Nat Neurosci</source>. <year>2021</year>; <volume>24</volume>:<fpage>425</fpage>&#8211;<lpage>36</lpage>.<pub-id pub-id-type="doi">10.1038/s41593-020-00787-0</pub-id>.<pub-id pub-id-type="pmid">33558695</pub-id><pub-id pub-id-type="pmcid">PMC8095368</pub-id></mixed-citation></ref><ref id="B11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Hullermeier</surname> &#160;<given-names>E</given-names></string-name>, <string-name name-style="western"><surname>Rifqi</surname> &#160;<given-names>M</given-names></string-name>, <string-name name-style="western"><surname>Henzgen</surname> &#160;<given-names>S</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Comparing fuzzy partitions: a generalization of the rand index and related measures</article-title>. <source>IEEE T Fuzzy Syst</source>. <year>2011</year>; <volume>20</volume>:<fpage>546</fpage>&#8211;<lpage>56</lpage>.<pub-id pub-id-type="doi">10.1109/TFUZZ.2011.2179303</pub-id>.</mixed-citation></ref><ref id="B12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>D&#8217;Ambrosio</surname> &#160;<given-names>A</given-names></string-name>, <string-name name-style="western"><surname>Amodio</surname> &#160;<given-names>S</given-names></string-name>, <string-name name-style="western"><surname>Iorio</surname> &#160;<given-names>C</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Adjusted concordance index: an extensionl of the adjusted rand index to fuzzy partitions</article-title>. <source>J Classif</source>. <year>2021</year>; <volume>38</volume>:<fpage>112</fpage>&#8211;<lpage>28</lpage>.<pub-id pub-id-type="doi">10.1007/s00357-020-09367-0</pub-id>.</mixed-citation></ref><ref id="B13"><label>13.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name name-style="western"><surname>Yan</surname> &#160;<given-names>Y</given-names></string-name>, <string-name name-style="western"><surname>Feng</surname> &#160;<given-names>X</given-names></string-name>, <string-name name-style="western"><surname>Luo</surname> &#160;<given-names>X</given-names></string-name></person-group> &#160;<article-title>Spatially aware adjusted rand index for evaluating spatial transcriptomics clustering</article-title>. <comment>bioRxiv</comment><comment>5 August 2025, preprint: not peer reviewed</comment><pub-id pub-id-type="doi">10.1101/2025.03.25.645156</pub-id>.<pub-id pub-id-type="pmid">41001748</pub-id></mixed-citation></ref><ref id="B14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Oliveira</surname> &#160;<given-names>MFd</given-names></string-name>, <string-name name-style="western"><surname>Romero</surname> &#160;<given-names>JP</given-names></string-name>, <string-name name-style="western"><surname>Chung</surname> &#160;<given-names>M</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>High-definition spatial transcriptomic profiling of immune cell populations in colorectal cancer</article-title>. <source>Nat Genetics</source>. <year>2025</year>; <volume>57</volume>:<fpage>1512</fpage>&#8211;<lpage>23</lpage>.<pub-id pub-id-type="pmid">40473992</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41588-025-02193-3</pub-id><pub-id pub-id-type="pmcid">PMC12165841</pub-id></mixed-citation></ref><ref id="B15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Varrone</surname> &#160;<given-names>M</given-names></string-name>, <string-name name-style="western"><surname>Tavernari</surname> &#160;<given-names>D</given-names></string-name>, <string-name name-style="western"><surname>Santamaria-Mart&#237;nez</surname> &#160;<given-names>A</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>CellCharter reveals spatial cell niches associated with tissue remodeling and cell plasticity</article-title>. <source>Nat Genetics</source>. <year>2024</year>; <volume>56</volume>:<fpage>74</fpage>&#8211;<lpage>84</lpage>.<pub-id pub-id-type="doi">10.1038/s41588-023-01588-4</pub-id>.<pub-id pub-id-type="pmid">38066188</pub-id></mixed-citation></ref><ref id="B16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Rezaei</surname> &#160;<given-names>M</given-names></string-name>, <string-name name-style="western"><surname>Fr&#228;nti</surname> &#160;<given-names>P</given-names></string-name></person-group> &#160;<article-title>Set matching measures for external cluster validity</article-title>. <source>IEEE T Knowl Data Eng</source>. <year>2016</year>; <volume>28</volume>:<fpage>2173</fpage>&#8211;<lpage>86</lpage>.<pub-id pub-id-type="doi">10.1109/TKDE.2016.2551240</pub-id>.</mixed-citation></ref><ref id="B17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Albatineh</surname> &#160;<given-names>AN</given-names></string-name>, <string-name name-style="western"><surname>Niewiadomska-Bugaj</surname> &#160;<given-names>M</given-names></string-name></person-group> &#160;<article-title>Correcting Jaccard and other similarity indices for chance agreement in cluster analysis</article-title>. <source>Adv Data Anal Classif</source>. <year>2011</year>; <volume>5</volume>:<fpage>179</fpage>&#8211;<lpage>200</lpage>.<pub-id pub-id-type="doi">10.1007/s11634-011-0090-y</pub-id>.</mixed-citation></ref><ref id="B18"><label>18.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name name-style="western"><surname>Wagner</surname> &#160;<given-names>S</given-names></string-name>, <string-name name-style="western"><surname>Wagner</surname> &#160;<given-names>D</given-names></string-name></person-group> &#160;<article-title>Comparing clusterings: an overview</article-title>. <year>2007</year>; <publisher-name>Institut f&#252;r Theoretische Informatik, Universit&#228;t Karlsruhe</publisher-name><pub-id pub-id-type="doi">10.5445/IR/1000011477</pub-id>.</mixed-citation></ref><ref id="B19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>van</surname> &#160;<given-names>der Hoef H</given-names></string-name>, <string-name name-style="western"><surname>Warrens</surname> &#160;<given-names>MJ</given-names></string-name></person-group> &#160;<article-title>Understanding information theoretic measures for comparing clusterings</article-title>. <source>Behaviormetrika</source>. <year>2019</year>; <volume>46</volume>:<fpage>353</fpage>&#8211;<lpage>70</lpage>.<pub-id pub-id-type="doi">10.1007/s41237-018-0075-7</pub-id>.</mixed-citation></ref><ref id="B20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>&#381;alik</surname> &#160;<given-names>KR</given-names></string-name>, <string-name name-style="western"><surname>&#381;alik</surname> &#160;<given-names>B</given-names></string-name></person-group> &#160;<article-title>Validity index for clusters of different sizes and densities</article-title>. <source>Pattern Recogn Lett</source>. <year>2011</year>; <volume>32</volume>:<fpage>221</fpage>&#8211;<lpage>34</lpage>.<pub-id pub-id-type="doi">10.1016/j.patrec.2010.08.007</pub-id>.</mixed-citation></ref><ref id="B21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Rand</surname> &#160;<given-names>WM</given-names></string-name></person-group> &#160;<article-title>Objective criteria for the evaluation of clustering methods</article-title>. <source>J Am Stat Assoc</source>. <year>1971</year>; <volume>66</volume>:<fpage>846</fpage>&#8211;<lpage>50</lpage>.<pub-id pub-id-type="doi">10.1080/01621459.1971.10482356</pub-id>.</mixed-citation></ref><ref id="B22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Wallace</surname> &#160;<given-names>DL</given-names></string-name></person-group> &#160;<article-title>A method for comparing two hierarchical clusterings: comment</article-title>. <source>J Am Stat Assoc</source>. <year>1983</year>; <volume>78</volume>:<fpage>569</fpage>&#8211;<lpage>76</lpage>.</mixed-citation></ref><ref id="B23"><label>23.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name name-style="western"><surname>Vinh</surname> &#160;<given-names>NX</given-names></string-name>, <string-name name-style="western"><surname>Epps</surname> &#160;<given-names>J</given-names></string-name>, <string-name name-style="western"><surname>Bailey</surname> &#160;<given-names>J</given-names></string-name></person-group> &#160;<article-title>Information theoretic measures for clusterings comparison: is a correction for chance necessary?</article-title>. <source>Proceedings of the 26th annual international conference on machine learning (ICML 2009)</source>. <year>2009</year>; <publisher-loc>New York, NY, USA</publisher-loc><publisher-name>ACM</publisher-name><fpage>1073</fpage>&#8211;<lpage>80</lpage>.<pub-id pub-id-type="doi">10.1145/1553374.1553511</pub-id>.</mixed-citation></ref><ref id="B24"><label>24.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name name-style="western"><surname>Rosenberg</surname> &#160;<given-names>A</given-names></string-name>, <string-name name-style="western"><surname>Hirschberg</surname> &#160;<given-names>J</given-names></string-name></person-group> &#160;<article-title>V-measure: A conditional entropy-based external cluster evaluation measure</article-title>. <source>Proceedings of the 2007 joint conference on empirical methods in natural language processing and computational natural language learning (EMNLP-CoNLL)</source>. <year>2007</year>; <publisher-loc>Stroudsburg, PA, USA</publisher-loc><publisher-name>Association for Computational Linguistics</publisher-name><fpage>410</fpage>&#8211;<lpage>20</lpage>.</mixed-citation></ref><ref id="B25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Maan</surname> &#160;<given-names>H</given-names></string-name>, <string-name name-style="western"><surname>Zhang</surname> &#160;<given-names>L</given-names></string-name>, <string-name name-style="western"><surname>Yu</surname> &#160;<given-names>C</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Characterizing the impacts of dataset imbalance on single-cell data integration</article-title>. <source>Nat Biotechnol</source>. <year>2024</year>; <volume>42</volume>:<fpage>1899</fpage>&#8211;<lpage>1908</lpage>.<pub-id pub-id-type="pmid">38429430</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41587-023-02097-9</pub-id></mixed-citation></ref><ref id="B26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Chen</surname> &#160;<given-names>H</given-names></string-name>, <string-name name-style="western"><surname>Lareau</surname> &#160;<given-names>C</given-names></string-name>, <string-name name-style="western"><surname>Andreani</surname> &#160;<given-names>T</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Assessment of computational methods for the analysis of single-cell ATAC-seq data</article-title>. <source>Genome Biol</source>. <year>2019</year>; <volume>20</volume>:<fpage>241</fpage><pub-id pub-id-type="doi">10.1186/s13059-019-1854-5</pub-id>.<pub-id pub-id-type="pmid">31739806</pub-id><pub-id pub-id-type="pmcid">PMC6859644</pub-id></mixed-citation></ref><ref id="B27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Wu</surname> &#160;<given-names>Z</given-names></string-name>, <string-name name-style="western"><surname>Wu</surname> &#160;<given-names>H</given-names></string-name></person-group> &#160;<article-title>Accounting for cell type hierarchy in evaluating single cell RNA-seq clustering</article-title>. <source>Genome Biol</source>. <year>2020</year>; <volume>21</volume>:<fpage>123</fpage><pub-id pub-id-type="doi">10.1186/s13059-020-02027-x</pub-id>.<pub-id pub-id-type="pmid">32450895</pub-id><pub-id pub-id-type="pmcid">PMC7249323</pub-id></mixed-citation></ref><ref id="B28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Wang</surname> &#160;<given-names>H</given-names></string-name>, <string-name name-style="western"><surname>Leskovec</surname> &#160;<given-names>J</given-names></string-name>, <string-name name-style="western"><surname>Regev</surname> &#160;<given-names>A</given-names></string-name></person-group> &#160;<article-title>Limitations of cell embedding metrics assessed using drifting islands</article-title>. <source>Nat Biotechnol</source>. <year>2025</year>; <pub-id pub-id-type="doi">10.1038/s41587-025-02702-z</pub-id>.<pub-id pub-id-type="pmid">40500472</pub-id></mixed-citation></ref><ref id="B29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Halkidi</surname> &#160;<given-names>M</given-names></string-name>, <string-name name-style="western"><surname>Vazirgiannis</surname> &#160;<given-names>M</given-names></string-name>, <string-name name-style="western"><surname>Hennig</surname> &#160;<given-names>C</given-names></string-name></person-group> &#160;<article-title>Method-independent indices for cluster validation and estimating the number of clusters</article-title>. <source>Handbook Cluster Analysis</source>. <year>2015</year>; <volume>26</volume>:<fpage>595</fpage>&#8211;<lpage>618</lpage>.</mixed-citation></ref><ref id="B30"><label>30.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name name-style="western"><surname>Savic</surname> &#160;<given-names>M</given-names></string-name>, <string-name name-style="western"><surname>Ivanovic</surname> &#160;<given-names>M</given-names></string-name></person-group> &#160;<article-title>Graph clustering evaluation metrics as software metrics</article-title>. <source>SQAMIA</source>. <year>2014</year>; <fpage>81</fpage>&#8211;<lpage>9</lpage>.</mixed-citation></ref><ref id="B31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Rousseeuw</surname> &#160;<given-names>PJ</given-names></string-name></person-group> &#160;<article-title>Silhouettes: a graphical aid to the interpretation and validation of cluster analysis</article-title>. <source>J Comput Appl Math</source>. <year>1987</year>; <volume>20</volume>:<fpage>53</fpage>&#8211;<lpage>65</lpage>.<pub-id pub-id-type="doi">10.1016/0377-0427(87)90125-7</pub-id>.</mixed-citation></ref><ref id="B32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Halkidi</surname> &#160;<given-names>M</given-names></string-name>, <string-name name-style="western"><surname>Vazirgiannis</surname> &#160;<given-names>M</given-names></string-name></person-group> &#160;<article-title>A density-based cluster validity approach using multi-representatives</article-title>. <source>Pattern Recogn Lett</source>. <year>2008</year>; <volume>29</volume>:<fpage>773</fpage>&#8211;<lpage>86</lpage>.<pub-id pub-id-type="doi">10.1016/j.patrec.2007.12.011</pub-id>.</mixed-citation></ref><ref id="B33"><label>33.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name name-style="western"><surname>Moulavi</surname> &#160;<given-names>D</given-names></string-name>, <string-name name-style="western"><surname>Jaskowiak</surname> &#160;<given-names>PA</given-names></string-name>, <string-name name-style="western"><surname>Campello</surname> &#160;<given-names>RJ</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Density-based clustering validation</article-title>. <source>Proceedings of the 2014 SIAM international conference on data mining</source>. <year>2014</year>; <publisher-loc>Philadelphia, PA, USA</publisher-loc><publisher-name>Society for Industrial and Applied Mathematics</publisher-name><fpage>839</fpage>&#8211;<lpage>47</lpage>.<pub-id pub-id-type="doi">10.1137/1.9781611973440.96</pub-id>.</mixed-citation></ref><ref id="B34"><label>34.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name name-style="western"><surname>Dudek</surname> &#160;<given-names>A</given-names></string-name></person-group> &#160;<article-title>Silhouette index as clustering evaluation tool</article-title>. <source>Classification and Data Analysis: Theory and Applications 28</source>. <year>2020</year>; <publisher-loc>Cham, Switzerland</publisher-loc><publisher-name>Springer</publisher-name><fpage>19</fpage>&#8211;<lpage>33</lpage>.<pub-id pub-id-type="doi">10.1007/978-3-030-52348-0_2</pub-id>.</mixed-citation></ref><ref id="B35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Chari</surname> &#160;<given-names>T</given-names></string-name>, <string-name name-style="western"><surname>Pachter</surname> &#160;<given-names>L</given-names></string-name></person-group> &#160;<article-title>The specious art of single-cell genomics</article-title>. <source>PLOS Comput Biol</source>. <year>2023</year>; <volume>19</volume>:<fpage>e1011288</fpage><pub-id pub-id-type="doi">10.1371/journal.pcbi.1011288</pub-id>.<pub-id pub-id-type="pmid">37590228</pub-id><pub-id pub-id-type="pmcid">PMC10434946</pub-id></mixed-citation></ref><ref id="B36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Lause</surname> &#160;<given-names>J</given-names></string-name>, <string-name name-style="western"><surname>Berens</surname> &#160;<given-names>P</given-names></string-name>, <string-name name-style="western"><surname>Kobak</surname> &#160;<given-names>D</given-names></string-name></person-group> &#160;<article-title>The art of seeing the elephant in the room: 2D embeddings of single-cell data do make sense</article-title>. <source>PLOS Computational Biology</source>. <year>2024</year>; <volume>20</volume>:<fpage>e1012403</fpage><pub-id pub-id-type="doi">10.1371/journal.pcbi.1012403</pub-id>.<pub-id pub-id-type="pmid">39356722</pub-id><pub-id pub-id-type="pmcid">PMC11446450</pub-id></mixed-citation></ref><ref id="B37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Luecken</surname> &#160;<given-names>MD</given-names></string-name>, <string-name name-style="western"><surname>Theis</surname> &#160;<given-names>FJ</given-names></string-name></person-group> &#160;<article-title>Current best practices in single-cell RNA-seq analysis: a tutorial</article-title>. <source>Mol Syst Biol</source>. <year>2019</year>; <volume>15</volume>:<fpage>e8746</fpage><pub-id pub-id-type="doi">10.15252/msb.20188746</pub-id>.<pub-id pub-id-type="pmid">31217225</pub-id><pub-id pub-id-type="pmcid">PMC6582955</pub-id></mixed-citation></ref><ref id="B38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Freytag</surname> &#160;<given-names>S</given-names></string-name>, <string-name name-style="western"><surname>Tian</surname> &#160;<given-names>L</given-names></string-name>, <string-name name-style="western"><surname>L&#246;nnstedt</surname> &#160;<given-names>I</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Comparison of clustering tools in R for medium-sized 10x Genomics single-cell RNA-sequencing data</article-title>. <source>F1000Research</source>. <year>2018</year>; <volume>7</volume>:<fpage>1297</fpage><pub-id pub-id-type="doi">10.12688/f1000research.15809.1</pub-id>.<pub-id pub-id-type="pmid">30228881</pub-id><pub-id pub-id-type="pmcid">PMC6124389</pub-id></mixed-citation></ref><ref id="B39"><label>39.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name name-style="western"><surname>Aggarwal</surname> &#160;<given-names>CC</given-names></string-name>, <string-name name-style="western"><surname>Hinneburg</surname> &#160;<given-names>A</given-names></string-name>, <string-name name-style="western"><surname>Keim</surname> &#160;<given-names>DA</given-names></string-name></person-group> &#160;<article-title>On the surprising behavior of distance metrics in high dimensional space</article-title>. <source>Database Theory&#8212;ICDT 2001: 8th International Conference London, UK, January 4&#8211;6, 2001 Proceedings 8</source>. <year>2001</year>; <publisher-loc>Cham, Switzerland</publisher-loc><publisher-name>Springer</publisher-name><fpage>420</fpage>&#8211;<lpage>34</lpage>.<pub-id pub-id-type="doi">10.1007/3-540-44503-X_27</pub-id>.</mixed-citation></ref><ref id="B40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Moon</surname> &#160;<given-names>KR</given-names></string-name>, <string-name name-style="western"><surname>Stanley</surname> &#160;<given-names>III JS</given-names></string-name>, <string-name name-style="western"><surname>Burkhardt</surname> &#160;<given-names>D</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Manifold learning-based methods for analyzing single-cell RNA-sequencing data</article-title>. <source>Curr Opin Syst Biol</source>. <year>2018</year>; <volume>7</volume>:<fpage>36</fpage>&#8211;<lpage>46</lpage>.<pub-id pub-id-type="doi">10.1016/j.coisb.2017.12.008</pub-id>.</mixed-citation></ref><ref id="B41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Huizing</surname> &#160;<given-names>GJ</given-names></string-name>, <string-name name-style="western"><surname>Peyr&#233;</surname> &#160;<given-names>G</given-names></string-name>, <string-name name-style="western"><surname>Cantini</surname> &#160;<given-names>L</given-names></string-name></person-group> &#160;<article-title>Optimal transport improves cell&#8211;cell similarity inference in single-cell omics data</article-title>. <source>Bioinformatics</source>. <year>2022</year>; <volume>38</volume>:<fpage>2169</fpage>&#8211;<lpage>77</lpage>.<pub-id pub-id-type="doi">10.1093/bioinformatics/btac084</pub-id>.<pub-id pub-id-type="pmid">35157031</pub-id><pub-id pub-id-type="pmcid">PMC9004651</pub-id></mixed-citation></ref><ref id="B42"><label>42.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name name-style="western"><surname>Almeida</surname> &#160;<given-names>H</given-names></string-name>, <string-name name-style="western"><surname>Guedes</surname> &#160;<given-names>D</given-names></string-name>, <string-name name-style="western"><surname>Meira</surname> &#160;<given-names>W</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Is there a best quality metric for graph clusters?</article-title>. <source>Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2011, Athens, Greece, September 5-9, 2011. Proceedings, Part I 11</source>. <year>2011</year>; <publisher-loc>Cham, Switzerland</publisher-loc><publisher-name>Springer</publisher-name><fpage>44</fpage>&#8211;<lpage>59</lpage>.</mixed-citation></ref><ref id="B43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Islam</surname> &#160;<given-names>S</given-names></string-name>, <string-name name-style="western"><surname>Kj&#228;llquist</surname> &#160;<given-names>U</given-names></string-name>, <string-name name-style="western"><surname>Moliner</surname> &#160;<given-names>A</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Characterization of the single-cell transcriptional landscape by highly multiplex RNA-seq</article-title>. <source>Genome Res</source>. <year>2011</year>; <volume>21</volume>:<fpage>1160</fpage>&#8211;<lpage>7</lpage>.<pub-id pub-id-type="doi">10.1101/gr.110882.110</pub-id>.<pub-id pub-id-type="pmid">21543516</pub-id><pub-id pub-id-type="pmcid">PMC3129258</pub-id></mixed-citation></ref><ref id="B44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Chen</surname> &#160;<given-names>H</given-names></string-name>, <string-name name-style="western"><surname>Yu</surname> &#160;<given-names>Z</given-names></string-name>, <string-name name-style="western"><surname>Yang</surname> &#160;<given-names>Q</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Community detection in subspace of attribute</article-title>. <source>Inform Sci</source>. <year>2022</year>; <volume>602</volume>:<fpage>220</fpage>&#8211;<lpage>35</lpage>.<pub-id pub-id-type="doi">10.1016/j.ins.2022.04.047</pub-id>.</mixed-citation></ref><ref id="B45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Sueur</surname> &#160;<given-names>C</given-names></string-name>, <string-name name-style="western"><surname>Petit</surname> &#160;<given-names>O</given-names></string-name>, <string-name name-style="western"><surname>De</surname> &#160;<given-names>Marco A</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>A comparative network analysis of social style in macaques</article-title>. <source>Anim Behav</source>. <year>2011</year>; <volume>82</volume>:<fpage>845</fpage>&#8211;<lpage>52</lpage>.<pub-id pub-id-type="doi">10.1016/j.anbehav.2011.07.020</pub-id>.</mixed-citation></ref><ref id="B46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Korsunsky</surname> &#160;<given-names>I</given-names></string-name>, <string-name name-style="western"><surname>Millard</surname> &#160;<given-names>N</given-names></string-name>, <string-name name-style="western"><surname>Fan</surname> &#160;<given-names>J</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Fast, sensitive and accurate integration of single-cell data with harmony</article-title>. <source>Nat Methods</source>. <year>2019</year>; <volume>16</volume>:<fpage>1289</fpage>&#8211;<lpage>96</lpage>.<pub-id pub-id-type="doi">10.1038/s41592-019-0619-0</pub-id>.<pub-id pub-id-type="pmid">31740819</pub-id><pub-id pub-id-type="pmcid">PMC6884693</pub-id></mixed-citation></ref><ref id="B47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>L&#252;tge</surname> &#160;<given-names>A</given-names></string-name>, <string-name name-style="western"><surname>Zyprych-Walczak</surname> &#160;<given-names>J</given-names></string-name>, <string-name name-style="western"><surname>Kunzmann</surname> &#160;<given-names>UB</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>CellMixS: quantifying and visualizing batch effects in single-cell RNA-seq data</article-title>. <source>Life SciAlliance</source>. <year>2021</year>; <volume>4</volume>:<fpage>e202001004</fpage>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.26508/lsa.202001004</pub-id><pub-id pub-id-type="pmcid">PMC7994321</pub-id><pub-id pub-id-type="pmid">33758076</pub-id></mixed-citation></ref><ref id="B48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>White</surname> &#160;<given-names>DR</given-names></string-name>, <string-name name-style="western"><surname>Harary</surname> &#160;<given-names>F</given-names></string-name></person-group> &#160;<article-title>The cohesiveness of blocks in social networks: node connectivity and conditional density</article-title>. <source>Sociol Methodol</source>. <year>2001</year>; <volume>31</volume>:<fpage>305</fpage>&#8211;<lpage>59</lpage>.<pub-id pub-id-type="doi">10.1111/0081-1750.00098</pub-id>.</mixed-citation></ref><ref id="B49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Baran</surname> &#160;<given-names>Y</given-names></string-name>, <string-name name-style="western"><surname>Bercovich</surname> &#160;<given-names>A</given-names></string-name>, <string-name name-style="western"><surname>Sebe-Pedros</surname> &#160;<given-names>A</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>MetaCell: analysis of single-cell RNA-seq data using k-NN graph partitions</article-title>. <source>Genome Biol</source>. <year>2019</year>; <volume>20</volume>:<fpage>206</fpage><pub-id pub-id-type="doi">10.1186/s13059-019-1812-2</pub-id>.<pub-id pub-id-type="pmid">31604482</pub-id><pub-id pub-id-type="pmcid">PMC6790056</pub-id></mixed-citation></ref><ref id="B50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Persad</surname> &#160;<given-names>S</given-names></string-name>, <string-name name-style="western"><surname>Choo</surname> &#160;<given-names>ZN</given-names></string-name>, <string-name name-style="western"><surname>Dien</surname> &#160;<given-names>C</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>SEACells infers transcriptional and epigenomic cellular states from single-cell genomics data</article-title>. <source>Nat Biotechnol</source>. <year>2023</year>; <volume>41</volume>:<fpage>1746</fpage>&#8211;<lpage>57</lpage>.<pub-id pub-id-type="doi">10.1038/s41587-023-01716-9</pub-id>.<pub-id pub-id-type="pmid">36973557</pub-id><pub-id pub-id-type="pmcid">PMC10713451</pub-id></mixed-citation></ref><ref id="B51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Shang</surname> &#160;<given-names>L</given-names></string-name>, <string-name name-style="western"><surname>Zhou</surname> &#160;<given-names>X</given-names></string-name></person-group> &#160;<article-title>Spatially aware dimension reduction for spatial transcriptomics</article-title>. <source>Nat Commun</source>. <year>2022</year>; <volume>13</volume>:<fpage>7203</fpage><pub-id pub-id-type="doi">10.1038/s41467-022-34879-1</pub-id>.<pub-id pub-id-type="pmid">36418351</pub-id><pub-id pub-id-type="pmcid">PMC9684472</pub-id></mixed-citation></ref><ref id="B52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Jackson</surname> &#160;<given-names>KC</given-names></string-name>, <string-name name-style="western"><surname>Booeshaghi</surname> &#160;<given-names>AS</given-names></string-name>, <string-name name-style="western"><surname>G&#225;lvez-Merch&#225;n</surname> &#160;<given-names>&#193;</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Identification of spatial homogeneous regions in tissues with concordex</article-title>. <source>bioRxiv</source>. <year>2024</year>; <fpage>2023</fpage>&#8211;<lpage>6</lpage>.<pub-id pub-id-type="doi">10.1101/2023.06.28.546949</pub-id>.</mixed-citation></ref><ref id="B53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Yuan</surname> &#160;<given-names>Z</given-names></string-name>, <string-name name-style="western"><surname>Zhao</surname> &#160;<given-names>F</given-names></string-name>, <string-name name-style="western"><surname>Lin</surname> &#160;<given-names>S</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Benchmarking spatial clustering methods with spatially resolved transcriptomics data</article-title>. <source>Nat Methods</source>. <year>2024</year>; <volume>21</volume>:<fpage>712</fpage>&#8211;<lpage>22</lpage>.<pub-id pub-id-type="doi">10.1038/s41592-024-02215-8</pub-id>.<pub-id pub-id-type="pmid">38491270</pub-id></mixed-citation></ref><ref id="B54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Hu</surname> &#160;<given-names>Y</given-names></string-name>, <string-name name-style="western"><surname>Xie</surname> &#160;<given-names>M</given-names></string-name>, <string-name name-style="western"><surname>Li</surname> &#160;<given-names>Y</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Benchmarking clustering, alignment, and integration methods for spatial transcriptomics</article-title>. <source>Genome Biol</source>. <year>2024</year>; <volume>25</volume>:<fpage>212</fpage><pub-id pub-id-type="doi">10.1186/s13059-024-03361-0</pub-id>.<pub-id pub-id-type="pmid">39123269</pub-id><pub-id pub-id-type="pmcid">PMC11312151</pub-id></mixed-citation></ref><ref id="B55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Cheng</surname> &#160;<given-names>A</given-names></string-name>, <string-name name-style="western"><surname>Hu</surname> &#160;<given-names>G</given-names></string-name>, <string-name name-style="western"><surname>Li</surname> &#160;<given-names>WV</given-names></string-name></person-group> &#160;<article-title>Benchmarking cell-type clustering methods for spatially resolved transcriptomics data</article-title>. <source>Brief Bioinform</source>. <year>2023</year>; <volume>24</volume>:<fpage>bbac475</fpage><pub-id pub-id-type="doi">10.1093/bib/bbac475</pub-id>.<pub-id pub-id-type="pmid">36410733</pub-id><pub-id pub-id-type="pmcid">PMC9851325</pub-id></mixed-citation></ref><ref id="B56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Liu</surname> &#160;<given-names>T</given-names></string-name>, <string-name name-style="western"><surname>Fang</surname> &#160;<given-names>ZY</given-names></string-name>, <string-name name-style="western"><surname>Zhang</surname> &#160;<given-names>Z</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>A comprehensive overview of graph neural network-based approaches to clustering for spatial transcriptomics</article-title>. <source>Computational and Structural Biotechnology Journal</source>. <year>2024</year>; <volume>23</volume>:<fpage>106</fpage>&#8211;<lpage>28</lpage>.<pub-id pub-id-type="pmid">38089467</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.csbj.2023.11.055</pub-id><pub-id pub-id-type="pmcid">PMC10714345</pub-id></mixed-citation></ref><ref id="B57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Naimi</surname> &#160;<given-names>B</given-names></string-name>, <string-name name-style="western"><surname>Hamm</surname> &#160;<given-names>NA</given-names></string-name>, <string-name name-style="western"><surname>Groen</surname> &#160;<given-names>TA</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>ELSA: entropy-based local indicator of spatial association</article-title>. <source>Spat Stat</source>. <year>2019</year>; <volume>29</volume>:<fpage>66</fpage>&#8211;<lpage>88</lpage>.<pub-id pub-id-type="doi">10.1016/j.spasta.2018.10.001</pub-id>.</mixed-citation></ref><ref id="B58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Kuhn</surname> &#160;<given-names>HW</given-names></string-name></person-group> &#160;<article-title>The Hungarian method for the assignment problem</article-title>. <source>Nav Res Log Quart</source>. <year>1955</year>; <volume>2</volume>:<fpage>83</fpage>&#8211;<lpage>97</lpage>.<pub-id pub-id-type="doi">10.1002/nav.3800020109</pub-id>.</mixed-citation></ref><ref id="B59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Liu</surname> &#160;<given-names>W</given-names></string-name>, <string-name name-style="western"><surname>Liao</surname> &#160;<given-names>X</given-names></string-name>, <string-name name-style="western"><surname>Luo</surname> &#160;<given-names>Z</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Probabilistic embedding, clustering, and alignment for integrating spatial transcriptomics data with PRECAST</article-title>. <source>Nat Commun</source>. <year>2023</year>; <volume>14</volume>:<fpage>296</fpage><pub-id pub-id-type="doi">10.1038/s41467-023-35947-w</pub-id>.<pub-id pub-id-type="pmid">36653349</pub-id><pub-id pub-id-type="pmcid">PMC9849443</pub-id></mixed-citation></ref><ref id="B60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Xu</surname> &#160;<given-names>H</given-names></string-name>, <string-name name-style="western"><surname>Fu</surname> &#160;<given-names>H</given-names></string-name>, <string-name name-style="western"><surname>Long</surname> &#160;<given-names>Y</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Unsupervised spatially embedded deep representation of spatial transcriptomics</article-title>. <source>Genome Med</source>. <year>2024</year>; <volume>16</volume>:<fpage>12</fpage><pub-id pub-id-type="doi">10.1186/s13073-024-01283-x</pub-id>.<pub-id pub-id-type="pmid">38217035</pub-id><pub-id pub-id-type="pmcid">PMC10790257</pub-id></mixed-citation></ref><ref id="B61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Zhao</surname> &#160;<given-names>E</given-names></string-name>, <string-name name-style="western"><surname>Stone</surname> &#160;<given-names>MR</given-names></string-name>, <string-name name-style="western"><surname>Ren</surname> &#160;<given-names>X</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Spatial transcriptomics at subspot resolution with BayesSpace</article-title>. <source>Nat Biotechnol</source>. <year>2021</year>; <volume>39</volume>:<fpage>1375</fpage>&#8211;<lpage>84</lpage>.<pub-id pub-id-type="doi">10.1038/s41587-021-00935-2</pub-id>.<pub-id pub-id-type="pmid">34083791</pub-id><pub-id pub-id-type="pmcid">PMC8763026</pub-id></mixed-citation></ref><ref id="B62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Long</surname> &#160;<given-names>Y</given-names></string-name>, <string-name name-style="western"><surname>Ang</surname> &#160;<given-names>KS</given-names></string-name>, <string-name name-style="western"><surname>Li</surname> &#160;<given-names>M</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Spatially informed clustering, integration, and deconvolution of spatial transcriptomics with GraphST</article-title>. <source>Nat Commun</source>. <year>2023</year>; <volume>14</volume>:<fpage>1155</fpage><pub-id pub-id-type="doi">10.1038/s41467-023-36796-3</pub-id>.<pub-id pub-id-type="pmid">36859400</pub-id><pub-id pub-id-type="pmcid">PMC9977836</pub-id></mixed-citation></ref><ref id="B63"><label>63.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name name-style="western"><surname>Sun</surname> &#160;<given-names>J</given-names></string-name>, <string-name name-style="western"><surname>Biharie</surname> &#160;<given-names>K</given-names></string-name>, <string-name name-style="western"><surname>Cai</surname> &#160;<given-names>P</given-names></string-name> &#160;<etal>et al</etal>.</person-group> &#160;<article-title>Beyond benchmarking: an expert-guided consensus approach to spatially aware clustering</article-title>. <comment>bioRxiv</comment><comment>27 June 2025, preprint: not peer reviewed</comment><pub-id pub-id-type="doi">10.1101/2025.06.23.660861</pub-id>.</mixed-citation></ref><ref id="B64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Anselin</surname> &#160;<given-names>L</given-names></string-name></person-group> &#160;<article-title>Local indicators of spatial association&#8212;LISA</article-title>. <source>Geogr Anal</source>. <year>1995</year>; <volume>27</volume>:<fpage>93</fpage>&#8211;<lpage>115</lpage>.<pub-id pub-id-type="doi">10.1111/j.1538-4632.1995.tb00338.x</pub-id>.</mixed-citation></ref></ref-list></back></article></pmc-articleset>