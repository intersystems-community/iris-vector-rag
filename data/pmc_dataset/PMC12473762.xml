<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xml:lang="en" article-type="research-article" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="pmc-domain-id">1660</journal-id><journal-id journal-id-type="pmc-domain">sensors</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>Multidisciplinary Digital Publishing Institute  (MDPI)</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12473762</article-id><article-id pub-id-type="pmcid-ver">PMC12473762.1</article-id><article-id pub-id-type="pmcaid">12473762</article-id><article-id pub-id-type="pmcaiid">12473762</article-id><article-id pub-id-type="pmid">41013082</article-id><article-id pub-id-type="doi">10.3390/s25185844</article-id><article-id pub-id-type="publisher-id">sensors-25-05844</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Bilateral Teleoperation of Aerial Manipulator with Hybrid Mapping Framework for Physical Interaction</article-title></title-group><contrib-group><contrib contrib-type="author"><name name-style="western"><surname>Meng</surname><given-names initials="L">Lingda</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><xref rid="af1-sensors-25-05844" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Rong</surname><given-names initials="Y">Yongfeng</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology/">Methodology</role><xref rid="af2-sensors-25-05844" ref-type="aff">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-1737-1030</contrib-id><name name-style="western"><surname>Chou</surname><given-names initials="W">Wusheng</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org/" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision/">Supervision</role><xref rid="af1-sensors-25-05844" ref-type="aff">1</xref><xref rid="c1-sensors-25-05844" ref-type="corresp">*</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name name-style="western"><surname>Tian</surname><given-names initials="Y">Yanling</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-05844"><label>1</label>School of Mechanical Engineering &amp; Automation, Beihang University, Beijing 100191, China; <email>lingda.meng@buaa.edu.cn</email></aff><aff id="af2-sensors-25-05844"><label>2</label>Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China; <email>yfrong@mail.tsinghua.edu.cn</email></aff><author-notes><corresp id="c1-sensors-25-05844"><label>*</label>Correspondence: <email>wschou@buaa.edu.cn</email></corresp></author-notes><pub-date pub-type="epub"><day>19</day><month>9</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>9</month><year>2025</year></pub-date><volume>25</volume><issue>18</issue><issue-id pub-id-type="pmc-issue-id">497667</issue-id><elocation-id>5844</elocation-id><history><date date-type="received"><day>24</day><month>7</month><year>2025</year></date><date date-type="rev-recd"><day>23</day><month>8</month><year>2025</year></date><date date-type="accepted"><day>11</day><month>9</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>19</day><month>09</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>27</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-28 18:25:14.327"><day>28</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; 2025 by the authors.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="sensors-25-05844.pdf"/><abstract><p>Bilateral teleoperation combines the agility of robotic manipulators with the ability to perform complex contact tasks guided by human expertise, thereby fulfilling a pivotal function in environments beyond human access. However, due to the limited workspace of existing master robots necessitating frequent mapping mode switches, coupled with the pronounced heterogeneity and asymmetry between the workspaces of the master and slave systems, achieving teleoperation of the mobile manipulator remains challenging. In this study, we innovatively introduced a 7 DOFs upper limb exoskeleton as the master control device, rigorously designed to align with the motion coordination of the human arm. Regarding teleoperation mapping, a hybrid heterogeneous teleoperation control framework with a variable mapping scheme, designed for an aerial manipulator performing physical operations, is proposed. The system incorporates mode switching driven by the operator&#8217;s hand gestures, seamlessly and intuitively integrating the advantages of position control and rate control modalities to enable adaptive transitions adaptable to diverse task requirements. Comparative teleoperation experiments were conducted using a fully actuated aerial equipped with a compliant 3D end-effector performing physical aerial writing tasks. The mode-switching algorithm was effectively validated in experiments, demonstrating no instability during transitions and achieving a position tracking RMSE of 7.7% and 5.2% in the <italic toggle="yes">X</italic>,<italic toggle="yes">Y</italic>-axis, respectively. This approach holds significant potential for future applications in UAM inspection and physical operational scenarios.</p></abstract><kwd-group><kwd>bilateral teleoperation</kwd><kwd>wearable exoskeleton</kwd><kwd>unmanned aerial manipulator</kwd><kwd>hybrid mode control</kwd><kwd>physical contact task</kwd></kwd-group><funding-group><funding-statement>This research received no external funding.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-05844"><title>1. Introduction</title><p>One of the primary objectives of teleoperation systems is to extend human manipulation capabilities across different scales, facilitating interaction in remote or hazardous tasks [<xref rid="B1-sensors-25-05844" ref-type="bibr">1</xref>]. As a remote operation carrier for humans, mobile robots have seen widespread development and application across various fields with the continuous advancement of robot technology, computer science, and control theory. Within these, unmanned aerial manipulators (UAMs), typically comprising an unmanned aerial vehicle (UAV) and a robotic manipulator, enable agile three-dimensional motion [<xref rid="B2-sensors-25-05844" ref-type="bibr">2</xref>] attributable to their remarkable maneuverability and versatility, which have received considerable attention in physical interaction tasks, including drawer operation [<xref rid="B3-sensors-25-05844" ref-type="bibr">3</xref>], door opening [<xref rid="B4-sensors-25-05844" ref-type="bibr">4</xref>], glass-wall inspection [<xref rid="B5-sensors-25-05844" ref-type="bibr">5</xref>], aerial writing [<xref rid="B6-sensors-25-05844" ref-type="bibr">6</xref>], and outdoor industrial inspection and maintenance [<xref rid="B7-sensors-25-05844" ref-type="bibr">7</xref>]. While autonomous approaches leverage machine intelligence to perform these tasks, full autonomy is often neither feasible nor desirable due to safety concerns and the complexity of operational environments. The teleoperated UAM scheme, which employs the &#8220;human-in-the-loop&#8221; control architecture, facilitates the accomplishment of tasks in complex operational conditions under human superior cognitive capabilities and skills.</p><p>In a UAM teleoperation system, the operator employs a master robot to articulate specific intentions, including position and velocity inputs. These commands are conveyed through a communication channel to the slave UAMs, facilitating precise remote interaction with the operational environment [<xref rid="B8-sensors-25-05844" ref-type="bibr">8</xref>]. Concurrently, force feedback and visual information perceived by the UAMs can be transported back to the human operator to assist the decision making and enhance the immersion of the teleoperation. This has garnered significant attention in research on the control of UAMs under a bilateral teleoperation scheme [<xref rid="B9-sensors-25-05844" ref-type="bibr">9</xref>,<xref rid="B10-sensors-25-05844" ref-type="bibr">10</xref>,<xref rid="B11-sensors-25-05844" ref-type="bibr">11</xref>].</p><p>However, due to master&#8211;slave heterogeneity, the workspace for UAMs is not proportionally aligned with the operator inevitably. The teleoperation of UAMs predominantly employs single-mapping modes, mainly the rate control strategy, which greatly limits the application of UAMs in practical scenarios. From the literature, several studies have concentrated on hybrid teleoperation mapping schemes of ground mobile manipulators. A hybrid position&#8211;position and position&#8211;velocity control algorithm was introduced for the teleoperation of generic mobile manipulators [<xref rid="B12-sensors-25-05844" ref-type="bibr">12</xref>]. The current progress of teleoperation mapping of mobile manipulators is summarized in [<xref rid="B13-sensors-25-05844" ref-type="bibr">13</xref>], with consideration given to time delay and stability analysis. Such a variable mapping strategy is also extensively employed in the field of robotic arm teleoperation [<xref rid="B14-sensors-25-05844" ref-type="bibr">14</xref>,<xref rid="B15-sensors-25-05844" ref-type="bibr">15</xref>]. For UAV/UAM teleoperation, a variable kinetic scrolling-based mapping scheme was proposed to overcome master workspace limitations and enable teleoperation of the aerial vehicle in an unbounded workspace [<xref rid="B16-sensors-25-05844" ref-type="bibr">16</xref>]. Additionally, a user-defined variable scale mapping controller was also presented [<xref rid="B9-sensors-25-05844" ref-type="bibr">9</xref>]. Nevertheless, the existing UAV teleoperation mapping modes primarily focus on free movement, i.e., rate mode and position mode, neglecting contact operation modes. It is noteworthy that the transition between operational modes can potentially introduce the risk of misoperation due to complexity and potential operator errors. Therefore, developing intuitive and efficient conversion transitions between different modes based on user intention in teleoperation is crucial for advancing practical UAM applications.</p><p>Furthermore, physical contact tasks represent a significant area of focus for the future advancement of UAMs [<xref rid="B2-sensors-25-05844" ref-type="bibr">2</xref>,<xref rid="B17-sensors-25-05844" ref-type="bibr">17</xref>]. Implementing force feedback to perceive forces exerted by UAMs during contact tasks is recognized as an effective control approach. Shared control of path planning with integral haptic feedback was presented in [<xref rid="B18-sensors-25-05844" ref-type="bibr">18</xref>]. Macchini et al. presented a hand-worn haptic interface to enable users to control UAV trajectories and enhance environmental awareness [<xref rid="B19-sensors-25-05844" ref-type="bibr">19</xref>]. Meanwhile, haptic bilateral teleoperation is sophisticatedly employed in advanced UAV applications, including evaluation of obstacle avoidance [<xref rid="B20-sensors-25-05844" ref-type="bibr">20</xref>], environmental perception [<xref rid="B21-sensors-25-05844" ref-type="bibr">21</xref>], and nuclear sources detection [<xref rid="B22-sensors-25-05844" ref-type="bibr">22</xref>]. Several studies have explored the bilateral teleoperation of UAMs in scenarios involving environmental interaction. Schill. et al. investigated the use of a haptic teleoperation joystick with limited workspace in admittance mode [<xref rid="B23-sensors-25-05844" ref-type="bibr">23</xref>]. A force-based bilateral teleoperation framework was proposed both in contact-free flight and in physical contact with the environment [<xref rid="B24-sensors-25-05844" ref-type="bibr">24</xref>]. Haptic-based shared control, incorporating artificial and virtual impedance for interaction force reflection, was designed for the telemanipulation of micro aerial vehicle (MAV) systems [<xref rid="B25-sensors-25-05844" ref-type="bibr">25</xref>]. A team of UAMs employing a force-feedback bilateral teleoperation scheme was proposed [<xref rid="B26-sensors-25-05844" ref-type="bibr">26</xref>], capable of cooperatively grasping objects and performing Vertical Take-Off and Landing (VTOL). A fully decoupled six DOFs bilateral teleoperation framework for omnidirectional micro aerial vehicles (OMAVs) was developed to support aerial physical interaction [<xref rid="B10-sensors-25-05844" ref-type="bibr">10</xref>]. Byun et al. addressed the abrupt reduction in interaction force during the extraction of a wedge-shaped object (e.g., plug pulling) from a static structure, proposing a haptic-based bilateral teleoperation strategy that compensates for reaction time [<xref rid="B11-sensors-25-05844" ref-type="bibr">11</xref>].</p><p>To improve the applicability of UAMs in physical contact tasks and ensure the stability and seamlessness of mode transitions, this paper proposes a haptic-based bilateral teleoperation scheme of a UAM for the aerial writing task. To this end, we develop an upper-limb exoskeleton as the master haptic device, configured with data glove from SenseGlove. The upper arm exoskeleton, utilized as the input device for pose control, simultaneously provides intuitive haptic feedback of the remote environment to the operator, while the application of a data glove for gesture-based switching in UAM control modes is intuitive and effective compared to traditional key-based operation [<xref rid="B27-sensors-25-05844" ref-type="bibr">27</xref>].</p><p>Because the fully actuated UAV possesses independent control over its position and orientation, it is capable of applying force and torque in any direction with precise control over both the direction and magnitude without adjusting the fuselage posture like traditional UAVs [<xref rid="B28-sensors-25-05844" ref-type="bibr">28</xref>]. Such UAVs are more suitable for applications such as indoor exploration in a narrow space, or as a stable platform for other air operation equipment [<xref rid="B29-sensors-25-05844" ref-type="bibr">29</xref>]. Thus, a fully actuated UAV equipped with a 3D end-effector is utilized in this work as a teleoperation slave robot for aerial writing tasks. Based on the actual task situation, the aerial writing task was divided into free movement and contact working phases.</p><p>When in the free movement phase, the UAM is controlled in the rate mode and the pose of the master is mapped to a possibly scaled velocity reference of the slave. In this mode, UAM possesses a theoretically infinite operational space, enabling approach of the target position expeditiously and effectively. Subsequently, during the contact phase, haptic feedback is proposed as cues to indicate the teleoperated state of the slave. Also, a transition algorithm between the above two mapping methods for the master haptic device is developed to achieve smoothing switches. As a case study for the aerial writing task, two sets of experiments were conducted with the teleoperation structure. The experimental results demonstrate that the teleoperation method incorporating mapping switching enables rapid execution of contact operations. Overall, the key contributions are as follows:<list list-type="simple"><list-item><label>(1)</label><p>The development of a novel UAM teleoperation framework utilizing an exoskeleton as the master control robot.</p></list-item><list-item><label>(2)</label><p>Proposing a mode-switching teleoperation mapping algorithm, with mode transitions facilitated by gestures captured through data gloves.</p></list-item><list-item><label>(3)</label><p>Experimental validations on the aerial writing teleoperation experiment based on the theoretical framework.</p></list-item></list></p><p>The rest of the article is organized as follows: The system structure is presented and defined in <xref rid="sec2-sensors-25-05844" ref-type="sec">Section 2</xref>. <xref rid="sec3-sensors-25-05844" ref-type="sec">Section 3</xref> provides a comprehensive examination of the two mapping modes and transition algorithms, in addition to a discussion on the passivity of the control method. <xref rid="sec4-sensors-25-05844" ref-type="sec">Section 4</xref> presents the validation of simulation and experimental results, demonstrating the efficacy and performance of the proposed UAM teleoperation structure. Finally, <xref rid="sec5-sensors-25-05844" ref-type="sec">Section 5</xref> concludes this article.</p></sec><sec id="sec2-sensors-25-05844"><title>2. Teleoperation System Overview</title><p>We focus on the representative scenario illustrated in <xref rid="sensors-25-05844-f001" ref-type="fig">Figure 1</xref>, in which a 7 DOFs upper limb exoskeleton and the data gloves are employed as master devices to teleoperate a UAM equipped with a 3D end-effector to accomplish aerial writing tasks. Visual and <italic toggle="yes">Z</italic>-axis contact data from the UAM are transmitted to the master operator via the communication channel, meanwhile enabling the operator to execute mode-switching and control commands to the UAM.</p><sec id="sec2dot1-sensors-25-05844"><title>2.1. Exoskeleton Master Robot</title><p>In this section, the master endoskeleton detailing the structural design and control framework are introduced. Additionally, forward kinematics analysis and a description of the Bluetooth glove employed for hand data acquisition are presented.</p><sec id="sec2dot1dot1-sensors-25-05844"><title>2.1.1. Functional Characterization of the Upper-Limb Exoskeleton</title><p>In a bilateral teleoperation robot system, the master device is required to simultaneously capture real-time data on the motion of the operator&#8217;s upper limb and deliver force-feedback signals to the operator. Current commercial master devices can be primarily categorized into series input equipment, such as Phantom from Geomagic Touch [<xref rid="B30-sensors-25-05844" ref-type="bibr">30</xref>], and parallel input equipment, such as Sigma from Force Dimension [<xref rid="B31-sensors-25-05844" ref-type="bibr">31</xref>]. Nevertheless, the limited compatibility with human anatomy necessitates extensive training to achieve a satisfactory level of performance. Furthermore, the master robots mentioned above are unsuitable for large-scale workspaces due to their lack of intuitive interaction with the human arm. Therefore, in this study, an ergonomic upper limb exoskeleton is developed as the master input device, as shown in <xref rid="sensors-25-05844-f002" ref-type="fig">Figure 2</xref>.</p><p>The upper limb exoskeleton features 7 active DOF configurations to support shoulder, elbow, and wrist as SRS (spherical-rotation-spherical) joints. Each joint is equipped with encoders that measure the movements of the human arm, enabling the calculation of the end-effector <italic toggle="yes">p<sub>ee</sub></italic> position. The exoskeleton is attached to the human upper limb at three key locations: the upper arm, the lower arm, and the mounting bracket for the Bluetooth data gloves. The innovation of this exoskeleton mechanical arm lies in the replacement of conventional capstan gears in the shoulder and wrist joint mechanisms with a double parallelogram spherical mechanism (DPM), which ensures precise alignment of the torque axis with the human operator axis while significantly reducing the overall weight of the exoskeleton arm. Additionally, active motors are fitted for each joint and counteract gravitational forces and provide feedback force in all three Cartesian directions (XYZ) as well as about roll, pitch, and yaw (RPY) orientations. Our exoskeleton delivers the highest continuous torque-output-to-weight ratio compared to state-of-the-art teleoperation exoskeletons.</p><p>To facilitate high-speed control of the master exoskeleton, the system employs an EtherCAT bus and achieves a control rate update of 1 kHz. The Beckhoff CX5140 Embedded PC integrating TwinCAT 3 (from Beckhoff, Wil City, Germany) establishes communication with motor drivers Elmo G-POLTWI10/100 (from Elmo, Tel Aviv, Israel). The local computer model ARK-3530F (from Advantech, Kunshan, China) interacts with the Beckhoff PC via the ADS server. The high-level control algorithms including kinematic calculation, mode mapping and force feedback mapping algorithm are executed on the local computer and communicate with the motor drivers through the TwinCAT3 (from Beckhoff, Wil City, Germany) ADS router API. This configuration enables real-time execution of advanced control algorithms and direct management of the underlying driver.</p></sec><sec id="sec2dot1dot2-sensors-25-05844"><title>2.1.2. Kinematic Analysis of the Upper Exoskeleton</title><p>The exoskeleton incorporates seven active degrees of freedom (DOFs), with the shoulder, elbow, and wrist joints configured as a serial spherical-rotational-spherical (SRS) kinematic chain. The sternoclavicular joint on the right side is selected as the base, with <italic toggle="yes">l<sub>a</sub></italic> = 42 mm and <italic toggle="yes">l<sub>b</sub></italic> = 175 mm representing the distances from sternoclavicular joint to the glenoid joint in the sagittal and coronal planes, respectively. The lengths of the upper arm <italic toggle="yes">l<sub>c</sub>
</italic>= 265 mm, forearm <italic toggle="yes">l<sub>d</sub>
</italic>= 315 mm, and palm length can be adjusted by the passive prismatic joints to accommodate variations in the operator&#8217;s height. The system is engineered to accommodate operators with statues ranging from 165 cm to 185 cm, ensuring optimal ergonomic compatibility. The kinematic model of the exoskeleton is developed using modified Denavit&#8211;Hartenberg parameters, as presented in <xref rid="sensors-25-05844-t001" ref-type="table">Table 1</xref>. The right column of the table specifies the allowable range of joint rotation angles for the robotic exoskeleton.</p><p>The Monte Carlo method is utilized to calculate the effective workspace of the master exoskeleton. Joint angles are incorporated as variables within the forward kinematics model, and the workspace is discretized into a series of cells through slicing along the <italic toggle="yes">X</italic>, <italic toggle="yes">Y</italic>, and <italic toggle="yes">Z</italic> axes. As depicted in <xref rid="sensors-25-05844-f003" ref-type="fig">Figure 3</xref>b, the red 3D point cloud represents the working space accessible by the center point of the right wrist joint. The working space of the exoskeleton approximates a hemispherical volume, aligning with the operational space anterior to the human body. The diameter of this hemispherical workspace varies with the length of the operator&#8217;s arm, achieving a maximum radius oof 629 mm, as depicted in <xref rid="sensors-25-05844-f003" ref-type="fig">Figure 3</xref>a. Notably, to address the practical requirements of teleoperation, only the motion space corresponding to the anterior coronal plane is extracted. In contrast to heterogeneous robotic arms, the UAM is theoretically capable of possessing an infinite workspace; therefore, traditional workspace mapping methods as described in [<xref rid="B30-sensors-25-05844" ref-type="bibr">30</xref>] are insufficient. Detailed control strategies will be comprehensively addressed in the following section.</p></sec><sec id="sec2dot1dot3-sensors-25-05844"><title>2.1.3. Data Gloves</title><p>Prior research on mode switching during teleoperation has primarily utilized button-based interfaces, which can lead to operator disorientation regarding the current operational mode, potentially compromising system stability. This study proposes addressing this issue by employing data gloves to track the operator&#8217;s hand movements and assign distinct hand gestures to specific modes. This approach not only enhances the range of motion mapping modes but also provides an intuitive human&#8211;machine interface. To achieve this, the investigation utilizes the SenseGlove Nova Bluetooth data gloves, which measure the flexion and extension of the thumb, index, middle, and ring fingers using individual sensors, with an additional sensor for thumb abduction and adduction, as illustrated in <xref rid="sensors-25-05844-f004" ref-type="fig">Figure 4</xref>. The pinky finger&#8217;s flexion is mechanically coupled to that of the ring finger. These movements are captured by monitoring the extension of cables integrated into the gloves.</p><p>The data glove interfaces with the local computer via Bluetooth 4.2 protocol and samples cable extensions at a rate of 60 Hz with a resolution of 0.03 mm. The latency for detecting finger movement and updating the position ranges from 10 to 29 ms, while the latency for issuing a new command and its activation on the glove ranges from 15 to 22.5 ms. To accommodate the practical requirements of this study, latency issues are not considered, and thus, delays arising from data acquisition and transmission are neglected.</p></sec></sec><sec id="sec2dot2-sensors-25-05844"><title>2.2. Teleoperation Slave Robot</title><p>In this section, a comprehensive description of the slave robot designed for aerial writing is provided, with the structural control framework of the fully actuated UAM and the 3D end-effector to accommodate the offsets in all rotational axes.</p><sec id="sec2dot2dot1-sensors-25-05844"><title>2.2.1. Fully Actuated UAV</title><p>The fully actuated UAV is transformed from a traditional hexarotor by tilting each propeller 30 degrees about the mounting arm [<xref rid="B32-sensors-25-05844" ref-type="bibr">32</xref>]. The UAV features a diagonal wheelbase of 1000 mm, with each propeller capable of generating a maximum thrust of 15 N. The actuator dynamics of the motor is tested using a 1D force sensor capable of measuring force along the <italic toggle="yes">Z</italic>-axis, following a methodology akin to that in [<xref rid="B33-sensors-25-05844" ref-type="bibr">33</xref>], and the average time constant is &#945; = 0.08. The open-source Pixhawk flight controller generates PWM commands for the UAV motors and manipulator servos, while odometry feedback is provided by a RealSense T265 camera (from Intel, Santa Clara, CA, USA). The control algorithm operates at a frequency of 100 Hz on an onboard computer model 11TNHi7 from Intel interfaced with the Pixhawk2.4.8 via USB. A 24 V tethered power supply sustains the operation of the system. The inertia of the UAV is set constantly to <italic toggle="yes">J</italic><sub>u</sub><sup>B</sup> = diag {0.2, 0.45, 0.45} (kg&#183;m<sup>2</sup>). The structure of the remotely controlled UAM is depicted in <xref rid="sensors-25-05844-f005" ref-type="fig">Figure 5</xref>. The 3D end-effector is mounted on the underside of the UAM&#8217;s fuselage and is controlled by a servo motor to transition between the folded state and the extended state during takeoff and landing phases. The design of the 3D end-effector is elaborated in detail in the subsequent section.</p></sec><sec id="sec2dot2dot2-sensors-25-05844"><title>2.2.2. Design of the 3D End-Effector</title><p>A 3D end-effector is affixed to the UAV and internally equipped with a whiteboard pen for aerial writing. To accommodate the offsets in all rotational axes and ensure that the whiteboard pen is physically perpendicular to the whiteboard, a spherical joint is implemented, as well featuring a universal ball beneath the contact plate, which facilitates multidirectional rolling.</p><p>As illustrated in <xref rid="sensors-25-05844-f006" ref-type="fig">Figure 6</xref>, the 3D end-effector structure design can be segmented into three layers from top to bottom. The top layer comprises three linear bearings and springs in a circular arrangement, acting as a damper to isolate <italic toggle="yes">Z</italic>-axis disturbances. A 1-D force sensor with a measurement range of 0&#8211;20 N and with an accuracy of 0.1 N is mounted below this to measure the end-effector interaction force alone UAM&#8217;s Z direction. The middle layer features a ball joint connecting the 1-D force sensor to the marker holder, along with six flexure springs to stabilize rotational movements and maintain the marker&#8217;s perpendicular alignment with the writing surface. The bottom layer houses the whiteboard marker within a sleeve, with a compression spring ensuring consistent surface contact. Universal balls located beneath the support disk allow the end-effector to glide freely on the tablet. To optimize the maneuverability of the UAM, the integrated module, with a minimal mass of only 580 g, is securely mounted to the ventral surface of the unmanned aerial vehicle. The system is driven by a servomotor to reorient to a vertical contact plane under stabilized operational conditions.</p></sec></sec><sec id="sec2dot3-sensors-25-05844"><title>2.3. Teleoperation Scheme</title><p>The architectural framework of the exoskeleton&#8211;UAM teleoperation system is illustrated in <xref rid="sensors-25-05844-f007" ref-type="fig">Figure 7</xref>, comprising a master system, a slave system, and a communication channel. The master system incorporates an exoskeleton engineered to capture the operator&#8217;s motion data with precision and deliver haptic feedback, effectively transmitting interaction forces from the remote environment to the operator. In addition, the master system also integrates the human operator, a monitor for displaying returned image information, data gloves for capturing the operator&#8217;s hand movements, a local computer that facilitates communication between the data gloves and the Beckhoff CX5140 embedded PC, and the master device. The slave system includes the fully actuated UAM with the 3D end-effector and the remote environment. The slave system is equipped with a camera for real-time visual data acquisition, enabling the continuous monitoring of dynamic changes in both the slave-end equipment and its surroundings. A data exchange stream uses a separate data channel from the video channel, with tests confirming a signal latency of less than 10 ms; consequently, teleoperation system delays are not addressed in this study.</p><p>The local computer in the master system incorporates control modules for kinematic analysis, spatial mapping algorithms, haptic feedback control, and mode-switching capabilities. The terminal position of the wrist joint center point is calculated through the angular motion of the operator&#8217;s upper limb and mapped to the UAM&#8217;s motion using a spatial mapping algorithm. To mitigate instability due to operator input jitter, mean filtering is applied to the positional signals derived from kinematic calculations. Haptic feedback control is then employed to complete aerial rigid contact operation. In the slave system, a novel adaptive extended-state-observer-based (AESO-based) impedance control method, as introduced in [<xref rid="B34-sensors-25-05844" ref-type="bibr">34</xref>], is implemented to regulate the UAM position.</p></sec></sec><sec id="sec3-sensors-25-05844"><title>3. Model and Method</title><p>To enhance the remote operability of UAMs, intuitive and accessible human&#8211;robot mapping strategies are critical for achieving superior maneuverability. Harnessing human intelligence for mapping transformations enables effective control within the constrained workspace of the master robot. A dynamic mapping approach is proposed, integrating free-rate and position-based modes, effectively addressing the challenges of mapping between constrained and unconstrained spaces. Furthermore, the incorporation of force feedback is under consideration to augment operational flexibility, precision, and efficiency in complex task execution.</p><sec id="sec3dot1-sensors-25-05844"><title>3.1. Free Rate Mode</title><p>Rate control has proven suitable for UAMs during unconstrained motion. Within the remote manipulation framework of this study, the free rate mode of UAM operation is employed at the prepare position, typically remote from the operational area, to enable swift transit to the designated target location. However, when the slave UAM is operated in the rate control mode, significant stability and transparency issues are experienced upon contacting the environment [<xref rid="B35-sensors-25-05844" ref-type="bibr">35</xref>]. Notably, due to the serial configuration of the exoskeleton master robot, changes in the position of the end-effector also influence its orientation and the attitude adjustment range of the UAM is limited during operations. Consequently, we employ a decoupled mapping strategy for teleoperation: the UAM positional movements are mapped through the shoulder and elbow joint position illustrated in <xref rid="sensors-25-05844-f002" ref-type="fig">Figure 2</xref>, while the orientation is directly controlled by three wrist joints. This decoupled attitude&#8211;position mapping approach also effectively mitigates singularities in robotic control systems and ensures that the UAM orientation will not change along with the variation in the end position. This decoupling may increase control complexity and limit the system&#8217;s overall flexibility. Nevertheless, these trade-offs are effectively counterbalanced by the significantly enhanced precision of UAM control and the expanded effective operational range achieved through mode switching.</p><p>To avoid misoperation by the operator&#8217;s input, a dead zone is defined around the center of wrist joint <italic toggle="yes">p<sub>ee</sub></italic>, as illustrated in <xref rid="sensors-25-05844-f008" ref-type="fig">Figure 8</xref>. The velocity of the UAM is characterized as a vector with a magnitude directed outward from the central point. A maximum operational region <italic toggle="yes">r</italic><sub>max</sub> is defined, and when the input from the master robot surpasses the boundary, the slave robot is instructed to maximum velocity. In the free rate mode, the position and wrist joint angle denoted as <inline-formula><mml:math id="mm1" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> is mapped to a scaled twist reference for the slave manipulator as follows:<disp-formula id="FD1-sensors-25-05844"><label>(1)</label><mml:math id="mm2" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>T</mml:mi><mml:mrow><mml:mi>rate</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">&#934;</mml:mi><mml:mrow><mml:mi>rate</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:mrow><mml:mtable equalrows="true" equalcolumns="true"><mml:mtr><mml:mtd><mml:mrow><mml:mrow><mml:mi>diag</mml:mi><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:mfenced close="&#x2016;" open="&#x2016;"><mml:mrow><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:mfenced><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>&#945;</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>diag</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mfenced><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:mfenced close="&#x2016;" open="&#x2016;"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:mfenced><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mi>&#945;</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>
with<disp-formula id="FD2-sensors-25-05844"><label>(2)</label><mml:math id="mm3" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mtext>&#160;</mml:mtext><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">&#955;</italic> = [<italic toggle="yes">&#955;<sub>v&#952;x</sub></italic>, <italic toggle="yes">&#955;<sub>v&#952;y</sub></italic>, <italic toggle="yes">&#955;<sub>v&#952;z</sub></italic>, <italic toggle="yes">&#955;<sub>vx</sub></italic>, <italic toggle="yes">&#955;<sub>vy</sub></italic>, <italic toggle="yes">&#955;<sub>vz</sub></italic>]<sup>T</sup> is the scaling factor of angle and position of end-effector. In the free rate mode, position commands are transmitted to control velocity via scaling factors <italic toggle="yes">&#955;<sub>v</sub></italic>, as illustrated in <xref rid="sensors-25-05844-f008" ref-type="fig">Figure 8</xref>; whereas in the position mode, the scaling factors <italic toggle="yes">&#955;<sub>p</sub></italic> serve as workspace mapping adjustment parameters. <italic toggle="yes">&#945;</italic><sub><italic toggle="yes">n</italic>&#8722;1</sub> = [<italic toggle="yes">&#945;<sub>&#952;x</sub></italic>, <italic toggle="yes">&#945;<sub>&#952;y</sub></italic>, <italic toggle="yes">&#945;<sub>&#952;z</sub></italic>, <italic toggle="yes">&#945;<sub>x</sub></italic>, <italic toggle="yes">&#945;<sub>y</sub></italic>, <italic toggle="yes">&#945;<sub>z</sub></italic>]<sup>T</sup> is a vector representing the desired pose offset between the center point of the master end-effector and UAM, respectively. <italic toggle="yes">&#952;<sub>ee</sub></italic> and <italic toggle="yes">p<sub>ee</sub></italic> denote the wrist joint angles and central position of the end-effector. Similarly, <italic toggle="yes">&#952;<sub>dz</sub></italic> and <italic toggle="yes">p<sub>dz</sub></italic> denote the sphere center of position and rotation and <italic toggle="yes">r<sub>&#952;</sub></italic> and <italic toggle="yes">r<sub>t</sub></italic> denote the coordinate range of the designated dead zone.</p><p>To enhance the efficiency and intuitiveness of UAM teleoperation, we integrate reset and normal modes within the mapping framework. Under optimal conditions in the normal mode, the operator initiates teleoperation from a neutral pose, where the effective control zone resides within the master robot&#8217;s workspace, and effective control of the UAM becomes infeasible. Therefore, inspired by the computer mouse, the cursor remains stationary when the mouse is lifted from the surface, regardless of its position. Meanwhile, contact with the surface sets a new zero-point for control. The reset mode in this study suspends teleoperation to recalibrate the neutral center of the mapping between the master and slave workspaces, ensuring precise alignment and effective control. In reset mode, the master robot&#8217;s neutral pose is redefined to align with the UAM&#8217;s current position, recentering the effective control zone within the master&#8217;s workspace while the UAM maintains its position and orientation. Once recalibration is complete, the operator resumes control in normal mode with an adjusted workspace, enabling seamless and intuitive operation in challenging environments.</p><p>In this research, we establish two mapping submodes by altering the offset &#945; of the pose of the master when instruction is issued at n-th switching time. In the reset mode, the desired offset &#945; represents the pose at the time of switching (<italic toggle="yes">t<sub>n</sub></italic>), as shown in Equation (4). When switching from position mode to reset mode at <italic toggle="yes">t<sub>n</sub></italic>, the system records the instantaneous pose data. While in reset mode, the dead zone center dynamically tracks the motion trajectory, whereas UAM control commands remain constant. Upon transitioning back to position mode, the system redefines the dead zone center by leveraging the positional data recorded at the time of mode transition <italic toggle="yes">t<sub>n</sub></italic><sub>+1</sub>, thereby effectively repositioning the center of the dead zone to match the normal mode perceived pose. The alpha values for the two submodes are denoted as follows:<disp-formula id="FD3-sensors-25-05844"><label>(3)</label><mml:math id="mm4" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>&#945;</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mfenced close="" open="{"><mml:mrow><mml:mtable equalrows="true" equalcolumns="true"><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mtext>&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;</mml:mtext><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mfenced close="]" open="["><mml:mrow><mml:mtable equalrows="true" equalcolumns="true"><mml:mtr><mml:mtd><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>&#955;</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:mfenced close="&#x2016;" open="&#x2016;"><mml:mrow><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:mfenced><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mfenced><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:mfenced close="&#x2016;" open="&#x2016;"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:mfenced><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>
with<disp-formula id="FD4-sensors-25-05844"><label>(4)</label><mml:math id="mm5" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mtext>&#160;</mml:mtext><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="sec3dot2-sensors-25-05844"><title>3.2. Pose Mode</title><p>Rate mapping enables teleoperation across unbounded spaces but lacks the precision necessary for operational tasks. In contrast, pose mapping provides enhanced precision for contact tasks within a constrained workspace. In the pose mode, the end-effector&#8217;s pose of the master robot is mapped to the central pose of the UAM through a scaling factor. Specify the homogeneous matrix representations for the orientation of the master exoskeleton&#8217;s end-effector, with the mapping function defined as follows:<disp-formula id="FD5-sensors-25-05844"><label>(5)</label><mml:math id="mm6" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">&#934;</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:mrow><mml:mtable equalrows="true" equalcolumns="true"><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle><mml:mrow><mml:mi>m</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
with<disp-formula id="FD6-sensors-25-05844"><label>(6)</label><mml:math id="mm7" display="block" overflow="scroll"><mml:mrow><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle><mml:mrow><mml:mi>m</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:mrow><mml:mtable equalrows="true" equalcolumns="true"><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>c</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>&#952;</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mi>s</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>&#952;</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mi>s</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>&#952;</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>c</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>&#952;</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mfenced close="]" open="["><mml:mrow><mml:mtable equalrows="true" equalcolumns="true"><mml:mtr><mml:mtd><mml:mrow><mml:mi>c</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>&#952;</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mi>s</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>&#952;</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mi>s</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>&#952;</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mi>c</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>&#952;</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>&#8195;&#8195;&#8195;&#8195;</mml:mtext><mml:mfenced close="]" open="["><mml:mrow><mml:mtable equalrows="true" equalcolumns="true"><mml:mtr><mml:mtd><mml:mrow><mml:mi>c</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>&#952;</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mi>s</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>&#952;</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>s</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>&#952;</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>c</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>&#952;</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mfenced close="]" open="["><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>&#955;</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:mfenced close="&#x2016;" open="&#x2016;"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:mfenced><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>&#945;</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mi>T</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">c</italic>(.) and <italic toggle="yes">s</italic>(.) represent the cosine and sine functions. <bold>R</bold><italic toggle="yes"><sub>ms</sub></italic><sup>0</sup>(<italic toggle="yes">t</italic>) and <italic toggle="yes">p<sub>ms</sub></italic><sup>0</sup>(<italic toggle="yes">t</italic>) denote the rotation matrix and position vector relative to the <italic toggle="yes">X</italic>, <italic toggle="yes">Y</italic>, <italic toggle="yes">Z</italic> axes. Noting that, the rotation matrix adheres to the ZYX Euler angle convention, where rotations are performed sequentially about the <italic toggle="yes">Z</italic>-axis (yaw, <italic toggle="yes">&#968;</italic>), <italic toggle="yes">Y</italic>-axis (pitch, <italic toggle="yes">&#952;</italic>), and <italic toggle="yes">X</italic>-axis (roll, <italic toggle="yes">&#966;</italic>) with respect to the master wrist joint 7, 6, 5. A dead zone is also implemented in the pose mode to minimize vibrations during teleoperation both for position and orientation. The mapped waist angle, denoted as <bold><italic toggle="yes">&#952;</italic></bold><italic toggle="yes"><sub>t</sub></italic>, aligns with the angular representation provided in Equation (1).<disp-formula id="FD7-sensors-25-05844"><label>(7)</label><mml:math id="mm8" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>&#955;</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:mfenced close="&#x2016;" open="&#x2016;"><mml:mrow><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:mfenced><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>&#945;</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
with<disp-formula id="FD8-sensors-25-05844"><label>(8)</label><mml:math id="mm9" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>In pose mode, a larger scaling factor <italic toggle="yes">&#955;<sub>p</sub></italic> can obtain a greater position range but also diminish the control accuracy. A significant challenge in the other research lies in achieving an optimal balance between control accuracy and spatial extent. A dual-submode switching approach, analogous to speed mapping, is employed to enhance precision. In normal mode, the effective control zone is directly confined to the master workspace. The discrepancy between the master and the dead zone, as specified by the operator, represents the desired offset relative to the zero pose of slave UAM.</p><p>Similarly to the reset mode in free rate mode, through the pose reset mode, the origin of the master and slave workspaces is recalibrated. This recalibration aligns the slave&#8217;s posture, as perceived by the operator during mode switching, with a neutral posture that serves as the desired reinitialized reference between the master and slave workspace. Effectively, this process recenters the achievable workspace of the slave to this posture when the operator perceives it. In this state, the teleoperation workspaces of the master and slave are asymmetric. We designate this sub-mode as the pose reset submode, where the offset &#945; in the two sub-modes of the posture mode can be expressed as follows:<disp-formula id="FD9-sensors-25-05844"><label>(9)</label><mml:math id="mm10" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>&#945;</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mfenced close="" open="{"><mml:mrow><mml:mtable equalrows="true" equalcolumns="true"><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mtext>&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;</mml:mtext><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mfenced close="]" open="["><mml:mrow><mml:mtable equalrows="true" equalcolumns="true"><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>&#955;</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:mfenced close="&#x2016;" open="&#x2016;"><mml:mrow><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:mfenced><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>&#952;</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mfenced><mml:mrow><mml:msub><mml:mi>&#955;</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mfenced><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:mfenced close="&#x2016;" open="&#x2016;"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:mfenced><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>
with<disp-formula id="FD10-sensors-25-05844"><label>(10)</label><mml:math id="mm11" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>&#952;</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mtext>&#160;</mml:mtext><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="sec3dot3-sensors-25-05844"><title>3.3. Mode Transformation</title><p>In this section, the transition algorithm for switching between the two workspace mapping methods is developed and described in detail. The Novasense Bluetooth data glove is utilized as the mode switching device capable of sensing and receiving hand command information from the operator intuitively. Gesture one depicted in <xref rid="sensors-25-05844-f009" ref-type="fig">Figure 9</xref>a serves as the control signal for the rate mode, and gesture two shown in <xref rid="sensors-25-05844-f009" ref-type="fig">Figure 9</xref>b acts as the switching signal for the position mode. The gesture illustrated in <xref rid="sensors-25-05844-f009" ref-type="fig">Figure 9</xref>d represents the reset mode, while the gesture depicted in <xref rid="sensors-25-05844-f009" ref-type="fig">Figure 9</xref>c denotes force feedback mode which is described in detail in the next section. The switch controlled by the operator can be performed when mode transformation is necessary. Compared to conventional button-based switching modes, the data glove enhances the flexibility of the mapping algorithm and offers diverse switching options. By enabling direct operator control over mode switching, the teleoperation mapping achieves greater transparency.</p><p>To prevent conflicts between the speed mode and position control mode, a binary logical input <italic toggle="yes">s</italic> is introduced to denote the operational mode, where <italic toggle="yes">s</italic> = 0 corresponds to the position control mode and <italic toggle="yes">s</italic> = 1 corresponds to the speed mode. To ensure the safety of the teleoperation process, transitions between the speed control mode and the rate control mode are restricted, requiring passage through the reset mode. Conversely, the pose control mode and the force feedback mode may be interchanged freely during operation. Upon switching to force feedback mode, it is postulated that the UAM is in contact with the whiteboard surface, thereby fixing the <italic toggle="yes">Z</italic>-axis position at the height established during the mode switch, with no teleoperation control applied to the <italic toggle="yes">Z</italic>-axis. Furthermore, force feedback mode incorporates haptic feedback, while the <italic toggle="yes">X</italic>,<italic toggle="yes">Y</italic>-axis teleoperation mapping algorithm remains consistent with that employed in position mode. The mapping function is expressed by the following equation:<disp-formula id="FD11-sensors-25-05844"><label>(11)</label><mml:math id="mm12" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">&#934;</mml:mi><mml:mfenced><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">&#934;</mml:mi><mml:mrow><mml:mrow><mml:mi>pose</mml:mi><mml:mtext>&#160;</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mfenced><mml:mrow><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>s</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">&#934;</mml:mi><mml:mrow><mml:mrow><mml:mi>rate</mml:mi><mml:mtext>&#160;</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mfenced><mml:mrow><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The proposed mapping strategy allows for continuous and seamless switching between two sub-modes. Switching transformation signals are sent under the operator&#8217;s control whenever necessary, enhancing the flexibility of the mapping algorithm. In contrast to button-based switching, the data glove utilized in this research offers an intuitive approach and minimizes the probability of operational errors due to mode switching.</p></sec><sec id="sec3dot4-sensors-25-05844"><title>3.4. Force Feedback in Physical Contact Tasks</title><p>The present research proposes a haptic feedback framework aimed at enhancing performance and operator immersion in human&#8211;robot interaction systems. Within the established position-mode teleoperation framework, pose commands from the master are directly mapped and transmitted to the contact end of the unmanned autonomous manipulator (UAM).</p><p>When the end-effector of the slave UAM encounters a rigid object, minor positional errors may generate substantial contact forces, potentially undermining the stability and safety of the teleoperation system. To mitigate this, a force feedback framework based on impedance control, as depicted in <xref rid="sensors-25-05844-f010" ref-type="fig">Figure 10</xref>, is introduced.</p><p>Through the master&#8211;slave pose mapping algorithm, the position commands of the master device <italic toggle="yes">x<sub>m</sub></italic> are transformed into the desired position of the slave device <italic toggle="yes">x<sub>s</sub></italic>. The characteristics of a spring-damper second-order system are integrated into the impedance model of UAM, and the impedance controller is formulated as follows:<disp-formula id="FD12-sensors-25-05844"><label>(12)</label><mml:math id="mm13" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mtable columnalign="left" equalrows="true" equalcolumns="true"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>M</mml:mi></mml:mstyle><mml:mi>d</mml:mi></mml:msub><mml:mo>&#916;</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mrow><mml:mo>..</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>D</mml:mi></mml:mstyle><mml:mi>d</mml:mi></mml:msub><mml:mo>&#916;</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo>.</mml:mo></mml:mover></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>K</mml:mi></mml:mstyle><mml:mi>d</mml:mi></mml:msub><mml:mo>&#916;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The dynamics model of the slave UAM can be represented as follows:<disp-formula id="FD13-sensors-25-05844"><label>(13)</label><mml:math id="mm14" display="block" overflow="scroll"><mml:mrow><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>u</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>T</mml:mi></mml:mstyle><mml:mrow><mml:mi>f</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>F</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>M</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mover><mml:mi>q</mml:mi><mml:mrow><mml:mo>..</mml:mo></mml:mrow></mml:mover><mml:mo>+</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>C</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo>,</mml:mo><mml:mover><mml:mi>q</mml:mi><mml:mo>.</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo><mml:mover><mml:mi>q</mml:mi><mml:mo>.</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">F<sub>s</sub></italic> indicates the detect force from the force sensor. <bold>K</bold><italic toggle="yes"><sub>d</sub></italic> is the stiffness parameter; <bold>D</bold><italic toggle="yes"><sub>d</sub></italic> is the damping parameter; <bold>M</bold><italic toggle="yes"><sub>d</sub></italic> is the inertia parameter; <bold>M</bold><italic toggle="yes"><sub>s</sub></italic> is the inertia matrix. <inline-formula><mml:math id="mm15" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>C</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>q</mml:mi><mml:mo>&#729;</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the Kohl force matrix; <bold>G</bold><italic toggle="yes"><sub>s</sub></italic>(<italic toggle="yes">q</italic>) is the gravity matrix of UAM and <bold>T</bold><italic toggle="yes"><sub>fs</sub></italic> represents the conversion matrix that transforms the external force into a control value. The term u<italic toggle="yes"><sub>d</sub></italic> represents the control input for the UAM generated by the control framework to regulate the UAM&#8217;s dynamic. Conversely, u<italic toggle="yes"><sub>s</sub></italic> denotes the external control value transmitted to the UAM, which accounts for external forces or disturbance. In addition, the UAV is subject to external disturbances <italic toggle="yes">d</italic>, such as wind, during task execution. To address this issue, an extended state observer (ESO) is incorporated into the control system of the UAM to enhance stability [<xref rid="B36-sensors-25-05844" ref-type="bibr">36</xref>]. Finally, the following impedance control calculation can be obtained as follows:<disp-formula id="FD14-sensors-25-05844"><label>(14)</label><mml:math id="mm16" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mtable columnalign="left" equalrows="true" equalcolumns="true"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>&#964;</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>J</mml:mi></mml:mstyle><mml:mi>s</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mfenced><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>M</mml:mi></mml:mstyle><mml:mi>d</mml:mi></mml:msub><mml:mo>&#916;</mml:mo><mml:mover><mml:mi>x</mml:mi><mml:mrow><mml:mo>..</mml:mo></mml:mrow></mml:mover><mml:mo>+</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>D</mml:mi></mml:mstyle><mml:mi>d</mml:mi></mml:msub><mml:mo>&#916;</mml:mo><mml:mover><mml:mi>x</mml:mi><mml:mo>.</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>K</mml:mi></mml:mstyle><mml:mi>d</mml:mi></mml:msub><mml:mo>&#916;</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>M</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mover><mml:mi>q</mml:mi><mml:mrow><mml:mo>..</mml:mo></mml:mrow></mml:mover><mml:mo>+</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>C</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo>,</mml:mo><mml:mover><mml:mi>q</mml:mi><mml:mo>.</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo><mml:mover><mml:mi>q</mml:mi><mml:mo>.</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Feedback force <italic toggle="yes">F<sub>f</sub></italic> comprising the contact force <italic toggle="yes">F<sub>s</sub></italic> from the slave environment and the difference <italic toggle="yes">p<sub>e</sub></italic> between the desired and actual positions of the UAM are transmitted to the master robot through the force mapping channel as follows:<disp-formula id="FD15-sensors-25-05844"><label>(15)</label><mml:math id="mm17" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:msubsup><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>m</mml:mi></mml:msubsup><mml:msub><mml:mi>K</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mfenced><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:msub><mml:mi>p</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:msub><mml:mi>F</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">K<sub>s</sub></italic> and <italic toggle="yes">K<sub>e</sub></italic> denote the coefficient of the contact force and impedance force because of position error. Meanwhile, <italic toggle="yes">K<sub>f</sub></italic> denotes the force feedback mapping coefficient, which scales the combined impedance forces and contact force to the force feedback output. In the experiment, <italic toggle="yes">K<sub>s</sub></italic> and <italic toggle="yes">K<sub>f</sub></italic> were set as 1 to ensure the transparency of force feedback, while <italic toggle="yes">K<sub>e</sub></italic> was set as 50 N/m. The teleoperation framework presented in this paper is decoupled for position and orientation. Specifically, the first four joints of the master exoskeleton are responsible for position control and feedback three-dimensional contact forces, while the three motors in the wrist joint control the orientation. The end-effector is equipped with a 1-D force sensor, which detects the contact force in the vertical direction between the UAM and the operating environment. The relationship between the feedback force <italic toggle="yes">F<sub>f</sub></italic> and the exoskeleton motor torque <bold><italic toggle="yes">&#964;</italic></bold><sub>m</sub> can be represented as follows:<disp-formula id="FD16-sensors-25-05844"><label>(16)</label><mml:math id="mm18" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">&#964;</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>J</mml:mi></mml:mstyle><mml:mi mathvariant="normal">m</mml:mi></mml:msub><mml:mi>T</mml:mi></mml:msup><mml:mo>&#8901;</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
where <bold>J</bold><sub>m</sub> denotes the Jacobian matrix of the exoskeleton. The inverse kinematics solution for the 7-DOF robotic system involves redundancy, resulting in multiple feasible configurations. To address this, the present study incorporates an additional constraint, as defined in Equation (17), which minimizes joint torque output to identify the optimal solution. The term <bold><italic toggle="yes">&#964;</italic></bold><italic toggle="yes"><sub>i</sub></italic> specifically represents the force feedback applied to the shoulder and elbow joints of the exoskeleton, excluding the total output torque, as it also accounts for gravity compensation within the exoskeleton.<disp-formula id="FD17-sensors-25-05844"><label>(17)</label><mml:math id="mm19" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>Minimize</mml:mi><mml:mrow><mml:mtable equalrows="true" equalcolumns="true"><mml:mtr><mml:mtd><mml:mrow><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mfenced close="&#x2016;" open="&#x2016;"><mml:mrow><mml:msub><mml:mi>&#964;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mstyle></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The teleoperation system typically consists of the operator, the master robot and controller, the communication channel, the slave robot and controller, and the operating environment. Accordingly, establishing the theoretical stability of the teleoperation system is complicated and challenging. Alternatively, passivity theory presents an approach to establish system stability from the energy perspective [<xref rid="B37-sensors-25-05844" ref-type="bibr">37</xref>]. The total energy is dissipated but not increased in a passive system [<xref rid="B38-sensors-25-05844" ref-type="bibr">38</xref>]. In the passive system, the stored energy remains bounded by the sum of the initial energy storage and the energy supplied to the system which is expressed as follows [<xref rid="B39-sensors-25-05844" ref-type="bibr">39</xref>]:<disp-formula id="FD18-sensors-25-05844"><label>(18)</label><mml:math id="mm20" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8722;</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8804;</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>&#8747;</mml:mo><mml:mn>0</mml:mn><mml:mi>t</mml:mi></mml:msubsup><mml:mi>W</mml:mi></mml:mrow></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mo>&#8704;</mml:mo><mml:mi>t</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">W</italic>(t) represents the real-valued rate of energy, corresponding to the input power supplied to the system. <italic toggle="yes">V</italic>(0) is the initial energy, while <italic toggle="yes">V</italic>(t) is the stored energy function. The stability of the interconnected systems can be rigorously established through passivity theory.</p><p>In the teleoperation system, the operator refrains from deliberately compromising system stability and adopts a passive response to external inputs. Concurrently, both the human operator and the environment can be modeled as passive systems [<xref rid="B40-sensors-25-05844" ref-type="bibr">40</xref>]. Consequently, both the master and slave robots demonstrate passivity with respect to the human operator and the environment. Additionally, a cloud server is incorporated into the master&#8211;slave system to facilitate data transmission. The data stream is transmitted independently of the video stream, with a time delay not exceeding 10 ms. As such, the time delay between the master and slave in this study is deemed negligible. In conclusion, passivity provides sufficient conditions to ensure the stability of the teleoperated robotic control system.</p></sec></sec><sec sec-type="results" id="sec4-sensors-25-05844"><title>4. Results</title><p>The experimental results are described in this section, including the experimental setup, the speed mode experiment, the position mode experiment, the corresponding mode switching, and the <italic toggle="yes">Z</italic>-axis force feedback effect.</p><sec id="sec4dot1-sensors-25-05844"><title>4.1. Experimental Setup</title><p>As illustrated in <xref rid="sensors-25-05844-f011" ref-type="fig">Figure 11</xref>, the operator interfaces with the exoskeleton master robot through an upper arm cuff, a forearm cuff, and a data glove mounting bracket, while the UAM relays visual feedback via a wide-area network server, enabling operation beyond the line of sight. Data communication between the exoskeleton and the unmanned aerial vehicle is facilitated via the TCP/IP protocol over a local area network. The UAM and the end-effector of the exoskeleton are specified within a modified Cartesian coordinate framework.</p><p>The experimental protocol proceeds as follows:<list list-type="simple"><list-item><label>(a)</label><p>Preparation: The UAM operator activates an automated takeoff sequence, directing the UAM to ascend to the designated operational altitude. Upon attaining this altitude, a servo mechanism deploys the 3D end-effector in a perpendicular orientation relative to the operational surface.</p></list-item><list-item><label>(b)</label><p>Teleoperation: The system subsequently transitions to teleoperation control mode, initiating in the reset state. Thereafter, the operator configures the operational mode using the data glove to switch mode in accordance with the requirements to execute interactive control writing tasks. Upon completion of the teleoperation writing task, the operation mode reverts to the reset mode.</p></list-item><list-item><label>(c)</label><p>Completion: The UAM operator activates the recovery sequence, retracting the 3D end-effector via the servo system and guiding the UAM to land.</p></list-item></list></p></sec><sec id="sec4dot2-sensors-25-05844"><title>4.2. Free Rate Mode Experiment</title><p>In the first experiment, the free rate mode was applied for validation of UAM free rate mode results. The control parameters were set as <italic toggle="yes">&#955;<sub>vt</sub></italic> = 0.1, <italic toggle="yes">&#955;<sub>v</sub><sub>&#952;</sub></italic> = 0.05, <italic toggle="yes">r<sub>vt</sub>
</italic>= 15 mm, <italic toggle="yes">r<sub>v</sub><sub>&#952;</sub>
</italic>= 10&#176;, v<sub>max</sub> = 0.05 m/s. The selection of these parameters is designed to capture the operator&#8217;s real intentions, mitigate the impact of end jitter, and ensure that the slave UAM operates within a reasonable velocity range while maintaining approximately the same tracking error at the slave 3D end-effector. Although the algorithm proposed in this study can be applied to 6 DOF teleoperation mapping for the UAM, given the high sensitivity of the UAM stabilizer attitude control, control parameters were made to minimize the impact of primary control parameters on the stabilizer&#8217;s attitude. This enabled the stabilizer to autonomously maintain a posture perpendicular to the horizontal plane. Consequently, the attitude was minimally affected by teleoperation control signals and was not prominently demonstrated in the experiments.</p><p><xref rid="sensors-25-05844-f012" ref-type="fig">Figure 12</xref> illustrates the tracking error in free rate mode. <xref rid="sensors-25-05844-f012" ref-type="fig">Figure 12</xref>a&#8211;c depicts the master control commands and the UAM position feedback along the <italic toggle="yes">X</italic>, <italic toggle="yes">Y</italic>, and <italic toggle="yes">Z</italic> axes, respectively. The green line represents the master-end velocity commands, the red line indicates the UAM position control commands derived from the integration of velocity commands, and the blue curve corresponds to the UAM real-time position feedback. The master control command (green line) with the area enclosed by the <italic toggle="yes">x</italic>-axis corresponds to velocity, which is reflected in the slope of the red line depicts the UAM control response. However, as the <italic toggle="yes">Z</italic>-axis corresponds to the direction of physical interaction and gravitational influence, the impedance control parameters for the <italic toggle="yes">Z</italic>-axis are distinct, leading to noticeable oscillatory behavior during motion along the <italic toggle="yes">Z</italic>-axis. The impedance controller parameters corresponding to the six degrees of freedom for the UAM are configured as follows: <italic toggle="yes">m<sub>c</sub></italic> = [4.5, 4.5, 2, 0.085, 0.085, 0.123], <italic toggle="yes">b<sub>c</sub></italic> = [6, 6, 6, 1.3, 1.3, 1.3], <italic toggle="yes">k<sub>c</sub></italic> = [8, 8, 12, 1.8, 1.8, 2.0] [<xref rid="B41-sensors-25-05844" ref-type="bibr">41</xref>]. It is evident that the UAM achieves effective tracking of the position control commands in the X-Y plane. However, due to differing controller parameter settings for the <italic toggle="yes">Z</italic>-axis, noticeable oscillations are observed in the <italic toggle="yes">Z</italic>-axis motion. <xref rid="sensors-25-05844-f012" ref-type="fig">Figure 12</xref>d illustrates the mode-switching flag generated by the Bluetooth data glove, indicating a reset mode transition at approximately 0.5 sampling time. Consequently, the master-end motion exerts no influence on the UAM motion control, thereby confirming the practical efficacy of the mapping and mode-switching under the free-rate mode.</p></sec><sec id="sec4dot3-sensors-25-05844"><title>4.3. Position and Feedback Mode Experiment</title><p>In the position and feedback mode experiment, the control parameters were set as <italic toggle="yes">&#955;<sub>pt</sub></italic> = 1.0, <italic toggle="yes">&#955;<sub>p</sub><sub>&#952;</sub></italic> = 0.2, <italic toggle="yes">r<sub>pt</sub></italic> = 15 mm, <italic toggle="yes">r<sub>p</sub><sub>&#952;</sub></italic> = 10&#176;. Furthermore, due to the tethered configuration of the drone, its operational radius was limited to 0.3 m, with teleoperation position commands that exceed this limit being considered invalid and subsequently limited within a maximum range. As depicted in <xref rid="sensors-25-05844-f013" ref-type="fig">Figure 13</xref>c,d, the switching flag for position mode is designated as 2, while that for force feedback mode is set to 3, respectively. In the experiment, the UAM was initially operated in position control mode to gradually descend until the 3D end-effector reached a contact height of approximately &#8722;0.15 m with the whiteboard, at which point the system transitioned to force feedback mode. Notably, upon entering force feedback mode and contact with the whiteboard, the UAM <italic toggle="yes">Z</italic>-axis altitude becomes unresponsive to teleoperation commands, autonomously maintaining the contact height until switching back to position mode, while <italic toggle="yes">X-</italic> and <italic toggle="yes">Y</italic>-axis commands remain effective. <xref rid="sensors-25-05844-f013" ref-type="fig">Figure 13</xref> shows that position control mode achieves superior tracking accuracy compared to velocity control mode due to the lower motion speed.</p><p><xref rid="sensors-25-05844-f014" ref-type="fig">Figure 14</xref>a shows the XY-plane projection of the master control and UAM position feedback trajectories, while <xref rid="sensors-25-05844-f014" ref-type="fig">Figure 14</xref>b depicts the real trajectory of 3D end-effector pen on the whiteboard. These trajectories exhibit broadly similar contour shapes, though discrepancies persist in finer details. The position tracking RMSE for position tracking along the <italic toggle="yes">X</italic> and <italic toggle="yes">Y</italic> axes is computed as 7.7% and 5.2%, respectively. The discrepancies observed are primarily attributed to the limited control precision of the UAM, localization inaccuracies stemming from the T265, and frictional effects at the contact interface further compromising trajectory fidelity. The experimental process and results can be visualized in the <xref rid="app1-sensors-25-05844" ref-type="app">supplemental video (Video S1 in Supplementary Materials)</xref>.</p><p><xref rid="sensors-25-05844-f015" ref-type="fig">Figure 15</xref> illustrates the force feedback provided during the aerial writing task. The data smoothed via a Gaussian filter with a window size of 100 exhibit frequent and alternating variations in tactile force along the <italic toggle="yes">Z</italic>-axis, indicating dynamic fluctuations in contact interaction. This behavior stems from the application of impedance control along the <italic toggle="yes">Z</italic>-axis, as depicted in <xref rid="sensors-25-05844-f010" ref-type="fig">Figure 10</xref>, which converts the contact force of the UAM along the <italic toggle="yes">Z</italic>-axis into position errors. Additionally, contact force feedback is seamlessly incorporated into the end-effector of the exoskeleton, enabling perception of physical interaction from the slave UAM.</p></sec></sec><sec sec-type="discussion" id="sec5-sensors-25-05844"><title>5. Discussion</title><p>Compared to traditional teleoperation systems based on serial or parallel master robots, this study employs a 7 DOF wearable upper-limb exoskeleton, which aligns naturally with the operator joint angles, offering intuitive control logic and a significantly expanded operational workspace of the master device. Additionally, in contrast to conventional button-based mode switching, this work utilizes Bluetooth data gloves as mode-switching sensors, providing a broader, clearer, and intuitive interaction framework according to the operational task that effectively minimizes the risk of erroneous operations. Combined with the hybrid mapping framework we proposed, the operator can leverage velocity mapping to rapidly approach the target, subsequently transitioning seamlessly to either a heterogeneous position mode or a force feedback mode to perform interactive tasks with enhanced precision control. By wearing the exoskeleton arm and configuring appropriate mapping parameters, operators achieved velocity mapping and interactive aerial writing modes. Experimental findings not only verify the feasibility and stability of the entire system but also demonstrate that the mode-switching algorithm facilitates efficient teleoperation processes. Furthermore, the algorithm proposed herein is not only applicable to UAM teleoperation but, with appropriate parameter adjustments, is equally suitable for mobile manipulator platform.</p><p>To quantitatively evaluate the system&#8217;s usability, focusing on the intuitiveness and operator comfort, a System Usability Scale (SUS) survey, as is shown in <xref rid="app2-sensors-25-05844" ref-type="app">Appendix A</xref>, was conducted. The results based on responses from ten participants (nine males and one female) provide a comprehensive evaluation of the exoskeleton for teleoperating the UAM. The mean SUS score was 86.3 (SD = 8.2), surpassing the industry benchmark of 68, indicating above-average usability. Analysis revealed strengths in specific usability dimensions: the statement &#8220;The wearable exoskeleton offers enhanced comfort&#8221; received a mean score of 4.3, suggesting high user satisfaction with physical ergonomics. Similarly, &#8220;The teleoperation mode switching is intuitive and user-friendly&#8221; scored 4.8, reflecting intuitive mode transitions, and &#8220;The data gloves did not exhibit mode-switching errors during operation&#8221; averaged 5.0, confirming reliable performance of mode switching interface. Additionally, &#8220;The teleoperation process is free from dizziness or discomfort&#8221; scored 4.8, indicating minimal adverse physical effects. However, the statement &#8220;The teleoperation process does not exhibit noticeable jitter and unexpected movements&#8221; received a lower mean score of 3.9, highlighting a critical area for improvement in control stability. Finally, &#8220;The UAM&#8217;s trajectory aligns consistently with the master control trajectory&#8221; scored 3.1, suggesting generally accurate trajectory tracking but with potential for refinement. These findings validate the system&#8217;s intuitive design and comfort while identifying jitter and minor trajectory inconsistencies as priorities for future optimization.</p><p>Due to the limited control precision of the UAM, which is significantly lower than the millimeter-level accuracy achievable by robotic manipulators, and the visual localization based on the T265 sensor, constrained to centimeter-level accuracy, experimental trajectories exhibit deviations from actual trajectories, as illustrated in <xref rid="sensors-25-05844-f014" ref-type="fig">Figure 14</xref>. Nevertheless, the aerial writing experiments have comprehensively validated the efficacy of the hybrid mapping algorithm.</p></sec><sec sec-type="conclusions" id="sec6-sensors-25-05844"><title>6. Conclusions</title><p>This paper describes a generic haptic teleoperation control architecture for a UAM contact task. Firstly, this paper employs an upper arm exoskeleton as the user-friendly master robot, offering superior human adaptability and a broader workspace compared to conventional desktop level haptic devices. Then, to address the requirements of workspace and accuracy in UAM contact tasks, this work introduces a continuous rate and position control mode that innovatively employs a bluetooth data glove as the command-switching device. The proposed control architecture adeptly addresses challenges in teleoperation, including misoperations arising from non-intuitive mode switching, oscillations triggered by mode switching, and limitations in the workspace of master devices, thereby significantly enhancing system stability and operational efficacy. Finally, a comprehensive experimental platform was established, and an aerial writing experiment was conducted. The results showed that the trajectory tracking error of the areal writing experiment achieved a position tracking RMSE of 7.7% and 5.2% in the <italic toggle="yes">X</italic>,<italic toggle="yes">Y</italic>-axis, respectively. Additionally, the smooth UAM motion observed during the experiments, with no abrupt feedback force variations, further highlights the excellent stability of the control framework, which has potential applications in autonomous aerial vehicles and human&#8211;machine interaction. The SUS survey effectively validates the intuitive and comfort design of the teleoperation master system.</p><p>In the future, we plan to implement the teleoperation system in a six-dimensional workspace and on a broader spectrum of robotic platforms to further evaluate its universality.</p></sec></body><back><fn-group><fn><p><bold>Disclaimer/Publisher&#8217;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><app-group><app id="app1-sensors-25-05844"><title>Supplementary Materials</title><p>The following supporting information can be downloaded at <uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.mdpi.com/article/10.3390/s25185844/s1">https://www.mdpi.com/article/10.3390/s25185844/s1</uri>, Video S1: Video of the verification experiment for bilateral teleoperation of aerial manipulators based on the hybrid mapping framework.</p><supplementary-material id="sensors-25-05844-s001" position="float" content-type="local-data" orientation="portrait"><media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="sensors-25-05844-s001.zip" position="float" orientation="portrait"/></supplementary-material></app></app-group><notes><title>Author Contributions</title><p>Conceptualization: L.M.; Methodology: L.M.; Writing&#8212;original draft preparation: L.M.; Writing&#8212;review and editing: L.M. and Y.R.; Data curation: L.M. and Y.R.; Supervision: W.C. All authors have read and agreed to the published version of the manuscript.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflict of interest.</p></notes><app-group><app id="app2-sensors-25-05844"><title>Appendix A</title><sec><title>Exoskeleton Teleoperation User Survey Questionnaire</title><p>A System Usability Scale (SUS) survey was conducted to systematically evaluate the user experience of the wearable upper arm exoskeleton for teleoperating the Unmanned Aerial Manipulator (UAM). We recruited ten participants (including nine males and one female) to perform UAM teleoperation using the exoskeleton and data gloves as mater robot. Subsequently, the following feedback questionnaire incorporating evaluations of the experimental results and comfort level after experiment are completed.</p><table-wrap position="anchor" id="sensors-25-05844-t0A1" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05844-t0A1_Table A1</object-id><label>Table A1</label><caption><p>The system usability scale questionnaire of the teleoperation system. For each of the following statements, mark one box that best describes your reaction to the teleoperation experiment today.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Question Options</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Strongly Disagree</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Strongly Agree</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">The wearable exoskeleton robotic arm offers enhanced comfort</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">The teleoperation mode switching is intuitive and user-friendly</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">The data gloves do not exhibit mode-switching errors during operation</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">The teleoperation process is free from dizziness or discomfort</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">The teleoperation does not process exhibit noticeable jitters <break/>and unexpected movements</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#9633;</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">The UAM&#8217;s trajectory aligns consistently with the master control trajectory</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#9633;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#9633;</td></tr></tbody></table></table-wrap></sec></app></app-group><ref-list><title>References</title><ref id="B1-sensors-25-05844"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Darvish</surname><given-names>K.</given-names></name><name name-style="western"><surname>Penco</surname><given-names>L.</given-names></name><name name-style="western"><surname>Ramos</surname><given-names>J.</given-names></name><name name-style="western"><surname>Cisneros</surname><given-names>R.</given-names></name><name name-style="western"><surname>Pratt</surname><given-names>J.</given-names></name><name name-style="western"><surname>Yoshida</surname><given-names>E.</given-names></name><name name-style="western"><surname>Ivaldi</surname><given-names>S.</given-names></name><name name-style="western"><surname>Pucci</surname><given-names>D.</given-names></name></person-group><article-title>Teleoperation of Humanoid Robots: A Survey</article-title><source>IEEE Trans. Robot.</source><year>2023</year><volume>39</volume><fpage>1706</fpage><lpage>1727</lpage><pub-id pub-id-type="doi">10.1109/TRO.2023.3236952</pub-id></element-citation></ref><ref id="B2-sensors-25-05844"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Meng</surname><given-names>X.</given-names></name><name name-style="western"><surname>He</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Han</surname><given-names>J.</given-names></name></person-group><article-title>Survey on Aerial Manipulator: System, Modeling, and Control&#8212;CORRIGENDUM</article-title><source>Robotica</source><year>2020</year><volume>38</volume><fpage>1343</fpage><pub-id pub-id-type="doi">10.1017/S026357472000048X</pub-id></element-citation></ref><ref id="B3-sensors-25-05844"><label>3.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Kim</surname><given-names>S.</given-names></name><name name-style="western"><surname>Seo</surname><given-names>H.</given-names></name><name name-style="western"><surname>Kim</surname><given-names>H.J.</given-names></name></person-group><article-title>Operating an unknown drawer using an aerial manipulator</article-title><source>Proceedings of the 2015 IEEE International Conference on Robotics and Automation (ICRA)</source><conf-loc>Seattle, WA, USA</conf-loc><conf-date>26&#8211;30 May 2015</conf-date><fpage>5503</fpage><lpage>5508</lpage></element-citation></ref><ref id="B4-sensors-25-05844"><label>4.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Lee</surname><given-names>D.</given-names></name><name name-style="western"><surname>Seo</surname><given-names>H.</given-names></name><name name-style="western"><surname>Kim</surname><given-names>D.</given-names></name><name name-style="western"><surname>Kim</surname><given-names>H.J.</given-names></name></person-group><article-title>Aerial manipulation using model predictive control for opening a hinged door</article-title><source>Proceedings of the 2020 IEEE International Conference on Robotics and Automation (ICRA)</source><conf-loc>Paris, France</conf-loc><conf-date>31 May&#8211;31 August 2020</conf-date><fpage>1237</fpage><lpage>1242</lpage></element-citation></ref><ref id="B5-sensors-25-05844"><label>5.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Meng</surname><given-names>X.</given-names></name><name name-style="western"><surname>He</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Han</surname><given-names>J.</given-names></name></person-group><article-title>Design and implementation of a contact aerial manipulator system for glass-wall inspection tasks</article-title><source>Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</source><conf-loc>Macau, China</conf-loc><conf-date>4&#8211;8 November 2019</conf-date><fpage>215</fpage><lpage>220</lpage></element-citation></ref><ref id="B6-sensors-25-05844"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tzoumanikas</surname><given-names>D.</given-names></name><name name-style="western"><surname>Graule</surname><given-names>F.</given-names></name><name name-style="western"><surname>Yan</surname><given-names>Q.</given-names></name><name name-style="western"><surname>Shah</surname><given-names>D.</given-names></name><name name-style="western"><surname>Popovic</surname><given-names>M.</given-names></name><name name-style="western"><surname>Leutenegger</surname><given-names>S.</given-names></name></person-group><article-title>Aerial manipulation using hybrid force and position nmpc applied to aerial writing. Robotics: Science and Systems(RSS)</article-title><source>arXiv</source><year>2020</year><pub-id pub-id-type="arxiv">2006.02116</pub-id></element-citation></ref><ref id="B7-sensors-25-05844"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ollero</surname><given-names>A.</given-names></name><name name-style="western"><surname>Heredia</surname><given-names>G.</given-names></name><name name-style="western"><surname>Franchi</surname><given-names>A.</given-names></name><name name-style="western"><surname>Antonelli</surname><given-names>G.</given-names></name><name name-style="western"><surname>Kondak</surname><given-names>K.</given-names></name><name name-style="western"><surname>Sanfeliu</surname><given-names>A.</given-names></name><name name-style="western"><surname>Viguria</surname><given-names>A.</given-names></name><name name-style="western"><surname>Martinez-de Dios</surname><given-names>J.R.</given-names></name><name name-style="western"><surname>Pierri</surname><given-names>F.</given-names></name><name name-style="western"><surname>Cortes</surname><given-names>J.</given-names></name><etal/></person-group><article-title>The AEROARMS Project: Aerial Robots with Advanced Manipulation Capabilities for Inspection and Maintenance</article-title><source>IEEE Robot. Autom. Mag.</source><year>2018</year><volume>25</volume><fpage>12</fpage><lpage>23</lpage><pub-id pub-id-type="doi">10.1109/MRA.2018.2852789</pub-id></element-citation></ref><ref id="B8-sensors-25-05844"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Moniruzzaman</surname><given-names>M.</given-names></name><name name-style="western"><surname>Rassau</surname><given-names>A.</given-names></name><name name-style="western"><surname>Chai</surname><given-names>D.</given-names></name><name name-style="western"><surname>Islam</surname><given-names>S.M.S.</given-names></name></person-group><article-title>Teleoperation Methods and Enhancement Techniques for Mobile Robots: A Comprehensive Survey</article-title><source>Robot. Auton. Syst.</source><year>2022</year><volume>150</volume><fpage>103973</fpage><pub-id pub-id-type="doi">10.1016/j.robot.2021.103973</pub-id></element-citation></ref><ref id="B9-sensors-25-05844"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mersha</surname><given-names>A.Y.</given-names></name><name name-style="western"><surname>Stramigioli</surname><given-names>S.</given-names></name><name name-style="western"><surname>Carloni</surname><given-names>R.</given-names></name></person-group><article-title>On Bilateral Teleoperation of Aerial Robots</article-title><source>IEEE Trans. Robot.</source><year>2014</year><volume>30</volume><fpage>258</fpage><lpage>274</lpage><pub-id pub-id-type="doi">10.1109/TRO.2013.2281563</pub-id></element-citation></ref><ref id="B10-sensors-25-05844"><label>10.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Allenspach</surname><given-names>M.</given-names></name><name name-style="western"><surname>Lawrance</surname><given-names>N.</given-names></name><name name-style="western"><surname>Tognon</surname><given-names>M.</given-names></name><name name-style="western"><surname>Siegwart</surname><given-names>R.</given-names></name></person-group><article-title>Towards 6DoF bilateral teleoperation of an omnidirectional aerial vehicle for aerial physical interaction</article-title><source>Proceedings of the 2022 International Conference on Robotics and Automation (ICRA)</source><conf-loc>Philadelphia, PA, USA</conf-loc><conf-date>23&#8211;27 May 2022</conf-date><fpage>9302</fpage><lpage>9308</lpage></element-citation></ref><ref id="B11-sensors-25-05844"><label>11.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Byun</surname><given-names>J.</given-names></name><name name-style="western"><surname>Eom</surname><given-names>D.</given-names></name><name name-style="western"><surname>Kim</surname><given-names>H.J.</given-names></name></person-group><article-title>Haptic-based bilateral teleoperation of aerial manipulator for extracting wedged object with compensation of human reaction time</article-title><source>Proceedings of the 2024 International Conference on Unmanned Aircraft Systems (ICUAS)</source><conf-loc>Chania, Greece</conf-loc><conf-date>4&#8211;7 June 2024</conf-date><fpage>624</fpage><lpage>630</lpage></element-citation></ref><ref id="B12-sensors-25-05844"><label>12.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Pepe</surname><given-names>A.</given-names></name><name name-style="western"><surname>Chiaravalli</surname><given-names>D.</given-names></name><name name-style="western"><surname>Melchiorri</surname><given-names>C.</given-names></name></person-group><article-title>A Hybrid teleoperation control scheme for a single-arm mobile manipulator with omnidirectional wheels</article-title><source>Proceedings of the 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</source><conf-loc>Daejeon, Republic of Korea</conf-loc><conf-date>9&#8211;14 October 2016</conf-date><fpage>1450</fpage><lpage>1455</lpage></element-citation></ref><ref id="B13-sensors-25-05844"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chicaiza</surname><given-names>F.A.</given-names></name><name name-style="western"><surname>Slawi&#241;ski</surname><given-names>E.</given-names></name><name name-style="western"><surname>Mut</surname><given-names>V.</given-names></name></person-group><article-title>Delayed Bilateral Teleoperation of Mobile Manipulators with Hybrid Mapping</article-title><source>IEEE Open J. Ind. Electron. Soc.</source><year>2024</year><volume>5</volume><fpage>663</fpage><lpage>681</lpage><pub-id pub-id-type="doi">10.1109/OJIES.2024.3419422</pub-id></element-citation></ref><ref id="B14-sensors-25-05844"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tian</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>G.</given-names></name><name name-style="western"><surname>Li</surname><given-names>L.</given-names></name><name name-style="western"><surname>Jin</surname><given-names>T.</given-names></name><name name-style="western"><surname>Xi</surname><given-names>F.</given-names></name><name name-style="western"><surname>Yuan</surname><given-names>G.</given-names></name></person-group><article-title>A Universal Self-Adaption Workspace Mapping Method for Human&#8211;Robot Interaction Using Kinect Sensor Data</article-title><source>IEEE Sens. J.</source><year>2020</year><volume>20</volume><fpage>7918</fpage><lpage>7928</lpage><pub-id pub-id-type="doi">10.1109/JSEN.2020.2981091</pub-id></element-citation></ref><ref id="B15-sensors-25-05844"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Yan</surname><given-names>S.</given-names></name><name name-style="western"><surname>Yuan</surname><given-names>M.</given-names></name><name name-style="western"><surname>Yao</surname><given-names>B.</given-names></name><name name-style="western"><surname>Hu</surname><given-names>J.</given-names></name></person-group><article-title>Modular Development of Master-Slave Asymmetric Teleoperation Systems with a Novel Workspace Mapping Algorithm</article-title><source>IEEE Access</source><year>2018</year><volume>6</volume><fpage>15356</fpage><lpage>15364</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2018.2809860</pub-id></element-citation></ref><ref id="B16-sensors-25-05844"><label>16.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>R&#252;esch</surname><given-names>A.</given-names></name><name name-style="western"><surname>Mersha</surname><given-names>A.Y.</given-names></name><name name-style="western"><surname>Stramigioli</surname><given-names>S.</given-names></name><name name-style="western"><surname>Carloni</surname><given-names>R.</given-names></name></person-group><article-title>Kinetic scrolling-based position mapping for haptic teleoperation of unmanned aerial vehicles</article-title><source>Proceedings of the 2012 IEEE International Conference on Robotics and Automation</source><conf-loc>Saint Paul, MN, USA</conf-loc><conf-date>14&#8211;18 May 2012</conf-date><fpage>3116</fpage><lpage>3121</lpage></element-citation></ref><ref id="B17-sensors-25-05844"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ollero</surname><given-names>A.</given-names></name><name name-style="western"><surname>Tognon</surname><given-names>M.</given-names></name><name name-style="western"><surname>Suarez</surname><given-names>A.</given-names></name><name name-style="western"><surname>Lee</surname><given-names>D.</given-names></name><name name-style="western"><surname>Franchi</surname><given-names>A.</given-names></name></person-group><article-title>Past, Present, and Future of Aerial Robotic Manipulators</article-title><source>IEEE Trans. Robot</source><year>2021</year><volume>38</volume><fpage>626</fpage><lpage>645</lpage><pub-id pub-id-type="doi">10.1109/TRO.2021.3084395</pub-id></element-citation></ref><ref id="B18-sensors-25-05844"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Masone</surname><given-names>C.</given-names></name><name name-style="western"><surname>Mohammadi</surname><given-names>M.</given-names></name><name name-style="western"><surname>Robuffo Giordano</surname><given-names>P.</given-names></name><name name-style="western"><surname>Franchi</surname><given-names>A.</given-names></name></person-group><article-title>Shared Planning and Control for Mobile Robots with Integral Haptic Feedback</article-title><source>Int. J. Robot. Res.</source><year>2018</year><volume>37</volume><fpage>1395</fpage><lpage>1420</lpage><pub-id pub-id-type="doi">10.1177/0278364918802006</pub-id></element-citation></ref><ref id="B19-sensors-25-05844"><label>19.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Macchini</surname><given-names>M.</given-names></name><name name-style="western"><surname>Havy</surname><given-names>T.</given-names></name><name name-style="western"><surname>Weber</surname><given-names>A.</given-names></name><name name-style="western"><surname>Schiano</surname><given-names>F.</given-names></name><name name-style="western"><surname>Floreano</surname><given-names>D.</given-names></name></person-group><article-title>Hand-worn haptic interface for drone teleoperation</article-title><source>Proceedings of the 2020 IEEE International Conference on Robotics and Automation (ICRA)</source><conf-loc>Paris, France</conf-loc><conf-date>31 May&#8211;31 August</conf-date><fpage>10212</fpage><lpage>10218</lpage></element-citation></ref><ref id="B20-sensors-25-05844"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chicaiza</surname><given-names>F.A.</given-names></name><name name-style="western"><surname>Slawi&#241;ski</surname><given-names>E.</given-names></name><name name-style="western"><surname>Salinas</surname><given-names>L.R.</given-names></name><name name-style="western"><surname>Mut</surname><given-names>V.A.</given-names></name></person-group><article-title>Evaluation of Path Planning with Force Feedback for Bilateral Teleoperation of Unmanned Rotorcraft Systems</article-title><source>J. Intell. Robot. Syst.</source><year>2022</year><volume>105</volume><fpage>34</fpage><pub-id pub-id-type="doi">10.1007/s10846-022-01651-y</pub-id></element-citation></ref><ref id="B21-sensors-25-05844"><label>21.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Moortgat-Pick</surname><given-names>A./</given-names></name><name name-style="western"><surname>Adamczyk</surname><given-names>A.</given-names></name><name name-style="western"><surname>Tomi&#263;</surname><given-names>T.</given-names></name><name name-style="western"><surname>Haddadin</surname><given-names>S.</given-names></name></person-group><article-title>Feeling the true force in haptic telepresence for flying robots</article-title><source>Proceedings of the 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</source><conf-loc>Las Vegas, NV, USA</conf-loc><conf-date>25&#8211;29 October 2020</conf-date><fpage>9789</fpage><lpage>9796</lpage></element-citation></ref><ref id="B22-sensors-25-05844"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Aleotti</surname><given-names>J.</given-names></name><name name-style="western"><surname>Micconi</surname><given-names>G.</given-names></name><name name-style="western"><surname>Caselli</surname><given-names>S.</given-names></name><name name-style="western"><surname>Benassi</surname><given-names>G.</given-names></name><name name-style="western"><surname>Zambelli</surname><given-names>N.</given-names></name><name name-style="western"><surname>Bettelli</surname><given-names>M.</given-names></name><name name-style="western"><surname>Zappettini</surname><given-names>A.</given-names></name></person-group><article-title>Detection of Nuclear Sources by UAV Teleoperation Using a Visuo-Haptic Augmented Reality Interface</article-title><source>Sensors</source><year>2017</year><volume>17</volume><elocation-id>2234</elocation-id><pub-id pub-id-type="doi">10.3390/s17102234</pub-id><pub-id pub-id-type="pmid">28961198</pub-id><pub-id pub-id-type="pmcid">PMC5677116</pub-id></element-citation></ref><ref id="B23-sensors-25-05844"><label>23.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Schill</surname><given-names>F.</given-names></name><name name-style="western"><surname>Hou</surname><given-names>X.</given-names></name><name name-style="western"><surname>Mahony</surname><given-names>R.</given-names></name></person-group><article-title>Admittance mode framework for haptic teleoperation of hovering vehicles with unlimited workspace</article-title><source>Proceedings of the Australasian Conference on Robotics and Automation (ACRA)</source><conf-loc>Brisbane, Australia</conf-loc><conf-date>1&#8211;3 December 2010</conf-date></element-citation></ref><ref id="B24-sensors-25-05844"><label>24.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Gioioso</surname><given-names>G.</given-names></name><name name-style="western"><surname>Mohammadi</surname><given-names>M.</given-names></name><name name-style="western"><surname>Franchi</surname><given-names>A.</given-names></name><name name-style="western"><surname>Prattichizzo</surname><given-names>D.</given-names></name></person-group><article-title>A force-based bilateral teleoperation framework for aerial robots in contact with the environment</article-title><source>Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)</source><conf-loc>Seattle, WA, USA</conf-loc><conf-date>26&#8211;30 May 2015</conf-date><fpage>318</fpage><lpage>324</lpage></element-citation></ref><ref id="B25-sensors-25-05844"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Islam</surname><given-names>S.</given-names></name><name name-style="western"><surname>Ashour</surname><given-names>R.</given-names></name><name name-style="western"><surname>Sunda-Meya</surname><given-names>A.</given-names></name></person-group><article-title>Haptic and Virtual Reality Based Shared Control for MAV</article-title><source>IEEE Trans. Aerosp. Electron. Syst.</source><year>2019</year><volume>55</volume><fpage>2337</fpage><lpage>2346</lpage><pub-id pub-id-type="doi">10.1109/TAES.2018.2885642</pub-id></element-citation></ref><ref id="B26-sensors-25-05844"><label>26.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Mohammadi</surname><given-names>M.</given-names></name><name name-style="western"><surname>Franchi</surname><given-names>A.</given-names></name><name name-style="western"><surname>Barcelli</surname><given-names>D.</given-names></name><name name-style="western"><surname>Prattichizzo</surname><given-names>D.</given-names></name></person-group><article-title>Cooperative aerial tele-manipulation with haptic feedback</article-title><source>Proceedings of the 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</source><conf-loc>Daejeon, Republic of Korea</conf-loc><conf-date>9&#8211;14 October 2016</conf-date><fpage>5092</fpage><lpage>5098</lpage></element-citation></ref><ref id="B27-sensors-25-05844"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gao</surname><given-names>Q.</given-names></name><name name-style="western"><surname>Ju</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Chen</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>Q.</given-names></name><name name-style="western"><surname>Chi</surname><given-names>C.</given-names></name></person-group><article-title>An Efficient RGB-D Hand Gesture Detection Framework for Dexterous Robot Hand-Arm Teleoperation System</article-title><source>IEEE Trans. Hum. Mach. Syst.</source><year>2023</year><volume>53</volume><fpage>13</fpage><lpage>23</lpage><pub-id pub-id-type="doi">10.1109/THMS.2022.3206663</pub-id></element-citation></ref><ref id="B28-sensors-25-05844"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rashad</surname><given-names>R.</given-names></name><name name-style="western"><surname>Goerres</surname><given-names>J.</given-names></name><name name-style="western"><surname>Aarts</surname><given-names>R.</given-names></name><name name-style="western"><surname>Engelen</surname><given-names>J.B.C.</given-names></name><name name-style="western"><surname>Stramigioli</surname><given-names>S.</given-names></name></person-group><article-title>Fully Actuated Multirotor UAVs: A Literature Review</article-title><source>IEEE Robot. Autom. Mag.</source><year>2020</year><volume>27</volume><fpage>97</fpage><lpage>107</lpage><pub-id pub-id-type="doi">10.1109/MRA.2019.2955964</pub-id></element-citation></ref><ref id="B29-sensors-25-05844"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shu</surname><given-names>P.</given-names></name><name name-style="western"><surname>Li</surname><given-names>F.</given-names></name><name name-style="western"><surname>Zhao</surname><given-names>J.</given-names></name><name name-style="western"><surname>Oya</surname><given-names>M.</given-names></name></person-group><article-title>Robust Adaptive Control for a Novel Fully-Actuated Octocopter UAV with Wind Disturbance</article-title><source>J. Intell. Robot. Syst.</source><year>2021</year><volume>103</volume><fpage>6</fpage><pub-id pub-id-type="doi">10.1007/s10846-021-01450-x</pub-id></element-citation></ref><ref id="B30-sensors-25-05844"><label>30.</label><element-citation publication-type="webpage"><person-group person-group-type="author"><collab>3dsystems</collab></person-group><article-title>Touch&#8212;Haptic Device</article-title><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.3dsystems.com/haptics-devices/touch" ext-link-type="uri">https://www.3dsystems.com/haptics-devices/touch</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-08-16">(accessed on 16 August 2025)</date-in-citation></element-citation></ref><ref id="B31-sensors-25-05844"><label>31.</label><element-citation publication-type="webpage"><person-group person-group-type="author"><collab>forcedimension</collab></person-group><article-title>Sigma.7</article-title><comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.forcedimension.com/products/sigma" ext-link-type="uri">https://www.forcedimension.com/products/sigma</ext-link></comment><date-in-citation content-type="access-date" iso-8601-date="2025-08-16">(accessed on 16 August 2025)</date-in-citation></element-citation></ref><ref id="B32-sensors-25-05844"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Hai</surname><given-names>M.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>X.</given-names></name><name name-style="western"><surname>Pei</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Qian</surname><given-names>S.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>D.</given-names></name></person-group><article-title>A human&#8211;robot interaction control strategy for Teleoperation Robot System Under Multi-Scenario Applications</article-title><source>Int. J. Intell. Robot. Appl.</source><year>2025</year><volume>9</volume><fpage>125</fpage><lpage>145</lpage><pub-id pub-id-type="doi">10.1007/s41315-024-00351-0</pub-id></element-citation></ref><ref id="B33-sensors-25-05844"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rong</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Chou</surname><given-names>W.</given-names></name></person-group><article-title>Design and Control of An Aerial Manipulator with Invariant Center of Gravity for Physical Interaction</article-title><source>J. Mech. Robot.</source><year>2024</year><volume>16</volume><fpage>071001</fpage><pub-id pub-id-type="doi">10.1115/1.4063368</pub-id></element-citation></ref><ref id="B34-sensors-25-05844"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Qi</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Zhu</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Wang</surname><given-names>J.</given-names></name><name name-style="western"><surname>Shan</surname><given-names>J.</given-names></name><name name-style="western"><surname>Liu</surname><given-names>H.H.T.</given-names></name></person-group><article-title>MUDE-Based Control of Quadrotor for Accurate Attitude Tracking</article-title><source>Control Eng. Pract.</source><year>2021</year><volume>108</volume><fpage>104721</fpage><pub-id pub-id-type="doi">10.1016/j.conengprac.2020.104721</pub-id></element-citation></ref><ref id="B35-sensors-25-05844"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Han</surname><given-names>J.</given-names></name><name name-style="western"><surname>Yang</surname><given-names>G.-H.</given-names></name></person-group><article-title>Improving Teleoperator Efficiency Using Position&#8211;Rate Hybrid Controllers and Task Decomposition</article-title><source>Appl. Sci.</source><year>2022</year><volume>12</volume><elocation-id>9672</elocation-id><pub-id pub-id-type="doi">10.3390/app12199672</pub-id></element-citation></ref><ref id="B36-sensors-25-05844"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rong</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Chou</surname><given-names>W.</given-names></name><name name-style="western"><surname>Jiao</surname><given-names>R.</given-names></name></person-group><article-title>Robust Fault-Tolerant Motion/Force Control of a Fully-Actuated Hexarotor Using Adaptive Sliding Mode Impedance Control</article-title><source>Int. J. Robust Nonlinear Control</source><year>2022</year><volume>32</volume><fpage>4149</fpage><lpage>4172</lpage><pub-id pub-id-type="doi">10.1002/rnc.6005</pub-id></element-citation></ref><ref id="B37-sensors-25-05844"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lawrence</surname><given-names>D.A.</given-names></name></person-group><article-title>Stability and Transparency in Bilateral Teleoperation</article-title><source>IEEE Trans. Robot. Autom.</source><year>1993</year><volume>9</volume><fpage>624</fpage><lpage>637</lpage><pub-id pub-id-type="doi">10.1109/70.258054</pub-id></element-citation></ref><ref id="B38-sensors-25-05844"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Estrada</surname><given-names>E.</given-names></name><name name-style="western"><surname>Yu</surname><given-names>W.</given-names></name><name name-style="western"><surname>Li</surname><given-names>X.</given-names></name></person-group><article-title>Stability and Transparency of Delayed Bilateral Teleoperation with Haptic Feedback</article-title><source>Int. J. Appl. Math. Comput. Sci.</source><year>2019</year><volume>29</volume><fpage>681</fpage><lpage>692</lpage><pub-id pub-id-type="doi">10.2478/amcs-2019-0050</pub-id></element-citation></ref><ref id="B39-sensors-25-05844"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Feng</surname><given-names>K.</given-names></name><name name-style="western"><surname>Xu</surname><given-names>Q.</given-names></name><name name-style="western"><surname>Wong</surname><given-names>S.F.</given-names></name><name name-style="western"><surname>Zi</surname><given-names>B.</given-names></name></person-group><article-title>Design and Development of a Teleoperated Telepresence Robot System with High-Fidelity Haptic Feedback Assistance</article-title><source>IEEE Trans. Autom. Sci. Eng.</source><year>2024</year><volume>22</volume><fpage>1069</fpage><lpage>1080</lpage><pub-id pub-id-type="doi">10.1109/TASE.2024.3359243</pub-id></element-citation></ref><ref id="B40-sensors-25-05844"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Itoh</surname><given-names>T.</given-names></name><name name-style="western"><surname>Kosuge</surname><given-names>K.</given-names></name><name name-style="western"><surname>Fukuda</surname><given-names>T.</given-names></name></person-group><article-title>Human-Machine Cooperative Telemanipulation with Motion and Force Scaling Using Task-Oriented Virtual Tool Dynamics</article-title><source>IEEE Trans. Robot. Autom.</source><year>2000</year><volume>16</volume><fpage>505</fpage><lpage>516</lpage><pub-id pub-id-type="doi">10.1109/70.880801</pub-id></element-citation></ref><ref id="B41-sensors-25-05844"><label>41.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rong</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Chou</surname><given-names>W.</given-names></name></person-group><article-title>Wheeled Visuotactile Sensing for Aerial Physical Interaction with Surfaces of Unknown Curvature</article-title><source>IEEE Trans. Instrum. Meas.</source><year>2025</year><volume>74</volume><fpage>5016911</fpage><pub-id pub-id-type="doi">10.1109/TIM.2025.3551141</pub-id></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-05844-f001" orientation="portrait"><label>Figure 1</label><caption><p>Schematic diagram of teleoperation system.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05844-g001.jpg"/></fig><fig position="float" id="sensors-25-05844-f002" orientation="portrait"><label>Figure 2</label><caption><p>Upper arm exoskeleton robot.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05844-g002.jpg"/></fig><fig position="float" id="sensors-25-05844-f003" orientation="portrait"><label>Figure 3</label><caption><p>Upper arm exoskeleton workspace. (<bold>a</bold>) Reachable workspace. (<bold>b</bold>) Illustration of workspace using Monte Carlo in sagittal plane. (<bold>c</bold>) Workspace in horizontal plane.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05844-g003.jpg"/></fig><fig position="float" id="sensors-25-05844-f004" orientation="portrait"><label>Figure 4</label><caption><p>Data glove from SenseGlove Nova.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05844-g004.jpg"/></fig><fig position="float" id="sensors-25-05844-f005" orientation="portrait"><label>Figure 5</label><caption><p>Slave UAM structure diagram. (<bold>a</bold>) The folded state of the 3D end-effector; (<bold>b</bold>) the extended state of the 3D end-effector.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05844-g005.jpg"/></fig><fig position="float" id="sensors-25-05844-f006" orientation="portrait"><label>Figure 6</label><caption><p>Three-dimensional end-effector structure diagram.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05844-g006.jpg"/></fig><fig position="float" id="sensors-25-05844-f007" orientation="portrait"><label>Figure 7</label><caption><p>Teleoperation structure diagram.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05844-g007.jpg"/></fig><fig position="float" id="sensors-25-05844-f008" orientation="portrait"><label>Figure 8</label><caption><p>Master pose and mapping velocity in free rate mode.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05844-g008.jpg"/></fig><fig position="float" id="sensors-25-05844-f009" orientation="portrait"><label>Figure 9</label><caption><p>Mode transformation by hand gesture recognition. (<bold>a</bold>) Free rate normal mode; (<bold>b</bold>) pose mode; (<bold>c</bold>) force feedback mode; (<bold>d</bold>) reset mode.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05844-g009.jpg"/></fig><fig position="float" id="sensors-25-05844-f010" orientation="portrait"><label>Figure 10</label><caption><p>Force feedback control based on impedance control.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05844-g010.jpg"/></fig><fig position="float" id="sensors-25-05844-f011" orientation="portrait"><label>Figure 11</label><caption><p>Experimental setup for UAM teleoperated by upper exoskeleton. (<bold>a</bold>) operator wearing exoskeleton; (<bold>b</bold>) master system; (<bold>c</bold>) slave UAM with 3D end-effector.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05844-g011.jpg"/></fig><fig position="float" id="sensors-25-05844-f012" orientation="portrait"><label>Figure 12</label><caption><p>Results of the free rate mode experiment: trajectory tracking performance of master&#8211;slave. (<bold>a</bold>) Trajectory tracking alone <italic toggle="yes">X</italic>-axis; (<bold>b</bold>) trajectory tracking alone <italic toggle="yes">Y</italic>-axis; (<bold>c</bold>) trajectory tracking alone <italic toggle="yes">Z</italic>-axis; (<bold>d</bold>) switching mode flag via BT glove.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05844-g012.jpg"/></fig><fig position="float" id="sensors-25-05844-f013" orientation="portrait"><label>Figure 13</label><caption><p>Results of the position and force feedback mode experiment: trajectory tracking performance of master-slave. (<bold>a</bold>) Trajectory tracking alone <italic toggle="yes">X</italic>-axis; (<bold>b</bold>) trajectory tracking alone <italic toggle="yes">Y</italic>-axis; (<bold>c</bold>) trajectory tracking alone <italic toggle="yes">Z</italic>-axis; (<bold>d</bold>) switching mode flag via BT glove.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05844-g013.jpg"/></fig><fig position="float" id="sensors-25-05844-f014" orientation="portrait"><label>Figure 14</label><caption><p>Two-dimensional motion trajectory in the <italic toggle="yes">X</italic>-<italic toggle="yes">Y</italic> plane. (<bold>a</bold>) trajectory of master signal and UAM feedback trajectory; (<bold>b</bold>) real air writing trajectory of the whiteboard pen in the 3D end-effector.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05844-g014.jpg"/></fig><fig position="float" id="sensors-25-05844-f015" orientation="portrait"><label>Figure 15</label><caption><p>Z-axis contact force measurement curve.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05844-g015.jpg"/></fig><table-wrap position="float" id="sensors-25-05844-t001" orientation="portrait"><object-id pub-id-type="pii">sensors-25-05844-t001_Table 1</object-id><label>Table 1</label><caption><p>Modified D-H parameters of the right exoskeleton.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Link <italic toggle="yes">i</italic></th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
<italic toggle="yes">&#952;</italic>
</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
<italic toggle="yes">d</italic>
</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
<italic toggle="yes">a</italic>
</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">
<italic toggle="yes">&#945;</italic>
</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Offset</th><th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Range (&#176;)</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">1</td><td align="center" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">&#952;</italic>
<sub>1</sub>
</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;<italic toggle="yes">l<sub>a</sub></italic></td><td align="center" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">l<sub>b</sub></italic>
</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;pi/2</td><td align="center" valign="middle" rowspan="1" colspan="1">0</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;90~0</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">2</td><td align="center" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">&#952;</italic>
<sub>2</sub>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0</td><td align="center" valign="middle" rowspan="1" colspan="1">0</td><td align="center" valign="middle" rowspan="1" colspan="1">pi/2</td><td align="center" valign="middle" rowspan="1" colspan="1">pi/2</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;36~79</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">3</td><td align="center" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">&#952;</italic>
<sub>3</sub>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0</td><td align="center" valign="middle" rowspan="1" colspan="1">0</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;pi/2</td><td align="center" valign="middle" rowspan="1" colspan="1">pi/2</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;90~0</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">4</td><td align="center" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">&#952;</italic>
<sub>4</sub>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0</td><td align="center" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">l<sub>c</sub></italic>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0</td><td align="center" valign="middle" rowspan="1" colspan="1">0</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;142~0</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">5</td><td align="center" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">&#952;</italic>
<sub>5</sub>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0</td><td align="center" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">l<sub>d</sub></italic>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;pi/2</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;30~40</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">6</td><td align="center" valign="middle" rowspan="1" colspan="1">
<italic toggle="yes">&#952;</italic>
<sub>6</sub>
</td><td align="center" valign="middle" rowspan="1" colspan="1">0</td><td align="center" valign="middle" rowspan="1" colspan="1">0</td><td align="center" valign="middle" rowspan="1" colspan="1">pi/2</td><td align="center" valign="middle" rowspan="1" colspan="1">pi/2</td><td align="center" valign="middle" rowspan="1" colspan="1">&#8722;55~40</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">7</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<italic toggle="yes">&#952;</italic>
<sub>7</sub>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">pi/2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#8722;45~60</td></tr></tbody></table></table-wrap></floats-group></article></pmc-articleset>