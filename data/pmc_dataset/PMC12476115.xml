<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" id="hbm70364" xml:lang="en" article-type="research-article" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Hum Brain Mapp</journal-id><journal-id journal-id-type="iso-abbrev">Hum Brain Mapp</journal-id><journal-id journal-id-type="pmc-domain-id">3754</journal-id><journal-id journal-id-type="pmc-domain">humanbrain</journal-id><journal-id journal-id-type="publisher-id">HBM</journal-id><journal-title-group><journal-title>Human Brain Mapping</journal-title></journal-title-group><issn pub-type="ppub">1065-9471</issn><issn pub-type="epub">1097-0193</issn><publisher><publisher-name>Wiley</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12476115</article-id><article-id pub-id-type="pmcid-ver">PMC12476115.1</article-id><article-id pub-id-type="pmcaid">12476115</article-id><article-id pub-id-type="pmcaiid">12476115</article-id><article-id pub-id-type="pmid">41014302</article-id><article-id pub-id-type="doi">10.1002/hbm.70364</article-id><article-id pub-id-type="publisher-id">HBM70364</article-id><article-id pub-id-type="other">HBM-24-1252.R2</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="overline"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>st&#8208;<styled-content style="fixed-case" toggle="no">DenseViT</styled-content>: A Weakly Supervised Spatiotemporal Vision Transformer for Dense Prediction of Dynamic Brain Networks</article-title></title-group><contrib-group><contrib id="hbm70364-cr-0001" contrib-type="author" corresp="yes"><name name-style="western"><surname>Kazemivash</surname><given-names initials="B">Behnam</given-names></name><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-3852-8391</contrib-id><xref rid="hbm70364-aff-0001" ref-type="aff">
<sup>1</sup>
</xref><address><email>be.kazemivash@ieee.org</email></address></contrib><contrib id="hbm70364-cr-0002" contrib-type="author"><name name-style="western"><surname>Suresh</surname><given-names initials="P">Pranav</given-names></name><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-9167-3718</contrib-id><xref rid="hbm70364-aff-0002" ref-type="aff">
<sup>2</sup>
</xref></contrib><contrib id="hbm70364-cr-0003" contrib-type="author"><name name-style="western"><surname>Ye</surname><given-names initials="DH">Dong Hye</given-names></name><xref rid="hbm70364-aff-0003" ref-type="aff">
<sup>3</sup>
</xref><xref rid="hbm70364-aff-0004" ref-type="aff">
<sup>4</sup>
</xref></contrib><contrib id="hbm70364-cr-0004" contrib-type="author"><name name-style="western"><surname>Iraji</surname><given-names initials="A">Armin</given-names></name><xref rid="hbm70364-aff-0003" ref-type="aff">
<sup>3</sup>
</xref><xref rid="hbm70364-aff-0004" ref-type="aff">
<sup>4</sup>
</xref></contrib><contrib id="hbm70364-cr-0005" contrib-type="author"><name name-style="western"><surname>Liu</surname><given-names initials="J">Jingyu</given-names></name><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-1724-7523</contrib-id><xref rid="hbm70364-aff-0003" ref-type="aff">
<sup>3</sup>
</xref><xref rid="hbm70364-aff-0004" ref-type="aff">
<sup>4</sup>
</xref></contrib><contrib id="hbm70364-cr-0006" contrib-type="author"><name name-style="western"><surname>Plis</surname><given-names initials="S">Sergey</given-names></name><xref rid="hbm70364-aff-0003" ref-type="aff">
<sup>3</sup>
</xref><xref rid="hbm70364-aff-0004" ref-type="aff">
<sup>4</sup>
</xref></contrib><contrib id="hbm70364-cr-0007" contrib-type="author"><name name-style="western"><surname>Kochunov</surname><given-names initials="P">Peter</given-names></name><xref rid="hbm70364-aff-0005" ref-type="aff">
<sup>5</sup>
</xref></contrib><contrib id="hbm70364-cr-0008" contrib-type="author"><name name-style="western"><surname>Zhu</surname><given-names initials="DC">David C.</given-names></name><xref rid="hbm70364-aff-0001" ref-type="aff">
<sup>1</sup>
</xref></contrib><contrib id="hbm70364-cr-0009" contrib-type="author"><name name-style="western"><surname>Calhoun</surname><given-names initials="VD">Vince D.</given-names></name><xref rid="hbm70364-aff-0003" ref-type="aff">
<sup>3</sup>
</xref><xref rid="hbm70364-aff-0004" ref-type="aff">
<sup>4</sup>
</xref></contrib></contrib-group><aff id="hbm70364-aff-0001">
<label>
<sup>1</sup>
</label>
<named-content content-type="organisation-division">Department of Radiology and Gruss Magnetic Resonance Research Center</named-content>
<institution>Albert Einstein College of Medicine, Montefiore Medical Center</institution>
<city>Bronx</city>
<named-content content-type="country-part">New York</named-content>
<country country="US">USA</country>
</aff><aff id="hbm70364-aff-0002">
<label>
<sup>2</sup>
</label>
<institution>Laureate Institute for Brain Research</institution>
<city>Tulsa</city>
<named-content content-type="country-part">Oklahoma</named-content>
<country country="US">USA</country>
</aff><aff id="hbm70364-aff-0003">
<label>
<sup>3</sup>
</label>
<institution>Computer Science Department of Georgia State University</institution>
<city>Atlanta</city>
<named-content content-type="country-part">Georgia</named-content>
<country country="US">USA</country>
</aff><aff id="hbm70364-aff-0004">
<label>
<sup>4</sup>
</label>
<institution>Tri&#8208;Institutional Center for Translational Research in Neuroimaging and Data Science (TReNDS)</institution>
<city>Atlanta</city>
<named-content content-type="country-part">Georgia</named-content>
<country country="US">USA</country>
</aff><aff id="hbm70364-aff-0005">
<label>
<sup>5</sup>
</label>
<named-content content-type="organisation-division">Maryland Psychiatric Research Center, Department of Psychiatry</named-content>
<institution>University of Maryland School of Medicine</institution>
<city>Baltimore</city>
<named-content content-type="country-part">Maryland</named-content>
<country country="US">USA</country>
</aff><author-notes><corresp id="correspondenceTo"><label>*</label><bold>Correspondence:</bold><break/>
Behnam Kazemivash (<email>be.kazemivash@ieee.org</email>)<break/></corresp></author-notes><pub-date pub-type="epub"><day>27</day><month>9</month><year>2025</year></pub-date><pub-date pub-type="collection"><day>1</day><month>10</month><year>2025</year></pub-date><volume>46</volume><issue seq="250">14</issue><issue-id pub-id-type="pmc-issue-id">496851</issue-id><issue-id pub-id-type="doi">10.1002/hbm.v46.14</issue-id><elocation-id>e70364</elocation-id><history><date date-type="rev-recd"><day>09</day><month>9</month><year>2025</year></date><date date-type="received"><day>28</day><month>11</month><year>2024</year></date><date date-type="accepted"><day>14</day><month>9</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>27</day><month>09</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>28</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-28 21:25:17.150"><day>28</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement content-type="article-copyright">&#169; 2025 The Author(s). <italic toggle="yes">Human Brain Mapping</italic> published by Wiley Periodicals LLC.</copyright-statement><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article under the terms of the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link> License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="HBM-46-e70364.pdf"/><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pdf" xlink:href="file:HBM-46-e70364.pdf"/><abstract><title>ABSTRACT</title><p>Modeling dynamic neuronal activity within brain networks enables the precise tracking of rapid temporal fluctuations across different brain regions. However, current approaches in computational neuroscience fall short of capturing and representing the spatiotemporal dynamics within each brain network. We developed a novel weakly supervised spatiotemporal dense prediction model capable of generating personalized 4D dynamic brain networks from fMRI data, providing a more granular representation of brain activity over time. We developed a model that leverages the vision transformer (ViT) as its backbone, jointly encoding spatial and temporal information from fMRI inputs using two different configurations: space&#8211;time and sequential encoders. The model generates 4D brain network maps that evolve over time, capturing dynamic changes in both spatial and temporal dimensions. In the absence of ground&#8208;truth data, we used spatially constrained windowed independent component analysis (ICA) components derived from fMRI data as weak supervision to guide the training process. The model was evaluated using large&#8208;scale resting&#8208;state fMRI datasets, and statistical analyses were conducted to assess the effectiveness of the generated dynamic maps using various metrics. Our model effectively produced 4D brain maps that captured both inter&#8208;subject and temporal variations, offering a dynamic representation of evolving brain networks. Notably, the model demonstrated the ability to produce smooth maps from noisy priors, effectively denoising the resulting brain dynamics. Additionally, statistically significant differences were observed in the temporally averaged brain maps, as well as in the summation of absolute temporal gradient maps, between patients with schizophrenia and healthy controls. For example, within the Default Mode Network (DMN), significant differences emerged in the temporally averaged space&#8211;time configurations, particularly in the thalamus, where healthy controls exhibited higher activity levels compared to subjects with schizophrenia. These findings highlight the model's potential for differentiating between clinical populations. The proposed spatiotemporal dense prediction model offers an effective approach for generating dynamic brain maps by capturing significant spatiotemporal variations in brain activity. Leveraging weak supervision through ICA components enables the model to learn dynamic patterns without direct ground&#8208;truth data, making it a robust and efficient tool for brain mapping. Significance: This work presents an important new approach for dynamic brain mapping, potentially opening up new opportunities for studying brain dynamics within specific networks. By framing the problem as a spatiotemporal dense prediction task in computer vision, we leverage the spatiotemporal ViT architecture combined with weakly supervised learning techniques to efficiently and effectively estimate these maps.</p></abstract><abstract abstract-type="graphical"><p>Overview of the proposed spatiotemporal dense prediction framework. The model takes 4D fMRI data as input and generates dynamic brain maps that evolve over time. The input is first patchified into a sequence of spatiotemporal tokens. A Vision Transformer (ViT) encoder is used to model complex spatial and temporal dependencies across these tokens. We implement and compare two encoder variants: (1) a space&#8208;time encoder, which jointly attends to spatial and temporal tokens within a unified self&#8208;attention mechanism, and (2) a sequential encoder, which applies separate attention over spatial and temporal dimensions. The encoder output is passed to a lightweight CNN&#8208;based decoder head that reconstructs dense spatiotemporal predictions (4D dynamic maps). Weak supervision is incorporated during training via ICA&#8208;derived components, which guide learning through a soft loss function. This architecture enables learning of subject&#8208;specific, temporally dynamic brain activity patterns from weak supervision.<boxed-text position="anchor" content-type="graphic" id="hbm70364-blkfxd-0001" orientation="portrait"><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="anchor" id="jats-graphic-1" orientation="portrait" xlink:href="HBM-46-e70364-g003.jpg"/></boxed-text>
</p></abstract><kwd-group kwd-group-type="author-generated"><kwd id="hbm70364-kwd-0001">brain dynamics</kwd><kwd id="hbm70364-kwd-0002">computer vision</kwd><kwd id="hbm70364-kwd-0003">dynamic brain map</kwd><kwd id="hbm70364-kwd-0004">fMRI</kwd><kwd id="hbm70364-kwd-0005">spatiotemporal dense prediction</kwd><kwd id="hbm70364-kwd-0006">vision transformer</kwd><kwd id="hbm70364-kwd-0007">weakly supervised learning</kwd></kwd-group><funding-group><award-group id="funding-0001"><funding-source><institution-wrap><institution>National Institutes of Health</institution><institution-id institution-id-type="doi">10.13039/100000002</institution-id></institution-wrap></funding-source><award-id>R01MH123610</award-id></award-group><award-group id="funding-0002"><funding-source><institution-wrap><institution>National Science Foundation</institution><institution-id institution-id-type="doi">10.13039/100000001</institution-id></institution-wrap></funding-source><award-id>2112455</award-id></award-group></funding-group><counts><fig-count count="6"/><table-count count="4"/><page-count count="16"/><word-count count="11800"/></counts><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>source-schema-version-number</meta-name><meta-value>2.0</meta-value></custom-meta><custom-meta><meta-name>cover-date</meta-name><meta-value>October 1, 2025</meta-value></custom-meta><custom-meta><meta-name>details-of-publishers-convertor</meta-name><meta-value>Converter:WILEY_ML3GV2_TO_JATSPMC version:6.6.4 mode:remove_FC converted:27.09.2025</meta-value></custom-meta></custom-meta-group></article-meta><notes><p content-type="self-citation">
<mixed-citation publication-type="journal" id="hbm70364-cit-1001"><string-name name-style="western"><surname>Kazemivash</surname>, <given-names>B.</given-names></string-name>, <string-name name-style="western"><given-names>P.</given-names><surname>Suresh</surname></string-name>, <string-name name-style="western"><given-names>D. H.</given-names><surname>Ye</surname></string-name>, et al. <year>2025</year>. &#8220;<article-title>st&#8208;<styled-content style="fixed-case" toggle="no">DenseViT</styled-content>: A Weakly Supervised Spatiotemporal Vision Transformer for Dense Prediction of Dynamic Brain Networks</article-title>.&#8221; <source>Human Brain Mapping</source><volume>46</volume>, no. <issue>14</issue>: <elocation-id>e70364</elocation-id>. <pub-id pub-id-type="doi">10.1002/hbm.70364</pub-id>.<pub-id pub-id-type="pmid">41014302</pub-id></mixed-citation>
</p><fn-group id="hbm70364-ntgp-0001"><fn fn-type="funding" id="hbm70364-note-0001"><p>
<bold>Funding:</bold> This work was supported in part by the U.S. National Institutes of Health (NIH) under grant R01MH123610 and the U.S. National Science Foundation (NSF) under grant 2112455. Source code is available at: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/bkazemivash/Scepter" ext-link-type="uri">https://github.com/bkazemivash/Scepter</ext-link>.</p></fn></fn-group></notes></front><body id="hbm70364-body-0001"><sec id="hbm70364-sec-0001"><label>1</label><title>Introduction</title><p>The human brain, an incredibly complex system, consists of nearly one hundred billion neurons, each forming tens of thousands of unique connections with other neurons (Bear et&#160;al.&#160;<xref rid="hbm70364-bib-0009" ref-type="bibr">2020</xref>; Hawrylycz et&#160;al.&#160;<xref rid="hbm70364-bib-0034" ref-type="bibr">2012</xref>; Sporns&#160;<xref rid="hbm70364-bib-0093" ref-type="bibr">2022</xref>). This forms complex computational and memory networks that exhibit non&#8208;linear dynamics underpinning essential functions such as cognition, memory, emotion, and perception. This dynamic behavior is key to shaping conscious experience and understanding human cognition and consciousness (Li&#233;geois et&#160;al.&#160;<xref rid="hbm70364-bib-0058" ref-type="bibr">2019</xref>; Raut et&#160;al.&#160;<xref rid="hbm70364-bib-0081" ref-type="bibr">2020</xref>; Bruining et&#160;al.&#160;<xref rid="hbm70364-bib-0013" ref-type="bibr">2020</xref>).</p><p>Advances in neuroimaging, particularly functional magnetic resonance imaging (fMRI), have significantly transformed computational neuroscience by enabling the simultaneous recording of blood oxygenation level dependence (BOLD) signal activity across the entire brain (Zhang, Wang, and Liu&#160;<xref rid="hbm70364-bib-0118" ref-type="bibr">2024</xref>; Marino and Mantini&#160;<xref rid="hbm70364-bib-0067" ref-type="bibr">2024</xref>). Many analytical and modeling techniques have been developed to investigate brain dynamics using sequential neural data. One widely used method is based on co&#8208;activation patterns (CAPs), which identify transient brain patterns that contribute to the formation of resting&#8208;state networks (Liu et&#160;al.&#160;<xref rid="hbm70364-bib-0062" ref-type="bibr">2018</xref>; Zhang, Lin, et&#160;al.&#160;<xref rid="hbm70364-bib-0120" ref-type="bibr">2024</xref>). CAPs provide an effective method for identifying recurring neural configurations but struggle to resolve meaningful patterns when functionally distinct brain states exhibit significant temporal overlap, potentially limiting their sensitivity in capturing complex or concurrent neural processes (Li et&#160;al.&#160;<xref rid="hbm70364-bib-0055" ref-type="bibr">2021</xref>; Matsui et&#160;al.&#160;<xref rid="hbm70364-bib-0068" ref-type="bibr">2022</xref>; Iraji et&#160;al.&#160;<xref rid="hbm70364-bib-0040" ref-type="bibr">2022</xref>).</p><p>Another prominent approach is sliding window correlation (SWC), commonly used to investigate dynamic changes in regional connectivity. This method involves calculating pairwise correlation or covariance matrices within a specified time window across successive time points (Vergara et&#160;al.&#160;<xref rid="hbm70364-bib-0103" ref-type="bibr">2019</xref>; Shakil et&#160;al.&#160;<xref rid="hbm70364-bib-0091" ref-type="bibr">2016</xref>). While it is effective for tracking the temporal evolution of functional connectivity, the choice of window length can significantly influence the results. Newer models attempt to relax this constraint (Faghiri et&#160;al.&#160;<xref rid="hbm70364-bib-0025" ref-type="bibr">2021</xref>). However, overlapping windows may introduce correlated noise and redundancy, complicating the distinction between true dynamic changes and artifacts in the data (Hindriks et&#160;al.&#160;<xref rid="hbm70364-bib-0035" ref-type="bibr">2016</xref>; Savva et&#160;al.&#160;<xref rid="hbm70364-bib-0087" ref-type="bibr">2020</xref>, <xref rid="hbm70364-bib-0088" ref-type="bibr">2019</xref>).</p><p>Similarly, phase synchrony (PS) has been used to measure coherence and phase coupling between neural components, providing insights into the synchrony between brain regions (Honari et&#160;al.&#160;<xref rid="hbm70364-bib-0036" ref-type="bibr">2021</xref>; Omidvarnia et&#160;al.&#160;<xref rid="hbm70364-bib-0074" ref-type="bibr">2016</xref>). This method is well&#8208;suited for capturing the temporal coordination of neural activity; however, it is primarily focused on phase relationships and may not fully capture the amplitude variations (Sadaghiani et&#160;al.&#160;<xref rid="hbm70364-bib-0086" ref-type="bibr">2012</xref>; Zarghami et&#160;al.&#160;<xref rid="hbm70364-bib-0117" ref-type="bibr">2020</xref>; Honari and Lindquist&#160;<xref rid="hbm70364-bib-0037" ref-type="bibr">2022</xref>). Switching linear dynamical systems (SLDS) are another modeling approach used to represent nonlinear dynamics by approximating complex systems through transitions between multiple linear regimes (Li, Li, et&#160;al.&#160;<xref rid="hbm70364-bib-0056" ref-type="bibr">2024</xref>). These models are flexible and can represent nonlinear behaviors in brain activity, but the need for multiple discrete states to approximate a single nonlinear vector field can make the models difficult to interpret. The number of latent dimensions required for each regime further complicates the visualization and interpretation of results (Karniol&#8208;Tambour et&#160;al.&#160;<xref rid="hbm70364-bib-0045" ref-type="bibr">2024</xref>).</p><p>Although many methods focus on temporal variations across fixed spatial nodes, recent work emphasizes the importance of capturing spatial variability within functional domains for a more comprehensive understanding of brain activity (Iraji et&#160;al.&#160;<xref rid="hbm70364-bib-0042" ref-type="bibr">2020</xref>). Quasi&#8208;periodic patterns (QPPs) capture reliable spatiotemporal patterns in low&#8208;frequency neural activity (Fransson and Strindberg&#160;<xref rid="hbm70364-bib-0029" ref-type="bibr">2023</xref>; Thompson et&#160;al.&#160;<xref rid="hbm70364-bib-0098" ref-type="bibr">2014</xref>). This approach is valuable for uncovering recurring dynamics over time, offering insights into both temporal and spatial interactions in brain function. However, QPPs are primarily focused on low&#8208;frequency activity, potentially limiting their ability to detect higher&#8208;frequency events critical for understanding brain dynamics (Abbas&#160;<xref rid="hbm70364-bib-0001" ref-type="bibr">2019</xref>; Belloy et&#160;al.&#160;<xref rid="hbm70364-bib-0010" ref-type="bibr">2018</xref>; Seeburger et&#160;al.&#160;<xref rid="hbm70364-bib-0089" ref-type="bibr">2024</xref>). Hierarchical models that integrate high&#8208;order spatial independent component analysis (ICA) reveal the fluidity of spatial associations, distinguishing functional homogeneity and stability at lower levels from greater spatial variability at higher levels (Iraji, Deramus, et&#160;al.&#160;<xref rid="hbm70364-bib-0039" ref-type="bibr">2019</xref>; Iraji, Fu, et&#160;al.&#160;<xref rid="hbm70364-bib-0041" ref-type="bibr">2019</xref>). Windowed ICA approaches provide even more flexibility, allowing spatially varying maps for each brain network (Iraji, Deramus, et&#160;al.&#160;<xref rid="hbm70364-bib-0039" ref-type="bibr">2019</xref>).</p><p>Although each method offers distinct advantages, a comprehensive understanding of brain dynamics requires analyzing both the temporal evolution of individual networks and the interactions between different brain regions over short timescales. The generation of dynamic brain networks can be reframed as a computer vision problem, using UNet&#8208;style models to capture spatially evolving patterns in brain data (Kazemivash and Calhoun&#160;<xref rid="hbm70364-bib-0046" ref-type="bibr">2020</xref>, <xref rid="hbm70364-bib-0047" ref-type="bibr">2022a</xref>). These generated maps have been effective in distinguishing between schizophrenia and control groups, demonstrating their potential for identifying subtle alterations in brain activity (Kazemivash and Calhoun&#160;<xref rid="hbm70364-bib-0048" ref-type="bibr">2022b</xref>; Kazemivash et&#160;al.&#160;<xref rid="hbm70364-bib-0049" ref-type="bibr">2023</xref>). While these innovative methods advance the creation of dynamic brain maps, the development of robust parcellation techniques that yield detailed, temporally resolved maps remains a critical challenge in the field.</p><p>In this study, we present a novel model that addresses three challenges in the analysis of dynamic brain networks. First, the model introduces a soft brain parcellation technique that produces high&#8208;resolution 4D brain maps. Second, it functions as a dynamic estimation tool, capturing and representing distinct spatiotemporal activity patterns across multiple brain networks over time. Third, it overcomes the absence of ground&#8208;truth data by incorporating spatially constrained windowed ICA components (Iraji et&#160;al.&#160;<xref rid="hbm70364-bib-0038" ref-type="bibr">2024</xref>) as weak supervision to initialize the training. Although we use linear ICA&#8208;derived components as priors, our model is designed to also capture nonlinear spatial dependencies and temporal dynamics in brain activity patterns, enabling a more expressive, flexible, and data&#8208;driven representation of functional networks. Finally, we assess the medical relevance and performance of the generated 4D maps to highlight the practical impact of our approach.</p></sec><sec id="hbm70364-sec-0002"><label>2</label><title>Related Concepts</title><p>In this section, we explore key concepts central to our approach, including weakly supervised learning, spatiotemporal dense prediction, and brain parcellation. Understanding these foundational ideas is essential for grasping the methods and objectives of our research on dynamic brain mapping.</p><sec id="hbm70364-sec-0003"><label>2.1</label><title>Weakly Supervised Learning</title><p>Weakly supervised learning approaches allow predictive models to be trained using datasets that lack precise, fully labeled examples. Instead of relying on exact labels for every data point, these methods can handle noisy, ambiguous, or incomplete data (Murphy&#160;<xref rid="hbm70364-bib-0072" ref-type="bibr">2022</xref>; Ahuja et&#160;al.&#160;<xref rid="hbm70364-bib-0004" ref-type="bibr">2022</xref>). One common scenario in weakly supervised learning is label uncertainty, where each training instance is associated with a distribution of possible labels rather than a single definitive label. In such cases, training is performed by minimizing the cross&#8208;entropy between the true label distribution and the model's predicted distribution, a technique known as label smoothing. This method can regularize the model by replacing hard labels with softer, probabilistic versions (M&#252;ller et&#160;al.&#160;<xref rid="hbm70364-bib-0071" ref-type="bibr">2019</xref>; Gong et&#160;al.&#160;<xref rid="hbm70364-bib-0030" ref-type="bibr">2024</xref>; Liu et&#160;al.&#160;<xref rid="hbm70364-bib-0061" ref-type="bibr">2022</xref>).</p><p>Another method in weakly supervised learning is multiple instance learning (MIL). In MIL, training data is grouped into sets or &#8220;bags&#8221; where only a label for the entire bag is available, but not for individual instances within the bag (Lv et&#160;al.&#160;<xref rid="hbm70364-bib-0066" ref-type="bibr">2023</xref>; Yuan et&#160;al.&#160;<xref rid="hbm70364-bib-0116" ref-type="bibr">2021</xref>; Cui et&#160;al.&#160;<xref rid="hbm70364-bib-0018" ref-type="bibr">2024</xref>). Distant supervision is yet another strategy in this framework, where labels are inferred from external knowledge sources, such as databases (Qi et&#160;al.&#160;<xref rid="hbm70364-bib-0079" ref-type="bibr">2024</xref>; Yao et&#160;al.&#160;<xref rid="hbm70364-bib-0113" ref-type="bibr">2021</xref>; Lin et&#160;al.&#160;<xref rid="hbm70364-bib-0060" ref-type="bibr">2022</xref>). Label&#8208;noise learning (LNL), which addresses issues caused by incorrect or noisy labels from sources like human error, data uncertainty, or subjective labeling criteria, along with other methods, enables machine learning models to be trained effectively even when ground&#8208;truth data is sparse, incomplete, or noisy (Lu et&#160;al.&#160;<xref rid="hbm70364-bib-0063" ref-type="bibr">2023</xref>; Han et&#160;al.&#160;<xref rid="hbm70364-bib-0033" ref-type="bibr">2020</xref>; Rokham et&#160;al.&#160;<xref rid="hbm70364-bib-0082" ref-type="bibr">2023</xref>, <xref rid="hbm70364-bib-0083" ref-type="bibr">2020</xref>). In the era of big data, where obtaining fully labeled datasets is often impractical, weakly supervised learning has become an essential approach.</p></sec><sec id="hbm70364-sec-0004"><label>2.2</label><title>Spatiotemporal Dense Prediction</title><p>In computer vision, dense prediction is a task of pixel&#8208;wise or voxel&#8208;wise predictions, where the model generates outputs at the level of individual picture or volume elements, rather than at higher levels of abstraction (Yang, Jiang, et&#160;al.&#160;<xref rid="hbm70364-bib-0112" ref-type="bibr">2024</xref>; Yang, Yuan, et&#160;al.&#160;<xref rid="hbm70364-bib-0111" ref-type="bibr">2024</xref>; Xia et&#160;al.&#160;<xref rid="hbm70364-bib-0110" ref-type="bibr">2024</xref>). Examples of dense prediction tasks include semantic (Alexandropoulos et&#160;al.&#160;<xref rid="hbm70364-bib-0005" ref-type="bibr">2024</xref>; Sung et&#160;al.&#160;<xref rid="hbm70364-bib-0096" ref-type="bibr">2024</xref>), panoptic (de Geus and Dubbelman&#160;<xref rid="hbm70364-bib-0020" ref-type="bibr">2024</xref>; Sun et&#160;al.&#160;<xref rid="hbm70364-bib-0095" ref-type="bibr">2024</xref>), and instance segmentation (Kalluri et&#160;al.&#160;<xref rid="hbm70364-bib-0044" ref-type="bibr">2024</xref>; Wei et&#160;al.&#160;<xref rid="hbm70364-bib-0106" ref-type="bibr">2024</xref>), optical flow estimation (Luo, Li, et&#160;al.&#160;<xref rid="hbm70364-bib-0064" ref-type="bibr">2024</xref>; Luo, Luo, et&#160;al.&#160;<xref rid="hbm70364-bib-0065" ref-type="bibr">2024</xref>), depth estimation (Li, Wang, et&#160;al.&#160;<xref rid="hbm70364-bib-0057" ref-type="bibr">2024</xref>; Ke et&#160;al.&#160;<xref rid="hbm70364-bib-0050" ref-type="bibr">2024</xref>), and even image reconstruction (Szymanowicz et&#160;al.&#160;<xref rid="hbm70364-bib-0097" ref-type="bibr">2024</xref>; Charatan et&#160;al.&#160;<xref rid="hbm70364-bib-0017" ref-type="bibr">2024</xref>).</p><p>The dense prediction models need to accurately capture both spatial and temporal information to produce coherent spatiotemporal representations (Weng et&#160;al.&#160;<xref rid="hbm70364-bib-0107" ref-type="bibr">2024</xref>; Nguyen et&#160;al.&#160;<xref rid="hbm70364-bib-0073" ref-type="bibr">2024</xref>). To address these challenges, recent techniques have been developed that aggregate flow&#8208;guided features, leverage sequence modeling, and apply heuristic approaches to model temporal variations. These methods aim to exploit redundancies and correlations across different time points, improving both predictive accuracy and efficiency (Arnab et&#160;al.&#160;<xref rid="hbm70364-bib-0007" ref-type="bibr">2021</xref>).</p></sec><sec id="hbm70364-sec-0005"><label>2.3</label><title>Brain Parcellation</title><p>Brain parcellation refers to the segmentation of the brain into distinct regions that are assumed to be functionally or structurally distinct (Moghimi et&#160;al.&#160;<xref rid="hbm70364-bib-0070" ref-type="bibr">2022</xref>). The simplest approaches are atlas&#8208;based methods that rely on predefined anatomical templates with rigid boundaries (i.e., hard parcellation) and therefore face limitations due to individual variability in brain size, shape, and folding, as well as the computational demands of spatial registration (Fan et&#160;al.&#160;<xref rid="hbm70364-bib-0026" ref-type="bibr">2016</xref>; Auzias et&#160;al.&#160;<xref rid="hbm70364-bib-0008" ref-type="bibr">2016</xref>).</p><p>Alternatively, segmentation approaches use functional connectivity (Lawrence et&#160;al.&#160;<xref rid="hbm70364-bib-0053" ref-type="bibr">2021</xref>) parcellation that clusters voxels based on their connectivity profiles, providing an individual&#8208;level data&#8208;driven representation of brain organization (Eickhoff et&#160;al.&#160;<xref rid="hbm70364-bib-0024" ref-type="bibr">2015</xref>). Among connectivity&#8208;based approaches, independent component analysis (ICA), a soft parcellation technique (i.e., allowing voxels to contribute to multiple networks with varying weights), is widely employed (Calhoun and Adali&#160;<xref rid="hbm70364-bib-0014" ref-type="bibr">2012</xref>). ICA extracts independent spatial maps and captures the temporal contribution of these maps through corresponding time courses. However, reducing these temporal contributions to scalar values per volume may oversimplify the underlying complexity of brain activity (Iraji et&#160;al.&#160;<xref rid="hbm70364-bib-0042" ref-type="bibr">2020</xref>; Calhoun et&#160;al.&#160;<xref rid="hbm70364-bib-0015" ref-type="bibr">2009</xref>, <xref rid="hbm70364-bib-0016" ref-type="bibr">2015</xref>). Consequently, there remains a critical gap in the development of advanced dynamic brain parcellation methods capable of fully capturing the intricate temporal dynamics present in neural data and generating spatiotemporally evolving brain activity patterns that accurately reflect the continuous nature of functional brain processes.</p></sec></sec><sec sec-type="methods" id="hbm70364-sec-0006"><label>3</label><title>Methods</title><p>Our model generates dynamic patterns of brain networks by employing two distinct configurations independently: a space&#8211;time encoder and a sequential encoder, both of which utilize the self&#8208;attention mechanism (updating features based on relationships within the input sequence only) to encode spatial and temporal information using different strategies, as shown in Figure&#160;<xref rid="hbm70364-fig-0001" ref-type="fig">1</xref>. Additionally, we propose a method to tackle the challenge of missing ground&#8208;truth data when generating dynamic brain maps.</p><fig position="float" fig-type="FIGURE" id="hbm70364-fig-0001" orientation="portrait"><label>FIGURE 1</label><caption><p>Overview of the proposed spatiotemporal dense prediction framework. The model takes 4D fMRI data as input and generates dynamic brain maps that evolve over time. The input is first patchified into a sequence of spatiotemporal tokens. A Vision Transformer (ViT) encoder is used to model complex spatial and temporal dependencies across these tokens. We implement and compare two encoder variants: (1) a space&#8211;time encoder, which jointly attends to spatial and temporal tokens within a unified self&#8208;attention mechanism, and (2) a sequential encoder, which applies separate attention over spatial and temporal dimensions. The encoder output is passed to a lightweight CNN&#8208;based decoder head that reconstructs dense spatiotemporal predictions (4D dynamic maps). Weak supervision is incorporated during training via ICA&#8208;derived components, which guide learning through a soft loss function. This architecture enables the learning of subject&#8208;specific, temporally dynamic brain activity patterns from weak supervision.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="anchor" id="jats-graphic-3" orientation="portrait" xlink:href="HBM-46-e70364-g004.jpg"/></fig><p>We utilize a vision transformer as the backbone of our model. First, we patchify the input fMRI data (i.e., Dividing the 3D spatial volume, height by width by depth, into smaller cubic pieces called patches, at each time point), <mml:math id="jats-math-1" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi mathvariant="normal">&#8477;</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>w</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>d</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math>, into a sequence of tokens <mml:math id="jats-math-2" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi mathvariant="normal">&#8477;</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>p</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math>. More precisely, we extract <mml:math id="jats-math-3" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mrow></mml:math> non&#8208;overlapping 3D patches <mml:math id="jats-math-4" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math> from the spatial dimensions, apply a linear projection <mml:math id="jats-math-5" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#960;</mml:mi></mml:mrow></mml:mrow></mml:math>, and then flatten them into 1D feature vectors, or tokens (a numeric representation of each patch information), <mml:math id="jats-math-6" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi mathvariant="normal">&#8477;</mml:mi><mml:mi>e</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math>. Additionally, a learnable positional embedding, <mml:math id="jats-math-7" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="italic">pe</mml:mi><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi mathvariant="normal">&#8477;</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>p</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math>, is added to the tokens to retain positional information, addressing the permutation invariance of self&#8208;attention module within the transformer. So we have <mml:math id="jats-math-8" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math> representing a token for a timepoint <mml:math id="jats-math-9" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:math> as follows:<disp-formula id="hbm70364-disp-0001"><label>(1)</label><mml:math id="jats-math-10" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfenced close="]" open="[" separators=",,"><mml:mrow><mml:mi>&#960;</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mi>s</mml:mi><mml:mn>1</mml:mn><mml:mi>t</mml:mi></mml:msubsup></mml:mfenced></mml:mrow><mml:mo>&#8943;</mml:mo><mml:mrow><mml:mi>&#960;</mml:mi><mml:mfenced close=")" open="("><mml:msubsup><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:msubsup></mml:mfenced></mml:mrow></mml:mfenced><mml:mo linebreak="goodbreak">+</mml:mo><mml:msub><mml:mi mathvariant="italic">pe</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
</p><sec id="hbm70364-sec-0007"><label>3.1</label><title>Space&#8211;Time Configuration</title><p>In our first scenario, the encoder architecture is designed to process all extracted patches from all spatial locations across all time points simultaneously. By feeding the entire sequence of spatiotemporal tokens into the encoder, the model can effectively learn complex spatial structures while capturing temporal dependencies. To achieve this, we employ an encoder equipped with a spatiotemporal self&#8208;attention module, which enables the model to weigh the importance of different tokens dynamically. This mechanism allows the encoder to jointly encode both spatial and temporal information, facilitating the extraction of meaningful dynamic patterns across brain volumes over time.</p><p>The encoder consists of a stack of <mml:math id="jats-math-11" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow></mml:math> transformer layers, each incorporating key components such as multi&#8208;head self&#8208;attention (MHSA), layer normalization (LN), and a multi&#8208;layer perceptron (MLP) with two fully connected layers. Additionally, the MLP includes dropout for regularization and employs randomized leaky rectified linear unit (RReLU) activation to enhance model expressivity. This structure ensures that the encoder effectively models complex interactions within the data, capturing both local and global spatiotemporal dependencies.<disp-formula id="hbm70364-disp-0002"><label>(2)</label><mml:math id="jats-math-12" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="normal">&#8467;</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo linebreak="goodbreak">=</mml:mo><mml:mtext mathvariant="italic">MHSA</mml:mtext><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="italic">LN</mml:mi><mml:mfenced close=")" open="("><mml:msup><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mi mathvariant="normal">&#8467;</mml:mi></mml:msup></mml:mfenced></mml:mrow></mml:mfenced><mml:mo linebreak="goodbreak">+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mi mathvariant="normal">&#8467;</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="hbm70364-disp-0003"><label>(3)</label><mml:math id="jats-math-13" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="normal">&#8467;</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo linebreak="goodbreak">=</mml:mo><mml:mi mathvariant="italic">MLP</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="italic">LN</mml:mi><mml:mfenced close=")" open="("><mml:msup><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="normal">&#8467;</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mfenced></mml:mrow></mml:mfenced><mml:mo linebreak="goodbreak">+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="normal">&#8467;</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula>
</p><p>The attention mechanism enables the model to selectively focus on relevant features within the input data by weighting the importance of different tokens (spatiotemporal features). This capability allows the model to capture dynamic patterns more effectively, which is particularly crucial for modeling complex temporal dependencies. Moreover, the attention mechanism is defined as follows, where the queries <mml:math id="jats-math-14" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:mrow></mml:math>, keys <mml:math id="jats-math-15" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:mrow></mml:math>, and values <mml:math id="jats-math-16" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mrow></mml:math> are linear projections of the input, with <mml:math id="jats-math-17" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi mathvariant="normal">&#8477;</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math>, and <mml:math id="jats-math-18" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:mrow></mml:math> representing the embedding dimension. All spatiotemporal tokens extracted from input data are then passed through the transformer encoder to capture dynamic patterns:<disp-formula id="hbm70364-disp-0004"><label>(4)</label><mml:math id="jats-math-19" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mtext mathvariant="italic">Attention</mml:mtext><mml:mfenced close=")" open="("><mml:mrow><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:mfenced><mml:mo linebreak="goodbreak">=</mml:mo><mml:mtext mathvariant="italic">Softmax</mml:mtext><mml:mfenced close=")" open="("><mml:mfrac><mml:mrow><mml:mi>Q</mml:mi><mml:mo>.</mml:mo><mml:msup><mml:mi>K</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:msqrt><mml:msub><mml:mi>e</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt></mml:mfrac></mml:mfenced><mml:mi>V</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula>
</p></sec><sec id="hbm70364-sec-0008"><label>3.2</label><title>Sequential Encoders Configuration</title><p>In our second configuration, we design an encoder architecture that separately models spatial and temporal dependencies using two distinct transformer&#8208;based modules: a temporal attention encoder and a spatial attention encoder. Unlike the first configuration, which employs a unified spatiotemporal self&#8208;attention mechanism, this approach explicitly factorizes spatial and temporal feature extraction to enhance structured representation learning.</p><p>First, we process the fMRI data by extracting spatial patches at each time point, resulting in a sequence of spatial tokens. The input token tensor, initially shaped as <mml:math id="jats-math-20" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi mathvariant="normal">&#8477;</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>p</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math>, is permuted to <mml:math id="jats-math-21" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi mathvariant="normal">&#8477;</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>t</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math> so that temporal relationships can be effectively captured. This reshaped tensor is then fed into the temporal encoder, which applies multi&#8208;headed self&#8208;attention (MHSA) across the time dimension while preserving spatial structure. By doing so, the temporal encoder learns dependencies across different time points, allowing the model to capture dynamic patterns in brain activity.</p><p>Next, the output from the temporal encoder is reshaped back to its original form, <mml:math id="jats-math-22" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi mathvariant="normal">&#8477;</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>p</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math>, and passed into the spatial encoder. This module applies self&#8208;attention over spatial tokens at each time step, refining spatial feature representations while incorporating the temporal context previously learned. The embedding dimensionality remains consistent between the temporal and spatial encoders to ensure seamless information propagation and avoid representational discrepancies. By leveraging separate attention modules for spatial and temporal encoding, this two&#8208;stage strategy allows the model to effectively capture dynamic spatiotemporal dependencies while maintaining computational efficiency.</p></sec><sec id="hbm70364-sec-0009"><label>3.3</label><title>Decoder Head</title><p>Unlike the encoder, which is built on the ViT architecture, the decoder head is designed with a series of components. It consists of a layer normalization, followed by a fully connected layer, a fixed sine&#8208;cosine positional encoding to represent the time&#8208;point indices, and a sequence of 3D depth&#8208;wise transposed convolution operator (ConvTranspose) layers with various kernel sizes of 7, 5, and 9, respectively. The final ConvTranspose layer has a dilation rate of 2. The decoder also includes a point&#8208;wise Conv3D layer, with RReLU serving as the activation function. The output of the decoder corresponds to the predicted spatiotemporal brain maps.</p></sec><sec id="hbm70364-sec-0010"><label>3.4</label><title>Customized Loss Function</title><p>Selecting an appropriate loss function that simultaneously preserves the global structure of the data while capturing dynamic patterns is a challenging task. To address this, we utilize a combination of photometric and perceptual losses to guide the network's training, as formulated below:<disp-formula id="hbm70364-disp-0005"><label>(5)</label><mml:math id="jats-math-23" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">&#8466;</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo>&#8764;</mml:mo><mml:mi>U</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.2em"/><mml:mfenced close="]" open="["><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">log</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="italic">cosh</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>y</mml:mi><mml:mo linebreak="goodbreak">&#8722;</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi mathvariant="italic">max</mml:mi><mml:mspace width="0.1em"/><mml:mfenced close=")" open="(" separators=","><mml:mi mathvariant="normal">&#1013;</mml:mi><mml:mrow><mml:mtext mathvariant="italic">SSIM</mml:mtext><mml:mfenced close=")" open="("><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="hbm70364-disp-0006"><label>(6)</label><mml:math id="jats-math-24" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mtext>SSIM</mml:mtext><mml:mfenced close=")" open="("><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:mfenced><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>&#956;</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:msub><mml:mi>&#956;</mml:mi><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:msub><mml:mo linebreak="goodbreak">+</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfenced><mml:mfenced close=")" open="("><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>&#963;</mml:mi><mml:mrow><mml:mi>y</mml:mi><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:msub><mml:mo linebreak="goodbreak">+</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mi>&#956;</mml:mi><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo linebreak="goodbreak">+</mml:mo><mml:msubsup><mml:mi>&#956;</mml:mi><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msubsup><mml:mo linebreak="goodbreak">+</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfenced><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mi>&#963;</mml:mi><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo linebreak="goodbreak">+</mml:mo><mml:msubsup><mml:mi>&#963;</mml:mi><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msubsup><mml:mo linebreak="goodbreak">+</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>
</p><p>Here, <mml:math id="jats-math-25" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:mrow></mml:math> represents the prior (weak supervision), and <mml:math id="jats-math-26" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math> corresponds to the model's prediction, while SSIM denotes the structural similarity index. <mml:math id="jats-math-27" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo>&#8764;</mml:mo><mml:mi>U</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math> represents the expectation over all samples in the trainset (true <mml:math id="jats-math-28" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:mrow></mml:math> and output <mml:math id="jats-math-29" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math>), which, given that they are assumed to be uniformly drawn, is practically computed as an average over a batch in our training phase. The parameter <mml:math id="jats-math-30" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">&#1013;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math> is used to prevent division by zero or negative values in the denominator and <mml:math id="jats-math-31" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math> are small constants to stabilize the division. The <mml:math id="jats-math-32" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="italic">log</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="italic">cosh</mml:mi><mml:mfenced close=")" open="("><mml:mo>.</mml:mo></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math> function serves as a robust regression loss, similar to mean squared error (MSE), but less prone to being influenced by outliers. Similar to the Huber loss, the <mml:math id="jats-math-33" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>log</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>cosh</mml:mi><mml:mfenced close=")" open="("><mml:mo>&#8901;</mml:mo></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math> function tries to strike a balance between L1 loss for extreme values and L2 loss for the rest, providing robustness to large residuals. However, unlike the Huber loss&#8212;which is only piecewise differentiable and has a non&#8208;smooth point at the transition threshold&#8212;<mml:math id="jats-math-34" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>log</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>cosh</mml:mi><mml:mfenced close=")" open="("><mml:mo>&#8901;</mml:mo></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math> is continuously differentiable everywhere. This smoothness enables more stable and consistent gradient updates, which can improve optimization dynamics and convergence speed and reliability. Additionally, we observe empirically that incorporating SSIM loss creates more opportunities for improving prediction quality.</p></sec><sec id="hbm70364-sec-0011"><label>3.5</label><title>Weak Supervision</title><p>One of the main challenges in our research is the lack of ground&#8208;truth labels, which we addressed by utilizing a windowed version of spatially constrained ICA (Iraji et&#160;al.&#160;<xref rid="hbm70364-bib-0038" ref-type="bibr">2024</xref>), a powerful semi&#8208;blind source separation technique (Lin et&#160;al.&#160;<xref rid="hbm70364-bib-0059" ref-type="bibr">2010</xref>). This method enables us to extract independent components (ICs), each representing a distinct brain network, which we used as weak supervision to guide the training of our model. Specifically, we applied spatially constrained ICA in a sliding&#8208;window fashion to extract temporally localized independent components (ICs) that serve as coarse spatiotemporal priors. This provides a robust and computationally tractable initializer, using a linear unmixing approach. We incorporated the ICs as soft prior during training, encouraging the model to align with their general spatial topology without enforcing strict voxel&#8208;level correspondence. Unlike ICA, which is restricted to linear unmixing, our deep learning model learns a nonlinear spatiotemporal mapping capable of capturing complex and temporally coherent brain activity. As a result, the model produces smooth, denoised, and interpretable&#160;4D brain activity maps that generalize beyond the noisy supervision provided by ICA.</p><p>Our method leverages constrained ICA by using the NeuroMark&#8208;fMRI&#8208;1.0 template (Du et&#160;al.&#160;<xref rid="hbm70364-bib-0023" ref-type="bibr">2020</xref>), which consists of reproducible independent components derived from the Genomic Superstructure Project (GSP) and Human Connectome Project (HCP) datasets. These group&#8208;level constrained windowed ICs were computed by spatially aligning the correlated components from more than 800 healthy control fMRI datasets. The NeuroMark template provides a reference for calculating subject&#8208;specific ICs using a multi&#8208;objective optimization strategy as follows:<disp-formula id="hbm70364-disp-0007"><label>(7)</label><mml:math id="jats-math-35" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mi mathvariant="italic">AS</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="hbm70364-disp-0008"><label>(8)</label><mml:math id="jats-math-36" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mtable columnalign="left" displaystyle="true"><mml:mtr><mml:mtd><mml:mi mathvariant="italic">max</mml:mi><mml:mspace width="1em"/><mml:mi>J</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo>&#8733;</mml:mo><mml:msup><mml:mfenced close="}" open="{"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mfenced close="]" open="["><mml:mrow><mml:mi>G</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced><mml:mo linebreak="goodbreak">&#8722;</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mfenced close="]" open="["><mml:mrow><mml:mi>G</mml:mi><mml:mfenced close=")" open="("><mml:mi>v</mml:mi></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>s</mml:mi><mml:mo>.</mml:mo><mml:mi>t</mml:mi><mml:mo>.</mml:mo><mml:mspace width="1em"/><mml:mi>&#966;</mml:mi><mml:mfenced close=")" open="(" separators=","><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mi>x</mml:mi></mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo linebreak="goodbreak">&#8722;</mml:mo><mml:mi mathvariant="normal">&#1013;</mml:mi><mml:mo>&#8804;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mfenced close="]" open="["><mml:msubsup><mml:mi>C</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfenced><mml:mo linebreak="goodbreak">&#8722;</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="goodbreak">=</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math></disp-formula>
</p><p>In this context, <mml:math id="jats-math-37" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi mathvariant="normal">&#8477;</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math> denotes the input fMRI data matrix with <mml:math id="jats-math-38" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:math> time points and voxel size of <mml:math id="jats-math-39" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:math>, modeled as <mml:math id="jats-math-40" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="italic">AS</mml:mi></mml:mrow></mml:mrow></mml:math>, where <mml:math id="jats-math-41" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi mathvariant="normal">&#8477;</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math> is the mixing matrix containing the temporal profiles of the components as columns, and <mml:math id="jats-math-42" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi mathvariant="normal">&#8477;</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math> contains the spatially independent sources as rows. To estimate the sources, we compute an unmixing matrix <mml:math id="jats-math-43" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>W</mml:mi><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi mathvariant="normal">&#8477;</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>&#215;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math> such that <mml:math id="jats-math-44" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="italic">WX</mml:mi></mml:mrow></mml:mrow></mml:math>. Each spatial component <mml:math id="jats-math-45" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi mathvariant="normal">&#8477;</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#215;</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math> is obtained as <mml:math id="jats-math-46" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mo>&#8868;</mml:mo></mml:msubsup><mml:mi>X</mml:mi></mml:mrow></mml:mrow></mml:math>, where <mml:math id="jats-math-47" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi mathvariant="normal">&#8477;</mml:mi><mml:mi>t</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math> is the <italic toggle="yes">i</italic>&#8208;th row of <mml:math id="jats-math-48" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>W</mml:mi></mml:mrow></mml:mrow></mml:math>, and corresponds to the inverse of the associated time course in <mml:math id="jats-math-49" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:mrow></mml:math>. The term <mml:math id="jats-math-50" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>J</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mrow></mml:math> estimates the negentropy of the <italic toggle="yes">i</italic>&#8208;th source <mml:math id="jats-math-51" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math>, with <mml:math id="jats-math-52" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math> as its corresponding unmixing vector. <mml:math id="jats-math-53" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mfenced close="]" open="["><mml:mo>.</mml:mo></mml:mfenced></mml:mrow></mml:mrow></mml:math> stands for the expectation, while <mml:math id="jats-math-54" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mfenced close=")" open="("><mml:mo>.</mml:mo></mml:mfenced></mml:mrow></mml:mrow></mml:math> is a non&#8208;quadratic function. The variable <mml:math id="jats-math-55" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:mrow></mml:math> is a Gaussian random variable with a mean of zero and unit variance. The function <mml:math id="jats-math-56" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#966;</mml:mi></mml:mrow></mml:mrow></mml:math> measures the similarity (Pearson correlation) between the estimated source <mml:math id="jats-math-57" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math> and its normalized reference <mml:math id="jats-math-58" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math>, with <mml:math id="jats-math-59" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">&#1013;</mml:mi></mml:mrow></mml:mrow></mml:math> acting as a threshold to control the separation accuracy between the independent component and the reference signal. We utilize spatially constrained ICA on fMRI data by implementing overlapping windows, with a window size of 30 and a stride of 1, to extract a sequence of independent components. The choice of a 30&#8208;point window reflects a heuristic balance between capturing dynamic temporal changes and maintaining stability in component estimation. This approach offers advantages in extracting brain networks compared to other methods, though it remains a linear technique. Additionally, spatially constrained windowed ICA method is sensitive to noise, and in cases of low signal&#8208;to&#8208;noise ratio, the accuracy of component separation may be affected. In the windowed ICA configuration, it is also assumed that the statistical properties of the sources remain constant, an assumption that may not always hold. Despite these limitations, spatially constrained windowed ICA can serve as a suitable weak prior for a deep learning model, as we propose in this work. Alternative approaches also exhibit various limitations. For example, anatomic atlas&#8208;based methods rely on fixed, predefined templates that overlook individual variability in brain organization. Clustering&#8208;based techniques typically require pre&#8208;specifying the number of clusters, are sensitive to initialization, and may lead to spatially fragmented regions. Graph&#8208;based methods are highly dependent on graph construction strategies and often lack spatial contiguity. While IVA&#8208;based approaches are effective in modeling inter&#8208;subject variability, they are computationally expensive and are typically estimated from group data rather than from a single subject.</p></sec></sec><sec id="hbm70364-sec-0012"><label>4</label><title>Experiment</title><p>We implemented a straightforward experimental setup for our research. Our study utilized a subset of 508 fMRI datasets, which included data from the MPRC (Adhikari et&#160;al.&#160;<xref rid="hbm70364-bib-0003" ref-type="bibr">2019</xref>), FBIRN (Potkin and Ford&#160;<xref rid="hbm70364-bib-0078" ref-type="bibr">2009</xref>), and COBRE (Mayer et&#160;al.&#160;<xref rid="hbm70364-bib-0069" ref-type="bibr">2013</xref>) datasets. The demographic information for this subset is outlined in Table&#160;<xref rid="hbm70364-tbl-0001" ref-type="table">1</xref>. To reduce computational demands, we uniformly sampled time points from the fMRI data at 10&#8208;timepoint intervals, resulting in a total of 10 time points instead of using the full dataset. We also applied a Gaussian filter for image smoothing, with a standard deviation of <mml:math id="jats-math-60" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#963;</mml:mi><mml:mo>=</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:mrow></mml:math> set for Gaussian kernel, followed by z&#8208;scoring to ensure proper normalization of the data. The model configuration included an embedding dimension of 96, 6 attention heads, a depth of 1, an attention dropout rate of 0.4, and an encoder dropout rate of 0.3, with a patch size of 5. Training was conducted on two A40 GPUs, each equipped with 45&#8201;GB of memory, using a batch size of 2. We utilized the Adam optimizer with a learning rate of 0.01 and a weight decay of 0.1, running for a total of 150 epochs and implementing an early stopping strategy to prevent overfitting, with a threshold of <mml:math id="jats-math-61" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#948;</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math>.</p><table-wrap position="float" id="hbm70364-tbl-0001" content-type="TABLE" orientation="portrait"><label>TABLE 1</label><caption><p>Demographic information.</p></caption><table frame="hsides" rules="groups"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><thead valign="bottom"><tr style="border-bottom:solid 1px #000000"><th align="left" rowspan="2" valign="bottom" colspan="1">Diagnostic</th><th align="center" colspan="2" valign="bottom" rowspan="1">Sex</th><th align="center" valign="bottom" rowspan="1" colspan="1">Age</th><th align="center" colspan="3" valign="bottom" rowspan="1">Race</th></tr><tr style="border-bottom:solid 1px #000000"><th align="center" valign="bottom" rowspan="1" colspan="1">Male</th><th align="center" valign="bottom" rowspan="1" colspan="1">Female</th><th align="center" valign="bottom" rowspan="1" colspan="1">Mean &#177; SD</th><th align="center" valign="bottom" rowspan="1" colspan="1">American</th><th align="center" valign="bottom" rowspan="1" colspan="1">European</th><th align="center" valign="bottom" rowspan="1" colspan="1">Other</th></tr></thead><tbody valign="top"><tr><td align="left" valign="top" rowspan="1" colspan="1">Control</td><td align="center" valign="top" rowspan="1" colspan="1">185</td><td align="center" valign="top" rowspan="1" colspan="1">130</td><td align="center" valign="top" rowspan="1" colspan="1">38.40 &#177;&#8201;12.73</td><td align="center" valign="top" rowspan="1" colspan="1">192</td><td align="center" valign="top" rowspan="1" colspan="1">65</td><td align="center" valign="top" rowspan="1" colspan="1">58</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Schizophrenia</td><td align="center" valign="top" rowspan="1" colspan="1">154</td><td align="center" valign="top" rowspan="1" colspan="1">39</td><td align="center" valign="top" rowspan="1" colspan="1">38.61 &#177;&#8201;13.29</td><td align="center" valign="top" rowspan="1" colspan="1">112</td><td align="center" valign="top" rowspan="1" colspan="1">44</td><td align="center" valign="top" rowspan="1" colspan="1">37</td></tr></tbody></table></table-wrap><sec id="hbm70364-sec-0013"><label>4.1</label><title>Qualitative Metrics</title><p>We present qualitative comparisons between the dense visual representations learned by our model and the extracted sequence of ICA components (used for weak supervision) across different networks, employing both space&#8211;time and sequential encoder configurations, as shown in Figure&#160;<xref rid="hbm70364-fig-0002" ref-type="fig">2</xref>. The dynamic patterns of brain activities observed in the generated maps exhibit smooth transitions in both space and time, with noticeable fluctuations in activation weights (scores) across different time points. These transitions highlight the model's capability to capture temporal continuity, resulting in more plausible representations of brain activity. The generated maps show a strong alignment with known brain atlases, particularly in the spatial localization of functional regions, reinforcing the model's accuracy in learning meaningful spatial features. Moreover, we provide additional evidence of the model's ability to capture dynamic patterns over time by calculating the summation of absolute temporal gradients, approximated using the forward difference approach. This metric quantifies the temporal changes in brain activity, offering a complementary view of how the model captures both gradual and abrupt transitions across time points. The temporal gradients underscore the model's sensitivity to changes in activation dynamics, further validating its capacity to generate temporally consistent and biologically meaningful representations.</p><fig position="float" fig-type="FIGURE" id="hbm70364-fig-0002" orientation="portrait"><label>FIGURE 2</label><caption><p>Model&#8208;generated dynamic brain maps within the Default Mode, Salience, Motor, Visual, Subcortical, and Cerebellar networks, averaged over time for a randomly selected test subject. The figure includes the summation of absolute temporal gradient maps and prior maps, comparing outputs from both the Space&#8211;Time encoder and Sequential encoder configurations.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="anchor" id="jats-graphic-5" orientation="portrait" xlink:href="HBM-46-e70364-g005.jpg"/></fig><p>Additionally, the subject&#8208;specific maps in the cerebellar network at the 5th time point, as illustrated in Figure&#160;<xref rid="hbm70364-fig-0003" ref-type="fig">3</xref>, show examples of individual&#8208;level variations captured by the model. These observations indicate that the model can reflect differences across subjects, although they should be interpreted as illustrative rather than conclusive evidence of population&#8208;level heterogeneity. Furthermore, the model's robustness is evidenced by its ability to effectively denoise highly noisy prior (weak supervision), refining them into clearer, more interpretable dynamic brain maps. This denoising capability not only improves the signal&#8208;to&#8208;noise ratio but also enhances the interpretability of the spatiotemporal patterns, facilitating a deeper understanding of the underlying neural processes. Overall, the model translates raw, noisy data into coherent, higher&#8208;resolution representations that capture global patterns of brain activity over time, while also allowing for the depiction of possible individual&#8208;level differences within each brain network.</p><fig position="float" fig-type="FIGURE" id="hbm70364-fig-0003" orientation="portrait"><label>FIGURE 3</label><caption><p>Generated maps for five example subjects at the 5th time point illustrate inter&#8208;subject variations, with some observable differences in morphology, scale, spatial displacement, and activation intensity of active regions. The top row shows the space&#8211;time configuration, while the bottom row shows the sequential encoder configuration.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="anchor" id="jats-graphic-7" orientation="portrait" xlink:href="HBM-46-e70364-g006.jpg"/></fig><p>To assess the clinical relevance of the generated dynamic brain maps, we conducted a series of experiments to explore their potential for differentiating between healthy controls (HC) and individuals with schizophrenia (SCZ). The dynamic brain maps, generated by our model for all subjects, included both HC and SCZ groups. In the first experiment, we averaged the dynamic maps across time and applied a mask to extract brain voxels, <mml:math id="jats-math-62" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="italic">HC</mml:mi><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi mathvariant="normal">&#8477;</mml:mi><mml:mrow><mml:mn>315</mml:mn><mml:mo>&#215;</mml:mo><mml:mn>68</mml:mn><mml:mo>,</mml:mo><mml:mn>235</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math> and <mml:math id="jats-math-63" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi mathvariant="italic">SCZ</mml:mi><mml:mo>&#8712;</mml:mo><mml:msup><mml:mi mathvariant="normal">&#8477;</mml:mi><mml:mrow><mml:mn>193</mml:mn><mml:mo>&#215;</mml:mo><mml:mn>68</mml:mn><mml:mo>,</mml:mo><mml:mn>235</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math>. A voxel&#8208;wise t&#8208;test was then performed to identify regions with significant differences between the two groups, and the resulting <italic toggle="yes">p</italic>&#8208;values were corrected for multiple comparisons using false discovery rate (FDR) correction at a significance level of <mml:math id="jats-math-64" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&#8804;</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:mrow></mml:math>. This analysis enabled the detection of specific brain regions that exhibit altered dynamics in SCZ, potentially revealing biomarkers for the disorder. In the second experiment, we applied the same t&#8208;test to the TG maps, which capture voxel&#8208;wise differences between consecutive time&#8208;points, to assess group differences in dynamic brain activity. This approach allows us to study variations in dynamic brain patterns, as shown in Figure&#160;<xref rid="hbm70364-fig-0004" ref-type="fig">4</xref>, and their potential association with the pathophysiology of schizophrenia. These findings lay a foundation for further exploration of their relevance in clinical observations and future research on diagnostic and therapeutic strategies.</p><fig position="float" fig-type="FIGURE" id="hbm70364-fig-0004" orientation="portrait"><label>FIGURE 4</label><caption><p>Group&#8208;level differences across multiple regions are highlighted in both the averaged maps and the sum of temporal gradients, assessed using a two&#8208;sample t&#8208;test with FDR correction and masked at <mml:math id="jats-math-65" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&#8804;</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:mrow></mml:math> across the default mode, salience, motor, visual, subcortical, and cerebellar networks. The maps display <mml:math id="jats-math-66" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mi>log</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>p</mml:mi><mml:mo>_</mml:mo><mml:mtext mathvariant="italic">value</mml:mtext></mml:mrow></mml:mfenced><mml:mo>&#215;</mml:mo><mml:mi>sign</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>t</mml:mi><mml:mo>_</mml:mo><mml:mtext mathvariant="italic">value</mml:mtext></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math>, emphasizing the relevance of the generated dynamic maps to our understanding of schizophrenia. Widespread group differences are observed across several brain regions, with schizophrenia associated with both spatial and temporal changes. While healthy controls (HCs) generally exhibit greater hyperactivity and variations, schizophrenia demonstrates increased activity and variation in specific regions. Notably, these changes often exhibit structured patterns that do not strictly align with regions strongly contributing to the networks, suggesting the presence of transient states or functional connectivity across networks. The left two columns illustrate the space&#8211;time configuration, whereas the right two columns present the sequential encoder configuration, highlighting differences between the two scenarios.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="anchor" id="jats-graphic-9" orientation="portrait" xlink:href="HBM-46-e70364-g002.jpg"/></fig></sec><sec id="hbm70364-sec-0014"><label>4.2</label><title>Quantitative Metrics</title><p>We quantitatively assess the model's capacity to generate plausible dense representations using an indirect standard approach. This evaluation focuses on several key metrics, including active region localization accuracy, visual fidelity, consistency with expected patterns, and regional homogeneity, which is quantified by the correlation of voxel time&#8208;series within each region of interest (ROI). We perform these assessments on both the generated maps and the priors, averaging results over time, while applying a threshold of <mml:math id="jats-math-67" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8805;</mml:mo><mml:mn>80</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:mrow></mml:math> specifically to the mean intersection over union (mIOU) and homogeneity (Hgt) metrics, as detailed in Table&#160;<xref rid="hbm70364-tbl-0002" ref-type="table">2</xref>. Here, mIOU refers to the mean intersection over union, which quantifies spatial overlap between the predicted and reference activation regions; Hgt denotes the homogeneity of within&#8208;region temporal variations, capturing region&#8208;wise consistency in dynamic signal fluctuations; and mARE represents the mean absolute relative error, which measures the relative voxel&#8208;wise deviation between predicted and reference maps. SSIM signifies the structural similarity index, reflecting perceptual and structural alignment between spatial patterns.</p><table-wrap position="float" id="hbm70364-tbl-0002" content-type="TABLE" orientation="portrait"><label>TABLE 2</label><caption><p>Quantitative metrics on quality of generated dynamic maps.</p></caption><table frame="hsides" rules="groups"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><thead valign="bottom"><tr style="border-bottom:solid 1px #000000"><th align="left" valign="bottom" rowspan="1" colspan="1"/><th align="center" valign="bottom" rowspan="1" colspan="1">Networks</th><th align="center" valign="bottom" rowspan="1" colspan="1">mARE <mml:math id="jats-math-68" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8595;</mml:mo></mml:mrow></mml:mrow></mml:math>
</th><th align="center" valign="bottom" rowspan="1" colspan="1">mIOU <mml:math id="jats-math-69" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8593;</mml:mo></mml:mrow></mml:mrow></mml:math>
</th><th align="center" valign="bottom" rowspan="1" colspan="1">SSIM <mml:math id="jats-math-70" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8593;</mml:mo></mml:mrow></mml:mrow></mml:math>
</th><th align="center" valign="bottom" rowspan="1" colspan="1">Hgt <mml:math id="jats-math-71" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8593;</mml:mo></mml:mrow></mml:mrow></mml:math>
</th></tr></thead><tbody valign="top"><tr><td align="left" rowspan="6" valign="top" colspan="1">Space&#8211;Time</td><td align="center" valign="top" rowspan="1" colspan="1">Default Mode</td><td align="center" valign="top" rowspan="1" colspan="1">0.12</td><td align="center" valign="top" rowspan="1" colspan="1">0.77</td><td align="center" valign="top" rowspan="1" colspan="1">
<bold>0.87</bold>
</td><td align="center" valign="top" rowspan="1" colspan="1">0.77</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Salience</td><td align="center" valign="top" rowspan="1" colspan="1">0.17</td><td align="center" valign="top" rowspan="1" colspan="1">0.71</td><td align="center" valign="top" rowspan="1" colspan="1">0.79</td><td align="center" valign="top" rowspan="1" colspan="1">0.79</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Motor</td><td align="center" valign="top" rowspan="1" colspan="1">0.14</td><td align="center" valign="top" rowspan="1" colspan="1">0.73</td><td align="center" valign="top" rowspan="1" colspan="1">0.86</td><td align="center" valign="top" rowspan="1" colspan="1">0.77</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Visual</td><td align="center" valign="top" rowspan="1" colspan="1">0.15</td><td align="center" valign="top" rowspan="1" colspan="1">0.77</td><td align="center" valign="top" rowspan="1" colspan="1">0.84</td><td align="center" valign="top" rowspan="1" colspan="1">0.81</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Subcortical</td><td align="center" valign="top" rowspan="1" colspan="1">0.15</td><td align="center" valign="top" rowspan="1" colspan="1">0.77</td><td align="center" valign="top" rowspan="1" colspan="1">0.81</td><td align="center" valign="top" rowspan="1" colspan="1">0.72</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Cerebellar</td><td align="center" valign="top" rowspan="1" colspan="1">
<bold>0.1</bold>
</td><td align="center" valign="top" rowspan="1" colspan="1">
<bold>0.81</bold>
</td><td align="center" valign="top" rowspan="1" colspan="1">0.86</td><td align="center" valign="top" rowspan="1" colspan="1">
<bold>0.84</bold>
</td></tr><tr><td align="left" rowspan="6" valign="top" colspan="1">Sequential Enc</td><td align="center" valign="top" rowspan="1" colspan="1">Default Mode</td><td align="center" valign="top" rowspan="1" colspan="1">0.15</td><td align="center" valign="top" rowspan="1" colspan="1">0.73</td><td align="center" valign="top" rowspan="1" colspan="1">
<bold>0.85</bold>
</td><td align="center" valign="top" rowspan="1" colspan="1">0.7</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Salience</td><td align="center" valign="top" rowspan="1" colspan="1">0.21</td><td align="center" valign="top" rowspan="1" colspan="1">0.69</td><td align="center" valign="top" rowspan="1" colspan="1">0.73</td><td align="center" valign="top" rowspan="1" colspan="1">0.63</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Motor</td><td align="center" valign="top" rowspan="1" colspan="1">0.17</td><td align="center" valign="top" rowspan="1" colspan="1">0.72</td><td align="center" valign="top" rowspan="1" colspan="1">0.8</td><td align="center" valign="top" rowspan="1" colspan="1">0.74</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Visual</td><td align="center" valign="top" rowspan="1" colspan="1">0.16</td><td align="center" valign="top" rowspan="1" colspan="1">0.77</td><td align="center" valign="top" rowspan="1" colspan="1">0.8</td><td align="center" valign="top" rowspan="1" colspan="1">0.72</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Subcortical</td><td align="center" valign="top" rowspan="1" colspan="1">0.17</td><td align="center" valign="top" rowspan="1" colspan="1">0.74</td><td align="center" valign="top" rowspan="1" colspan="1">0.75</td><td align="center" valign="top" rowspan="1" colspan="1">0.66</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Cerebellar</td><td align="center" valign="top" rowspan="1" colspan="1">
<bold>0.13</bold>
</td><td align="center" valign="top" rowspan="1" colspan="1">
<bold>0.79</bold>
</td><td align="center" valign="top" rowspan="1" colspan="1">0.82</td><td align="center" valign="top" rowspan="1" colspan="1">
<bold>0.79</bold>
</td></tr></tbody></table><table-wrap-foot id="pa2949-ntgp-0002"><fn id="pa2949-note-0002"><p>
<italic toggle="yes">Note:</italic> Bold values indicate the best result for each metric.</p></fn></table-wrap-foot></table-wrap><p>The quantitative results reveal several interesting patterns across networks and encoding schemes. The Cerebellar network stands out with the best overall performance, achieving the lowest mARE and highest Hgt in both Space&#8211;Time (mARE: 0.10, Hgt: 0.84) and Sequential Enc (mARE: 0.13, Hgt: 0.79), along with competitive mIOU and SSIM scores. In contrast, the Salience network consistently underperforms, with the highest mARE and lowest mIOU, SSIM, and Hgt in both encoding schemes, suggesting challenges in capturing its diffuse and variable activity patterns. The Default Mode network excels in structural similarity, achieving the highest SSIM (0.87 in Space&#8211;Time and 0.85 in Sequential Enc), indicating robust reconstruction of its coherent activity patterns. The Visual network demonstrates stable performance, with relatively high mIOU and Hgt scores across both schemes, reflecting the predictable nature of visual dynamics. Notably, Space&#8211;Time encoding generally results in lower mARE values, highlighting better reconstruction accuracy, while Sequential Enc slightly outperforms in mIOU for the Cerebellar and Subcortical networks, suggesting improved spatial overlap capture in specific cases. These findings are consistent with the expected dynamic characteristics of these brain networks.</p><p>Furthermore, we evaluate the model's capacity to represent temporal changes by calculating the Shannon entropy of the temporal gradient maps, capturing changes in information content as an additional indication of the model's dynamic behavior. This metric provides a way to quantify evolving patterns across time and serves as an indicator of the variability captured in the model outputs, as illustrated in the upper row of Figure&#160;<xref rid="hbm70364-fig-0005" ref-type="fig">5</xref>.</p><fig position="float" fig-type="FIGURE" id="hbm70364-fig-0005" orientation="portrait"><label>FIGURE 5</label><caption><p>Shannon entropy trends (computed for a single random test subject) and blob density histograms (calculated across the entire test set) for six brain networks: Default mode, salience, motor, visual, subcortical, and cerebellar. These are presented for two encoding schemes: A space&#8211;time configuration (rows 1 and 3) and a sequential encoder configuration (rows 2 and 4). The space&#8211;time configuration shows a somewhat wider range of entropy fluctuations across networks, indicating slightly more sensitivity to temporal changes, while the sequential encoder configuration exhibits more stable temporal gradients in Shannon entropy, reflecting consistent representations of spatiotemporal dynamics (e.g., DMN entropy ranges from [10.5, 10.7] for space&#8211;time and [10.25, 10.50] for sequential encoder). The blob density histograms reveal distinct behaviors across networks in both configurations. For instance, in the sequential encoder scenario, the cerebellar network shows a tighter and more compact distribution, which is also shifted to lower values compared to other networks, suggesting higher spatial consistency across the test set&#8212;most subjects exhibit a similar, smaller number of blobs throughout the entire time interval. In contrast, the space&#8211;time configuration displays a wider distribution for the cerebellar network, indicating higher variability while also being shifted toward lower values. Additionally, the motor network in the sequential encoder scenario demonstrates a noticeable shift toward lower values, highlighting reduced activity or variation in blob density for this configuration.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="anchor" id="jats-graphic-11" orientation="portrait" xlink:href="HBM-46-e70364-g001.jpg"/></fig><p>Additionally, we utilize the connected components algorithm as an effective method to measure the dynamicity of the generated 4D maps. By applying this algorithm to the thresholded maps at each time point with <mml:math id="jats-math-72" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#948;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.65</mml:mn></mml:mrow></mml:mrow></mml:math>, the algorithm identifies spatially contiguous clusters of active voxels&#8212;referred to as &#8220;blobs&#8221;&#8212;which represent regions undergoing dynamic transitions. By counting the number of connected components (blobs) across time and across different networks for the entire test set, we assess the spatial dispersion and temporal evolution of dynamic activity. This approach is illustrated in lower part of Figure&#160;<xref rid="hbm70364-fig-0005" ref-type="fig">5</xref>. The number of blobs changes over time, reflecting occasional merges and shrinkage of active regions, and serves as a descriptive characterization of the dynamic nature of the model outputs.</p></sec><sec id="hbm70364-sec-0015"><label>4.3</label><title>Ablation Study</title><p>To evaluate the influence of key design decisions in our model in both space&#8211;time and sequential encoder configurations, we performed comprehensive ablation studies focused on two critical aspects: the number of tokens and the temporal resolution. These were systematically varied by modifying patch sizes and the number of time points included in the input data. By experimenting with different patch configurations and temporal granularity, we sought to understand how these factors impact the quality of the results. Specifically, we trained separate model instances for each configuration and assessed their performance on the test set using structural similarity index (SSIM) and mean relative absolute error (mRAE) as evaluation metrics. The findings from these experiments, detailed in Tables&#160;<xref rid="hbm70364-tbl-0003" ref-type="table">3</xref> and <xref rid="hbm70364-tbl-0004" ref-type="table">4</xref>, provide valuable insights into the trade&#8208;offs associated with tokenization strategies and temporal encoding choices, guiding the optimization of our model's architecture for enhanced accuracy and robustness.</p><table-wrap position="float" id="hbm70364-tbl-0003" content-type="TABLE" orientation="portrait"><label>TABLE 3</label><caption><p>Ablation study on visual quality of generated maps using SSIM.</p></caption><table frame="hsides" rules="groups"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><thead valign="bottom"><tr style="border-bottom:solid 1px #000000"><th align="left" valign="bottom" rowspan="1" colspan="1"/><th align="center" valign="bottom" rowspan="1" colspan="1">Networks</th><th align="center" valign="bottom" rowspan="1" colspan="1">PS&#8201;=&#8201;9</th><th align="center" valign="bottom" rowspan="1" colspan="1">PS&#8201;=&#8201;7</th><th align="center" valign="bottom" rowspan="1" colspan="1">PS&#8201;=&#8201;5</th></tr></thead><tbody valign="top"><tr><td align="left" rowspan="6" valign="top" colspan="1">Space&#8211;Time</td><td align="center" valign="top" rowspan="1" colspan="1">Default Mode</td><td align="center" valign="top" rowspan="1" colspan="1">0.37</td><td align="center" valign="top" rowspan="1" colspan="1">0.51</td><td align="center" valign="top" rowspan="1" colspan="1">0.87</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Salience</td><td align="center" valign="top" rowspan="1" colspan="1">0.28</td><td align="center" valign="top" rowspan="1" colspan="1">0.49</td><td align="center" valign="top" rowspan="1" colspan="1">0.79</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Motor</td><td align="center" valign="top" rowspan="1" colspan="1">0.32</td><td align="center" valign="top" rowspan="1" colspan="1">0.62</td><td align="center" valign="top" rowspan="1" colspan="1">0.86</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Visual</td><td align="center" valign="top" rowspan="1" colspan="1">0.27</td><td align="center" valign="top" rowspan="1" colspan="1">0.59</td><td align="center" valign="top" rowspan="1" colspan="1">0.84</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Subcortical</td><td align="center" valign="top" rowspan="1" colspan="1">0.23</td><td align="center" valign="top" rowspan="1" colspan="1">0.63</td><td align="center" valign="top" rowspan="1" colspan="1">0.81</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Cerebellar</td><td align="center" valign="top" rowspan="1" colspan="1">0.3</td><td align="center" valign="top" rowspan="1" colspan="1">0.66</td><td align="center" valign="top" rowspan="1" colspan="1">0.86</td></tr><tr><td align="left" rowspan="6" valign="top" colspan="1">Sequential Enc</td><td align="center" valign="top" rowspan="1" colspan="1">Default Mode</td><td align="center" valign="top" rowspan="1" colspan="1">0.32</td><td align="center" valign="top" rowspan="1" colspan="1">0.44</td><td align="center" valign="top" rowspan="1" colspan="1">0.85</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Salience</td><td align="center" valign="top" rowspan="1" colspan="1">0.3</td><td align="center" valign="top" rowspan="1" colspan="1">0.45</td><td align="center" valign="top" rowspan="1" colspan="1">0.73</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Motor</td><td align="center" valign="top" rowspan="1" colspan="1">0.29</td><td align="center" valign="top" rowspan="1" colspan="1">0.6</td><td align="center" valign="top" rowspan="1" colspan="1">0.8</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Visual</td><td align="center" valign="top" rowspan="1" colspan="1">0.22</td><td align="center" valign="top" rowspan="1" colspan="1">0.57</td><td align="center" valign="top" rowspan="1" colspan="1">0.8</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Subcortical</td><td align="center" valign="top" rowspan="1" colspan="1">0.17</td><td align="center" valign="top" rowspan="1" colspan="1">0.6</td><td align="center" valign="top" rowspan="1" colspan="1">0.75</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Cerebellar</td><td align="center" valign="top" rowspan="1" colspan="1">0.13</td><td align="center" valign="top" rowspan="1" colspan="1">0.64</td><td align="center" valign="top" rowspan="1" colspan="1">0.82</td></tr></tbody></table></table-wrap><table-wrap position="float" id="hbm70364-tbl-0004" content-type="TABLE" orientation="portrait"><label>TABLE 4</label><caption><p>Ablation study on dynamicity of generated maps using mRAE for different number of time points (TP).</p></caption><table frame="hsides" rules="groups"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><thead valign="bottom"><tr style="border-bottom:solid 1px #000000"><th align="left" valign="bottom" rowspan="1" colspan="1"/><th align="center" valign="bottom" rowspan="1" colspan="1">Networks</th><th align="center" valign="bottom" rowspan="1" colspan="1">TP&#8201;=&#8201;10</th><th align="center" valign="bottom" rowspan="1" colspan="1">TP&#8201;=&#8201;7</th><th align="center" valign="bottom" rowspan="1" colspan="1">TP&#8201;=&#8201;3</th></tr></thead><tbody valign="top"><tr><td align="left" rowspan="6" valign="top" colspan="1">Space&#8211;Time</td><td align="center" valign="top" rowspan="1" colspan="1">Default Mode</td><td align="center" valign="top" rowspan="1" colspan="1">0.12</td><td align="center" valign="top" rowspan="1" colspan="1">0.1</td><td align="center" valign="top" rowspan="1" colspan="1">0.08</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Salience</td><td align="center" valign="top" rowspan="1" colspan="1">0.17</td><td align="center" valign="top" rowspan="1" colspan="1">0.14</td><td align="center" valign="top" rowspan="1" colspan="1">0.1</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Motor</td><td align="center" valign="top" rowspan="1" colspan="1">0.14</td><td align="center" valign="top" rowspan="1" colspan="1">0.11</td><td align="center" valign="top" rowspan="1" colspan="1">0.09</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Visual</td><td align="center" valign="top" rowspan="1" colspan="1">0.15</td><td align="center" valign="top" rowspan="1" colspan="1">0.13</td><td align="center" valign="top" rowspan="1" colspan="1">0.1</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Subcortical</td><td align="center" valign="top" rowspan="1" colspan="1">0.15</td><td align="center" valign="top" rowspan="1" colspan="1">0.12</td><td align="center" valign="top" rowspan="1" colspan="1">0.1</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Cerebellar</td><td align="center" valign="top" rowspan="1" colspan="1">0.1</td><td align="center" valign="top" rowspan="1" colspan="1">0.08</td><td align="center" valign="top" rowspan="1" colspan="1">0.05</td></tr><tr><td align="left" rowspan="6" valign="top" colspan="1">Sequential Enc</td><td align="center" valign="top" rowspan="1" colspan="1">Default Mode</td><td align="center" valign="top" rowspan="1" colspan="1">0.15</td><td align="center" valign="top" rowspan="1" colspan="1">0.12</td><td align="center" valign="top" rowspan="1" colspan="1">0.1</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Salience</td><td align="center" valign="top" rowspan="1" colspan="1">0.21</td><td align="center" valign="top" rowspan="1" colspan="1">0.17</td><td align="center" valign="top" rowspan="1" colspan="1">0.14</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Motor</td><td align="center" valign="top" rowspan="1" colspan="1">0.17</td><td align="center" valign="top" rowspan="1" colspan="1">0.16</td><td align="center" valign="top" rowspan="1" colspan="1">0.11</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Visual</td><td align="center" valign="top" rowspan="1" colspan="1">0.16</td><td align="center" valign="top" rowspan="1" colspan="1">0.13</td><td align="center" valign="top" rowspan="1" colspan="1">0.11</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Subcortical</td><td align="center" valign="top" rowspan="1" colspan="1">0.17</td><td align="center" valign="top" rowspan="1" colspan="1">0.15</td><td align="center" valign="top" rowspan="1" colspan="1">0.13</td></tr><tr><td align="center" valign="top" rowspan="1" colspan="1">Cerebellar</td><td align="center" valign="top" rowspan="1" colspan="1">0.13</td><td align="center" valign="top" rowspan="1" colspan="1">0.1</td><td align="center" valign="top" rowspan="1" colspan="1">0.07</td></tr></tbody></table></table-wrap><p>Our study reveals several important insights regarding the impact of architectural choices on model performance. Specifically, we observe that increasing the patch sizes within the ViT backbone leads to a modest degradation in the visual fidelity of the generated dense representations. Larger patch sizes reduce the spatial resolution of the input data, thereby limiting the model's ability to capture fine&#8208;grained spatial details. This trade&#8208;off results in a less accurate representation of subtle, local features, which are crucial for high&#8208;quality dynamic brain mapping.</p><p>Additionally, we found that using fewer time&#8208;points in the temporal encoding significantly affects the spatiotemporal dynamics of the generated maps. When fewer time&#8208;points are included, the resulting maps exhibit more stationary behavior over time. This is because the reduced temporal granularity leads to less variation between consecutive time&#8208;points, as evidenced by a minimal mRAE between consecutive time&#8208;points, averaged across subjects. Consequently, this lack of variation results in a loss of dynamic information, diminishing the model's ability to capture the intricate temporal fluctuations that are essential for modeling brain activity patterns over time. These findings underscore the importance of both spatial and temporal resolution in accurately capturing the dynamic behavior of brain networks and highlight the need for careful selection of patch sizes and time&#8208;points in spatiotemporal modeling tasks.</p></sec></sec><sec sec-type="discussion" id="hbm70364-sec-0016"><label>5</label><title>Discussion</title><p>Our study presents a new approach to capturing brain dynamics that reveal spatiotemporal variations in shape, size, and regional location of active regions. The averaged maps align with the results from established ICA&#8208;based models and existing brain atlases (Calhoun and Adali&#160;<xref rid="hbm70364-bib-0014" ref-type="bibr">2012</xref>; Ding et&#160;al.&#160;<xref rid="hbm70364-bib-0021" ref-type="bibr">2016</xref>). Furthermore, our model helps to interpret the outcomes by generating denoised maps. Our quantitative metrics, including a low mean mARE and high values for mIOU, SSIM, and homogeneity (shown in Table&#160;<xref rid="hbm70364-tbl-0002" ref-type="table">2</xref>), provide strong evidence of the model's ability to produce plausible maps that preserve essential spatial patterns. In the absence of ground&#8208;truth data, we evaluated the method from multiple perspectives, recognizing that different configurations, such as the space&#8211;time and sequential encoders, may capture distinct aspects of the underlying dynamics in the fMRI data. The sequential encoder emphasizes temporal patterns, revealing intriguing new properties of the temporal dynamics, as explored in the clinical application section. On the other hand, the space&#8211;time encoder demonstrates stronger quantitative performance, effectively capturing both spatial and temporal dynamics. Together, these configurations provide complementary insights, highlighting the multifaceted nature of brain activity and the value of leveraging multiple perspectives to study its complexity.</p><p>Furthermore, the summation of absolute temporal gradient maps (TGs) showcases the model's ability to capture dynamic brain activity, providing insights that extend beyond those available from averaged maps and aligning well with recent findings in computational neuroscience. For instance, elevated variation is detected in the posterior cingulate cortex (PCC) of the default mode network (DMN), a region invisible in averaged maps but known for its role in default mode processing (Fransson and Marrelec&#160;<xref rid="hbm70364-bib-0028" ref-type="bibr">2008</xref>). Similarly, the temporal gradient map for the sequential configuration highlights prominent activity in the thalamus&#8212;a region intricately connected with the medial prefrontal cortex (mPFC) and functionally conserved across mammalian species, including humans (Zhao et&#160;al.&#160;<xref rid="hbm70364-bib-0121" ref-type="bibr">2024</xref>; Klein et&#160;al.&#160;<xref rid="hbm70364-bib-0052" ref-type="bibr">2010</xref>).</p><p>Within the salience network, the temporal gradient map for the space&#8211;time configuration highlights significant activity in the PCC, a region implicated in the processing of salient events and facial recognition (Leech and Sharp&#160;<xref rid="hbm70364-bib-0054" ref-type="bibr">2014</xref>). In the motor network, the model captures the expected elevated activity in the midbrain (Ruchalski and Hathout&#160;<xref rid="hbm70364-bib-0084" ref-type="bibr">2012</xref>). Additionally, the sequential encoder configuration reveals prominent activity in the prefrontal cortex, a central area for motor planning, decision&#8208;making, and cognitive control (Grafton and Volz&#160;<xref rid="hbm70364-bib-0031" ref-type="bibr">2019</xref>). These observations reflect the interconnected nature of these networks as documented in existing research.</p><p>In examining the visual network, the model detects activity in the hippocampus, which aligns with literature suggesting the hippocampus's role in spatial processing and its functional coupling with visual cortical neurons during natural behavior (Turk&#8208;Browne&#160;<xref rid="hbm70364-bib-0099" ref-type="bibr">2019</xref>; Haggerty and Ji&#160;<xref rid="hbm70364-bib-0032" ref-type="bibr">2015</xref>). In contrast, the sequential encoder configuration highlights dynamic patterns in the thalamus, particularly within the lateral geniculate nucleus (LGN)&#8212;a crucial relay center for transmitting visual information from the retina to the primary visual cortex (Saalmann and Kastner&#160;<xref rid="hbm70364-bib-0085" ref-type="bibr">2011</xref>; Usrey and Alitto&#160;<xref rid="hbm70364-bib-0101" ref-type="bibr">2015</xref>).</p><p>In the subcortical network, the sequential encoder configuration's temporal gradient reveals notable variability in the anterior cingulate cortex, a region that serves as the origin of the anterior cingulate&#8208;subcortical circuit, providing input to subcortical structures such as the ventral striatum and other related areas (Bonelli and Cummings&#160;<xref rid="hbm70364-bib-0011" ref-type="bibr">2007</xref>; Stevens et&#160;al.&#160;<xref rid="hbm70364-bib-0094" ref-type="bibr">2011</xref>). Additionally, we observe pronounced variability in the activity scores of the cerebellum in the cerebellar network under the space&#8211;time configuration, whereas the sequential encoder configuration shows greater variability in the basal ganglia. The interconnection between these regions is well documented, linking the motor and non&#8208;motor domains of one subcortical system to the corresponding domain in the other. This anatomical connection supports the idea that cerebellar output can influence the input stage of the basal ganglia and vice versa (Bostan et&#160;al.&#160;<xref rid="hbm70364-bib-0012" ref-type="bibr">2010</xref>; Yoshida et&#160;al.&#160;<xref rid="hbm70364-bib-0115" ref-type="bibr">2022</xref>).</p><p>Figure&#160;<xref rid="hbm70364-fig-0005" ref-type="fig">5</xref> provides further quantitative evidence of the model's ability to capture dynamic brain patterns. In Figure&#160;<xref rid="hbm70364-fig-0005" ref-type="fig">5</xref>, Shannon entropy values are computed over temporal gradient maps for a random test subject across all networks, including the default mode, salience, motor, visual, subcortical, and cerebellar networks. This entropy analysis highlights the model's sensitivity to variations in temporal dynamics, with the top row representing the space&#8211;time configuration and the bottom row the sequential encoder configuration. Higher entropy values across networks indicate the model's capacity to capture complex, fluctuating activity patterns across these functional regions. Figure&#160;<xref rid="hbm70364-fig-0005" ref-type="fig">5</xref> further explores dynamic brain patterns through changes in blob count in the time interval. These metrics emphasize fluctuations in activity within the 4D maps, providing insights into the spatiotemporal variation captured by each configuration. Notably, the space&#8211;time configuration exhibits more pronounced changes in blob characteristics than the sequential encoder configuration, underscoring its enhanced ability to capture and represent dynamic spatial features in brain activity.</p><p>Overall, these findings demonstrate the model's robustness in capturing complex, dynamic activity patterns across multiple brain networks, highlighting its potential as a tool for examining the temporal and spatial organization of brain function.</p><sec id="hbm70364-sec-0017"><label>5.1</label><title>Application to Clinical Dataset</title><p>In the DMN, there are indications of potential differences in the temporally averaged space&#8211;time configurations, particularly within the thalamus, where healthy controls may exhibit higher activity compared to individuals with schizophrenia. This observation aligns, in part, with studies suggesting that disruptions in information flow to and from the thalamus could contribute to symptoms of schizophrenia (Iraji, Deramus, et&#160;al.&#160;<xref rid="hbm70364-bib-0039" ref-type="bibr">2019</xref>; Pergola et&#160;al.&#160;<xref rid="hbm70364-bib-0076" ref-type="bibr">2015</xref>; Anticevic and Halassa&#160;<xref rid="hbm70364-bib-0006" ref-type="bibr">2023</xref>). Similarly, the TG map suggests possible differences in the parietal lobules, which could indicate dysconnectivity between the parietal lobe and other brain regions in the disorganization symptoms of schizophrenia (Das et&#160;al.&#160;<xref rid="hbm70364-bib-0019" ref-type="bibr">2020</xref>). Increased activity in the middle frontal gyrus is also tentatively observed in schizophrenia subjects, potentially supporting hypotheses regarding alterations in this region in the condition (Woodward et&#160;al.&#160;<xref rid="hbm70364-bib-0109" ref-type="bibr">2011</xref>; Pomarol&#8208;Clotet et&#160;al.&#160;<xref rid="hbm70364-bib-0077" ref-type="bibr">2010</xref>). Finally, variability in the anterior cingulate cortex (ACC) appears elevated in schizophrenia, resonating with findings that report both hypoactivation and hyperactivation of the ACC. This variability might reflect a hyperactive ACC at rest, which could struggle to further activate under increased task demands, resulting in relative hypoactivity (Adams and David&#160;<xref rid="hbm70364-bib-0002" ref-type="bibr">2007</xref>).</p><p>In the salience network, temporally averaged space&#8211;time maps show a tendency for higher prefrontal cortex activation in healthy controls compared to schizophrenia subjects. This observation is partially consistent with research suggesting that schizophrenia patients often face difficulties with tasks dependent on prefrontal cortical function, such as Continuous Performance (attention), Wisconsin Card Sort (cognitive flexibility), Delayed Response (working memory), and N&#8208;Back (working memory) tasks (Selemon and Zecevic&#160;<xref rid="hbm70364-bib-0090" ref-type="bibr">2015</xref>). Additionally, there are hints of greater variability in the left primary auditory cortex (Heschl's gyrus) in healthy controls, which could align with findings linking reduced volume and thickness in this region to auditory hallucinations in schizophrenia (Soler&#8208;Vidal et&#160;al.&#160;<xref rid="hbm70364-bib-0092" ref-type="bibr">2022</xref>; Doucet et&#160;al.&#160;<xref rid="hbm70364-bib-0022" ref-type="bibr">2019</xref>). Schizophrenia subjects also seem to show localized activation in a small region of the anterior cingulate and increased variability in the right superior temporal sulcus (STS), a region previously associated with hyperactivation in schizophrenia (Wible et&#160;al.&#160;<xref rid="hbm70364-bib-0108" ref-type="bibr">2009</xref>).</p><p>In the motor network, temporally averaged maps suggest hyperactivation in the right lateral parietal region of the DMN in healthy controls, while schizophrenia subjects show hyperactivation in the right inferior parietal cortex. These observations may correspond with existing evidence of altered connectivity patterns in schizophrenia, where the lateral DMN exhibits decreased connectivity with sensorimotor regions but increased connectivity with heteromodal association areas (Wang et&#160;al.&#160;<xref rid="hbm70364-bib-0105" ref-type="bibr">2015</xref>). Furthermore, higher variability in cerebellar interactions with motor networks is observed in healthy controls, which could align with studies suggesting disrupted functional associations between cerebellar lobules and motor regions in schizophrenia (Kim et&#160;al.&#160;<xref rid="hbm70364-bib-0051" ref-type="bibr">2020</xref>). Schizophrenia also appears to be associated with hypoactivation in the precuneus (Forlim et&#160;al.&#160;<xref rid="hbm70364-bib-0027" ref-type="bibr">2020</xref>) and reduced variability in the thalamus compared to healthy controls.</p><p>In the visual network, temporally averaged maps suggest hyperactivation in the posterior hippocampus in healthy controls, aligning with previous findings (Ragland et&#160;al.&#160;<xref rid="hbm70364-bib-0080" ref-type="bibr">2017</xref>). However, schizophrenia subjects show increased variability in the superior parietal cortex, a region involved in spatial perception, attention, and self&#8208;awareness (Yildiz et&#160;al.&#160;<xref rid="hbm70364-bib-0114" ref-type="bibr">2011</xref>). Similar to the motor network, hypoactivation of the precuneus is observed in schizophrenia. Additionally, reduced variability is seen in the extrastriate cortex for schizophrenia subjects, a region associated with visual processing abnormalities in the disorder (van der Stelt et&#160;al.&#160;<xref rid="hbm70364-bib-0102" ref-type="bibr">2006</xref>).</p><p>In the subcortical network, individuals with schizophrenia show hypoactivation in the primary motor cortex, which may be linked to motor symptoms arising from disrupted neural circuitry and dysregulated dopamine signaling (Uddin et&#160;al.&#160;<xref rid="hbm70364-bib-0100" ref-type="bibr">2010</xref>). However, they also exhibit hyperactivation in a region of the parietal lobe. Furthermore, increased variability is seen in the default mode network in healthy controls, while these controls show hyperactivation in the left parietal lobe and greater variability in the angular gyrus under sequential encoder configurations.</p><p>Finally, the temporally averaged maps of space&#8211;time configuration suggest hyperactivation in the parietal lobes and medial frontal gyrus, regions that are known to be functionally connected (O'reilly et&#160;al.&#160;<xref rid="hbm70364-bib-0075" ref-type="bibr">2010</xref>; Jobson et&#160;al.&#160;<xref rid="hbm70364-bib-0043" ref-type="bibr">2021</xref>). Healthy controls also show greater variability in the orbitofrontal cortex (Walton et&#160;al.&#160;<xref rid="hbm70364-bib-0104" ref-type="bibr">2017</xref>). Sequential encoder configurations indicate hyperactivation in the parietal cortex and heightened variability in the intraparietal cortex in healthy controls compared to schizophrenia subjects. While these trends are intriguing, further investigation is required to better understand the complexities of these network alterations in schizophrenia.</p></sec></sec><sec sec-type="conclusions" id="hbm70364-sec-0018"><label>6</label><title>Conclusion</title><p>Our study established a new experimental paradigm for the study of brain dynamics by proposing a novel method to model both spatial and temporal dimensions from input fMRI data and generate dynamic brain maps. This approach enables us to study brain dynamics within different brain networks with a high degree of granularity. By leveraging the spatiotemporal ViT architecture and weakly supervised learning techniques, our model effectively captures the spatiotemporal variations in brain activity, even in the absence of direct ground&#8208;truth data. The model's ability to produce smooth, temporally evolving brain maps from noisy priors offers a promising new tool for neuroimaging research, particularly in understanding complex neurological conditions such as schizophrenia. The significant differences observed between patient and control groups underscore the model's potential for clinical applications, including differential diagnosis and personalized treatment strategies. Ultimately, this work lays the foundation for future advancements in dynamic brain mapping, providing a powerful framework for exploring brain activity in health and disease.</p></sec></body><back><sec sec-type="data-availability" id="hbm70364-sec-0020"><title>Data Availability Statement</title><p>The data that support the findings of this study are available from the corresponding author upon reasonable request.</p></sec><ref-list content-type="cited-references" id="hbm70364-bibl-0001"><title>References</title><ref id="hbm70364-bib-0001"><mixed-citation publication-type="book" id="hbm70364-cit-0001"><string-name name-style="western"><surname>Abbas</surname>, <given-names>A.</given-names></string-name><year>2019</year>. <source>Understanding Brain Activity Dynamics Through the Investigation of Quasi&#8208;Periodic Patterns</source>. <publisher-name>Emory University</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0002"><mixed-citation publication-type="journal" id="hbm70364-cit-0002"><string-name name-style="western"><surname>Adams</surname>, <given-names>R.</given-names></string-name>, and <string-name name-style="western"><given-names>A. S.</given-names><surname>David</surname></string-name>. <year>2007</year>. &#8220;<article-title>Patterns of Anterior Cingulate Activation in Schizophrenia: A Selective Review</article-title>.&#8221; <source>Neuropsychiatric Disease and Treatment</source><volume>3</volume>, no. <issue>1</issue>: <fpage>87</fpage>&#8211;<lpage>101</lpage>.<pub-id pub-id-type="pmid">19300540</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.2147/nedt.2007.3.1.87</pub-id><pub-id pub-id-type="pmcid">PMC2654525</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0003"><mixed-citation publication-type="journal" id="hbm70364-cit-0003"><string-name name-style="western"><surname>Adhikari</surname>, <given-names>B. M.</given-names></string-name>, <string-name name-style="western"><given-names>L. E.</given-names><surname>Hong</surname></string-name>, <string-name name-style="western"><given-names>H.</given-names><surname>Sampath</surname></string-name>, et&#160;al. <year>2019</year>. &#8220;<article-title>Functional Network Connectivity Impairments and Core Cognitive Deficits in Schizophrenia</article-title>.&#8221; <source>Human Brain Mapping</source><volume>40</volume>, no. <issue>16</issue>: <fpage>4593</fpage>&#8211;<lpage>4605</lpage>.<pub-id pub-id-type="pmid">31313441</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/hbm.24723</pub-id><pub-id pub-id-type="pmcid">PMC6865503</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0004"><mixed-citation publication-type="journal" id="hbm70364-cit-0004"><string-name name-style="western"><surname>Ahuja</surname>, <given-names>K.</given-names></string-name>, <string-name name-style="western"><given-names>J. S.</given-names><surname>Hartford</surname></string-name>, and <string-name name-style="western"><given-names>Y.</given-names><surname>Bengio</surname></string-name>. <year>2022</year>. &#8220;<article-title>Weakly Supervised Representation Learning With Sparse Perturbations</article-title>.&#8221; <source>Advances in Neural Information Processing Systems</source><volume>35</volume>: <fpage>15516</fpage>&#8211;<lpage>15528</lpage>.</mixed-citation></ref><ref id="hbm70364-bib-0005"><mixed-citation publication-type="book" id="hbm70364-cit-0005"><string-name name-style="western"><surname>Alexandropoulos</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western"><given-names>C.</given-names><surname>Sakaridis</surname></string-name>, and <string-name name-style="western"><given-names>P.</given-names><surname>Maragos</surname></string-name>. <year>2024</year>. &#8220;<part-title>Ovenet: Offset Vector Network for Semantic Segmentation</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</source>, <fpage>7407</fpage>&#8211;<lpage>7418</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0006"><mixed-citation publication-type="journal" id="hbm70364-cit-0006"><string-name name-style="western"><surname>Anticevic</surname>, <given-names>A.</given-names></string-name>, and <string-name name-style="western"><given-names>M. M.</given-names><surname>Halassa</surname></string-name>. <year>2023</year>. &#8220;<article-title>The Thalamus in Psychosis Spectrum Disorder</article-title>.&#8221; <source>Frontiers in Neuroscience</source><volume>17</volume>: <elocation-id>1163600</elocation-id>.<pub-id pub-id-type="pmid">37123374</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3389/fnins.2023.1163600</pub-id><pub-id pub-id-type="pmcid">PMC10133512</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0007"><mixed-citation publication-type="book" id="hbm70364-cit-0007"><string-name name-style="western"><surname>Arnab</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western"><given-names>M.</given-names><surname>Dehghani</surname></string-name>, <string-name name-style="western"><given-names>G.</given-names><surname>Heigold</surname></string-name>, <string-name name-style="western"><given-names>C.</given-names><surname>Sun</surname></string-name>, <string-name name-style="western"><given-names>M.</given-names><surname>Lu&#269;i&#263;</surname></string-name>, and <string-name name-style="western"><given-names>C.</given-names><surname>Schmid</surname></string-name>. <year>2021</year>. &#8220;<part-title>Vivit: A Video Vision Transformer</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF International Conference on Computer Vision</source>, <fpage>6836</fpage>&#8211;<lpage>6846</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0008"><mixed-citation publication-type="journal" id="hbm70364-cit-0008"><string-name name-style="western"><surname>Auzias</surname>, <given-names>G.</given-names></string-name>, <string-name name-style="western"><given-names>O.</given-names><surname>Coulon</surname></string-name>, and <string-name name-style="western"><given-names>A.</given-names><surname>Brovelli</surname></string-name>. <year>2016</year>. &#8220;<article-title>Marsatlas: A Cortical Parcellation Atlas for Functional Mapping</article-title>.&#8221; <source>Human Brain Mapping</source><volume>37</volume>, no. <issue>4</issue>: <fpage>1573</fpage>&#8211;<lpage>1592</lpage>.<pub-id pub-id-type="pmid">26813563</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/hbm.23121</pub-id><pub-id pub-id-type="pmcid">PMC6867384</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0009"><mixed-citation publication-type="book" id="hbm70364-cit-0009"><string-name name-style="western"><surname>Bear</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western"><given-names>B.</given-names><surname>Connors</surname></string-name>, and <string-name name-style="western"><given-names>M. A.</given-names><surname>Paradiso</surname></string-name>. <year>2020</year>. <source>Neuroscience: Exploring the Brain, Enhanced Edition: Exploring the Brain</source>. <publisher-name>Jones &amp; Bartlett Learning</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0010"><mixed-citation publication-type="journal" id="hbm70364-cit-0010"><string-name name-style="western"><surname>Belloy</surname>, <given-names>M. E.</given-names></string-name>, <string-name name-style="western"><given-names>M.</given-names><surname>Naeyaert</surname></string-name>, <string-name name-style="western"><given-names>A.</given-names><surname>Abbas</surname></string-name>, et&#160;al. <year>2018</year>. &#8220;<article-title>Dynamic Resting State fMRI Analysis in Mice Reveals a Set of Quasi&#8208;Periodic Patterns and Illustrates Their Relationship With the Global Signal</article-title>.&#8221; <source>NeuroImage</source><volume>180</volume>: <fpage>463</fpage>&#8211;<lpage>484</lpage>.<pub-id pub-id-type="pmid">29454935</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neuroimage.2018.01.075</pub-id><pub-id pub-id-type="pmcid">PMC6093802</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0011"><mixed-citation publication-type="journal" id="hbm70364-cit-0011"><string-name name-style="western"><surname>Bonelli</surname>, <given-names>R. M.</given-names></string-name>, and <string-name name-style="western"><given-names>J. L.</given-names><surname>Cummings</surname></string-name>. <year>2007</year>. &#8220;<article-title>Frontal&#8208;Subcortical Circuitry and Behavior</article-title>.&#8221; <source>Dialogues in Clinical Neuroscience</source><volume>9</volume>, no. <issue>2</issue>: <fpage>141</fpage>&#8211;<lpage>151</lpage>.<pub-id pub-id-type="pmid">17726913</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.31887/DCNS.2007.9.2/rbonelli</pub-id><pub-id pub-id-type="pmcid">PMC3181854</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0012"><mixed-citation publication-type="journal" id="hbm70364-cit-0012"><string-name name-style="western"><surname>Bostan</surname>, <given-names>A. C.</given-names></string-name>, <string-name name-style="western"><given-names>R. P.</given-names><surname>Dum</surname></string-name>, and <string-name name-style="western"><given-names>P. L.</given-names><surname>Strick</surname></string-name>. <year>2010</year>. &#8220;<article-title>The Basal Ganglia Communicate With the Cerebellum</article-title>.&#8221; <source>Proceedings of the National Academy of Sciences</source><volume>107</volume>, no. <issue>18</issue>: <fpage>8452</fpage>&#8211;<lpage>8456</lpage>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1073/pnas.1000496107</pub-id><pub-id pub-id-type="pmcid">PMC2889518</pub-id><pub-id pub-id-type="pmid">20404184</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0013"><mixed-citation publication-type="journal" id="hbm70364-cit-0013"><string-name name-style="western"><surname>Bruining</surname>, <given-names>H.</given-names></string-name>, <string-name name-style="western"><given-names>R.</given-names><surname>Hardstone</surname></string-name>, <string-name name-style="western"><given-names>E. L.</given-names><surname>Juarez&#8208;Martinez</surname></string-name>, et&#160;al. <year>2020</year>. &#8220;<article-title>Measurement of Excitation&#8208;Inhibition Ratio in Autism Spectrum Disorder Using Critical Brain Dynamics</article-title>.&#8221; <source>Scientific Reports</source><volume>10</volume>, no. <issue>1</issue>: <fpage>9195</fpage>.<pub-id pub-id-type="pmid">32513931</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-020-65500-4</pub-id><pub-id pub-id-type="pmcid">PMC7280527</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0014"><mixed-citation publication-type="journal" id="hbm70364-cit-0014"><string-name name-style="western"><surname>Calhoun</surname>, <given-names>V. D.</given-names></string-name>, and <string-name name-style="western"><given-names>T.</given-names><surname>Adali</surname></string-name>. <year>2012</year>. &#8220;<article-title>Multisubject Independent Component Analysis of fMRI: A Decade of Intrinsic Networks, Default Mode, and Neurodiagnostic Discovery</article-title>.&#8221; <source>IEEE Reviews in Biomedical Engineering</source><volume>5</volume>: <fpage>60</fpage>&#8211;<lpage>73</lpage>.<pub-id pub-id-type="pmid">23231989</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/RBME.2012.2211076</pub-id><pub-id pub-id-type="pmcid">PMC4433055</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0015"><mixed-citation publication-type="journal" id="hbm70364-cit-0015"><string-name name-style="western"><surname>Calhoun</surname>, <given-names>V. D.</given-names></string-name>, <string-name name-style="western"><given-names>J.</given-names><surname>Liu</surname></string-name>, and <string-name name-style="western"><given-names>T.</given-names><surname>Adal&#305;</surname></string-name>. <year>2009</year>. &#8220;<article-title>A Review of Group Ica for fMRI Data and Ica for Joint Inference of Imaging, Genetic, and Erp Data</article-title>.&#8221; <source>NeuroImage</source><volume>45</volume>, no. <issue>1</issue>: <fpage>S163</fpage>&#8211;<lpage>S172</lpage>.<pub-id pub-id-type="pmid">19059344</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neuroimage.2008.10.057</pub-id><pub-id pub-id-type="pmcid">PMC2651152</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0016"><mixed-citation publication-type="journal" id="hbm70364-cit-0016"><string-name name-style="western"><surname>Calhoun</surname>, <given-names>V. D.</given-names></string-name>, <string-name name-style="western"><given-names>R. F.</given-names><surname>Silva</surname></string-name>, <string-name name-style="western"><given-names>T.</given-names><surname>Adal&#305;</surname></string-name>, and <string-name name-style="western"><given-names>S.</given-names><surname>Rachakonda</surname></string-name>. <year>2015</year>. &#8220;<article-title>Comparison of Pca Approaches for Very Large Group Ica</article-title>.&#8221; <source>NeuroImage</source><volume>118</volume>: <fpage>662</fpage>&#8211;<lpage>666</lpage>.<pub-id pub-id-type="pmid">26021216</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neuroimage.2015.05.047</pub-id><pub-id pub-id-type="pmcid">PMC4554805</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0017"><mixed-citation publication-type="book" id="hbm70364-cit-0017"><string-name name-style="western"><surname>Charatan</surname>, <given-names>D.</given-names></string-name>, <string-name name-style="western"><given-names>S. L.</given-names><surname>Li</surname></string-name>, <string-name name-style="western"><given-names>A.</given-names><surname>Tagliasacchi</surname></string-name>, and <string-name name-style="western"><given-names>V.</given-names><surname>Sitzmann</surname></string-name>. <year>2024</year>. &#8220;<part-title>Pixelsplat: 3d Gaussian Splats From Image Pairs for Scalable Generalizable 3d Reconstruction</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>, <fpage>19457</fpage>&#8211;<lpage>19467</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0018"><mixed-citation publication-type="journal" id="hbm70364-cit-0018"><string-name name-style="western"><surname>Cui</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western"><given-names>Z.</given-names><surname>Liu</surname></string-name>, <string-name name-style="western"><given-names>Y.</given-names><surname>Chen</surname></string-name>, et&#160;al. <year>2024</year>. &#8220;<article-title>Retrieval&#8208;Augmented Multiple Instance Learning</article-title>.&#8221; <source>Advances in Neural Information Processing Systems</source><volume>36</volume>: <fpage>24859</fpage>&#8211;<lpage>24878</lpage>.</mixed-citation></ref><ref id="hbm70364-bib-0019"><mixed-citation publication-type="journal" id="hbm70364-cit-0019"><string-name name-style="western"><surname>Das</surname>, <given-names>T. K.</given-names></string-name>, <string-name name-style="western"><given-names>J.</given-names><surname>Kumar</surname></string-name>, <string-name name-style="western"><given-names>S.</given-names><surname>Francis</surname></string-name>, <string-name name-style="western"><given-names>P. F.</given-names><surname>Liddle</surname></string-name>, and <string-name name-style="western"><given-names>L.</given-names><surname>Palaniyappan</surname></string-name>. <year>2020</year>. &#8220;<article-title>Parietal Lobe and Disorganisation Syndrome in Schizophrenia and Psychotic Bipolar Disorder: A Bimodal Connectivity Study</article-title>.&#8221; <source>Psychiatry Research: Neuroimaging</source><volume>303</volume>: <elocation-id>111139</elocation-id>.<pub-id pub-id-type="pmid">32707490</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.pscychresns.2020.111139</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0020"><mixed-citation publication-type="book" id="hbm70364-cit-0020"><string-name name-style="western"><surname>de Geus</surname>, <given-names>D.</given-names></string-name>, and <string-name name-style="western"><given-names>G.</given-names><surname>Dubbelman</surname></string-name>. <year>2024</year>. &#8220;<part-title>Task&#8208;Aligned Part&#8208;Aware Panoptic Segmentation Through Joint Object&#8208;Part Representations</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>, <fpage>3174</fpage>&#8211;<lpage>3183</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0021"><mixed-citation publication-type="journal" id="hbm70364-cit-0021"><string-name name-style="western"><surname>Ding</surname>, <given-names>S.&#8208;L.</given-names></string-name>, <string-name name-style="western"><given-names>J. J.</given-names><surname>Royall</surname></string-name>, <string-name name-style="western"><given-names>S. M.</given-names><surname>Sunkin</surname></string-name>, et&#160;al. <year>2016</year>. &#8220;<article-title>Comprehensive Cellular&#8208;Resolution Atlas of the Adult Human Brain</article-title>.&#8221; <source>Journal of Comparative Neurology</source><volume>524</volume>, no. <issue>16</issue>: <fpage>3127</fpage>&#8211;<lpage>3481</lpage>.<pub-id pub-id-type="pmid">27418273</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/cne.24080</pub-id><pub-id pub-id-type="pmcid">PMC5054943</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0022"><mixed-citation publication-type="journal" id="hbm70364-cit-0022"><string-name name-style="western"><surname>Doucet</surname>, <given-names>G. E.</given-names></string-name>, <string-name name-style="western"><given-names>M. J.</given-names><surname>Luber</surname></string-name>, <string-name name-style="western"><given-names>P.</given-names><surname>Balchandani</surname></string-name>, <string-name name-style="western"><given-names>I. E.</given-names><surname>Sommer</surname></string-name>, and <string-name name-style="western"><given-names>S.</given-names><surname>Frangou</surname></string-name>. <year>2019</year>. &#8220;<article-title>Abnormal Auditory Tonotopy in Patients With Schizophrenia</article-title>.&#8221; <source>npj Schizophrenia</source><volume>5</volume>, no. <issue>1</issue>: <fpage>1</fpage>&#8211;<lpage>6</lpage>.<pub-id pub-id-type="pmid">31578332</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41537-019-0084-x</pub-id><pub-id pub-id-type="pmcid">PMC6775081</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0023"><mixed-citation publication-type="journal" id="hbm70364-cit-0023"><string-name name-style="western"><surname>Du</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western"><given-names>Z.</given-names><surname>Fu</surname></string-name>, <string-name name-style="western"><given-names>J.</given-names><surname>Sui</surname></string-name>, et&#160;al. <year>2020</year>. &#8220;<article-title>Neuromark: An Automated and Adaptive Ica Based Pipeline to Identify Reproducible fMRI Markers of Brain Disorders</article-title>.&#8221; <source>NeuroImage: Clinical</source><volume>28</volume>: <elocation-id>102375</elocation-id>.<pub-id pub-id-type="pmid">32961402</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.nicl.2020.102375</pub-id><pub-id pub-id-type="pmcid">PMC7509081</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0024"><mixed-citation publication-type="journal" id="hbm70364-cit-0024"><string-name name-style="western"><surname>Eickhoff</surname>, <given-names>S. B.</given-names></string-name>, <string-name name-style="western"><given-names>B.</given-names><surname>Thirion</surname></string-name>, <string-name name-style="western"><given-names>G.</given-names><surname>Varoquaux</surname></string-name>, and <string-name name-style="western"><given-names>D.</given-names><surname>Bzdok</surname></string-name>. <year>2015</year>. &#8220;<article-title>Connectivity&#8208;Based Parcellation: Critique and Implications</article-title>.&#8221; <source>Human Brain Mapping</source><volume>36</volume>, no. <issue>12</issue>: <fpage>4771</fpage>&#8211;<lpage>4792</lpage>.<pub-id pub-id-type="pmid">26409749</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/hbm.22933</pub-id><pub-id pub-id-type="pmcid">PMC6869530</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0025"><mixed-citation publication-type="journal" id="hbm70364-cit-0025"><string-name name-style="western"><surname>Faghiri</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western"><given-names>A.</given-names><surname>Iraji</surname></string-name>, <string-name name-style="western"><given-names>E.</given-names><surname>Damaraju</surname></string-name>, <string-name name-style="western"><given-names>J.</given-names><surname>Turner</surname></string-name>, and <string-name name-style="western"><given-names>V. D.</given-names><surname>Calhoun</surname></string-name>. <year>2021</year>. &#8220;<article-title>A Unified Approach for Characterizing Static/Dynamic Connectivity Frequency Profiles Using Filter Banks</article-title>.&#8221; <source>Network Neuroscience</source><volume>5</volume>, no. <issue>1</issue>: <fpage>56</fpage>&#8211;<lpage>82</lpage>.<pub-id pub-id-type="pmid">33688606</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1162/netn_a_00155</pub-id><pub-id pub-id-type="pmcid">PMC7935048</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0026"><mixed-citation publication-type="journal" id="hbm70364-cit-0026"><string-name name-style="western"><surname>Fan</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western"><given-names>H.</given-names><surname>Li</surname></string-name>, <string-name name-style="western"><given-names>J.</given-names><surname>Zhuo</surname></string-name>, et&#160;al. <year>2016</year>. &#8220;<article-title>The Human Brainnetome Atlas: A New Brain Atlas Based on Connectional Architecture</article-title>.&#8221; <source>Cerebral Cortex</source><volume>26</volume>, no. <issue>8</issue>: <fpage>3508</fpage>&#8211;<lpage>3526</lpage>.<pub-id pub-id-type="pmid">27230218</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/cercor/bhw157</pub-id><pub-id pub-id-type="pmcid">PMC4961028</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0027"><mixed-citation publication-type="journal" id="hbm70364-cit-0027"><string-name name-style="western"><surname>Forlim</surname>, <given-names>C. G.</given-names></string-name>, <string-name name-style="western"><given-names>L.</given-names><surname>Klock</surname></string-name>, <string-name name-style="western"><given-names>J.</given-names><surname>B&#228;chle</surname></string-name>, et&#160;al. <year>2020</year>. &#8220;<article-title>Reduced Resting&#8208;State Connectivity in the Precuneus Is Correlated With Apathy in Patients With Schizophrenia</article-title>.&#8221; <source>Scientific Reports</source><volume>10</volume>, no. <issue>1</issue>: <fpage>2616</fpage>.<pub-id pub-id-type="pmid">32054907</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-020-59393-6</pub-id><pub-id pub-id-type="pmcid">PMC7018974</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0028"><mixed-citation publication-type="journal" id="hbm70364-cit-0028"><string-name name-style="western"><surname>Fransson</surname>, <given-names>P.</given-names></string-name>, and <string-name name-style="western"><given-names>G.</given-names><surname>Marrelec</surname></string-name>. <year>2008</year>. &#8220;<article-title>The Precuneus/Posterior Cingulate Cortex Plays a Pivotal Role in the Default Mode Network: Evidence From a Partial Correlation Network Analysis</article-title>.&#8221; <source>NeuroImage</source><volume>42</volume>, no. <issue>3</issue>: <fpage>1178</fpage>&#8211;<lpage>1184</lpage>.<pub-id pub-id-type="pmid">18598773</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neuroimage.2008.05.059</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0029"><mixed-citation publication-type="journal" id="hbm70364-cit-0029"><string-name name-style="western"><surname>Fransson</surname>, <given-names>P.</given-names></string-name>, and <string-name name-style="western"><given-names>M.</given-names><surname>Strindberg</surname></string-name>. <year>2023</year>. &#8220;<article-title>Brain Network Integration, Segregation and Quasi&#8208;Periodic Activation and Deactivation During Tasks and Rest</article-title>.&#8221; <source>NeuroImage</source><volume>268</volume>: <elocation-id>119890</elocation-id>.<pub-id pub-id-type="pmid">36681135</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neuroimage.2023.119890</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0030"><mixed-citation publication-type="book" id="hbm70364-cit-0030"><string-name name-style="western"><surname>Gong</surname>, <given-names>X.</given-names></string-name>, <string-name name-style="western"><given-names>N.</given-names><surname>Bisht</surname></string-name>, and <string-name name-style="western"><given-names>G.</given-names><surname>Xu</surname></string-name>. <year>2024</year>. &#8220;<part-title>Does Label Smoothing Help Deep Partial Label Learning?</part-title>&#8221; In <source>Forty&#8208;First International Conference on Machine Learning</source>. <publisher-name>Curran Associates, Inc</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0031"><mixed-citation publication-type="book" id="hbm70364-cit-0031"><string-name name-style="western"><surname>Grafton</surname>, <given-names>S. T.</given-names></string-name>, and <string-name name-style="western"><given-names>L. J.</given-names><surname>Volz</surname></string-name>. <year>2019</year>. &#8220;<part-title>From Ideas to Action: The Prefrontal&#8211;Premotor Connections That Shape Motor Behavior</part-title>.&#8221; In <source>Handbook of Clinical Neurology</source>, vol. <volume>163</volume>, <fpage>237</fpage>&#8211;<lpage>255</lpage>. <publisher-name>Elsevier</publisher-name>.<pub-id pub-id-type="pmid">31590733</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/B978-0-12-804281-6.00013-6</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0032"><mixed-citation publication-type="journal" id="hbm70364-cit-0032"><string-name name-style="western"><surname>Haggerty</surname>, <given-names>D. C.</given-names></string-name>, and <string-name name-style="western"><given-names>D.</given-names><surname>Ji</surname></string-name>. <year>2015</year>. &#8220;<article-title>Activities of Visual Cortical and Hippocampal Neurons Co&#8208;Fluctuate in Freely Moving Rats During Spatial Behavior</article-title>.&#8221; <source>eLife</source><volume>4</volume>: <elocation-id>e08902</elocation-id>.<pub-id pub-id-type="pmid">26349031</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.7554/eLife.08902</pub-id><pub-id pub-id-type="pmcid">PMC4595967</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0033"><mixed-citation publication-type="miscellaneous" id="hbm70364-cit-0033"><string-name name-style="western"><surname>Han</surname>, <given-names>B.</given-names></string-name>, <string-name name-style="western"><given-names>Q.</given-names><surname>Yao</surname></string-name>, <string-name name-style="western"><given-names>T.</given-names><surname>Liu</surname></string-name>, et&#160;al. <year>2020</year>. <article-title>&#8220;A Survey of Label&#8208;Noise Representation Learning: Past, Present and Future,&#8221; arXiv preprint arXiv:2011.04406</article-title>.</mixed-citation></ref><ref id="hbm70364-bib-0034"><mixed-citation publication-type="journal" id="hbm70364-cit-0034"><string-name name-style="western"><surname>Hawrylycz</surname>, <given-names>M. J.</given-names></string-name>, <string-name name-style="western"><given-names>E. S.</given-names><surname>Lein</surname></string-name>, <string-name name-style="western"><given-names>A. L.</given-names><surname>Guillozet&#8208;Bongaarts</surname></string-name>, et&#160;al. <year>2012</year>. &#8220;<article-title>An Anatomically Comprehensive Atlas of the Adult Human Brain Transcriptome</article-title>.&#8221; <source>Nature</source><volume>489</volume>, no. <issue>7416</issue>: <fpage>391</fpage>&#8211;<lpage>399</lpage>.<pub-id pub-id-type="pmid">22996553</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/nature11405</pub-id><pub-id pub-id-type="pmcid">PMC4243026</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0035"><mixed-citation publication-type="journal" id="hbm70364-cit-0035"><string-name name-style="western"><surname>Hindriks</surname>, <given-names>R.</given-names></string-name>, <string-name name-style="western"><given-names>M. H.</given-names><surname>Adhikari</surname></string-name>, <string-name name-style="western"><given-names>Y.</given-names><surname>Murayama</surname></string-name>, et&#160;al. <year>2016</year>. &#8220;<article-title>Can Sliding&#8208;Window Correlations Reveal Dynamic Functional Connectivity in Resting&#8208;State fMRI?</article-title>&#8221; <source>NeuroImage</source><volume>127</volume>: <fpage>242</fpage>&#8211;<lpage>256</lpage>.<pub-id pub-id-type="pmid">26631813</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neuroimage.2015.11.055</pub-id><pub-id pub-id-type="pmcid">PMC4758830</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0036"><mixed-citation publication-type="journal" id="hbm70364-cit-0036"><string-name name-style="western"><surname>Honari</surname>, <given-names>H.</given-names></string-name>, <string-name name-style="western"><given-names>A. S.</given-names><surname>Choe</surname></string-name>, and <string-name name-style="western"><given-names>M. A.</given-names><surname>Lindquist</surname></string-name>. <year>2021</year>. &#8220;<article-title>Evaluating Phase Synchronization Methods in fMRI: A Comparison Study and New Approaches</article-title>.&#8221; <source>NeuroImage</source><volume>228</volume>: <elocation-id>117704</elocation-id>.<pub-id pub-id-type="pmid">33385554</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neuroimage.2020.117704</pub-id><pub-id pub-id-type="pmcid">PMC8011682</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0037"><mixed-citation publication-type="journal" id="hbm70364-cit-0037"><string-name name-style="western"><surname>Honari</surname>, <given-names>H.</given-names></string-name>, and <string-name name-style="western"><given-names>M. A.</given-names><surname>Lindquist</surname></string-name>. <year>2022</year>. &#8220;<article-title>Mode Decomposition&#8208;Based Time&#8208;Varying Phase Synchronization for fMRI</article-title>.&#8221; <source>NeuroImage</source><volume>261</volume>: <elocation-id>119519</elocation-id>.<pub-id pub-id-type="pmid">35905810</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neuroimage.2022.119519</pub-id><pub-id pub-id-type="pmcid">PMC9451171</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0038"><mixed-citation publication-type="journal" id="hbm70364-cit-0038"><string-name name-style="western"><surname>Iraji</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western"><given-names>J.</given-names><surname>Chen</surname></string-name>, <string-name name-style="western"><given-names>N.</given-names><surname>Lewis</surname></string-name>, et&#160;al. <year>2024</year>. &#8220;<article-title>Spatial Dynamic Subspaces Encode Sex&#8208;Specific Schizophrenia Disruptions in Transient Network Overlap and Their Links to Genetic Risk</article-title>.&#8221; <source>Biological Psychiatry</source><volume>96</volume>, no. <issue>3</issue>: <fpage>188</fpage>&#8211;<lpage>197</lpage>.<pub-id pub-id-type="pmid">38070846</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.biopsych.2023.12.002</pub-id><pub-id pub-id-type="pmcid">PMC11156799</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0039"><mixed-citation publication-type="journal" id="hbm70364-cit-0039"><string-name name-style="western"><surname>Iraji</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western"><given-names>T. P.</given-names><surname>Deramus</surname></string-name>, <string-name name-style="western"><given-names>N.</given-names><surname>Lewis</surname></string-name>, et&#160;al. <year>2019</year>. &#8220;<article-title>The Spatial Chronnectome Reveals a Dynamic Interplay Between Functional Segregation and Integration</article-title>.&#8221; <source>Human Brain Mapping</source><volume>40</volume>, no. <issue>10</issue>: <fpage>3058</fpage>&#8211;<lpage>3077</lpage>.<pub-id pub-id-type="pmid">30884018</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/hbm.24580</pub-id><pub-id pub-id-type="pmcid">PMC6548674</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0040"><mixed-citation publication-type="journal" id="hbm70364-cit-0040"><string-name name-style="western"><surname>Iraji</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western"><given-names>A.</given-names><surname>Faghiri</surname></string-name>, <string-name name-style="western"><given-names>Z.</given-names><surname>Fu</surname></string-name>, et&#160;al. <year>2022</year>. &#8220;<article-title>Moving Beyond the &#8216;Cap'of the Iceberg: Intrinsic Connectivity Networks in fMRI Are Continuously Engaging and Overlapping</article-title>.&#8221; <source>NeuroImage</source><volume>251</volume>: <elocation-id>119013</elocation-id>.<pub-id pub-id-type="pmid">35189361</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neuroimage.2022.119013</pub-id><pub-id pub-id-type="pmcid">PMC9107614</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0041"><mixed-citation publication-type="journal" id="hbm70364-cit-0041"><string-name name-style="western"><surname>Iraji</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western"><given-names>Z.</given-names><surname>Fu</surname></string-name>, <string-name name-style="western"><given-names>E.</given-names><surname>Damaraju</surname></string-name>, et&#160;al. <year>2019</year>. &#8220;<article-title>Spatial Dynamics Within and Between Brain Functional Domains: A Hierarchical Approach to Study Time&#8208;Varying Brain Function</article-title>.&#8221; <source>Human Brain Mapping</source><volume>40</volume>, no. <issue>6</issue>: <fpage>1969</fpage>&#8211;<lpage>1986</lpage>.<pub-id pub-id-type="pmid">30588687</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/hbm.24505</pub-id><pub-id pub-id-type="pmcid">PMC6692083</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0042"><mixed-citation publication-type="journal" id="hbm70364-cit-0042"><string-name name-style="western"><surname>Iraji</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western"><given-names>R.</given-names><surname>Miller</surname></string-name>, <string-name name-style="western"><given-names>T.</given-names><surname>Adali</surname></string-name>, and <string-name name-style="western"><given-names>V. D.</given-names><surname>Calhoun</surname></string-name>. <year>2020</year>. &#8220;<article-title>Space: A Missing Piece of the Dynamic Puzzle</article-title>.&#8221; <source>Trends in Cognitive Sciences</source><volume>24</volume>, no. <issue>2</issue>: <fpage>135</fpage>&#8211;<lpage>149</lpage>.<pub-id pub-id-type="pmid">31983607</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.tics.2019.12.004</pub-id><pub-id pub-id-type="pmcid">PMC7809367</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0043"><mixed-citation publication-type="journal" id="hbm70364-cit-0043"><string-name name-style="western"><surname>Jobson</surname>, <given-names>D. D.</given-names></string-name>, <string-name name-style="western"><given-names>Y.</given-names><surname>Hase</surname></string-name>, <string-name name-style="western"><given-names>A. N.</given-names><surname>Clarkson</surname></string-name>, and <string-name name-style="western"><given-names>R. N.</given-names><surname>Kalaria</surname></string-name>. <year>2021</year>. &#8220;<article-title>The Role of the Medial Prefrontal Cortex in Cognition, Ageing and Dementia</article-title>.&#8221; <source>Brain Communications</source><volume>3</volume>, no. <issue>3</issue>: <elocation-id>fcab125</elocation-id>.<pub-id pub-id-type="pmid">34222873</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/braincomms/fcab125</pub-id><pub-id pub-id-type="pmcid">PMC8249104</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0044"><mixed-citation publication-type="book" id="hbm70364-cit-0044"><string-name name-style="western"><surname>Kalluri</surname>, <given-names>T.</given-names></string-name>, <string-name name-style="western"><given-names>W.</given-names><surname>Wang</surname></string-name>, <string-name name-style="western"><given-names>H.</given-names><surname>Wang</surname></string-name>, <string-name name-style="western"><given-names>M.</given-names><surname>Chandraker</surname></string-name>, <string-name name-style="western"><given-names>L.</given-names><surname>Torresani</surname></string-name>, and <string-name name-style="western"><given-names>D.</given-names><surname>Tran</surname></string-name>. <year>2024</year>. &#8220;<part-title>Open&#8208;World Instance Segmentation: Top&#8208;Down Learning With Bottom&#8208;Up Supervision</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>, <fpage>2693</fpage>&#8211;<lpage>2703</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0045"><mixed-citation publication-type="miscellaneous" id="hbm70364-cit-0045"><string-name name-style="western"><surname>Karniol&#8208;Tambour</surname>, <given-names>O.</given-names></string-name>, <string-name name-style="western"><given-names>D. M.</given-names><surname>Zoltowski</surname></string-name>, <string-name name-style="western"><given-names>E. M.</given-names><surname>Diamanti</surname></string-name>, et&#160;al. <year>2024</year>. <article-title>&#8220;Modeling State&#8208;Dependent Communication Between Brain Regions with Switching Nonlinear Dynamical Systems,&#8221; in The Twelfth International Conference on Learning Representations</article-title>.</mixed-citation></ref><ref id="hbm70364-bib-0046"><mixed-citation publication-type="book" id="hbm70364-cit-0046"><string-name name-style="western"><surname>Kazemivash</surname>, <given-names>B.</given-names></string-name>, and <string-name name-style="western"><given-names>V. D.</given-names><surname>Calhoun</surname></string-name>. <year>2020</year>. &#8220;<part-title>Bparc: A Novel Spatio&#8208;Temporal (4d) Data&#8208;Driven Brain Parcellation Scheme Based on Deep Residual Networks</part-title>.&#8221; In <source>2020 IEEE 20th International Conference on Bioinformatics and Bioengineering (BIBE)</source>, <fpage>1071</fpage>&#8211;<lpage>1076</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0047"><mixed-citation publication-type="journal" id="hbm70364-cit-0047"><string-name name-style="western"><surname>Kazemivash</surname>, <given-names>B.</given-names></string-name>, and <string-name name-style="western"><given-names>V. D.</given-names><surname>Calhoun</surname></string-name>. <year>2022a</year>. &#8220;<article-title>A Novel 5d Brain Parcellation Approach Based on Spatio&#8208;Temporal Encoding of Resting fMRI Data From Deep Residual Learning</article-title>.&#8221; <source>Journal of Neuroscience Methods</source><volume>369</volume>: <elocation-id>109478</elocation-id>.<pub-id pub-id-type="pmid">35031344</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.jneumeth.2022.109478</pub-id><pub-id pub-id-type="pmcid">PMC9394484</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0048"><mixed-citation publication-type="book" id="hbm70364-cit-0048"><string-name name-style="western"><surname>Kazemivash</surname>, <given-names>B.</given-names></string-name>, and <string-name name-style="western"><given-names>V. D.</given-names><surname>Calhoun</surname></string-name>. <year>2022b</year>. &#8220;<part-title>A 5d Approach to Study Spatio&#8208;Temporal Dynamism of Resting&#8208;State Brain Networks in Schizophrenia</part-title>.&#8221; In <source>2022 44th Annual International Conference of the IEEE Engineering in Medicine &amp; Biology Society (EMBC)</source>, <fpage>3737</fpage>&#8211;<lpage>3740</lpage>. <publisher-name>IEEE</publisher-name>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/EMBC48229.2022.9871362</pub-id><pub-id pub-id-type="pmid">36085717</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0049"><mixed-citation publication-type="journal" id="hbm70364-cit-0049"><string-name name-style="western"><surname>Kazemivash</surname>, <given-names>B.</given-names></string-name>, <string-name name-style="western"><given-names>T. G.</given-names><surname>van Erp</surname></string-name>, <string-name name-style="western"><given-names>P.</given-names><surname>Kochunov</surname></string-name>, and <string-name name-style="western"><given-names>V. D.</given-names><surname>Calhoun</surname></string-name>. <year>2023</year>. &#8220;<article-title>A Deep Residual Model for Characterization of 5d Spatiotemporal Network Dynamics Reveals Widespread Spatiodynamic Changes in Schizophrenia</article-title>.&#8221; <source>Frontiers in Neuroimaging</source><volume>2</volume>: <elocation-id>1097523</elocation-id>.<pub-id pub-id-type="pmid">37554628</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3389/fnimg.2023.1097523</pub-id><pub-id pub-id-type="pmcid">PMC10406273</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0050"><mixed-citation publication-type="book" id="hbm70364-cit-0050"><string-name name-style="western"><surname>Ke</surname>, <given-names>B.</given-names></string-name>, <string-name name-style="western"><given-names>A.</given-names><surname>Obukhov</surname></string-name>, <string-name name-style="western"><given-names>S.</given-names><surname>Huang</surname></string-name>, <string-name name-style="western"><given-names>N.</given-names><surname>Metzger</surname></string-name>, <string-name name-style="western"><given-names>R. C.</given-names><surname>Daudt</surname></string-name>, and <string-name name-style="western"><given-names>K.</given-names><surname>Schindler</surname></string-name>. <year>2024</year>. &#8220;<part-title>Repurposing Diffusion&#8208;Based Image Generators for Monocular Depth Estimation</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>, <fpage>9492</fpage>&#8211;<lpage>9502</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0051"><mixed-citation publication-type="journal" id="hbm70364-cit-0051"><string-name name-style="western"><surname>Kim</surname>, <given-names>D.&#8208;J.</given-names></string-name>, <string-name name-style="western"><given-names>A. B.</given-names><surname>Moussa&#8208;Tooks</surname></string-name>, <string-name name-style="western"><given-names>A. R.</given-names><surname>Bolbecker</surname></string-name>, et&#160;al. <year>2020</year>. &#8220;<article-title>Cerebellar&#8211;Cortical Dysconnectivity in Resting&#8208;State Associated With Sensorimotor Tasks in Schizophrenia</article-title>.&#8221; <source>Human Brain Mapping</source><volume>41</volume>, no. <issue>11</issue>: <fpage>3119</fpage>&#8211;<lpage>3132</lpage>.<pub-id pub-id-type="pmid">32250008</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/hbm.25002</pub-id><pub-id pub-id-type="pmcid">PMC7336143</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0052"><mixed-citation publication-type="journal" id="hbm70364-cit-0052"><string-name name-style="western"><surname>Klein</surname>, <given-names>J. C.</given-names></string-name>, <string-name name-style="western"><given-names>M. F.</given-names><surname>Rushworth</surname></string-name>, <string-name name-style="western"><given-names>T. E.</given-names><surname>Behrens</surname></string-name>, et&#160;al. <year>2010</year>. &#8220;<article-title>Topography of Connections Between Human Prefrontal Cortex and Mediodorsal Thalamus Studied With Diffusion Tractography</article-title>.&#8221; <source>NeuroImage</source><volume>51</volume>, no. <issue>2</issue>: <fpage>555</fpage>&#8211;<lpage>564</lpage>.<pub-id pub-id-type="pmid">20206702</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neuroimage.2010.02.062</pub-id><pub-id pub-id-type="pmcid">PMC2877805</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0053"><mixed-citation publication-type="journal" id="hbm70364-cit-0053"><string-name name-style="western"><surname>Lawrence</surname>, <given-names>R. M.</given-names></string-name>, <string-name name-style="western"><given-names>E. W.</given-names><surname>Bridgeford</surname></string-name>, <string-name name-style="western"><given-names>P. E.</given-names><surname>Myers</surname></string-name>, et&#160;al. <year>2021</year>. &#8220;<article-title>Standardizing Human Brain Parcellations</article-title>.&#8221; <source>Scientific Data</source><volume>8</volume>, no. <issue>1</issue>: <fpage>78</fpage>.<pub-id pub-id-type="pmid">33686079</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41597-021-00849-3</pub-id><pub-id pub-id-type="pmcid">PMC7940391</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0054"><mixed-citation publication-type="journal" id="hbm70364-cit-0054"><string-name name-style="western"><surname>Leech</surname>, <given-names>R.</given-names></string-name>, and <string-name name-style="western"><given-names>D. J.</given-names><surname>Sharp</surname></string-name>. <year>2014</year>. &#8220;<article-title>The Role of the Posterior Cingulate Cortex in Cognition and Disease</article-title>.&#8221; <source>Brain</source><volume>137</volume>, no. <issue>1</issue>: <fpage>12</fpage>&#8211;<lpage>32</lpage>.<pub-id pub-id-type="pmid">23869106</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/brain/awt162</pub-id><pub-id pub-id-type="pmcid">PMC3891440</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0055"><mixed-citation publication-type="journal" id="hbm70364-cit-0055"><string-name name-style="western"><surname>Li</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western"><given-names>L.</given-names><surname>Dahmani</surname></string-name>, <string-name name-style="western"><given-names>D.</given-names><surname>Wang</surname></string-name>, et&#160;al. <year>2021</year>. &#8220;<article-title>Co&#8208;Activation Patterns Across Multiple Tasks Reveal Robust Anti&#8208;Correlated Functional Networks</article-title>.&#8221; <source>NeuroImage</source><volume>227</volume>: <elocation-id>117680</elocation-id>.<pub-id pub-id-type="pmid">33359345</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neuroimage.2020.117680</pub-id><pub-id pub-id-type="pmcid">PMC8034806</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0056"><mixed-citation publication-type="miscellaneous" id="hbm70364-cit-0056"><string-name name-style="western"><surname>Li</surname>, <given-names>W.</given-names></string-name>, <string-name name-style="western"><given-names>C.</given-names><surname>Li</surname></string-name>, <string-name name-style="western"><given-names>Y.</given-names><surname>Wang</surname></string-name>, and <string-name name-style="western"><given-names>A.</given-names><surname>Wu</surname></string-name>. <year>2024</year>. <article-title>&#8220;Multi&#8208;region markovian gaussian process: An efficient method to discover directional communications across multiple brain regions,&#8221; arXiv preprint arXiv:2402.02686</article-title>.<pub-id pub-id-type="pmcid">PMC11526605</pub-id><pub-id pub-id-type="pmid">39483393</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0057"><mixed-citation publication-type="journal" id="hbm70364-cit-0057"><string-name name-style="western"><surname>Li</surname>, <given-names>Z.</given-names></string-name>, <string-name name-style="western"><given-names>X.</given-names><surname>Wang</surname></string-name>, <string-name name-style="western"><given-names>X.</given-names><surname>Liu</surname></string-name>, and <string-name name-style="western"><given-names>J.</given-names><surname>Jiang</surname></string-name>. <year>2024</year>. &#8220;<article-title>Binsformer: Revisiting Adaptive Bins for Monocular Depth Estimation</article-title>.&#8221; <source>IEEE Transactions on Image Processing</source><volume>33</volume>: <fpage>3964</fpage>&#8211;<lpage>3976</lpage>.<pub-id pub-id-type="pmid">38913511</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/TIP.2024.3416065</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0058"><mixed-citation publication-type="journal" id="hbm70364-cit-0058"><string-name name-style="western"><surname>Li&#233;geois</surname>, <given-names>R.</given-names></string-name>, <string-name name-style="western"><given-names>J.</given-names><surname>Li</surname></string-name>, <string-name name-style="western"><given-names>R.</given-names><surname>Kong</surname></string-name>, et&#160;al. <year>2019</year>. &#8220;<article-title>Resting Brain Dynamics at Different Timescales Capture Distinct Aspects of Human Behavior</article-title>.&#8221; <source>Nature Communications</source><volume>10</volume>, no. <issue>1</issue>: <elocation-id>2317</elocation-id>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41467-019-10317-7</pub-id><pub-id pub-id-type="pmcid">PMC6534566</pub-id><pub-id pub-id-type="pmid">31127095</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0059"><mixed-citation publication-type="journal" id="hbm70364-cit-0059"><string-name name-style="western"><surname>Lin</surname>, <given-names>Q.&#8208;H.</given-names></string-name>, <string-name name-style="western"><given-names>J.</given-names><surname>Liu</surname></string-name>, <string-name name-style="western"><given-names>Y.&#8208;R.</given-names><surname>Zheng</surname></string-name>, <string-name name-style="western"><given-names>H.</given-names><surname>Liang</surname></string-name>, and <string-name name-style="western"><given-names>V. D.</given-names><surname>Calhoun</surname></string-name>. <year>2010</year>. &#8220;<article-title>Semiblind Spatial ICA of fMRI Using Spatial Constraints</article-title>.&#8221; <source>Human Brain Mapping</source><volume>31</volume>, no. <issue>7</issue>: <fpage>1076</fpage>&#8211;<lpage>1088</lpage>.<pub-id pub-id-type="pmid">20017117</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/hbm.20919</pub-id><pub-id pub-id-type="pmcid">PMC2891131</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0060"><mixed-citation publication-type="book" id="hbm70364-cit-0060"><string-name name-style="western"><surname>Lin</surname>, <given-names>X.</given-names></string-name>, <string-name name-style="western"><given-names>F.</given-names><surname>Petroni</surname></string-name>, <string-name name-style="western"><given-names>G.</given-names><surname>Bertasius</surname></string-name>, <string-name name-style="western"><given-names>M.</given-names><surname>Rohrbach</surname></string-name>, <string-name name-style="western"><given-names>S.&#8208;F.</given-names><surname>Chang</surname></string-name>, and <string-name name-style="western"><given-names>L.</given-names><surname>Torresani</surname></string-name>. <year>2022</year>. &#8220;<part-title>Learning to Recognize Procedural Activities With Distant Supervision</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>, <fpage>13853</fpage>&#8211;<lpage>13863</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0061"><mixed-citation publication-type="book" id="hbm70364-cit-0061"><string-name name-style="western"><surname>Liu</surname>, <given-names>B.</given-names></string-name>, <string-name name-style="western"><given-names>I.</given-names><surname>Ben Ayed</surname></string-name>, <string-name name-style="western"><given-names>A.</given-names><surname>Galdran</surname></string-name>, and <string-name name-style="western"><given-names>J.</given-names><surname>Dolz</surname></string-name>. <year>2022</year>. &#8220;<part-title>The Devil Is in the Margin: Margin&#8208;Based Label Smoothing for Network Calibration</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>, <fpage>80</fpage>&#8211;<lpage>88</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0062"><mixed-citation publication-type="journal" id="hbm70364-cit-0062"><string-name name-style="western"><surname>Liu</surname>, <given-names>X.</given-names></string-name>, <string-name name-style="western"><given-names>N.</given-names><surname>Zhang</surname></string-name>, <string-name name-style="western"><given-names>C.</given-names><surname>Chang</surname></string-name>, and <string-name name-style="western"><given-names>J. H.</given-names><surname>Duyn</surname></string-name>. <year>2018</year>. &#8220;<article-title>Co&#8208;Activation Patterns in Resting&#8208;State fmri Signals</article-title>.&#8221; <source>NeuroImage</source><volume>180</volume>: <fpage>485</fpage>&#8211;<lpage>494</lpage>.<pub-id pub-id-type="pmid">29355767</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neuroimage.2018.01.041</pub-id><pub-id pub-id-type="pmcid">PMC6082734</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0063"><mixed-citation publication-type="book" id="hbm70364-cit-0063"><string-name name-style="western"><surname>Lu</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western"><given-names>Y.</given-names><surname>Zhang</surname></string-name>, <string-name name-style="western"><given-names>B.</given-names><surname>Han</surname></string-name>, <string-name name-style="western"><given-names>Y.&#8208;m.</given-names><surname>Cheung</surname></string-name>, and <string-name name-style="western"><given-names>H.</given-names><surname>Wang</surname></string-name>. <year>2023</year>. &#8220;<part-title>Label&#8208;Noise Learning With Intrinsically Long&#8208;Tailed Data</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF International Conference on Computer Vision</source>, <fpage>1369</fpage>&#8211;<lpage>1378</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0064"><mixed-citation publication-type="book" id="hbm70364-cit-0064"><string-name name-style="western"><surname>Luo</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western"><given-names>X.</given-names><surname>Li</surname></string-name>, <string-name name-style="western"><given-names>F.</given-names><surname>Yang</surname></string-name>, <string-name name-style="western"><given-names>J.</given-names><surname>Liu</surname></string-name>, <string-name name-style="western"><given-names>H.</given-names><surname>Fan</surname></string-name>, and <string-name name-style="western"><given-names>S.</given-names><surname>Liu</surname></string-name>. <year>2024</year>. &#8220;<part-title>Flowdiffuser: Advancing Optical Flow Estimation With Diffusion Models</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>, <fpage>19167</fpage>&#8211;<lpage>19176</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0065"><mixed-citation publication-type="book" id="hbm70364-cit-0065"><string-name name-style="western"><surname>Luo</surname>, <given-names>X.</given-names></string-name>, <string-name name-style="western"><given-names>A.</given-names><surname>Luo</surname></string-name>, <string-name name-style="western"><given-names>Z.</given-names><surname>Wang</surname></string-name>, <string-name name-style="western"><given-names>C.</given-names><surname>Lin</surname></string-name>, <string-name name-style="western"><given-names>B.</given-names><surname>Zeng</surname></string-name>, and <string-name name-style="western"><given-names>S.</given-names><surname>Liu</surname></string-name>. <year>2024</year>. &#8220;<part-title>Efficient Meshflow and Optical Flow Estimation From Event Cameras</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>, <fpage>19198</fpage>&#8211;<lpage>19207</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0066"><mixed-citation publication-type="book" id="hbm70364-cit-0066"><string-name name-style="western"><surname>Lv</surname>, <given-names>H.</given-names></string-name>, <string-name name-style="western"><given-names>Z.</given-names><surname>Yue</surname></string-name>, <string-name name-style="western"><given-names>Q.</given-names><surname>Sun</surname></string-name>, <string-name name-style="western"><given-names>B.</given-names><surname>Luo</surname></string-name>, <string-name name-style="western"><given-names>Z.</given-names><surname>Cui</surname></string-name>, and <string-name name-style="western"><given-names>H.</given-names><surname>Zhang</surname></string-name>. <year>2023</year>. &#8220;<part-title>Unbiased Multiple Instance Learning for Weakly Supervised Video Anomaly Detection</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>, <fpage>8022</fpage>&#8211;<lpage>8031</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0067"><mixed-citation publication-type="journal" id="hbm70364-cit-0067"><string-name name-style="western"><surname>Marino</surname>, <given-names>M.</given-names></string-name>, and <string-name name-style="western"><given-names>D.</given-names><surname>Mantini</surname></string-name>. <year>2024</year>. &#8220;<article-title>Human Brain Imaging With High&#8208;Density Electroencephalography: Techniques and Applications</article-title>.&#8221; <source>Journal of Physiology</source>, Online ahead of print, August 22. <pub-id pub-id-type="doi">10.1113/JP286639</pub-id>.<pub-id pub-id-type="pmid">39173191</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0068"><mixed-citation publication-type="journal" id="hbm70364-cit-0068"><string-name name-style="western"><surname>Matsui</surname>, <given-names>T.</given-names></string-name>, <string-name name-style="western"><given-names>T. Q.</given-names><surname>Pham</surname></string-name>, <string-name name-style="western"><given-names>K.</given-names><surname>Jimura</surname></string-name>, and <string-name name-style="western"><given-names>J.</given-names><surname>Chikazoe</surname></string-name>. <year>2022</year>. &#8220;<article-title>On Co&#8208;Activation Pattern Analysis and Non&#8208;Stationarity of Resting Brain Activity</article-title>.&#8221; <source>NeuroImage</source><volume>249</volume>: <elocation-id>118904</elocation-id>.<pub-id pub-id-type="pmid">35031473</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neuroimage.2022.118904</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0069"><mixed-citation publication-type="journal" id="hbm70364-cit-0069"><string-name name-style="western"><surname>Mayer</surname>, <given-names>A. R.</given-names></string-name>, <string-name name-style="western"><given-names>D.</given-names><surname>Ruhl</surname></string-name>, <string-name name-style="western"><given-names>F.</given-names><surname>Merideth</surname></string-name>, et&#160;al. <year>2013</year>. &#8220;<article-title>Functional Imaging of the Hemodynamic Sensory Gating Response in Schizophrenia</article-title>.&#8221; <source>Human Brain Mapping</source><volume>34</volume>, no. <issue>9</issue>: <fpage>2302</fpage>&#8211;<lpage>2312</lpage>.<pub-id pub-id-type="pmid">22461278</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/hbm.22065</pub-id><pub-id pub-id-type="pmcid">PMC4020570</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0070"><mixed-citation publication-type="journal" id="hbm70364-cit-0070"><string-name name-style="western"><surname>Moghimi</surname>, <given-names>P.</given-names></string-name>, <string-name name-style="western"><given-names>A. T.</given-names><surname>Dang</surname></string-name>, <string-name name-style="western"><given-names>Q.</given-names><surname>Do</surname></string-name>, <string-name name-style="western"><given-names>T. I.</given-names><surname>Netoff</surname></string-name>, <string-name name-style="western"><given-names>K. O.</given-names><surname>Lim</surname></string-name>, and <string-name name-style="western"><given-names>G.</given-names><surname>Atluri</surname></string-name>. <year>2022</year>. &#8220;<article-title>Evaluation of Functional Mri&#8208;Based Human Brain Parcellation: A Review</article-title>.&#8221; <source>Journal of Neurophysiology</source><volume>128</volume>, no. <issue>1</issue>: <fpage>197</fpage>&#8211;<lpage>217</lpage>.<pub-id pub-id-type="pmid">35675446</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1152/jn.00411.2021</pub-id><pub-id pub-id-type="pmcid">PMC9291407</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0071"><mixed-citation publication-type="journal" id="hbm70364-cit-0071"><string-name name-style="western"><surname>M&#252;ller</surname>, <given-names>R.</given-names></string-name>, <string-name name-style="western"><given-names>S.</given-names><surname>Kornblith</surname></string-name>, and <string-name name-style="western"><given-names>G. E.</given-names><surname>Hinton</surname></string-name>. <year>2019</year>. &#8220;<article-title>When Does Label Smoothing Help?</article-title>&#8221; <source>Advances in Neural Information Processing Systems</source><volume>32</volume>: <fpage>4696</fpage>&#8211;<lpage>4705</lpage>.</mixed-citation></ref><ref id="hbm70364-bib-0072"><mixed-citation publication-type="book" id="hbm70364-cit-0072"><string-name name-style="western"><surname>Murphy</surname>, <given-names>K. P.</given-names></string-name><year>2022</year>. <source>Probabilistic Machine Learning: An Introduction</source>. <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0073"><mixed-citation publication-type="book" id="hbm70364-cit-0073"><string-name name-style="western"><surname>Nguyen</surname>, <given-names>H. C.</given-names></string-name>, <string-name name-style="western"><given-names>T.</given-names><surname>Wang</surname></string-name>, <string-name name-style="western"><given-names>J. M.</given-names><surname>Alvarez</surname></string-name>, and <string-name name-style="western"><given-names>M.</given-names><surname>Liu</surname></string-name>. <year>2024</year>. &#8220;<part-title>Mining Supervision for Dynamic Regions in Self&#8208;Supervised Monocular Depth Estimation</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>, <fpage>10446</fpage>&#8211;<lpage>10455</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0074"><mixed-citation publication-type="journal" id="hbm70364-cit-0074"><string-name name-style="western"><surname>Omidvarnia</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western"><given-names>M.</given-names><surname>Pedersen</surname></string-name>, <string-name name-style="western"><given-names>J. M.</given-names><surname>Walz</surname></string-name>, <string-name name-style="western"><given-names>D. N.</given-names><surname>Vaughan</surname></string-name>, <string-name name-style="western"><given-names>D. F.</given-names><surname>Abbott</surname></string-name>, and <string-name name-style="western"><given-names>G. D.</given-names><surname>Jackson</surname></string-name>. <year>2016</year>. &#8220;<article-title>Dynamic Regional Phase Synchrony (Dreps) an Instantaneous Measure of Local fMRI Connectivity Within Spatially Clustered Brain Areas</article-title>.&#8221; <source>Human Brain Mapping</source><volume>37</volume>, no. <issue>5</issue>: <fpage>1970</fpage>&#8211;<lpage>1985</lpage>.<pub-id pub-id-type="pmid">27019380</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/hbm.23151</pub-id><pub-id pub-id-type="pmcid">PMC6867553</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0075"><mixed-citation publication-type="journal" id="hbm70364-cit-0075"><string-name name-style="western"><surname>O'reilly</surname>, <given-names>J. X.</given-names></string-name>, <string-name name-style="western"><given-names>C. F.</given-names><surname>Beckmann</surname></string-name>, <string-name name-style="western"><given-names>V.</given-names><surname>Tomassini</surname></string-name>, <string-name name-style="western"><given-names>N.</given-names><surname>Ramnani</surname></string-name>, and <string-name name-style="western"><given-names>H.</given-names><surname>Johansen&#8208;Berg</surname></string-name>. <year>2010</year>. &#8220;<article-title>Distinct and Overlapping Functional Zones in the Cerebellum Defined by Resting State Functional Connectivity</article-title>.&#8221; <source>Cerebral Cortex</source><volume>20</volume>, no. <issue>4</issue>: <fpage>953</fpage>&#8211;<lpage>965</lpage>.<pub-id pub-id-type="pmid">19684249</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/cercor/bhp157</pub-id><pub-id pub-id-type="pmcid">PMC2837094</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0076"><mixed-citation publication-type="journal" id="hbm70364-cit-0076"><string-name name-style="western"><surname>Pergola</surname>, <given-names>G.</given-names></string-name>, <string-name name-style="western"><given-names>P.</given-names><surname>Selvaggi</surname></string-name>, <string-name name-style="western"><given-names>S.</given-names><surname>Trizio</surname></string-name>, <string-name name-style="western"><given-names>A.</given-names><surname>Bertolino</surname></string-name>, and <string-name name-style="western"><given-names>G.</given-names><surname>Blasi</surname></string-name>. <year>2015</year>. &#8220;<article-title>The Role of the Thalamus in Schizophrenia From a Neuroimaging Perspective</article-title>.&#8221; <source>Neuroscience &amp; Biobehavioral Reviews</source><volume>54</volume>: <fpage>57</fpage>&#8211;<lpage>75</lpage>.<pub-id pub-id-type="pmid">25616183</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neubiorev.2015.01.013</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0077"><mixed-citation publication-type="journal" id="hbm70364-cit-0077"><string-name name-style="western"><surname>Pomarol&#8208;Clotet</surname>, <given-names>E.</given-names></string-name>, <string-name name-style="western"><given-names>E. J.</given-names><surname>Canales&#8208;Rodr&#237;guez</surname></string-name>, <string-name name-style="western"><given-names>R.</given-names><surname>Salvador</surname></string-name>, et&#160;al. <year>2010</year>. &#8220;<article-title>Medial Prefrontal Cortex Pathology in Schizophrenia as Revealed by Convergent Findings From Multimodal Imaging</article-title>.&#8221; <source>Molecular Psychiatry</source><volume>15</volume>, no. <issue>8</issue>: <fpage>823</fpage>&#8211;<lpage>830</lpage>.<pub-id pub-id-type="pmid">20065955</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/mp.2009.146</pub-id><pub-id pub-id-type="pmcid">PMC2927029</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0078"><mixed-citation publication-type="journal" id="hbm70364-cit-0078"><string-name name-style="western"><surname>Potkin</surname>, <given-names>S. G.</given-names></string-name>, and <string-name name-style="western"><given-names>J. M.</given-names><surname>Ford</surname></string-name>. <year>2009</year>. &#8220;<article-title>Widespread Cortical Dysfunction in Schizophrenia: The Fbirn Imaging Consortium</article-title>.&#8221; <source>Schizophrenia Bulletin</source><volume>35</volume>, no. <issue>1</issue>: <fpage>15</fpage>&#8211;<lpage>18</lpage>.<pub-id pub-id-type="pmid">19023124</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/schbul/sbn159</pub-id><pub-id pub-id-type="pmcid">PMC2643955</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0079"><mixed-citation publication-type="journal" id="hbm70364-cit-0079"><string-name name-style="western"><surname>Qi</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western"><given-names>W.</given-names><surname>Zhao</surname></string-name>, and <string-name name-style="western"><given-names>X.</given-names><surname>Wu</surname></string-name>. <year>2024</year>. &#8220;<article-title>Relational Distant Supervision for Image Captioning Without Image&#8208;Text Pairs</article-title>.&#8221; <source>Proceedings of the AAAI Conference on Artificial Intelligence</source><volume>38</volume>, no. <issue>5</issue>: <fpage>4524</fpage>&#8211;<lpage>4532</lpage>.</mixed-citation></ref><ref id="hbm70364-bib-0080"><mixed-citation publication-type="journal" id="hbm70364-cit-0080"><string-name name-style="western"><surname>Ragland</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western"><given-names>E.</given-names><surname>Layher</surname></string-name>, <string-name name-style="western"><given-names>D.</given-names><surname>Hannula</surname></string-name>, et&#160;al. <year>2017</year>. &#8220;<article-title>Impact of Schizophrenia on Anterior and Posterior Hippocampus During Memory for Complex Scenes</article-title>.&#8221; <source>NeuroImage: Clinical</source><volume>13</volume>: <fpage>82</fpage>&#8211;<lpage>88</lpage>.<pub-id pub-id-type="pmid">27942450</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.nicl.2016.11.017</pub-id><pub-id pub-id-type="pmcid">PMC5133646</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0081"><mixed-citation publication-type="journal" id="hbm70364-cit-0081"><string-name name-style="western"><surname>Raut</surname>, <given-names>R. V.</given-names></string-name>, <string-name name-style="western"><given-names>A. Z.</given-names><surname>Snyder</surname></string-name>, and <string-name name-style="western"><given-names>M. E.</given-names><surname>Raichle</surname></string-name>. <year>2020</year>. &#8220;<article-title>Hierarchical Dynamics as a Macroscopic Organizing Principle of the Human Brain</article-title>.&#8221; <source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>117</volume>, no. <issue>34</issue>: <fpage>20890</fpage>&#8211;<lpage>20897</lpage>.<pub-id pub-id-type="pmid">32817467</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1073/pnas.2003383117</pub-id><pub-id pub-id-type="pmcid">PMC7456098</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0082"><mixed-citation publication-type="book" id="hbm70364-cit-0082"><string-name name-style="western"><surname>Rokham</surname>, <given-names>H.</given-names></string-name>, <string-name name-style="western"><given-names>H.</given-names><surname>Falakshahi</surname></string-name>, and <string-name name-style="western"><given-names>V. D.</given-names><surname>Calhoun</surname></string-name>. <year>2023</year>. &#8220;<part-title>A Deep Learning Approach for Psychosis Spectrum Label Noise Detection From Multimodal Neuroimaging Data</part-title>.&#8221; In <source>2023 45th Annual International Conference of the IEEE Engineering in Medicine &amp; Biology Society (EMBC)</source>, <fpage>1</fpage>&#8211;<lpage>4</lpage>. <publisher-name>IEEE</publisher-name>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/EMBC40787.2023.10339949</pub-id><pub-id pub-id-type="pmid">38082903</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0083"><mixed-citation publication-type="journal" id="hbm70364-cit-0083"><string-name name-style="western"><surname>Rokham</surname>, <given-names>H.</given-names></string-name>, <string-name name-style="western"><given-names>G.</given-names><surname>Pearlson</surname></string-name>, <string-name name-style="western"><given-names>A.</given-names><surname>Abrol</surname></string-name>, <string-name name-style="western"><given-names>H.</given-names><surname>Falakshahi</surname></string-name>, <string-name name-style="western"><given-names>S.</given-names><surname>Plis</surname></string-name>, and <string-name name-style="western"><given-names>V. D.</given-names><surname>Calhoun</surname></string-name>. <year>2020</year>. &#8220;<article-title>Addressing Inaccurate Nosology in Mental Health: A Multilabel Data Cleansing Approach for Detecting Label Noise From Structural Magnetic Resonance Imaging Data in Mood and Psychosis Disorders</article-title>.&#8221; <source>Biological Psychiatry: Cognitive Neuroscience and Neuroimaging</source><volume>5</volume>, no. <issue>8</issue>: <fpage>819</fpage>&#8211;<lpage>832</lpage>.<pub-id pub-id-type="pmid">32771180</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.bpsc.2020.05.008</pub-id><pub-id pub-id-type="pmcid">PMC7760893</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0084"><mixed-citation publication-type="journal" id="hbm70364-cit-0084"><string-name name-style="western"><surname>Ruchalski</surname>, <given-names>K.</given-names></string-name>, and <string-name name-style="western"><given-names>G. M.</given-names><surname>Hathout</surname></string-name>. <year>2012</year>. &#8220;<article-title>A Medley of Midbrain Maladies: A Brief Review of Midbrain Anatomy and Syndromology for Radiologists</article-title>.&#8221; <source>Radiology Research and Practice</source><volume>2012</volume>, no. <issue>1</issue>: <fpage>258524</fpage>.<pub-id pub-id-type="pmid">22693668</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1155/2012/258524</pub-id><pub-id pub-id-type="pmcid">PMC3366251</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0085"><mixed-citation publication-type="journal" id="hbm70364-cit-0085"><string-name name-style="western"><surname>Saalmann</surname>, <given-names>Y. B.</given-names></string-name>, and <string-name name-style="western"><given-names>S.</given-names><surname>Kastner</surname></string-name>. <year>2011</year>. &#8220;<article-title>Cognitive and Perceptual Functions of the Visual Thalamus</article-title>.&#8221; <source>Neuron</source><volume>71</volume>, no. <issue>2</issue>: <fpage>209</fpage>&#8211;<lpage>223</lpage>.<pub-id pub-id-type="pmid">21791281</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neuron.2011.06.027</pub-id><pub-id pub-id-type="pmcid">PMC3148184</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0086"><mixed-citation publication-type="journal" id="hbm70364-cit-0086"><string-name name-style="western"><surname>Sadaghiani</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western"><given-names>R.</given-names><surname>Scheeringa</surname></string-name>, <string-name name-style="western"><given-names>K.</given-names><surname>Lehongre</surname></string-name>, et&#160;al. <year>2012</year>. &#8220;<article-title>Alpha&#8208;Band Phase Synchrony Is Related to Activity in the Fronto&#8208;Parietal Adaptive Control Network</article-title>.&#8221; <source>Journal of Neuroscience</source><volume>32</volume>, no. <issue>41</issue>: <fpage>14305</fpage>&#8211;<lpage>14310</lpage>.<pub-id pub-id-type="pmid">23055501</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1523/JNEUROSCI.1358-12.2012</pub-id><pub-id pub-id-type="pmcid">PMC4057938</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0087"><mixed-citation publication-type="journal" id="hbm70364-cit-0087"><string-name name-style="western"><surname>Savva</surname>, <given-names>A. D.</given-names></string-name>, <string-name name-style="western"><given-names>M.</given-names><surname>Kassinopoulos</surname></string-name>, <string-name name-style="western"><given-names>N.</given-names><surname>Smyrnis</surname></string-name>, <string-name name-style="western"><given-names>G. K.</given-names><surname>Matsopoulos</surname></string-name>, and <string-name name-style="western"><given-names>G. D.</given-names><surname>Mitsis</surname></string-name>. <year>2020</year>. &#8220;<article-title>Effects of Motion Related Outliers in Dynamic Functional Connectivity Using the Sliding Window Method</article-title>.&#8221; <source>Journal of Neuroscience Methods</source><volume>330</volume>: <elocation-id>108519</elocation-id>.<pub-id pub-id-type="pmid">31730872</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.jneumeth.2019.108519</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0088"><mixed-citation publication-type="journal" id="hbm70364-cit-0088"><string-name name-style="western"><surname>Savva</surname>, <given-names>A. D.</given-names></string-name>, <string-name name-style="western"><given-names>G. D.</given-names><surname>Mitsis</surname></string-name>, and <string-name name-style="western"><given-names>G. K.</given-names><surname>Matsopoulos</surname></string-name>. <year>2019</year>. &#8220;<article-title>Assessment of Dynamic Functional Connectivity in Resting&#8208;State fMRI Using the Sliding Window Technique</article-title>.&#8221; <source>Brain and Behavior: A Cognitive Neuroscience Perspective</source><volume>9</volume>, no. <issue>4</issue>: <elocation-id>e01255</elocation-id>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/brb3.1255</pub-id><pub-id pub-id-type="pmcid">PMC6456784</pub-id><pub-id pub-id-type="pmid">30884215</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0089"><mixed-citation publication-type="journal" id="hbm70364-cit-0089"><string-name name-style="western"><surname>Seeburger</surname>, <given-names>D. T.</given-names></string-name>, <string-name name-style="western"><given-names>N.</given-names><surname>Xu</surname></string-name>, <string-name name-style="western"><given-names>M.</given-names><surname>Ma</surname></string-name>, et&#160;al. <year>2024</year>. &#8220;<article-title>Time&#8208;Varying Functional Connectivity Predicts Fluctuations in Sustained Attention in a Serial Tapping Task</article-title>.&#8221; <source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><volume>24</volume>, no. <issue>1</issue>: <fpage>111</fpage>&#8211;<lpage>125</lpage>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.3758/s13415-024-01156-1</pub-id><pub-id pub-id-type="pmcid">PMC10979291</pub-id><pub-id pub-id-type="pmid">38253775</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0090"><mixed-citation publication-type="journal" id="hbm70364-cit-0090"><string-name name-style="western"><surname>Selemon</surname>, <given-names>L.</given-names></string-name>, and <string-name name-style="western"><given-names>N.</given-names><surname>Zecevic</surname></string-name>. <year>2015</year>. &#8220;<article-title>Schizophrenia: A Tale of Two Critical Periods for Prefrontal Cortical Development</article-title>.&#8221; <source>Translational Psychiatry</source><volume>5</volume>, no. <issue>8</issue>: <elocation-id>e623</elocation-id>.<pub-id pub-id-type="pmid">26285133</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/tp.2015.115</pub-id><pub-id pub-id-type="pmcid">PMC4564568</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0091"><mixed-citation publication-type="journal" id="hbm70364-cit-0091"><string-name name-style="western"><surname>Shakil</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western"><given-names>C.&#8208;H.</given-names><surname>Lee</surname></string-name>, and <string-name name-style="western"><given-names>S. D.</given-names><surname>Keilholz</surname></string-name>. <year>2016</year>. &#8220;<article-title>Evaluation of Sliding Window Correlation Performance for Characterizing Dynamic Functional Connectivity and Brain States</article-title>.&#8221; <source>NeuroImage</source><volume>133</volume>: <fpage>111</fpage>&#8211;<lpage>128</lpage>.<pub-id pub-id-type="pmid">26952197</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neuroimage.2016.02.074</pub-id><pub-id pub-id-type="pmcid">PMC4889509</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0092"><mixed-citation publication-type="journal" id="hbm70364-cit-0092"><string-name name-style="western"><surname>Soler&#8208;Vidal</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western"><given-names>P.</given-names><surname>Fuentes&#8208;Claramonte</surname></string-name>, <string-name name-style="western"><given-names>P.</given-names><surname>Salgado&#8208;Pineda</surname></string-name>, et&#160;al. <year>2022</year>. &#8220;<article-title>Brain Correlates of Speech Perception in Schizophrenia Patients With and Without Auditory Hallucinations</article-title>.&#8221; <source>PLoS One</source><volume>17</volume>, no. <issue>12</issue>: <elocation-id>e0276975</elocation-id>.<pub-id pub-id-type="pmid">36525414</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1371/journal.pone.0276975</pub-id><pub-id pub-id-type="pmcid">PMC9757556</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0093"><mixed-citation publication-type="journal" id="hbm70364-cit-0093"><string-name name-style="western"><surname>Sporns</surname>, <given-names>O.</given-names></string-name><year>2022</year>. &#8220;<article-title>The Complex Brain: Connectivity, Dynamics, Information</article-title>.&#8221; <source>Trends in Cognitive Sciences</source><volume>26</volume>, no. <issue>12</issue>: <fpage>1066</fpage>&#8211;<lpage>1067</lpage>.<pub-id pub-id-type="pmid">36207260</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.tics.2022.08.002</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0094"><mixed-citation publication-type="journal" id="hbm70364-cit-0094"><string-name name-style="western"><surname>Stevens</surname>, <given-names>F. L.</given-names></string-name>, <string-name name-style="western"><given-names>R. A.</given-names><surname>Hurley</surname></string-name>, and <string-name name-style="western"><given-names>K. H.</given-names><surname>Taber</surname></string-name>. <year>2011</year>. &#8220;<article-title>Anterior Cingulate Cortex: Unique Role in Cognition and Emotion</article-title>.&#8221; <source>Journal of Neuropsychiatry and Clinical Neurosciences</source><volume>23</volume>, no. <issue>2</issue>: <fpage>121</fpage>&#8211;<lpage>125</lpage>.<pub-id pub-id-type="pmid">21677237</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1176/jnp.23.2.jnp121</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0095"><mixed-citation publication-type="journal" id="hbm70364-cit-0095"><string-name name-style="western"><surname>Sun</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western"><given-names>W.</given-names><surname>Wang</surname></string-name>, <string-name name-style="western"><given-names>A.</given-names><surname>Howard</surname></string-name>, <string-name name-style="western"><given-names>Q.</given-names><surname>Yu</surname></string-name>, <string-name name-style="western"><given-names>P.</given-names><surname>Torr</surname></string-name>, and <string-name name-style="western"><given-names>L.&#8208;C.</given-names><surname>Chen</surname></string-name>. <year>2024</year>. &#8220;<article-title>Remax: Relaxing for Better Training on Efficient Panoptic Segmentation</article-title>.&#8221; <source>Advances in Neural Information Processing Systems</source><volume>36</volume>: <fpage>73480</fpage>&#8211;<lpage>73496</lpage>.</mixed-citation></ref><ref id="hbm70364-bib-0096"><mixed-citation publication-type="book" id="hbm70364-cit-0096"><string-name name-style="western"><surname>Sung</surname>, <given-names>C.</given-names></string-name>, <string-name name-style="western"><given-names>W.</given-names><surname>Kim</surname></string-name>, <string-name name-style="western"><given-names>J.</given-names><surname>An</surname></string-name>, <string-name name-style="western"><given-names>W.</given-names><surname>Lee</surname></string-name>, <string-name name-style="western"><given-names>H.</given-names><surname>Lim</surname></string-name>, and <string-name name-style="western"><given-names>H.</given-names><surname>Myung</surname></string-name>. <year>2024</year>. &#8220;<part-title>Contextrast: Contextual Contrastive Learning for Semantic Segmentation</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>, <fpage>3732</fpage>&#8211;<lpage>3742</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0097"><mixed-citation publication-type="book" id="hbm70364-cit-0097"><string-name name-style="western"><surname>Szymanowicz</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western"><given-names>C.</given-names><surname>Rupprecht</surname></string-name>, and <string-name name-style="western"><given-names>A.</given-names><surname>Vedaldi</surname></string-name>. <year>2024</year>. &#8220;<part-title>Splatter Image: Ultra&#8208;Fast Single&#8208;View 3d Reconstruction</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>, <fpage>10208</fpage>&#8211;<lpage>10217</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0098"><mixed-citation publication-type="journal" id="hbm70364-cit-0098"><string-name name-style="western"><surname>Thompson</surname>, <given-names>G. J.</given-names></string-name>, <string-name name-style="western"><given-names>W.&#8208;J.</given-names><surname>Pan</surname></string-name>, <string-name name-style="western"><given-names>M. E.</given-names><surname>Magnuson</surname></string-name>, <string-name name-style="western"><given-names>D.</given-names><surname>Jaeger</surname></string-name>, and <string-name name-style="western"><given-names>S. D.</given-names><surname>Keilholz</surname></string-name>. <year>2014</year>. &#8220;<article-title>Quasi&#8208;Periodic Patterns (Qpp): Large&#8208;Scale Dynamics in Resting State fMRI That Correlate With Local Infraslow Electrical Activity</article-title>.&#8221; <source>NeuroImage</source><volume>84</volume>: <fpage>1018</fpage>&#8211;<lpage>1031</lpage>.<pub-id pub-id-type="pmid">24071524</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.neuroimage.2013.09.029</pub-id><pub-id pub-id-type="pmcid">PMC3869452</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0099"><mixed-citation publication-type="journal" id="hbm70364-cit-0099"><string-name name-style="western"><surname>Turk&#8208;Browne</surname>, <given-names>N. B.</given-names></string-name><year>2019</year>. &#8220;<article-title>The Hippocampus as a Visual Area Organized by Space and Time: A Spatiotemporal Similarity Hypothesis</article-title>.&#8221; <source>Vision Research</source><volume>165</volume>: <fpage>123</fpage>&#8211;<lpage>130</lpage>.<pub-id pub-id-type="pmid">31734633</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.visres.2019.10.007</pub-id><pub-id pub-id-type="pmcid">PMC6881556</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0100"><mixed-citation publication-type="journal" id="hbm70364-cit-0100"><string-name name-style="western"><surname>Uddin</surname>, <given-names>L. Q.</given-names></string-name>, <string-name name-style="western"><given-names>K.</given-names><surname>Supekar</surname></string-name>, <string-name name-style="western"><given-names>H.</given-names><surname>Amin</surname></string-name>, et&#160;al. <year>2010</year>. &#8220;<article-title>Dissociable Connectivity Within Human Angular Gyrus and Intraparietal Sulcus: Evidence From Functional and Structural Connectivity</article-title>.&#8221; <source>Cerebral Cortex</source><volume>20</volume>, no. <issue>11</issue>: <fpage>2636</fpage>&#8211;<lpage>2646</lpage>.<pub-id pub-id-type="pmid">20154013</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/cercor/bhq011</pub-id><pub-id pub-id-type="pmcid">PMC2951845</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0101"><mixed-citation publication-type="journal" id="hbm70364-cit-0101"><string-name name-style="western"><surname>Usrey</surname>, <given-names>W. M.</given-names></string-name>, and <string-name name-style="western"><given-names>H. J.</given-names><surname>Alitto</surname></string-name>. <year>2015</year>. &#8220;<article-title>Visual Functions of the Thalamus</article-title>.&#8221; <source>Annual Review of Vision Science</source><volume>1</volume>, no. <issue>1</issue>: <fpage>351</fpage>&#8211;<lpage>371</lpage>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1146/annurev-vision-082114-035920</pub-id><pub-id pub-id-type="pmcid">PMC5310631</pub-id><pub-id pub-id-type="pmid">28217740</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0102"><mixed-citation publication-type="journal" id="hbm70364-cit-0102"><string-name name-style="western"><surname>van der Stelt</surname>, <given-names>O.</given-names></string-name>, <string-name name-style="western"><given-names>J. A.</given-names><surname>Lieberman</surname></string-name>, and <string-name name-style="western"><given-names>A.</given-names><surname>Belger</surname></string-name>. <year>2006</year>. &#8220;<article-title>Attentional Modulation of Early&#8208;Stage Visual Processing in Schizophrenia</article-title>.&#8221; <source>Brain Research</source><volume>1125</volume>, no. <issue>1</issue>: <fpage>194</fpage>&#8211;<lpage>198</lpage>.<pub-id pub-id-type="pmid">17087921</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.brainres.2006.09.099</pub-id><pub-id pub-id-type="pmcid">PMC1933501</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0103"><mixed-citation publication-type="journal" id="hbm70364-cit-0103"><string-name name-style="western"><surname>Vergara</surname>, <given-names>V. M.</given-names></string-name>, <string-name name-style="western"><given-names>A.</given-names><surname>Abrol</surname></string-name>, and <string-name name-style="western"><given-names>V. D.</given-names><surname>Calhoun</surname></string-name>. <year>2019</year>. &#8220;<article-title>An Average Sliding Window Correlation Method for Dynamic Functional Connectivity</article-title>.&#8221; <source>Human Brain Mapping</source><volume>40</volume>, no. <issue>7</issue>: <fpage>2089</fpage>&#8211;<lpage>2103</lpage>.<pub-id pub-id-type="pmid">30659699</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1002/hbm.24509</pub-id><pub-id pub-id-type="pmcid">PMC6865616</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0104"><mixed-citation publication-type="journal" id="hbm70364-cit-0104"><string-name name-style="western"><surname>Walton</surname>, <given-names>E.</given-names></string-name>, <string-name name-style="western"><given-names>D. P.</given-names><surname>Hibar</surname></string-name>, <string-name name-style="western"><given-names>T. G.</given-names><surname>van Erp</surname></string-name>, et&#160;al. <year>2017</year>. &#8220;<article-title>Left Medial Orbitofrontal Cortical Thinning Is Associated With Negative Symptom Severity in Schizophrenia: A Meta&#8208;Analysis by the Enigma&#8208;Schizophrenia Consortium</article-title>.&#8221; <source>Psychological Medicine</source><volume>48</volume>, no. <issue>1</issue>: <fpage>82</fpage>.<pub-id pub-id-type="pmid">28545597</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1017/S0033291717001283</pub-id><pub-id pub-id-type="pmcid">PMC5826665</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0105"><mixed-citation publication-type="journal" id="hbm70364-cit-0105"><string-name name-style="western"><surname>Wang</surname>, <given-names>H.</given-names></string-name>, <string-name name-style="western"><given-names>L.&#8208;L.</given-names><surname>Zeng</surname></string-name>, <string-name name-style="western"><given-names>Y.</given-names><surname>Chen</surname></string-name>, <string-name name-style="western"><given-names>H.</given-names><surname>Yin</surname></string-name>, <string-name name-style="western"><given-names>Q.</given-names><surname>Tan</surname></string-name>, and <string-name name-style="western"><given-names>D.</given-names><surname>Hu</surname></string-name>. <year>2015</year>. &#8220;<article-title>Evidence of a Dissociation Pattern in Default Mode Subnetwork Functional Connectivity in Schizophrenia</article-title>.&#8221; <source>Scientific Reports</source><volume>5</volume>, no. <issue>1</issue>: <elocation-id>14655</elocation-id>.<pub-id pub-id-type="pmid">26419213</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/srep14655</pub-id><pub-id pub-id-type="pmcid">PMC4588504</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0106"><mixed-citation publication-type="book" id="hbm70364-cit-0106"><string-name name-style="western"><surname>Wei</surname>, <given-names>Z.</given-names></string-name>, <string-name name-style="western"><given-names>P.</given-names><surname>Chen</surname></string-name>, <string-name name-style="western"><given-names>X.</given-names><surname>Yu</surname></string-name>, <string-name name-style="western"><given-names>G.</given-names><surname>Li</surname></string-name>, <string-name name-style="western"><given-names>J.</given-names><surname>Jiao</surname></string-name>, and <string-name name-style="western"><given-names>Z.</given-names><surname>Han</surname></string-name>. <year>2024</year>. &#8220;<part-title>Semantic&#8208;Aware Sam for Point&#8208;Prompted Instance Segmentation</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>, <fpage>3585</fpage>&#8211;<lpage>3594</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0107"><mixed-citation publication-type="journal" id="hbm70364-cit-0107"><string-name name-style="western"><surname>Weng</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western"><given-names>M.</given-names><surname>Han</surname></string-name>, <string-name name-style="western"><given-names>H.</given-names><surname>He</surname></string-name>, et&#160;al. <year>2024</year>. &#8220;<article-title>Mask Propagation for Efficient Video Semantic Segmentation</article-title>.&#8221; <source>Advances in Neural Information Processing Systems</source><volume>36</volume>: <fpage>7170</fpage>&#8211;<lpage>7183</lpage>.</mixed-citation></ref><ref id="hbm70364-bib-0108"><mixed-citation publication-type="journal" id="hbm70364-cit-0108"><string-name name-style="western"><surname>Wible</surname>, <given-names>C. G.</given-names></string-name>, <string-name name-style="western"><given-names>A. P.</given-names><surname>Preus</surname></string-name>, and <string-name name-style="western"><given-names>R.</given-names><surname>Hashimoto</surname></string-name>. <year>2009</year>. &#8220;<article-title>A Cognitive Neuroscience View of Schizophrenic Symptoms: Abnormal Activation of a System for Social Perception and Communication</article-title>.&#8221; <source>Brain Imaging and Behavior</source><volume>3</volume>: <fpage>85</fpage>&#8211;<lpage>110</lpage>.<pub-id pub-id-type="pmid">19809534</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s11682-008-9052-1</pub-id><pub-id pub-id-type="pmcid">PMC2757313</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0109"><mixed-citation publication-type="journal" id="hbm70364-cit-0109"><string-name name-style="western"><surname>Woodward</surname>, <given-names>N. D.</given-names></string-name>, <string-name name-style="western"><given-names>B.</given-names><surname>Rogers</surname></string-name>, and <string-name name-style="western"><given-names>S.</given-names><surname>Heckers</surname></string-name>. <year>2011</year>. &#8220;<article-title>Functional Resting&#8208;State Networks Are Differentially Affected in Schizophrenia</article-title>.&#8221; <source>Schizophrenia Research</source><volume>130</volume>, no. <issue>1&#8211;3</issue>: <fpage>86</fpage>&#8211;<lpage>93</lpage>.<pub-id pub-id-type="pmid">21458238</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.schres.2011.03.010</pub-id><pub-id pub-id-type="pmcid">PMC3139756</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0110"><mixed-citation publication-type="book" id="hbm70364-cit-0110"><string-name name-style="western"><surname>Xia</surname>, <given-names>C.</given-names></string-name>, <string-name name-style="western"><given-names>X.</given-names><surname>Wang</surname></string-name>, <string-name name-style="western"><given-names>F.</given-names><surname>Lv</surname></string-name>, <string-name name-style="western"><given-names>X.</given-names><surname>Hao</surname></string-name>, and <string-name name-style="western"><given-names>Y.</given-names><surname>Shi</surname></string-name>. <year>2024</year>. &#8220;<part-title>Vit&#8208;Comer: Vision Transformer With Convolutional Multi&#8208;Scale Feature Interaction for Dense Predictions</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>, <fpage>5493</fpage>&#8211;<lpage>5502</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0111"><mixed-citation publication-type="book" id="hbm70364-cit-0111"><string-name name-style="western"><surname>Yang</surname>, <given-names>X.</given-names></string-name>, <string-name name-style="western"><given-names>L.</given-names><surname>Yuan</surname></string-name>, <string-name name-style="western"><given-names>K.</given-names><surname>Wilber</surname></string-name>, et&#160;al. <year>2024</year>. &#8220;<part-title>Polymax: General Dense Prediction With Mask Transformer</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</source>, <fpage>1050</fpage>&#8211;<lpage>1061</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0112"><mixed-citation publication-type="book" id="hbm70364-cit-0112"><string-name name-style="western"><surname>Yang</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western"><given-names>P.&#8208;T.</given-names><surname>Jiang</surname></string-name>, <string-name name-style="western"><given-names>Q.</given-names><surname>Hou</surname></string-name>, <string-name name-style="western"><given-names>H.</given-names><surname>Zhang</surname></string-name>, <string-name name-style="western"><given-names>J.</given-names><surname>Chen</surname></string-name>, and <string-name name-style="western"><given-names>B.</given-names><surname>Li</surname></string-name>. <year>2024</year>. &#8220;<part-title>Multi&#8208;Task Dense Prediction via Mixture of Low&#8208;Rank Experts</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>, <fpage>27927</fpage>&#8211;<lpage>27937</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0113"><mixed-citation publication-type="book" id="hbm70364-cit-0113"><string-name name-style="western"><surname>Yao</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western"><given-names>A.</given-names><surname>Zhang</surname></string-name>, <string-name name-style="western"><given-names>X.</given-names><surname>Han</surname></string-name>, et&#160;al. <year>2021</year>. &#8220;<part-title>Visual Distant Supervision for Scene Graph Generation</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF International Conference on Computer Vision</source>, <fpage>15816</fpage>&#8211;<lpage>15826</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0114"><mixed-citation publication-type="journal" id="hbm70364-cit-0114"><string-name name-style="western"><surname>Yildiz</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western"><given-names>S. J.</given-names><surname>Borgwardt</surname></string-name>, and <string-name name-style="western"><given-names>G. E.</given-names><surname>Berger</surname></string-name>. <year>2011</year>. &#8220;<article-title>Parietal Lobes in Schizophrenia: Do They Matter?</article-title>&#8221; <source>Schizophrenia Research and Treatment</source><volume>2011</volume>, no. <issue>1</issue>: <fpage>581686</fpage>.<pub-id pub-id-type="pmid">22937268</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1155/2011/581686</pub-id><pub-id pub-id-type="pmcid">PMC3420742</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0115"><mixed-citation publication-type="journal" id="hbm70364-cit-0115"><string-name name-style="western"><surname>Yoshida</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western"><given-names>M.</given-names><surname>O&#241;ate</surname></string-name>, <string-name name-style="western"><given-names>L.</given-names><surname>Khatami</surname></string-name>, <string-name name-style="western"><given-names>J.</given-names><surname>Vera</surname></string-name>, <string-name name-style="western"><given-names>F.</given-names><surname>Nadim</surname></string-name>, and <string-name name-style="western"><given-names>K.</given-names><surname>Khodakhah</surname></string-name>. <year>2022</year>. &#8220;<article-title>Cerebellar Contributions to the Basal Ganglia Influence Motor Coordination, Reward Processing, and Movement Vigor</article-title>.&#8221; <source>Journal of Neuroscience</source><volume>42</volume>, no. <issue>45</issue>: <fpage>8406</fpage>&#8211;<lpage>8415</lpage>.<pub-id pub-id-type="pmid">36351826</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1523/JNEUROSCI.1535-22.2022</pub-id><pub-id pub-id-type="pmcid">PMC9665921</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0116"><mixed-citation publication-type="book" id="hbm70364-cit-0116"><string-name name-style="western"><surname>Yuan</surname>, <given-names>T.</given-names></string-name>, <string-name name-style="western"><given-names>F.</given-names><surname>Wan</surname></string-name>, <string-name name-style="western"><given-names>M.</given-names><surname>Fu</surname></string-name>, et&#160;al. <year>2021</year>. &#8220;<part-title>Multiple Instance Active Learning for Object Detection</part-title>.&#8221; In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>, <fpage>5330</fpage>&#8211;<lpage>5339</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0117"><mixed-citation publication-type="journal" id="hbm70364-cit-0117"><string-name name-style="western"><surname>Zarghami</surname>, <given-names>T. S.</given-names></string-name>, <string-name name-style="western"><given-names>G.&#8208;A.</given-names><surname>Hossein&#8208;Zadeh</surname></string-name>, and <string-name name-style="western"><given-names>F.</given-names><surname>Bahrami</surname></string-name>. <year>2020</year>. &#8220;<article-title>Deep Temporal Organization of fMRI Phase Synchrony Modes Promotes Large&#8208;Scale Disconnection in Schizophrenia</article-title>.&#8221; <source>Frontiers in Neuroscience</source><volume>14</volume>: <elocation-id>214</elocation-id>.<pub-id pub-id-type="pmid">32292324</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3389/fnins.2020.00214</pub-id><pub-id pub-id-type="pmcid">PMC7118690</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0118"><mixed-citation publication-type="book" id="hbm70364-cit-0118"><string-name name-style="western"><surname>Zhang</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western"><given-names>X.</given-names><surname>Wang</surname></string-name>, and <string-name name-style="western"><given-names>H.</given-names><surname>Liu</surname></string-name>. <year>2024</year>. &#8220;<part-title>Functional Magnetic Resonance Imaging: An Overview of Technical Advances and Clinical Applications</part-title>.&#8221; In <source>AI&#8208;Driven Innovations in Digital Healthcare: Emerging Trends, Challenges, and Applications</source>, <fpage>120</fpage>&#8211;<lpage>140</lpage>. <publisher-name>Medical Information Science Reference</publisher-name>.</mixed-citation></ref><ref id="hbm70364-bib-0120"><mixed-citation publication-type="journal" id="hbm70364-cit-0120"><string-name name-style="western"><surname>Zhang</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western"><given-names>L.</given-names><surname>Lin</surname></string-name>, <string-name name-style="western"><given-names>D.</given-names><surname>Zhou</surname></string-name>, et&#160;al. <year>2024</year>. &#8220;<article-title>Age&#8208;Related Unstable Transient States and Imbalanced Activation Proportion of Brain Networks in People With Autism Spectrum Disorder: A Resting&#8208;State fMRI Study Using Co&#8208;Activation Pattern Analyses</article-title>.&#8221; <source>Network Neuroscience</source><volume>8</volume>: <fpage>1173</fpage>&#8211;<lpage>1191</lpage>.<pub-id pub-id-type="pmid">39735491</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1162/netn_a_00396</pub-id><pub-id pub-id-type="pmcid">PMC11674577</pub-id></mixed-citation></ref><ref id="hbm70364-bib-0121"><mixed-citation publication-type="journal" id="hbm70364-cit-0121"><string-name name-style="western"><surname>Zhao</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western"><given-names>T.</given-names><surname>Kirschenhofer</surname></string-name>, <string-name name-style="western"><given-names>M.</given-names><surname>Harvey</surname></string-name>, and <string-name name-style="western"><given-names>G.</given-names><surname>Rainer</surname></string-name>. <year>2024</year>. &#8220;<article-title>Mediodorsal Thalamus and Ventral Pallidum Contribute to Subcortical Regulation of the Default Mode Network</article-title>.&#8221; <source>Communications Biology</source><volume>7</volume>, no. <issue>1</issue>: <elocation-id>891</elocation-id>.<pub-id pub-id-type="pmid">39039239</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s42003-024-06531-9</pub-id><pub-id pub-id-type="pmcid">PMC11263694</pub-id></mixed-citation></ref></ref-list></back></article></pmc-articleset>