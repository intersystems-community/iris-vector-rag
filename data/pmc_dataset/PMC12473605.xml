<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xml:lang="en" article-type="research-article" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="pmc-domain-id">1660</journal-id><journal-id journal-id-type="pmc-domain">sensors</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>Multidisciplinary Digital Publishing Institute  (MDPI)</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12473605</article-id><article-id pub-id-type="pmcid-ver">PMC12473605.1</article-id><article-id pub-id-type="pmcaid">12473605</article-id><article-id pub-id-type="pmcaiid">12473605</article-id><article-id pub-id-type="pmid">41013156</article-id><article-id pub-id-type="doi">10.3390/s25185918</article-id><article-id pub-id-type="publisher-id">sensors-25-05918</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Continuous Vibration-Driven Virtual Tactile Motion Perception Across Fingertips</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-8874-3586</contrib-id><name name-style="western"><surname>Adibi</surname><given-names initials="M">Mehdi</given-names></name><xref rid="af1-sensors-25-05918" ref-type="aff">1</xref><xref rid="af2-sensors-25-05918" ref-type="aff">2</xref></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name name-style="western"><surname>Sato</surname><given-names initials="W">Wataru</given-names></name><role>Academic Editor</role></contrib><contrib contrib-type="editor"><name name-style="western"><surname>Valle</surname><given-names initials="M">Maurizio</given-names></name><role>Academic Editor</role></contrib></contrib-group><aff id="af1-sensors-25-05918"><label>1</label>Turner Institute of Brain and Mental Health, School of Psychological Sciences, Monash University, Clayton, VIC 3800, Australia; <email>mehdi.adibi@monash.edu</email></aff><aff id="af2-sensors-25-05918"><label>2</label>Neurodigit Laboratory, Department of Physiology, Monash Biomedicine Discovery Institute, Monash University, Clayton, VIC 3800, Australia</aff><pub-date pub-type="epub"><day>22</day><month>9</month><year>2025</year></pub-date><pub-date pub-type="collection"><month>9</month><year>2025</year></pub-date><volume>25</volume><issue>18</issue><issue-id pub-id-type="pmc-issue-id">497667</issue-id><elocation-id>5918</elocation-id><history><date date-type="received"><day>13</day><month>7</month><year>2025</year></date><date date-type="rev-recd"><day>11</day><month>9</month><year>2025</year></date><date date-type="accepted"><day>16</day><month>9</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>22</day><month>09</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>27</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-28 18:25:14.327"><day>28</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; 2025 by the author.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="sensors-25-05918.pdf"/><abstract><p>Motion perception is a fundamental function of the tactile system, essential for object exploration and manipulation. While human studies have largely focused on discrete or pulsed stimuli with staggered onsets, many natural tactile signals are continuous and rhythmically patterned. Here, we investigate whether phase differences between &#8220;simultaneously&#8221; presented, &#8220;continuous&#8221; amplitude-modulated vibrations can induce the perception of motion across fingertips. Participants reliably perceived motion direction at modulation frequencies up to 1 Hz, with discrimination performance systematically dependent on the phase lag between vibrations. Critically, trial-level confidence reports revealed the lowest certainty for anti-phase (180&#176;) conditions, consistent with stimulus ambiguity as predicted by the mathematical framework. I propose two candidate computational mechanisms for tactile motion processing. The first is a conventional cross-correlation computation over the envelopes; the second is a probabilistic model based on the uncertain detection of temporal reference points (e.g., envelope peaks) within threshold-defined windows. This model, despite having only a single parameter (uncertainty width determined by an amplitude discrimination threshold), accounts for both the non-linear shape and asymmetries of observed psychometric functions. These results demonstrate that the human tactile system can extract directional information from distributed phase-coded signals in the absence of spatial displacement, revealing a motion perception mechanism that parallels arthropod systems but potentially arises from distinct perceptual constraints. The findings underscore the feasibility of sparse, phase-coded stimulation as a lightweight and reproducible method for conveying motion cues in wearable, motion-capable haptic devices.</p></abstract><kwd-group><kwd>tactile</kwd><kwd>motion</kwd><kwd>somatosensory</kwd><kwd>psychophysics</kwd><kwd>vibration</kwd><kwd>vibrotactile</kwd><kwd>haptic</kwd></kwd-group><funding-group><award-group><funding-source>Australian Research Council (ARC) Discovery Early Career Researcher Award (DECRA)</funding-source><award-id>DE200101468</award-id></award-group><funding-statement>Funded by the Australian Research Council (ARC) Discovery Early Career Researcher Award (DECRA), number DE200101468.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-25-05918"><title>1. Introduction</title><p>Motion is a fundamental quality of sensory input. In vision, despite diverse evolutionary trajectories across different species, from insects and cephalopods to vertebrates, visual systems have converged on fundamentally similar mechanisms of motion processing [<xref rid="B1-sensors-25-05918" ref-type="bibr">1</xref>,<xref rid="B2-sensors-25-05918" ref-type="bibr">2</xref>]. However, motion is not exclusive to vision; it is also a hallmark of the tactile sensory system, with considerable behavioural relevance for both animals and humans. Everyday interactions such as object manipulation and haptic exploration involve relative motion between the skin and surfaces [<xref rid="B3-sensors-25-05918" ref-type="bibr">3</xref>]. For example, discerning roughness and smoothness, identifying material properties (e.g. metal vs. wood) or recognising object shapes requires dynamic contact through palpation and movement. Reading Braille depends on lateral movement of the fingertips to interpret sequences of raised dots. Tactile motion processing underpins fine motor control and precise object manipulation [<xref rid="B4-sensors-25-05918" ref-type="bibr">4</xref>,<xref rid="B5-sensors-25-05918" ref-type="bibr">5</xref>]. Yet, the perceptual and computational mechanisms underlying tactile motion remain incompletely understood.</p><p>Two principal sources of information for tactile motion have been identified in the literature [<xref rid="B5-sensors-25-05918" ref-type="bibr">5</xref>,<xref rid="B6-sensors-25-05918" ref-type="bibr">6</xref>]. The first relies on the sequential activation of mechanoreceptors at different skin locations as an object or stimulus moves across the skin&#8212;such as when an insect crawls along the arm. This includes apparent tactile motion, typically studied experimentally using discrete, pulsed stimuli delivered in succession to separate skin sites [<xref rid="B7-sensors-25-05918" ref-type="bibr">7</xref>,<xref rid="B8-sensors-25-05918" ref-type="bibr">8</xref>,<xref rid="B9-sensors-25-05918" ref-type="bibr">9</xref>,<xref rid="B10-sensors-25-05918" ref-type="bibr">10</xref>,<xref rid="B11-sensors-25-05918" ref-type="bibr">11</xref>,<xref rid="B12-sensors-25-05918" ref-type="bibr">12</xref>,<xref rid="B13-sensors-25-05918" ref-type="bibr">13</xref>,<xref rid="B14-sensors-25-05918" ref-type="bibr">14</xref>]. The second source involves skin deformation cues, particularly shear and stretch, which arise during sliding contact or friction. These deformations can convey directional information [<xref rid="B15-sensors-25-05918" ref-type="bibr">15</xref>], potentially through recruitment of distinct afferent populations, such as slowly adapting type II (SA2) units, which are sensitive to stretch and contribute to motion direction perception [<xref rid="B16-sensors-25-05918" ref-type="bibr">16</xref>].</p><p>At the level of periphery, slowly adapting type I (SA1) afferents convey high-resolution spatial information about contact location [<xref rid="B4-sensors-25-05918" ref-type="bibr">4</xref>,<xref rid="B17-sensors-25-05918" ref-type="bibr">17</xref>,<xref rid="B18-sensors-25-05918" ref-type="bibr">18</xref>]. The spatiotemporal pattern of their population activity is thought to encode motion direction and speed with acuity comparable to human perceptual performance [<xref rid="B18-sensors-25-05918" ref-type="bibr">18</xref>]. Rapidly adapting type I (RA1) afferents may also contribute to motion encoding via spatiotemporal patterns, though with lower spatial precision due to their larger receptive fields [<xref rid="B18-sensors-25-05918" ref-type="bibr">18</xref>]. SA2 afferents, previously mentioned, respond to skin stretch and support motion direction perception through their tuning to deformation patterns [<xref rid="B15-sensors-25-05918" ref-type="bibr">15</xref>,<xref rid="B16-sensors-25-05918" ref-type="bibr">16</xref>].</p><p>Here, I investigate a third and less explored mechanism for tactile motion: the perception of motion across fingers induced by phase-shifted, continuous streams of vibrotactile input delivered to two fingertips simultaneously. Unlike prior studies that typically rely on either (a) sequential, pulsed stimulations delivered to multiple discrete skin sites [<xref rid="B7-sensors-25-05918" ref-type="bibr">7</xref>,<xref rid="B9-sensors-25-05918" ref-type="bibr">9</xref>,<xref rid="B11-sensors-25-05918" ref-type="bibr">11</xref>,<xref rid="B13-sensors-25-05918" ref-type="bibr">13</xref>,<xref rid="B14-sensors-25-05918" ref-type="bibr">14</xref>,<xref rid="B19-sensors-25-05918" ref-type="bibr">19</xref>] or (b) physical sliding stimuli that engage friction-induced skin deformation [<xref rid="B5-sensors-25-05918" ref-type="bibr">5</xref>,<xref rid="B6-sensors-25-05918" ref-type="bibr">6</xref>], this paradigm involves two spatially fixed but temporally dynamic inputs. The stimulation does not involve skin movement or high spatial acuity, but rather evokes motion percepts through temporal phase differences between inputs to two fingerpads.</p><p>In previous tactile motion paradigms, the perceived continuity and smoothness of motion heavily relied on spatial continuity, either through densely packed actuator arrays or by delivering real mechanical motion through skin deformation. Apparent motion displays such as the OPTACON device and related arrays use a dense grid of vibratory pins to create a sense of continuous motion across the fingertip but are limited to a spatial extent of only a few millimetres on the skin surface [<xref rid="B9-sensors-25-05918" ref-type="bibr">9</xref>,<xref rid="B10-sensors-25-05918" ref-type="bibr">10</xref>,<xref rid="B11-sensors-25-05918" ref-type="bibr">11</xref>,<xref rid="B14-sensors-25-05918" ref-type="bibr">14</xref>,<xref rid="B20-sensors-25-05918" ref-type="bibr">20</xref>,<xref rid="B21-sensors-25-05918" ref-type="bibr">21</xref>,<xref rid="B22-sensors-25-05918" ref-type="bibr">22</xref>,<xref rid="B23-sensors-25-05918" ref-type="bibr">23</xref>]. Other approaches have relied on mechanical motion cues, where probes or surfaces are physically moved across the fingerpad, generating tangential shear and frictional forces that produce a percept of continuous sliding motion [<xref rid="B24-sensors-25-05918" ref-type="bibr">24</xref>,<xref rid="B25-sensors-25-05918" ref-type="bibr">25</xref>,<xref rid="B26-sensors-25-05918" ref-type="bibr">26</xref>,<xref rid="B27-sensors-25-05918" ref-type="bibr">27</xref>,<xref rid="B28-sensors-25-05918" ref-type="bibr">28</xref>]. However, these strategies are limited either by spatial coverage or by employing actual mechanical movement, which is not ideal for compact or wearable devices. The approach introduced here departs from these conventions by using only two spatially coarse stimulators, with smooth, continuous motion percepts instead emerging from the temporal continuity of phase-shifted vibrotactile stimulation across the fingers. This demonstrates a novel, temporally driven mechanism for tactile motion perception that does not depend on dense actuator arrays or elaborate skin-deforming hardware. Previous studies using similar phase-shifted vibrotacitle stimuli failed to elicit tactile motion perception, because they tested only relatively high modulation frequencies (e.g., 5 Hz) [<xref rid="B29-sensors-25-05918" ref-type="bibr">29</xref>], which lie above the range supporting directional motion perception. In the present study, I demonstrate that directional motion emerges only at lower envelope frequencies (&#8804;1.5 Hz), thereby establishing the critical range that earlier studies overlooked.</p><p>Fingertips are among the most densely innervated tactile regions in human body [<xref rid="B30-sensors-25-05918" ref-type="bibr">30</xref>] and are primary organs for active exploration [<xref rid="B3-sensors-25-05918" ref-type="bibr">3</xref>]. This work uses continuous amplitude-modulated vibrations known to predominantly recruit rapidly adapting type II (RA2) afferents&#8212;i.e., Pacinian corpuscles&#8212;which are sensitive to high-frequency vibratory energy and exhibit large receptive fields [<xref rid="B31-sensors-25-05918" ref-type="bibr">31</xref>,<xref rid="B32-sensors-25-05918" ref-type="bibr">32</xref>,<xref rid="B33-sensors-25-05918" ref-type="bibr">33</xref>]. Unlike SA1 and RA1 afferents, RA2 units are less sensitive to fine spatial features but can detect remote vibratory events across skin and even bone. Notably, the stimuli here are delivered over the entire fingertip pad, eliminating reliance on fine spatial localisation, instead leveraging temporal synchrony or asynchrony across digits. This approach is analogous in principle to mechanisms found in certain arthropods, such as chelicerates, which detect and localise remote vibratory sources using their paired appendages [<xref rid="B34-sensors-25-05918" ref-type="bibr">34</xref>]. Similarly, humans may infer motion direction or location of a remote source by comparing asynchronous vibratory input across fingerpads [<xref rid="B35-sensors-25-05918" ref-type="bibr">35</xref>,<xref rid="B36-sensors-25-05918" ref-type="bibr">36</xref>]&#8212;effectively extending tactile spatial perception beyond the point of contact.</p><p>In this study, I first formalise the physical basis for detecting the location and direction of a remotely moving vibration source, and how such stimuli can be simulated through asynchronous amplitude-modulated input to two fingertips. I then present a series of psychophysical experiments characterising human perceptual performance in detecting the direction of such inferred motion, revealing a tactile motion perception mechanism that operates independently of spatial acuity or physical surface movement. This paradigm has implications for wearable and compact haptic interfaces such as those developed by Seim et al. [<xref rid="B37-sensors-25-05918" ref-type="bibr">37</xref>], de Vlam et al. [<xref rid="B38-sensors-25-05918" ref-type="bibr">38</xref>] and Huang et al. [<xref rid="B39-sensors-25-05918" ref-type="bibr">39</xref>], where efficient solutions for conveying directional motion are increasingly needed [<xref rid="B40-sensors-25-05918" ref-type="bibr">40</xref>,<xref rid="B41-sensors-25-05918" ref-type="bibr">41</xref>,<xref rid="B42-sensors-25-05918" ref-type="bibr">42</xref>]. Such applications include tactile displays, virtual and augmented reality (VR/AR) environments, and neuroprosthetic feedback systems [<xref rid="B41-sensors-25-05918" ref-type="bibr">41</xref>,<xref rid="B42-sensors-25-05918" ref-type="bibr">42</xref>,<xref rid="B43-sensors-25-05918" ref-type="bibr">43</xref>].</p></sec><sec id="sec2-sensors-25-05918"><title>2. Materials and Methods</title><p>Vibrotactile stimulation is a versatile method for conveying spatiotemporal information through the skin and has been widely employed in both fundamental research and haptic technology applications [<xref rid="B44-sensors-25-05918" ref-type="bibr">44</xref>]. Arrays of tactors delivering temporally staggered pulses have been used to generate apparent motion across body surfaces such as between hands, along the arm, or across the back, simulating a moving tactile stimulus without physical displacement [<xref rid="B8-sensors-25-05918" ref-type="bibr">8</xref>,<xref rid="B12-sensors-25-05918" ref-type="bibr">12</xref>,<xref rid="B19-sensors-25-05918" ref-type="bibr">19</xref>,<xref rid="B44-sensors-25-05918" ref-type="bibr">44</xref>,<xref rid="B45-sensors-25-05918" ref-type="bibr">45</xref>]. While such paradigms rely on discrete bursts or pulses with differences in stimulus onset timing across spatially distinct sites to evoke motion percepts, the current study employs continuous amplitude-modulated waveforms with controlled phase offsets, enabling investigation of motion perception from continuous, distributed, phase-coded signals in the absence of distinct onsets or spatial displacement.</p><p>To model the stimuli generated by a remotely vibrating source, such as a mobile phone on a table, we consider a point source emitting a sinusoidal carrier wave <inline-formula><mml:math id="mm1" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="prefix">sin</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mi>t</mml:mi></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="mm2" overflow="scroll"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm3" overflow="scroll"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> denote the amplitude and carrier frequency of vibration, respectively. As this vibration propagates through the substrate&#8212;e.g., the table&#8212;approximately as a plane wave, it undergoes attenuation due to dissipation, scattering, and absorption. This attenuation typically follows an exponential decay with distance:<disp-formula id="FD1-sensors-25-05918"><label>(1)</label><mml:math id="mm4" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mfenced open="(" close=")"><mml:mi>d</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="prefix">exp</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mo>&#8722;</mml:mo><mml:mi>&#947;</mml:mi><mml:mi>d</mml:mi></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm5" overflow="scroll"><mml:mrow><mml:mi>&#947;</mml:mi></mml:mrow></mml:math></inline-formula> is the attenuation coefficient (dependent on medium properties and frequency), and <italic toggle="yes">d</italic> is the distance from the source.</p><p>When the source moves relative to a fixed point, the amplitude at that point changes with time due to the variation in distance. These changes are proportional to the radial component of the source&#8217;s motion. In the special case of periodic movement at a frequency <inline-formula><mml:math id="mm6" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>&#8810;</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, the received signal envelope at a fixed remote point with time-varying distance <inline-formula><mml:math id="mm7" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> is itself periodic, and the received signal can be written as follows:<disp-formula id="FD2-sensors-25-05918"><label>(2)</label><mml:math id="mm8" display="block" overflow="scroll"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mrow><mml:mi>A</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="prefix">exp</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mo>&#8722;</mml:mo><mml:mi>&#947;</mml:mi><mml:mi>d</mml:mi><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced></mml:mfenced><mml:mo form="prefix">sin</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:msub><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mo>&#916;</mml:mo><mml:mi>f</mml:mi></mml:mfenced><mml:mi>t</mml:mi></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm9" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is the delay due to propagation over distance <inline-formula><mml:math id="mm10" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="mm11" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is the Doppler shift caused by the source&#8217;s motion. Both parameters <inline-formula><mml:math id="mm12" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm13" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> depend on the wave propagation speed in the medium, which is determined by its stiffness and density (e.g., &#8764;5790 ms<sup>&#8722;1</sup> in stainless steel, and &#8764;3960 ms<sup>&#8722;1</sup> in hard wood).</p><p>For distances on the order of a meter or less, <inline-formula><mml:math id="mm14" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> corresponds to sub-millisecond or nanosecond delays, well below biologically plausible detection thresholds. Moreover, assuming slow motion of source relative to wave propagation speed, and <inline-formula><mml:math id="mm15" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>&#8810;</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, the Doppler shift <inline-formula><mml:math id="mm16" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is negligible. Henceforth, I assume <inline-formula><mml:math id="mm17" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#8776;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm18" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>f</mml:mi><mml:mo>&#8776;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><sec id="sec2dot1-sensors-25-05918"><title>2.1. Motion Direction Estimation via Two Touch Points</title><p>When a sensor (e.g., a fingertip) is placed at a fixed point (hereafter a `touch point&#8217;), the direction of source movement along the radial axis (toward or away from the touch point) can be inferred from temporal changes in the vibration envelope. However, a single touch point provides no information about the tangential component of the motion. To recover trajectory information, at least two touch points positioned at distinct spatial locations are required (<xref rid="sensors-25-05918-f001" ref-type="fig">Figure 1</xref>).</p><p>Let <inline-formula><mml:math id="mm19" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm20" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> denote two such points. The envelopes of vibration received at these two locations can, in principle, be used to infer the moment-by-moment position of a moving source in two-dimensional (2D) space. However, the reconstruction is ambiguous: any trajectory and its mirror reflection across the line connecting the two touch points (the touch-point axis) yields identical vibration patterns. This is illustrated in <xref rid="sensors-25-05918-f001" ref-type="fig">Figure 1</xref>A.</p><p>In three-dimensional (3D) space, ambiguity increases: all trajectories that are rotationally symmetric around the touch-point axis produce indistinguishable vibration profiles at the two points. That is, any trajectory that can be rotated about this axis into another remains perceptually equivalent at the touch points, leading to infinite number of trajectories that create an identical vibration pattern at touch points <inline-formula><mml:math id="mm21" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm22" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>.</p><sec id="sec2dot1dot1-sensors-25-05918"><title>2.1.1. In-Phase Vibrations</title><p>As discussed, a periodic source movement with frequency <italic toggle="yes">f</italic> results in a periodic amplitude modulation at each touch point. If the envelopes at <inline-formula><mml:math id="mm23" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm24" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> vary together over time&#8212;i.e., they are monotonic transformations of one another under a strictly increasing odd function&#8212;they are said to be `in phase&#8217;. For example, consider a trajectory confined to a plane perpendicular to the touch-point axis (<xref rid="sensors-25-05918-f001" ref-type="fig">Figure 1</xref>B). The closest and farthest positions on the trajectory to <inline-formula><mml:math id="mm25" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> are identical to those to <inline-formula><mml:math id="mm26" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. Let <inline-formula><mml:math id="mm27" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> denote the instantaneous orthogonal distance from the touch-point axis to the source trajectory at any moment <italic toggle="yes">t</italic>, and let <inline-formula><mml:math id="mm28" overflow="scroll"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> be the perpendicular distance from touch point <inline-formula><mml:math id="mm29" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> to the plane of the trajectory. The amplitude at each touch point is given by the following equation:<disp-formula id="FD3-sensors-25-05918"><label>(3)</label><mml:math id="mm30" display="block" overflow="scroll"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="prefix">exp</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mo>&#8722;</mml:mo><mml:mi>&#947;</mml:mi><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced></mml:mrow></mml:msqrt></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula>
and the derivative:<disp-formula id="FD4-sensors-25-05918"><label>(4)</label><mml:math id="mm31" display="block" overflow="scroll"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mrow><mml:mfrac><mml:mi>d</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mo>&#8722;</mml:mo><mml:mi>&#947;</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mfrac><mml:mrow><mml:mi>h</mml:mi><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced></mml:mrow><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced></mml:mrow></mml:msqrt></mml:mfrac><mml:mo form="prefix">exp</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mo>&#8722;</mml:mo><mml:mi>&#947;</mml:mi><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced></mml:mrow></mml:msqrt></mml:mfenced><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula>
This shows that the envelope at each touch point changes in the same direction (increasing or decreasing together), confirming that they are in phase. Additionally, one can show the following:<disp-formula id="FD5-sensors-25-05918"><label>(5)</label><mml:math id="mm32" display="block" overflow="scroll"><mml:mrow><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="prefix">exp</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mo>&#8722;</mml:mo><mml:msqrt><mml:mrow><mml:msup><mml:mi>&#947;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mfenced separators="" open="(" close=")"><mml:msubsup><mml:mi>r</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mfenced><mml:mo>+</mml:mo><mml:msup><mml:mo form="prefix">ln</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:msub><mml:mi>A</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mfrac></mml:mstyle></mml:mrow></mml:msqrt></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>
which is a strictly increasing function of <inline-formula><mml:math id="mm33" overflow="scroll"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, again confirming phase alignment.</p></sec><sec id="sec2dot1dot2-sensors-25-05918"><title>2.1.2. Anti-Phase Vibrations</title><p>Two waveforms are anti-phase if their envelopes exhibit a phase difference of <inline-formula><mml:math id="mm34" overflow="scroll"><mml:mrow><mml:mi>&#960;</mml:mi></mml:mrow></mml:math></inline-formula>, such that when one increases, the other decreases. This occurs when the envelopes are related through a negatively proportional transformation under a strictly increasing odd function. In this case, the perceived direction of motion alternates across each half-cycle, creating a bouncing or bidirectional trajectory. Perceptually, such anti-phase vibration patterns may give rise to &#8220;bistable&#8221; motion perception, wherein the ambiguous temporal dynamics support two competing interpretations, with each corresponding to motion in opposite directions, that may alternate spontaneously over time. Examples of anti-phase configurations are shown in <xref rid="sensors-25-05918-f001" ref-type="fig">Figure 1</xref>D,E.</p></sec></sec><sec id="sec2dot2-sensors-25-05918"><title>2.2. Circular Motion of a Vibrating Source</title><p>Consider a point source moving along a circular trajectory with radius <inline-formula><mml:math id="mm35" overflow="scroll"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and constant tangential velocity <italic toggle="yes">v</italic> (<xref rid="sensors-25-05918-f001" ref-type="fig">Figure 1</xref>C). The frequency of motion is<disp-formula id="FD6-sensors-25-05918"><label>(6)</label><mml:math id="mm36" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mi>v</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Let <italic toggle="yes">T</italic> be a touch point located at polar coordinates <inline-formula><mml:math id="mm37" overflow="scroll"><mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>&#966;</mml:mi></mml:mfenced></mml:mrow></mml:math></inline-formula> relative to the centre of the circular path <italic toggle="yes">O</italic>. The received vibration at time <italic toggle="yes">t</italic> is given by the following equation:<disp-formula id="FD7-sensors-25-05918"><label>(7)</label><mml:math id="mm38" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="prefix">exp</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mo>&#8722;</mml:mo><mml:mi>&#947;</mml:mi><mml:msqrt><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mn>0</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:mn>2</mml:mn><mml:mi>r</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="prefix">cos</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>&#966;</mml:mi></mml:mfenced></mml:mrow></mml:msqrt></mml:mfenced><mml:mo form="prefix">sin</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mi>t</mml:mi></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm39" overflow="scroll"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is the source amplitude, <inline-formula><mml:math id="mm40" overflow="scroll"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the carrier frequency, and <inline-formula><mml:math id="mm41" overflow="scroll"><mml:mrow><mml:mi>&#947;</mml:mi></mml:mrow></mml:math></inline-formula> is the attenuation coefficient of the medium. The envelope of the received vibration is the following time-varying function:<disp-formula id="FD8-sensors-25-05918"><label>(8)</label><mml:math id="mm42" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="prefix">exp</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mo>&#8722;</mml:mo><mml:mi>&#947;</mml:mi><mml:msqrt><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mn>0</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:mn>2</mml:mn><mml:mi>r</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="prefix">cos</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>&#966;</mml:mi></mml:mfenced></mml:mrow></mml:msqrt></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
which oscillates at frequency <italic toggle="yes">f</italic>, between a minimum of <inline-formula><mml:math id="mm43" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="prefix">exp</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mo>&#8722;</mml:mo><mml:mi>&#947;</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mfenced></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> and a maximum of <inline-formula><mml:math id="mm44" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="prefix">exp</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mo>&#8722;</mml:mo><mml:mi>&#947;</mml:mi><mml:mfenced separators="" open="|" close="|"><mml:mi>r</mml:mi><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mfenced></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><sec id="sec2dot2dot1-sensors-25-05918"><title>2.2.1. Extension to 3D</title><p>In three dimensions, the equation for the received signal becomes the following:<disp-formula id="FD9-sensors-25-05918"><label>(9)</label><mml:math id="mm45" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="prefix">exp</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mo>&#8722;</mml:mo><mml:mi>&#947;</mml:mi><mml:msqrt><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mn>0</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:mn>2</mml:mn><mml:mi>r</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="prefix">cos</mml:mo><mml:mi>&#945;</mml:mi><mml:mo form="prefix">cos</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>&#966;</mml:mi></mml:mfenced></mml:mrow></mml:msqrt></mml:mfenced><mml:mo form="prefix">sin</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mi>t</mml:mi></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm46" overflow="scroll"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow></mml:math></inline-formula> is the elevation of the touch point <italic toggle="yes">T</italic> relative to the trajectory plane denoted by <italic toggle="yes">P</italic>, and <inline-formula><mml:math id="mm47" overflow="scroll"><mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mi>&#960;</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mo>&#8722;</mml:mo><mml:mi>&#945;</mml:mi></mml:mfenced></mml:mrow></mml:math></inline-formula> is the inclination angle in spherical coordinates (<xref rid="sensors-25-05918-f001" ref-type="fig">Figure 1</xref>C).</p></sec><sec id="sec2dot2dot2-sensors-25-05918"><title>2.2.2. Phase Differences from Geometry</title><p>Let <italic toggle="yes">P</italic> denote the plane of circular trajectory, centred at <italic toggle="yes">O</italic>. Consider two touch points, <inline-formula><mml:math id="mm48" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm49" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, with projections <inline-formula><mml:math id="mm50" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>T</mml:mi><mml:mn>1</mml:mn><mml:mo>&#8242;</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm51" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>T</mml:mi><mml:mn>2</mml:mn><mml:mo>&#8242;</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> onto plane <italic toggle="yes">P</italic>. Without loss of generality, let the coordinates of the two touch points be <inline-formula><mml:math id="mm52" overflow="scroll"><mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:msub><mml:mi>&#952;</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>&#966;</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mfenced></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm53" overflow="scroll"><mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:msub><mml:mi>&#952;</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>&#966;</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mfenced></mml:mrow></mml:math></inline-formula>, respectively. According to Equation (<xref rid="FD9-sensors-25-05918" ref-type="disp-formula">9</xref>), the received vibrations at the two touch points are as follows:<disp-formula id="FD10-sensors-25-05918"><label>(10)</label><mml:math id="mm54" display="block" overflow="scroll"><mml:mrow><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="prefix">exp</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mo>&#8722;</mml:mo><mml:mi>&#947;</mml:mi><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mn>0</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="prefix">sin</mml:mo><mml:msub><mml:mi>&#952;</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo form="prefix">cos</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>&#966;</mml:mi></mml:mfenced></mml:mrow></mml:msqrt></mml:mfenced><mml:mo form="prefix">sin</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mi>t</mml:mi></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="prefix">exp</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mo>&#8722;</mml:mo><mml:mi>&#947;</mml:mi><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mn>0</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#8722;</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="prefix">sin</mml:mo><mml:msub><mml:mi>&#952;</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo form="prefix">cos</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>&#966;</mml:mi></mml:mfenced></mml:mrow></mml:msqrt></mml:mfenced><mml:mo form="prefix">sin</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mi>t</mml:mi></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>
Thus, the envelope phase difference between the two points is <inline-formula><mml:math id="mm55" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>&#966;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>Assume that the projected points and the centre of the circular path <italic toggle="yes">O</italic> lie on a straight line (<xref rid="sensors-25-05918-f001" ref-type="fig">Figure 1</xref>D). Then, if <italic toggle="yes">O</italic> lies between <inline-formula><mml:math id="mm56" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>T</mml:mi><mml:mn>1</mml:mn><mml:mo>&#8242;</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm57" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>T</mml:mi><mml:mn>2</mml:mn><mml:mo>&#8242;</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> (i.e., <inline-formula><mml:math id="mm58" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#966;</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mi>&#960;</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></inline-formula>) the envelopes of the vibrations are anti-phase (<xref rid="sensors-25-05918-f001" ref-type="fig">Figure 1</xref>D,E). Conversely, if <italic toggle="yes">O</italic> lies outside the segment connecting <inline-formula><mml:math id="mm59" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>T</mml:mi><mml:mn>1</mml:mn><mml:mo>&#8242;</mml:mo></mml:msubsup><mml:msubsup><mml:mi>T</mml:mi><mml:mn>2</mml:mn><mml:mo>&#8242;</mml:mo></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>&#8212;i.e., <inline-formula><mml:math id="mm60" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#966;</mml:mi><mml:mo>=</mml:mo><mml:mi>&#960;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>&#8212;the envelopes are in phase.</p><p>For simplicity, hereafter, I focus on the 2D symmetric case where the centre of the circular trajectory lies on the perpendicular bisector of the segment connecting the two touch points <inline-formula><mml:math id="mm61" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm62" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, such that <inline-formula><mml:math id="mm63" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. In this configuration, the two touch points are equidistant from the centre, resulting in vibration envelopes with equal amplitude range. This condition facilitates visualisation and analysis of in-phase and anti-phase conditions in a two-dimensional geometry.</p></sec></sec><sec id="sec2dot3-sensors-25-05918"><title>2.3. Experimental Procedure</title><p>Three psychophysical experiments were conducted to investigate vibrotactile motion direction discrimination using a common two-alternative forced-choice (2-AFC) discrete trial paradigm. In this experiment, participants reported the perceived direction of vibrotactile motion (left vs. right) generated by two amplitude-modulated (AM) vibrations delivered simultaneously to the index and middle fingertips of the right hand (see details below). All experimental procedures were approved by the Monash University Human Research Ethics Committee (MUHREC) and conducted in accordance with approved guidelines.</p><sec sec-type="subjects" id="sec2dot3dot1-sensors-25-05918"><title>2.3.1. Participants</title><p>A total of 25 participants (12 female; age range: 19&#8211;34; one left-handed) took part across the three experiments. All were undergraduate or graduate students at Monash University. Each experiment involved distinct participant groups. All participants provided written informed consent prior to the experiment.</p></sec><sec id="sec2dot3dot2-sensors-25-05918"><title>2.3.2. Vibrotactile Stimulation</title><p>In all experiments, vibrotactile stimuli were delivered simultaneously to the index and middle fingertips of the right hand using two miniature solenoid transducers (PMT-20N12AL04-04, Tymphany HK Ltd; 4 &#937;, 1 W, 20 mm diameter) mounted 5 cm apart on a vibration-isolated pad. Stimuli were generated in MATLAB (R2022a; MathWorks Inc.) at a sampling rate of either 48 kHz or 192 kHz and were output through a Creative Sound Blaster Audigy Fx 5.1 sound card (model SB1570). The peak-to-peak amplitude of the output waveform was set to 1.98 V. The shape and curvature of the transducer matched the size and contour of adult fingertips [<xref rid="B46-sensors-25-05918" ref-type="bibr">46</xref>]. The base (carrier) frequency of the vibrations was <inline-formula><mml:math id="mm64" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> Hz. Although this frequency is within the audible range, we verified during pilot testing that the stimuli were imperceptible to hearing and could only be perceived through tactile sensation. Amplitude modulation was applied to generate low-frequency envelopes, with each trial containing 3 modulation cycles. The modulation amplitude was set well above the detection threshold, and pilot testing confirmed that even halving the amplitude had negligible effects on performance in the motion discrimination task.</p><p>In all experiments, sinusoidal envelopes were used due to their mathematical and physical properties. Sinusoids are fundamental in Fourier decomposition and are the only waveforms that preserve their shape under summation with others of the same frequency. Sinusoidal modulation mimics natural oscillatory signals (e.g., wind, light, and sound waves) and implies motion with varying velocity, similar to pendular or spring&#8211;mass dynamics.</p><p>For a given phase difference <inline-formula><mml:math id="mm65" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, the two sinusoidally modulated vibrations were defined as follows:<disp-formula id="FD11-sensors-25-05918"><label>(11)</label><mml:math id="mm66" display="block" overflow="scroll"><mml:mrow><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced></mml:mrow></mml:mtd><mml:mtd><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mfenced separators="" open="(" close=")"><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mo form="prefix">sin</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mfenced></mml:mfenced><mml:mo form="prefix">sin</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mi>t</mml:mi></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced></mml:mrow></mml:mtd><mml:mtd><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mfenced separators="" open="(" close=")"><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mo form="prefix">sin</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mo>&#8722;</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mfenced></mml:mfenced><mml:mo form="prefix">sin</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mi>t</mml:mi></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>To avoid any response bias or cues about motion direction arising from differences in initial envelope amplitude, vibration onset was set to one of the two isoamplitude points where the envelopes were identical. For non-zero <inline-formula><mml:math id="mm67" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, these occur at <inline-formula><mml:math id="mm68" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>4</mml:mn><mml:mi>f</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm69" overflow="scroll"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>3</mml:mn><mml:mrow><mml:mn>4</mml:mn><mml:mi>f</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></inline-formula>, with the corresponding envelope amplitudes of <inline-formula><mml:math id="mm70" overflow="scroll"><mml:mrow><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mfenced separators="" open="(" close=")"><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mo form="prefix">cos</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mo>&#177;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle></mml:mfenced></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm71" overflow="scroll"><mml:mrow><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mfenced separators="" open="(" close=")"><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mo form="prefix">cos</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mo>&#177;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle></mml:mfenced></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>, respectively (<xref rid="sensors-25-05918-f002" ref-type="fig">Figure 2</xref>C). Since cosine is an even function, the envelope magnitudes are identical for <inline-formula><mml:math id="mm72" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm73" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. At each of these onset points, the envelopes have opposite slopes&#8212;one rising and the other falling&#8212;corresponding to opposite directions of motion along the circular trajectory. On each trial, one of these two onset points was selected at random with equal probability, ensuring that initial envelope phase provided no reliable cue about motion direction.</p><p>In Experiment 1, we additionally included stimuli with exponentially decaying envelopes to simulate more realistic, physically plausible patterns of vibration propagation. The envelopes were derived from Equation (<xref rid="FD10-sensors-25-05918" ref-type="disp-formula">10</xref>), using fixed parameters <inline-formula><mml:math id="mm74" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm75" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#947;</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:mo form="prefix">log</mml:mo><mml:mn>20</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="FD12-sensors-25-05918"><label>(12)</label><mml:math id="mm76" display="block" overflow="scroll"><mml:mrow><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced></mml:mrow></mml:mtd><mml:mtd><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="prefix">exp</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mo>&#8722;</mml:mo><mml:mo form="prefix">log</mml:mo><mml:mfenced open="(" close=")"><mml:mn>20</mml:mn></mml:mfenced><mml:msqrt><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mo form="prefix">cos</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mfenced></mml:mrow></mml:msqrt></mml:mfenced><mml:mo form="prefix">sin</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mi>t</mml:mi></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced></mml:mrow></mml:mtd><mml:mtd><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="prefix">exp</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mo>&#8722;</mml:mo><mml:mo form="prefix">log</mml:mo><mml:mfenced open="(" close=")"><mml:mn>20</mml:mn></mml:mfenced><mml:msqrt><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mo form="prefix">cos</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mo>&#8722;</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mfenced></mml:mrow></mml:msqrt></mml:mfenced><mml:mo form="prefix">sin</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mi>t</mml:mi></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>
These stimuli were also initiated at one of the two isoamplitude points selected randomly on each trial, consistent with the sinusoidal condition.</p></sec></sec><sec id="sec2dot4-sensors-25-05918"><title>2.4. Motion Direction Discrimination Task</title><p>Participants performed a discrete-trial two alternative forced-choice (2-AFC) task to judge the perceived direction of vibrotactile motion. On each trial, two amplitude-modulated vibrations were delivered simultaneously to the index and middle fingertips of the right hand. Participants were instructed to gently rest their fingertips on the transducers without applying force (<xref rid="sensors-25-05918-f002" ref-type="fig">Figure 2</xref>). The two transducers were spaced 5 cm apart on a vibration-isolated pad, arranged such that vibrations from one transducer were not perceptible at the other. Participants rested their arm on the chair armrest with their wrist comfortably supported on a padded surface aligned with the stimulation platform. They were instructed to maintain a stable hand posture throughout each session. All participants reported clear perception of the envelope modulation, and pilot testing confirmed that the stimulus amplitude was well above detection threshold.</p><p>The task was self-paced, with all responses made via keyboard. On each trial, a pair of vibrations with a specific envelope phase difference was presented for three cycles (e.g., 6 s at an envelope frequency of 0.5 Hz). Participants reported the perceived motion direction (leftward or rightward) by pressing the corresponding arrow key with their left hand. There was no time limit for responses, and participants could respond at any moment during or after stimulation.</p><p>The specific phase differences and envelope modulation frequencies varied across the three experiments. In Experiment 1, I compared sinusoidal and exponential envelopes with phase differences of &#177;30&#176; to &#177;150&#176; (30&#176; increments) at a fixed envelope frequency of 0.5 Hz. In Experiment 2, sinusoidal envelopes were used with phase differences ranging from &#8722;180&#176; to 180&#176; in 30&#176; increments, tested at envelope frequencies of 0.5, 1, and 1.5 Hz. In Experiment 3, sinusoidal envelopes were tested at phase differences of 0&#176;, &#177;30&#176;, &#177;60&#176;, &#177;90&#176;, and 180&#176; at a fixed frequency of 0.5 Hz, with participants additionally providing confidence ratings after each response by pressing a number key from &#8220;1&#8221; (no confidence) to &#8220;5&#8221; (absolute certainty). These ratings were linearly scaled to a 0&#8211;100% confidence range. Experimental conditions were presented in pseudo-random order across trials, with approximately 30 repetitions per condition.</p></sec><sec id="sec2dot5-sensors-25-05918"><title>2.5. Psychometric Modelling</title><p>To quantify sensitivity to phase differences at each modulation frequency, we modelled perceptual discrimination performance as a function of phase difference <inline-formula><mml:math id="mm77" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> using a nonlinear periodic-sigmoid psychometric function:<disp-formula id="FD13-sensors-25-05918"><label>(13)</label><mml:math id="mm78" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mi>&#954;</mml:mi><mml:mo>&#160;</mml:mo><mml:mo form="prefix">sin</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm79" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the predicted proportion of correct responses at a given phase difference <inline-formula><mml:math id="mm80" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="mm81" overflow="scroll"><mml:mrow><mml:mi>&#954;</mml:mi></mml:mrow></mml:math></inline-formula> is a sensitivity parameter reflecting the steepness of the psychometric function. Higher <inline-formula><mml:math id="mm82" overflow="scroll"><mml:mrow><mml:mi>&#954;</mml:mi></mml:mrow></mml:math></inline-formula> values indicate greater sensitivity to phase differences. The model is based on the well-known logistic function [<xref rid="B47-sensors-25-05918" ref-type="bibr">47</xref>] applied to the sine of the phase difference <inline-formula><mml:math id="mm83" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, ensuring that predicted performance is at chance (0.5) at 0&#176; and 180&#176;, where the vibrations provide no directional cue. The sinusoidal form, combined with its single-parameter structure, avoids overfitting and reflects the hypothesised mechanism of motion perception based on phase-difference readout across spatially separated tactile sensors. The model was fit to group-averaged accuracy data using nonlinear least-squares regression, and the model performance (goodness-of-fit) was assessed using the coefficient of determination (<inline-formula><mml:math id="mm84" overflow="scroll"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>).</p></sec><sec id="sec2dot6-sensors-25-05918"><title>2.6. Probabilistic Model of Temporal Reference Detection and Cycle Disambiguation</title><p>Consider two AM vibrations with phase difference <inline-formula><mml:math id="mm85" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, which corresponds to a temporal lag <italic toggle="yes">d</italic> between their envelopes:<disp-formula><mml:math id="mm86" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">f</italic> is the envelope modulation frequency. Let <inline-formula><mml:math id="mm87" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm88" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> denote the perceived moments of two consecutive salient reference points (e.g., peaks) of vibration 1, and let <inline-formula><mml:math id="mm89" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> denote the corresponding reference point of vibration 2 that occurs between <inline-formula><mml:math id="mm90" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm91" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. These reference points are extracted from the envelopes of the amplitude-modulated vibrations. Hereafter, we focus on peak features, but the same logic applies to other amplitude landmarks (e.g., troughs or zero-crossings). Due to sensory noise and perceptual limits, each detected peak is assumed to lie within a temporal uncertainty window around the true peak time. For each reference point, I model the perceived time as being uniformly distributed within a window of width <italic toggle="yes">w</italic> centred at the true peak. This uncertainty window depends on the perceptual threshold with which the envelope is extracted. For instance, assuming a sinusoidal envelope in Equation (<xref rid="FD11-sensors-25-05918" ref-type="disp-formula">11</xref>), the time intervals where the envelope deviates from the peak amplitude by less than a threshold value <inline-formula><mml:math id="mm92" overflow="scroll"><mml:mrow><mml:mi>&#948;</mml:mi></mml:mrow></mml:math></inline-formula> correspond to durations satisfying <inline-formula><mml:math id="mm93" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mo>&#8804;</mml:mo><mml:mi>&#948;</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, which implies the following:<disp-formula><mml:math id="mm94" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#8712;</mml:mo><mml:mfenced separators="" open="[" close="]"><mml:mo>&#8722;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo form="prefix">arcsin</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#948;</mml:mi></mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mfrac></mml:mstyle></mml:mfenced><mml:mo>&#8723;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo><mml:mo>&#160;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#960;</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo form="prefix">arcsin</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#948;</mml:mi></mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mfrac></mml:mstyle></mml:mfenced><mml:mo>&#8723;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
so that the total uncertainty window is as follows:<disp-formula id="FD14-sensors-25-05918"><label>(14)</label><mml:math id="mm95" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>&#960;</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo form="prefix">arcsin</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#948;</mml:mi></mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mfrac></mml:mstyle></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>Since the vibrations are periodic and have identical envelope shapes (with vibration 2 being a phase-shifted version of vibration 1), the reference point of vibration 2 is shifted by lag <italic toggle="yes">d</italic>. Similarly, <inline-formula><mml:math id="mm96" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is one cycle after <inline-formula><mml:math id="mm97" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, i.e., with an offset of <italic toggle="yes">T</italic>, where <inline-formula><mml:math id="mm98" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>f</mml:mi></mml:mfrac></mml:mstyle></mml:mrow></mml:mrow></mml:math></inline-formula> is the envelope modulation period. Without loss of generality, we assume <inline-formula><mml:math id="mm99" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and align the reference points relative to zero and define their distributions as <inline-formula><mml:math id="mm100" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#8764;</mml:mo><mml:mi mathvariant="script">U</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>w</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm101" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&#8764;</mml:mo><mml:mi mathvariant="script">U</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="mm102" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#8764;</mml:mo><mml:mi mathvariant="script">U</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Correct perception of motion direction depends on both (1) the reliability of judging the temporal order of salient reference points (e.g., peaks) and (2) disambiguation of within-cycle versus across-cycle intervals. As mentioned, while the focus here is on peak features, the same logic applies to other amplitude landmarks (e.g., troughs or zero-crossings).</p><p>Based on these distributions, two forms of perceptual inference are required to judge motion direction: first, the temporal order judgement, i.e., determining whether the peak of vibration 2 occurs after the peak of vibration 1 (<inline-formula><mml:math id="mm103" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>). Second, the inter-peak interval discrimination, i.e., comparing whether the interval between <inline-formula><mml:math id="mm104" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm105" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is shorter than the interval between <inline-formula><mml:math id="mm106" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm107" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, i.e., testing whether <inline-formula><mml:math id="mm108" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>The sections that follow formalise these probabilities and derive an analytical expression for the overall probability of a correct motion direction judgement.</p><sec id="sec2dot6dot1-sensors-25-05918"><title>2.6.1. Temporal Order Judgement</title><p>The first source of error arises from uncertainty in judging the temporal order of peaks. If the temporal lag <italic toggle="yes">d</italic> is smaller than the uncertainty window <italic toggle="yes">w</italic>, the perceived ordering of <inline-formula><mml:math id="mm109" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm110" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> may be incorrect. The probability that the peak of envelope 1 is perceived before that of envelope 2 (i.e., a correct temporal order judgement) is given by the integral of the joint distribution of <inline-formula><mml:math id="mm111" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm112" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> over the area <inline-formula><mml:math id="mm113" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula><mml:math id="mm114" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mfenced><mml:mo>=</mml:mo><mml:mo>&#8747;</mml:mo><mml:msub><mml:mo>&#8747;</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:msup><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mfrac></mml:mstyle><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>As <inline-formula><mml:math id="mm115" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm116" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> are mutually independent with uniform distributions, <inline-formula><mml:math id="mm117" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is distributed triangularly over the interval <inline-formula><mml:math id="mm118" overflow="scroll"><mml:mrow><mml:mfenced separators="" open="[" close="]"><mml:mi>d</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi></mml:mfenced></mml:mrow></mml:math></inline-formula>, yielding the following:<disp-formula id="FD15-sensors-25-05918"><label>(15)</label><mml:math id="mm119" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfenced separators="" open="{" close=""><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mfenced separators="" open="(" close=")"><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mi>d</mml:mi><mml:mi>w</mml:mi></mml:mfrac></mml:mstyle></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>for</mml:mi><mml:mspace width="4.pt"/><mml:mi>d</mml:mi><mml:mo>&#8804;</mml:mo><mml:mi>w</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>for</mml:mi><mml:mspace width="4.pt"/><mml:mi>d</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>w</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>The case <inline-formula><mml:math id="mm120" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> guarantees correct order due to non-overlapping supports.</p></sec><sec id="sec2dot6dot2-sensors-25-05918"><title>2.6.2. Across-Cycle Ambiguity and Inter-Peak Interval Discrimination</title><p>As <italic toggle="yes">d</italic> increases and the uncertainty window extends into the next modulation cycle, another form of error emerges. This is when the uncertainty around <inline-formula><mml:math id="mm121" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> extends beyond the halfway point of the modulation period <italic toggle="yes">T</italic>; the perceived peak of envelope 2 may fall closer in time to the next peak of envelope 1 (denoted <inline-formula><mml:math id="mm122" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#8712;</mml:mo><mml:mfenced separators="" open="[" close="]"><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>) rather than the original one at <inline-formula><mml:math id="mm123" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#8712;</mml:mo><mml:mfenced separators="" open="[" close="]"><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>w</mml:mi></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>. This may result in an incorrect interval comparison, i.e., <inline-formula><mml:math id="mm124" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, thus misjudging the motion direction. Based on the mutually independent uniform distributions of <inline-formula><mml:math id="mm125" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm126" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="mm127" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, the probability density function of <inline-formula><mml:math id="mm128" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is a piece-wise quadratic function of the following form:<disp-formula id="FD16-sensors-25-05918"><label>(16)</label><mml:math id="mm129" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>V</mml:mi></mml:msub><mml:mfenced separators="" open="(" close=")"><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>2</mml:mn><mml:mi>d</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced separators="" open="{" close=""><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>w</mml:mi></mml:mrow></mml:mfrac><mml:mfenced separators="" open="(" close=")"><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mfrac><mml:msup><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mfenced></mml:mrow></mml:mstyle></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>for</mml:mi><mml:mspace width="4.pt"/><mml:mo>&#8739;</mml:mo><mml:mi>v</mml:mi><mml:mo>&#8739;</mml:mo><mml:mo>&#8804;</mml:mo><mml:mi>w</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:msup><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>w</mml:mi><mml:mo>&#8722;</mml:mo><mml:mo>&#8739;</mml:mo><mml:mi>v</mml:mi><mml:mo>&#8739;</mml:mo></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mn>4</mml:mn><mml:msup><mml:mi>w</mml:mi><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>for</mml:mi><mml:mspace width="4.pt"/><mml:mi>w</mml:mi><mml:mo>&lt;</mml:mo><mml:mo>&#8739;</mml:mo><mml:mi>v</mml:mi><mml:mo>&#8739;</mml:mo><mml:mo>&#8804;</mml:mo><mml:mn>2</mml:mn><mml:mi>w</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>for</mml:mi><mml:mspace width="4.pt"/><mml:mn>2</mml:mn><mml:mi>w</mml:mi><mml:mo>&lt;</mml:mo><mml:mo>&#8739;</mml:mo><mml:mi>v</mml:mi><mml:mo>&#8739;</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The probability of avoiding this across-cycle confusion is as follows:<disp-formula id="FD17-sensors-25-05918"><label>(17)</label><mml:math id="mm130" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mfenced><mml:mo>=</mml:mo><mml:msubsup><mml:mo>&#8747;</mml:mo><mml:mn>0</mml:mn><mml:mrow><mml:mi>T</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mfenced separators="" open="(" close=")"><mml:mi>w</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>d</mml:mi></mml:mfenced></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>V</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mi>v</mml:mi></mml:mfenced><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>The probability is 1 when <inline-formula><mml:math id="mm131" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>T</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, and drops below 1 as <italic toggle="yes">d</italic> increases beyond this point.</p></sec><sec id="sec2dot6dot3-sensors-25-05918"><title>2.6.3. Joint Probability of Correct Motion Perception</title><p>Correct motion perception requires both correct temporal order identification of peaks and correct across-cycle inter-peak interval discrimination. These two conditions are not independent, and their joint probability must be calculated conditionally. Let <inline-formula><mml:math id="mm132" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>The joint probability of a correct response is as follows:<disp-formula><mml:math id="mm133" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>correct</mml:mi></mml:msub><mml:mspace width="4.pt"/><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#916;</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#183;</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mo>&#8739;</mml:mo><mml:mo>&#916;</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>Using the law of total probability over the distribution of <inline-formula><mml:math id="mm134" overflow="scroll"><mml:mrow><mml:mo>&#916;</mml:mo></mml:mrow></mml:math></inline-formula>, the second term can be rewritten as follows:<disp-formula><mml:math id="mm135" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mo>&#8739;</mml:mo><mml:mo>&#916;</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mo>&#8747;</mml:mo><mml:mn>0</mml:mn><mml:mrow><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn><mml:mi>x</mml:mi><mml:mo>&#8739;</mml:mo><mml:mo>&#916;</mml:mo><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#183;</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mo>&#916;</mml:mo><mml:mo>|</mml:mo><mml:mo>&#916;</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.166667em"/><mml:mi>d</mml:mi><mml:mi>x</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm136" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mo>&#916;</mml:mo><mml:mo>|</mml:mo><mml:mo>&#916;</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the conditional probability density function of <inline-formula><mml:math id="mm137" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> given <inline-formula><mml:math id="mm138" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, defined as follows:<disp-formula id="FD18-sensors-25-05918"><label>(18)</label><mml:math id="mm139" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mo>&#916;</mml:mo><mml:mo>|</mml:mo><mml:mo>&#916;</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mo>&#916;</mml:mo></mml:msub><mml:mfenced open="(" close=")"><mml:mi>x</mml:mi></mml:mfenced></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mo>&#916;</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mfenced></mml:mrow></mml:mfrac></mml:mstyle><mml:mspace width="1.em"/><mml:mi>for</mml:mi><mml:mspace width="4.pt"/><mml:mi>x</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
with <inline-formula><mml:math id="mm140" overflow="scroll"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mo>&#916;</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> denoting the triangular probability density function of <inline-formula><mml:math id="mm141" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mo>&#8712;</mml:mo><mml:mfenced separators="" open="[" close="]"><mml:mi>d</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> and the normalisation constant <inline-formula><mml:math id="mm142" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mo>&#916;</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> as derived in Equation (<xref rid="FD15-sensors-25-05918" ref-type="disp-formula">15</xref>). Thus, the joint probability becomes as follows:<disp-formula id="FD19-sensors-25-05918"><label>(19)</label><mml:math id="mm143" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>correct</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mo>&#8747;</mml:mo><mml:mn>0</mml:mn><mml:mrow><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn><mml:mi>x</mml:mi><mml:mo>&#8739;</mml:mo><mml:mo>&#916;</mml:mo><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mfenced separators="" open="[" close="]"><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mo>&#8739;</mml:mo><mml:mi>x</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>d</mml:mi><mml:mo>&#8739;</mml:mo></mml:mrow><mml:mi>w</mml:mi></mml:mfrac></mml:mstyle></mml:mfenced><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mi>w</mml:mi></mml:mfrac></mml:mstyle><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The conditioned probability <inline-formula><mml:math id="mm144" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn><mml:mi>x</mml:mi><mml:mo>&#8739;</mml:mo><mml:mo>&#916;</mml:mo><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> can be expressed as follows:<disp-formula id="FD20-sensors-25-05918"><label>(20)</label><mml:math id="mm145" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn><mml:mi>x</mml:mi><mml:mo>&#8739;</mml:mo><mml:mo>&#916;</mml:mo><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mo>&#8747;</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#8739;</mml:mo><mml:mo>&#916;</mml:mo><mml:mo>=</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mfenced open="(" close=")"><mml:mi>y</mml:mi></mml:mfenced><mml:mi>d</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm146" overflow="scroll"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#8739;</mml:mo><mml:mo>&#916;</mml:mo><mml:mo>=</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the distribution of the difference between <inline-formula><mml:math id="mm147" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#8764;</mml:mo><mml:mi mathvariant="script">U</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm148" overflow="scroll"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, given <inline-formula><mml:math id="mm149" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mo>=</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. The conditional distribution <inline-formula><mml:math id="mm150" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#8739;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#916;</mml:mo><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#8764;</mml:mo><mml:mi mathvariant="script">U</mml:mi><mml:mfenced separators="" open="[" close="]"><mml:mi>a</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>, where<disp-formula id="FD21-sensors-25-05918"><label>(21)</label><mml:math id="mm151" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mi>d</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mfenced><mml:mo>,</mml:mo><mml:mspace width="1.em"/><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>x</mml:mi></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
so that the support length is <inline-formula><mml:math id="mm152" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>b</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>&#8722;</mml:mo><mml:mi>a</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>w</mml:mi><mml:mo>&#8722;</mml:mo><mml:mo>|</mml:mo><mml:mi>d</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>x</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, at most <italic toggle="yes">w</italic>. This leads to a trapezoidal distribution for <inline-formula><mml:math id="mm153" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#8739;</mml:mo><mml:mo>&#916;</mml:mo><mml:mo>=</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, from which we derive the cumulative probability:<disp-formula id="FD22-sensors-25-05918"><label>(22)</label><mml:math id="mm154" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn><mml:mi>x</mml:mi><mml:mo>&#8739;</mml:mo><mml:mo>&#916;</mml:mo><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfenced separators="" open="{" close=""><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mn>1</mml:mn></mml:mstyle></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>x</mml:mi><mml:mo>&#8804;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>b</mml:mi><mml:mfenced open="(" close=")"><mml:mi>x</mml:mi></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mfrac><mml:msup><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mfenced open="(" close=")"><mml:mi>x</mml:mi></mml:mfenced><mml:mo>&#8722;</mml:mo><mml:mi>T</mml:mi></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mi>w</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mi>w</mml:mi><mml:mo>&#8722;</mml:mo><mml:mo>&#8739;</mml:mo><mml:mi>d</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>x</mml:mi><mml:mo>&#8739;</mml:mo></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>b</mml:mi><mml:mfenced open="(" close=")"><mml:mi>x</mml:mi></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mo>&lt;</mml:mo><mml:mi>x</mml:mi><mml:mo>&#8804;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>a</mml:mi><mml:mfenced open="(" close=")"><mml:mi>x</mml:mi></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>w</mml:mi><mml:mo>&#8722;</mml:mo><mml:mo>&#8739;</mml:mo><mml:mi>d</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>x</mml:mi><mml:mo>&#8739;</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>w</mml:mi></mml:mrow></mml:mfrac><mml:mo>&#8722;</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mfenced open="(" close=")"><mml:mi>x</mml:mi></mml:mfenced><mml:mo>&#8722;</mml:mo><mml:mi>T</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mi>w</mml:mi></mml:mfrac></mml:mrow></mml:mstyle></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>a</mml:mi><mml:mfenced open="(" close=")"><mml:mi>x</mml:mi></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mo>&lt;</mml:mo><mml:mi>x</mml:mi><mml:mo>&#8804;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>b</mml:mi><mml:mfenced open="(" close=")"><mml:mi>x</mml:mi></mml:mfenced><mml:mo>+</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:msup><mml:mfenced separators="" open="(" close=")"><mml:mn>2</mml:mn><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>a</mml:mi><mml:mfenced open="(" close=")"><mml:mi>x</mml:mi></mml:mfenced><mml:mo>&#8722;</mml:mo><mml:mi>T</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>w</mml:mi></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mi>w</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mi>w</mml:mi><mml:mo>&#8722;</mml:mo><mml:mo>&#8739;</mml:mo><mml:mi>d</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>x</mml:mi><mml:mo>&#8739;</mml:mo></mml:mfenced></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>b</mml:mi><mml:mfenced open="(" close=")"><mml:mi>x</mml:mi></mml:mfenced><mml:mo>+</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mo>&lt;</mml:mo><mml:mi>x</mml:mi><mml:mo>&#8804;</mml:mo><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>a</mml:mi><mml:mfenced open="(" close=")"><mml:mi>x</mml:mi></mml:mfenced><mml:mo>+</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mn>0</mml:mn></mml:mstyle></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="true"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mo>&#8722;</mml:mo><mml:mi>a</mml:mi><mml:mfenced open="(" close=")"><mml:mi>x</mml:mi></mml:mfenced><mml:mo>+</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mo>&lt;</mml:mo><mml:mi>x</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The total probability of a correct decision is obtained by substituting this into Equation (<xref rid="FD19-sensors-25-05918" ref-type="disp-formula">19</xref>). The full expression combines a triangular distribution for <inline-formula><mml:math id="mm155" overflow="scroll"><mml:mrow><mml:mo>&#916;</mml:mo></mml:mrow></mml:math></inline-formula>, a trapezoidal distribution for <inline-formula><mml:math id="mm156" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>&#8722;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, and a conditional integration over all valid <inline-formula><mml:math id="mm157" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mo>&#8712;</mml:mo><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Though based on simple assumptions, this model predicts a non-linear psychometric curve that captures key features observed in the data, including asymmetries in performance (e.g., better performance at 30&#176; than at 150&#176; phase lags in Experiment 2).</p></sec></sec></sec><sec sec-type="results" id="sec3-sensors-25-05918"><title>3. Results and Discussion</title><sec id="sec3dot1-sensors-25-05918"><title>3.1. Experiment 1: Direction Discrimination Using Sinusoidal vs. Exponential Envelopes</title><p>To examine whether tactile motion perception can arise from simple envelope phase differences alone, I first tested whether participants could discriminate the direction of motion from two simultaneous vibrations with either sinusoidal or naturalistic&#8212;i.e., exponential&#8212;amplitude-modulated (AM) envelopes. Both envelope types simulated a virtual motion trajectory via systematic phase differences across two fingertips. Participants performed a 2-AFC motion direction discrimination task at an envelope frequency of 0.5 Hz. On average across subjects (n = 8), direction discrimination accuracy was 85.5% &#177; 4.2% SEM for exponential envelopes, and 80.2% &#177; 5.1% SEM for sinusoidal envelopes (<xref rid="sensors-25-05918-f003" ref-type="fig">Figure 3</xref>). While exponential envelopes yielded slightly higher accuracy by 5.3% &#177; 1.5% SEM&#8212;possibly due to their closer resemblance to naturalistic wave propagation&#8212;participants still showed robust performance with sinusoidal envelopes. This demonstrates that the tactile system extracts directional information purely from sinusoidal phase offsets, despite their more abstract physical basis.</p></sec><sec id="sec3dot2-sensors-25-05918"><title>3.2. Experiment 2: Upper Frequency Limit for Tactile Motion Discrimination Lies Below or at 1.5&#160;Hz</title><p>To quantify discrimination performance at each envelope frequency, I fit a sigmoid psychometric model with a sensitivity parameter <inline-formula><mml:math id="mm158" overflow="scroll"><mml:mrow><mml:mi>&#954;</mml:mi></mml:mrow></mml:math></inline-formula> to the proportion of correct responses as a function of phase differences (see Methods). At 0.5 Hz, the model fit was robust (coefficient of determination <inline-formula><mml:math id="mm159" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>0.56</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) with a relatively high sensitivity parameter <inline-formula><mml:math id="mm160" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#954;</mml:mi><mml:mo>=</mml:mo><mml:mn>1.29</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, predicting a maximum accuracy of 78.4%. At 1 Hz, performance declined moderately (<inline-formula><mml:math id="mm161" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>0.82</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>; <inline-formula><mml:math id="mm162" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#954;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.78</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), with a predicted maximum accuracy of 68.5% correct responses. At 1.5 Hz, performance approached chance level (<inline-formula><mml:math id="mm163" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>0.36</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>; <inline-formula><mml:math id="mm164" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#954;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.17</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) with a predicted maximum of just 54.4% correct (<xref rid="sensors-25-05918-f004" ref-type="fig">Figure 4</xref>A), indicating that the upper temporal limit for perceiving direction of tactile motion lies below 1.5 Hz.</p><p>To further assess the effects of phase difference and modulation frequency on a trial-by-trial basis, while accounting for subject-level variability, I fit a generalised linear mixed-effects model (GLMM) using a logit link function and binomial distribution. The logit transformation yields a logistic sigmoidal response function, consistent with the psychometric curve fitted at the group level. Fixed effects included <inline-formula><mml:math id="mm165" overflow="scroll"><mml:mrow><mml:mrow><mml:mo form="prefix">sin</mml:mo><mml:mo>(</mml:mo><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and its interaction with modulation frequency (<italic toggle="yes">f</italic>), with random slopes for <inline-formula><mml:math id="mm166" overflow="scroll"><mml:mrow><mml:mrow><mml:mo form="prefix">sin</mml:mo><mml:mo>(</mml:mo><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> across participants. Specification enforces chance-level performance at 0&#176; and 180&#176;. The fixed sine term was significantly positive (<inline-formula><mml:math id="mm167" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#946;</mml:mi><mml:mo>=</mml:mo><mml:mn>1.671</mml:mn><mml:mo>&#177;</mml:mo><mml:mn>0.1376</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> SE; 95% CI <inline-formula><mml:math id="mm168" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mn>1.401</mml:mn><mml:mo>,</mml:mo><mml:mn>1.940</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>; <inline-formula><mml:math id="mm169" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>32</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>), indicating enhanced accuracy with increasing sine of phase difference. The interaction term was significantly negative (<inline-formula><mml:math id="mm170" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#946;</mml:mi><mml:mo>=</mml:mo><mml:mo>&#8722;</mml:mo><mml:mn>0.970</mml:mn><mml:mo>&#177;</mml:mo><mml:mn>0.0985</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> SE; 95% CI <inline-formula><mml:math id="mm171" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mo>&#8722;</mml:mo><mml:mn>1.163</mml:mn><mml:mo>,</mml:mo><mml:mo>&#8722;</mml:mo><mml:mn>0.777</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>; <inline-formula><mml:math id="mm172" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>22</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>), demonstrating that phase sensitivity declined at higher modulation frequencies. The model provided an adequate fit to the data (log-likelihood = &#8722;10,094; deviance = 20,187; <inline-formula><mml:math id="mm173" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>4664</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> trials). The estimated standard deviation of the subject-specific random slopes was 0.195, reflecting modest between-participant variability, and the dispersion parameter was 0.998, indicating no evidence of overdispersion beyond the binomial assumption. As illustrated in <xref rid="sensors-25-05918-f004" ref-type="fig">Figure 4</xref>B, model predictions captured the systematic decline in phase sensitivity with increasing frequency and matched the empirical data across frequencies.</p><p>To verify the unreliability of performance at 1.5 Hz, the population-average (marginal) GLMM accuracy at 90&#176; was computed for each frequency and statistically compared with chance performance (50%). These were obtained by Monte-Carlo integration over the estimated random-slope distribution, with 95% confidence intervals from 5000 parametric bootstrap samples of the the fixed effects (from the estimated covariance matrix). At 1.5 Hz, the model predicted 55.3% accuracy (95% CI <inline-formula><mml:math id="mm174" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mn>49.99</mml:mn><mml:mo>,</mml:mo><mml:mn>60.41</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>), which was marginal and not reliably different from chance (<inline-formula><mml:math id="mm175" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.050</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). In contrast, predictions at 1.0 and 0.5 Hz were 66.7% (95% CI <inline-formula><mml:math id="mm176" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mn>62.5</mml:mn><mml:mo>,</mml:mo><mml:mn>70.7</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) and 76.4% (95% CI <inline-formula><mml:math id="mm177" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mn>72.3</mml:mn><mml:mo>,</mml:mo><mml:mn>80.0</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>), respectively, both highly significant relative to chance (<inline-formula><mml:math id="mm178" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>).</p><p>To directly test performance at 1.5 Hz, a separate GLMM restricted to this frequency revealed that the effect of <inline-formula><mml:math id="mm179" overflow="scroll"><mml:mrow><mml:mrow><mml:mo form="prefix">sin</mml:mo><mml:mo>(</mml:mo><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> across the full range of tested phase differences was not statistically significant (<inline-formula><mml:math id="mm180" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#946;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.175</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, 95% CI <inline-formula><mml:math id="mm181" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mo>&#8722;</mml:mo><mml:mn>0.015</mml:mn><mml:mo>,</mml:mo><mml:mn>0.366</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm182" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.072</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). This aligns with the sharp drop in sensitivity observed in the group-level psychometric fits (<inline-formula><mml:math id="mm183" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#954;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.17</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), further supporting the interpretation that 1.5 Hz marks the upper perceptual limit for robust phase-based motion discrimination in this paradigm. The analysis included 1478 trials across participants, providing sufficient statistical power to detect meaningful effects. Moreover, in the GLMM analysis, the interaction between phase and frequency was highly significant (<inline-formula><mml:math id="mm184" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>22</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>), confirming that discrimination performance varies systematically with modulation frequency. The absence of a statistically reliable effect at 1.5 Hz reflects a genuine loss of directional information, not a lack of statistical power.</p><p>These findings contrast with those of Kuroki et al. [<xref rid="B35-sensors-25-05918" ref-type="bibr">35</xref>], who examined human sensitivity to AM vibrotactile stimuli up to 20 Hz in a synchronisation&#8211;asynchronisation detection task [<xref rid="B35-sensors-25-05918" ref-type="bibr">35</xref>]. They reported that participants could reliably detect synchrony or asynchrony in AM signals at modulation frequencies nearly ten times higher than those supporting motion direction discrimination in the present study. Moreover, they reported an inverse relationship between modulation frequency and detection threshold, with higher frequencies yielding better synchrony detection. A subsequent follow-up study using similar AM stimuli, however, examined frequencies above the present motion discrimination threshold (e.g., 2.5 and 5 Hz) and found no evidence of motion perception [<xref rid="B29-sensors-25-05918" ref-type="bibr">29</xref>], which is consistent with our present finding that directional motion perception is absent above 1.5 Hz. This discrepancy between the frequency ranges supporting asynchrony detection and directional motion perception underscores a critical distinction: while humans are capable of detecting synchrony in high-frequency AM signals, perceiving directional motion from inter-finger phase differences relies on much lower envelope frequencies. These differences point to potentially distinct neural mechanisms supporting temporal coincidence detection versus motion perception in the tactile domain.</p></sec><sec id="sec3dot3-sensors-25-05918"><title>3.3. Experiment 3: Cognitive and Metacognitive Signatures of Tactile Motion Perception</title><p>Building on Experiments 1 and 2, which established that tactile motion perception depends on the phase difference between fingertip vibrations, Experiment 3 introduced confidence ratings and examined behavioural signatures of perceptual ambiguity. By focusing on phase conditions with minimal directional information (e.g., 0&#176; and 180&#176;), Experiment 3 aimed to characterise how motion uncertainty is reflected in decision confidence, reaction times, and potential choice biases.</p><sec id="sec3dot3dot1-sensors-25-05918"><title>3.3.1. Ambiguity at 0&#176; and 180&#176; Revealed by Choice Distribution</title><p>To assess whether phase differences between fingertip vibrations generate a reliable perception of motion direction, I examined participants&#8217; choices across the range of phase offsets. For directional phase differences (e.g., &#177;30&#176;, &#177;60&#176;, and &#177;90&#176;) performance accuracy captures the extent to which participants reported motion direction consistent with the sign of the phase difference (see <xref rid="sensors-25-05918-f005" ref-type="fig">Figure 5</xref>A). However, at 0&#176; and 180&#176;, the vibrations were either perfectly in-phase or anti-phase across the two fingertips, resulting in symmetric temporal envelopes with no consistent directional cue. As such, for these two conditions, &#8220;correct&#8221; or &#8220;incorrect&#8221; responses are undefined. Thus, I instead analysed these conditions in terms of choice likelihood&#8212;specifically, the proportion of &#8220;leftward&#8221; responses (<xref rid="sensors-25-05918-f005" ref-type="fig">Figure 5</xref>B).</p><p>At 0&#176;, participants selected &#8220;left&#8221; on 52.2% of trials (SEM = 4.7%), not significantly different from chance (t(11) = 0.48; <italic toggle="yes">p</italic> = 0.64), consistent with perceptual ambiguity. At 180&#176;, however, participants showed a subtle but reliable leftward bias (mean = 56.8%; SEM = 2.1%), which was significantly above chance (t(11) = 3.24; <italic toggle="yes">p</italic> = 0.008). This bias suggests that at 180&#176;, even in the absence of reliable directional cues, early envelope asymmetries or internal decision biases may influence motion judgements.</p></sec><sec id="sec3dot3dot2-sensors-25-05918"><title>3.3.2. Slower Responses Reflect Ambiguity in Motion Signal</title><p>Response time (RT) provides a behavioural index of the strength of sensory evidence. Here, I analysed how RT changed as a function of phase difference to assess how tactile motion signals support directional judgements under varying degrees of ambiguity. As shown in <xref rid="sensors-25-05918-f005" ref-type="fig">Figure 5</xref>C, RTs followed a U-shaped pattern: responses were slower for the ambiguous conditions (0&#176; and 180&#176;) and faster for intermediate phase differences. To statistically assess this pattern, two linear mixed-effects (LME) models (with random intercepts per subject) were fitted to trial-level RTs. Trials with excessively long RTs (&gt;15 s) were excluded, and the remaining RTs were log-transformed to reduce skewness. To account for individual baseline differences, subject-wise mean log-transformed RTs were subtracted, yielding a normalised measure. This approach is equivalent to divisive normalisation of RTs by each participant&#8217;s geometric mean.</p><p>The first model included <inline-formula><mml:math id="mm185" overflow="scroll"><mml:mrow><mml:mrow><mml:mo form="prefix">sin</mml:mo><mml:mo>(</mml:mo><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> as a fixed-effects predictor with random intercepts across participants, capturing the expected U-shaped pattern. The model revealed a robust negative effect (<inline-formula><mml:math id="mm186" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#946;</mml:mi><mml:mo>=</mml:mo><mml:mo>&#8722;</mml:mo><mml:mn>0.152</mml:mn><mml:mo>&#177;</mml:mo><mml:mn>0.0184</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> SE; 95% CI <inline-formula><mml:math id="mm187" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mo>&#8722;</mml:mo><mml:mn>0.188</mml:mn><mml:mo>,</mml:mo><mml:mo>&#8722;</mml:mo><mml:mn>0.117</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>; <inline-formula><mml:math id="mm188" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>15</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>), consistent with slower responses at 0&#176; and 180&#176; and faster responses at 30&#176;&#8211;90&#176;. The second model included phase difference (in radians) and its square as fixed effects, allowing potential asymmetries. This quadratic model showed a significant positive quadratic term (<inline-formula><mml:math id="mm189" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#946;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.062</mml:mn><mml:mo>&#177;</mml:mo><mml:mn>0.0074</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> SE; 95% CI <inline-formula><mml:math id="mm190" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mn>0.047</mml:mn><mml:mo>,</mml:mo><mml:mn>0.077</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>; <inline-formula><mml:math id="mm191" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>15</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>) and a significant negative linear term (<inline-formula><mml:math id="mm192" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#946;</mml:mi><mml:mo>=</mml:mo><mml:mo>&#8722;</mml:mo><mml:mn>0.205</mml:mn><mml:mo>&#177;</mml:mo><mml:mn>0.0251</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> SE; 95% CI <inline-formula><mml:math id="mm193" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mo>&#8722;</mml:mo><mml:mn>0.255</mml:mn><mml:mo>,</mml:mo><mml:mo>&#8722;</mml:mo><mml:mn>0.156</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>; <inline-formula><mml:math id="mm194" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>15</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>), implying a vertex (minimum) at 95.0&#176;. These estimates align with a near-symmetric U-shaped RT pattern, as captured by the sine model. Indeed, the average RTs at 0&#176; and 180&#176; were nearly identical (5.32 &#177; 0.44 s and 5.32 &#177; 0.48 s, respectively), and both were higher than for other phase differences. However, a detailed characterisation of symmetry requires denser sampling across the full range of phase differences, particularly between 90&#176; and 180&#176;, as in Experiment 2.</p><p>Bayesian Information Criterion (BIC) provided preference for the simpler model (<inline-formula><mml:math id="mm195" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>BIC</mml:mi><mml:mo>=</mml:mo><mml:mo>+</mml:mo><mml:mn>6.9</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), while Akaike Information Criterion (AIC) showed partial preference (<inline-formula><mml:math id="mm196" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>AIC</mml:mi><mml:mo>=</mml:mo><mml:mo>+</mml:mo><mml:mn>0.7</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). A likelihood-ratio comparison treated heuristically (as models are not strictly nested) found no significant improvement in the fit over the simpler sine model (<inline-formula><mml:math id="mm197" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>&#967;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1.248</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm198" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.264</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), and residual dispersion was comparable for both models (&#8764;<inline-formula><mml:math id="mm199" overflow="scroll"><mml:mrow><mml:mrow><mml:mn>0.407</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> in log units). Thus, both approaches converge on the same conclusion that RTs were systematically longer under ambiguous conditions (0&#176; and 180&#176;) and shorter when phase differences provided stronger motion cues. The sine model, previously used to characterise performance in Experiments 2 and 3, captures this pattern well. Thus, the sine model specification was used as the primary summary of the RT effect in <xref rid="sensors-25-05918-f005" ref-type="fig">Figure 5</xref>C, with model predictions retransformed from log-space using the smearing estimator [<xref rid="B51-sensors-25-05918" ref-type="bibr">51</xref>].</p></sec><sec id="sec3dot3dot3-sensors-25-05918"><title>3.3.3. Confidence Ratings Track Motion Signal Strength</title><p>Confidence ratings reflect participants&#8217; subjective certainty about each decision, providing a metacognitive index of how strongly they perceived the motion signals on each trial. Confidence was lowest at the extreme phase differences (0&#176; and 180&#176;) and highest at intermediate phase differences (30&#176;&#8211;90&#176;) as shown in <xref rid="sensors-25-05918-f005" ref-type="fig">Figure 5</xref>D, mirroring the pattern observed in reaction times and consistent with weaker or more ambiguous motion signals at the extremes. As in the RT analysis, two linear mixed-effects models were used to model trial-level confidence. The first model used the phase difference (in radians) and its square for fixed effects with a random intercept per participant. The model revealed a robust quadratic relationship between confidence and phase difference reflected in a significant negative quadratic term (<inline-formula><mml:math id="mm200" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#946;</mml:mi><mml:mo>=</mml:mo><mml:mo>&#8722;</mml:mo><mml:mn>6.210</mml:mn><mml:mo>&#177;</mml:mo><mml:mn>0.4792</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> SE; 95% CI <inline-formula><mml:math id="mm201" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mo>&#8722;</mml:mo><mml:mn>7.761</mml:mn><mml:mo>,</mml:mo><mml:mo>&#8722;</mml:mo><mml:mn>5.882</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>; <inline-formula><mml:math id="mm202" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>43</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>) and a significant positive linear term (<inline-formula><mml:math id="mm203" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#946;</mml:mi><mml:mo>=</mml:mo><mml:mn>20.592</mml:mn><mml:mo>&#177;</mml:mo><mml:mn>1.6199</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> SE; 95% CI <inline-formula><mml:math id="mm204" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mn>17.416</mml:mn><mml:mo>,</mml:mo><mml:mn>23.768</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>; <inline-formula><mml:math id="mm205" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>35</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>), consistent with an inverted-U pattern.</p><p>The second model used <inline-formula><mml:math id="mm206" overflow="scroll"><mml:mrow><mml:mrow><mml:mo form="prefix">sin</mml:mo><mml:mo>(</mml:mo><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> as the fixed-effect, with random intercepts and participant-specific sine slopes. The fixed sine effect was positive and reliable (<inline-formula><mml:math id="mm207" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>&#946;</mml:mi><mml:mo>=</mml:mo><mml:mn>16.792</mml:mn><mml:mo>&#177;</mml:mo><mml:mn>2.5021</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> SE; 95% CI <inline-formula><mml:math id="mm208" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mn>11.886</mml:mn><mml:mo>,</mml:mo><mml:mn>21.698</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>; <inline-formula><mml:math id="mm209" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>). This model fit the data better than the quadratic model (<inline-formula><mml:math id="mm210" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>BIC</mml:mi><mml:mo>=</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm211" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>AIC</mml:mi><mml:mo>=</mml:mo><mml:mn>16</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), and this was also supported by a likelihood-ratio comparison treated heuristically because the models are not strictly nested (<inline-formula><mml:math id="mm212" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>&#967;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>17.51</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>; <inline-formula><mml:math id="mm213" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>). To justify its random-effects structure, this model was further compared with two nested variants that included either a random intercept or a random slope. The intercept-only model was worse than the full sine model (<inline-formula><mml:math id="mm214" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>BIC</mml:mi><mml:mo>=</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm215" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>AIC</mml:mi><mml:mo>=</mml:mo><mml:mn>21</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>; <inline-formula><mml:math id="mm216" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>&#967;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>24.80</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm217" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>), indicating that allowing participant-specific sine slopes improves fit. The slope-only model without a random intercept performed much worse than the full model (<inline-formula><mml:math id="mm218" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>BIC</mml:mi><mml:mo>=</mml:mo><mml:mn>210</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm219" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>AIC</mml:mi><mml:mo>=</mml:mo><mml:mn>221.7</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>; <inline-formula><mml:math id="mm220" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mi>&#967;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>225.74</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm221" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), supporting the inclusion of both random components.</p><p>These results indicate that participants were more confident when phase differences provided stronger directional cues and less confident when the motion signal was more ambiguous. Average confidence at 180&#176; was 49.4% &#177; 6.8% (mean &#177; SEM across participants), lower than all other conditions, including 0&#176; (52.8% &#177; 3.0%), indicating that anti-phase stimulation elicits especially uncertain percepts.</p></sec></sec><sec id="sec3dot4-sensors-25-05918"><title>3.4. Phase Differences, Not Amplitude Differences, Drive Tactile Motion Perception</title><p>The behavioural ambiguity observed at 180&#176; phase difference&#8212;reflected in a subtle directional bias, low confidence, and slow responses&#8212;raises a critical question: What stimulus features underlie tactile motion perception? Two plausible mechanisms are as follows: (i) motion perception based on the &#8220;phase difference&#8221; between two AM signals (i.e., relative temporal shifts in their envelopes), and (ii) perception based on moment-by-moment &#8220;amplitude&#8221; differences between the signals.</p><p>The present stimulus design enables these alternatives to be dissociated. While &#177;180&#176; phase differences produce the largest instantaneous amplitude differences between fingertips, they contain no consistent directional information, as the +180&#176; and &#8722;180&#176; stimuli are physically identical and indistinguishable. If motion perception were driven by amplitude differences alone, one would expect robust and consistent directional judgements under these conditions&#8212;contrary to the observed choice likelihood patterns.</p><p>Moreover, an amplitude-based account might predict high confidence on individual trial bases (despite random direction across trials), assuming a salient motion signal. Yet, confidence ratings at 180&#176; were the lowest across all phase differences, mirroring the slower responses typically associated with perceptual uncertainty. Together, these findings support a mechanism in which &#8220;phase differences&#8221; between signals, not momentary amplitude (or &#8220;energy&#8221;) differences, drive tactile motion perception.</p></sec><sec id="sec3dot5-sensors-25-05918"><title>3.5. Potential Underlying Neural Computations</title><p>As in vision, tactile motion perception may rely on multiple neural computations [<xref rid="B5-sensors-25-05918" ref-type="bibr">5</xref>,<xref rid="B52-sensors-25-05918" ref-type="bibr">52</xref>]. Here, I outline two candidate mechanisms that could support the perception of motion based on phase differences in vibrotactile signals. These mechanisms differ in whether they rely on the measures of similarity of temporal patterns or on the relative timing of specific features (e.g., peaks or troughs) in the tactile signals. Below, I briefly discuss each and assess their neural plausibility.</p><sec id="sec3dot5dot1-sensors-25-05918"><title>3.5.1. Temporal Cross-Correlation Mechanisms</title><p>A plausible computational mechanism underlying tactile motion perception is based on temporal cross-correlation of the continuous tactile sensory inputs received at the two fingers. In this scenario, the brain compares the envelopes of each vibration over a certain temporal window to estimate their relative lag (phase difference) similar to Reichardt detectors [<xref rid="B1-sensors-25-05918" ref-type="bibr">1</xref>,<xref rid="B53-sensors-25-05918" ref-type="bibr">53</xref>]. The inferred phase neural mechanisms for such temporal cross-correlation have been widely studied in other sensory systems. For example, in the auditory system, interaural time differences are computed via temporally sensitive circuits in the medial superior olive, involving coincidence detection mechanisms [<xref rid="B54-sensors-25-05918" ref-type="bibr">54</xref>]. In the electrosensory system of weakly electric fish, neurons perform delay-sensitive comparisons between signals from different electroreceptors to extract motion or phase differences of preys [<xref rid="B55-sensors-25-05918" ref-type="bibr">55</xref>]. While mammalian tactile system may not contain dedicated delay lines, some neurons in somatosensory cortex (particularly S1 and S2) exhibit phase-locked responses to frequency modulations [<xref rid="B56-sensors-25-05918" ref-type="bibr">56</xref>,<xref rid="B57-sensors-25-05918" ref-type="bibr">57</xref>], carrying information about the temporal patterns of sensory inputs. Additionally, cross-digit integration occurs at multiple levels, including primary and secondary somatosensory cortices, where receptive fields often span multiple fingers [<xref rid="B58-sensors-25-05918" ref-type="bibr">58</xref>,<xref rid="B59-sensors-25-05918" ref-type="bibr">59</xref>]. Such distributed, temporally sensitive representations could support correlation-based decoding of phase relationships. The observed sensitivity to small phase differences (e.g., 30&#176;) in the present study is consistent with this type of integration. Thus, a biologically plausible hypothesis is that populations of neurons in somatosensory cortex, or possibly parietal areas, integrate envelope information and compare their temporal alignment. Population-level decoding of such temporal relationships could underlie the perceptual sensitivity to direction based on phase difference, as observed in the present experiments. Whether these computations occur via explicit cross-correlation at the neural level, or are approximated by population-level pooling across temporal patterns, remains to be clarified.</p><p>Importantly, these computations are not limited to biological intuition but are also grounded in formal estimation theory. Under assumptions of linearity and Gaussian noise, cross-correlation, least-squares, and maximum likelihood methods yield equivalent estimates for time delay between signals [<xref rid="B60-sensors-25-05918" ref-type="bibr">60</xref>]. These mechanisms are sensitive to the overall similarity and alignment of time-varying signals, rather than to discrete features such as peaks or zero-crossings. As such, they can operate continuously and flexibly and do not depend on precise extraction of singular time points, potentially making them robust to noise.</p></sec><sec id="sec3dot5dot2-sensors-25-05918"><title>3.5.2. A Probabilistic Model from Envelope Landmarks</title><p>A second mechanism is that the tactile system detects specific temporal landmarks in the envelope of each vibration&#8212;such as peaks, troughs, or other salient features&#8212;and infers motion direction based on the temporal order or timing of these events relative to each other. This process is inherently susceptible to sensory noise and perceptual uncertainty, especially when the modulated envelope changes gradually or when features are close in time.</p><p>To formalise this temporal uncertainty, I propose a simple threshold-based model in which a temporal reference point (e.g., a peak) is detected when the change in the envelope exceeds a certain slope or amplitude threshold. Changes below this threshold are not perceived as distinct events. For instance, under this assumption, any portion of the envelope around the true peak whose amplitude lies within the threshold margin is perceptually indistinguishable from the true peak. This introduces variability in the perceived timing of features or leads to missed detections, particularly when the modulation depth is shallow or the envelope varies slowly.</p><p>Such detection uncertainty can lead to errors in temporal order judgements. For instance, two peaks occurring closely in time might be perceived in the wrong order, or the tactile system might match a peak from one vibration to the wrong cycle of the other, especially under large phase differences. These errors impair the brain&#8217;s ability to infer motion direction reliably. Importantly, this minimal model&#8212;based on a fixed amplitude detection threshold without any complex decoding and uniform temporal variability&#8212;produces non-trivial psychometric predictions. As illustrated in <xref rid="sensors-25-05918-f006" ref-type="fig">Figure 6</xref>A, the model correctly generates an asymmetric curve of predicted proportion as a function of phase difference: for phase differences below 90&#176; (e.g., 30&#176;), errors primarily result from uncertainty in the temporal order of closely spaced landmarks, described by a quadratic function of phase difference (Equation (<xref rid="FD15-sensors-25-05918" ref-type="disp-formula">15</xref>)), whereas for phase differences above 90&#176; (e.g., for 150&#176;), cross-cycle misalignments dominate due to increased ambiguity in aligning peaks across cycles, as captured by a piecewise cubic function of phase difference (Equation (<xref rid="FD17-sensors-25-05918" ref-type="disp-formula">17</xref>)). This asymmetry is also evident in the present experimental data, particularly in Experiment 2 (<xref rid="sensors-25-05918-f004" ref-type="fig">Figure 4</xref>), where performance at a 30&#176; phase difference (69.7% &#177; 5.1%) is higher than at 150&#176; (56.8% &#177; 2.6%), despite the physical symmetry of the stimuli.</p><p>To evaluate the model&#8217;s predictive validity, I fit the probabilistic model to behavioural accuracy data across participants. The best-fitting threshold&#8212;expressed as an amplitude proportion relative to the envelope peak&#8212;was 0.57 &#177; 0.07, with a root mean squared error (RMSE) of 0.068 &#177; 0.009 across subjects (<inline-formula><mml:math id="mm222" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>13</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, from Experiment 1 and 2). An RMSE of 0.068 corresponds to an average prediction error of 6.8% in accuracy, indicating that the model achieves reasonably close fits to the observed performances (<xref rid="sensors-25-05918-f006" ref-type="fig">Figure 6</xref>B).</p><p>While this model was implemented based on peak detection, the same logic applies to other types of envelope features, including troughs or points of inflection. The key principle is that temporal reference points are perceived only if they exceed a salience threshold, and perceptual errors emerge from variability in the timing or detectability of these points. This model captures the dual sources of perceptual error: (1) local ambiguity in temporal order when the temporal reference points are too close and (2) misattribution across cycles when phase differences approach 180&#176;.</p><p>Critically, this model explains why perceptual performance deteriorates at large phase differences despite increased amplitude contrast: the temporal lag between reference points (e.g. peaks) is closer to <inline-formula><mml:math id="mm223" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, increasing the probability that reference points from one vibration are misattributed to a different cycle of the other. These findings suggest that under threshold-limited temporal resolution, tactile motion perception involves a delicate balance between fine temporal discrimination and the global temporal structure of the stimulus.</p><p>Together, these results suggest that tactile motion perception across fingers could be shaped by both global (e.g., cross-correlation) and local (event-based) temporal processing mechanisms, each with distinct neural constraints and noise profiles.</p></sec></sec></sec><sec sec-type="conclusions" id="sec4-sensors-25-05918"><title>4. Conclusions</title><p>This study investigated how the tactile system extracts spatial information about object motion from temporally structured vibrations delivered to two fingertips. Across three experiments, I delivered pairs of amplitude-modulated vibrations&#8212;each comprising a 100 Hz carrier modulated by a low-frequency sinusoidal envelope&#8212;to simulate <italic toggle="yes">continuous</italic> tactile motion. By systematically varying the phase difference between the two envelopes, I quantified how inter-fingertip phase offsets influence perceived motion direction, response latency, and confidence.</p><p>The present findings confirmed that the direction of perceived motion is determined by the phase difference between the two vibrations and not by their absolute frequency or amplitude. Experiment 1 showed that sinusoidal envelope vibrations reliably elicited robust directional motion percepts, comparable to those evoked by natural patterns (e.g., exponential). Notably, Zhao et al. [<xref rid="B12-sensors-25-05918" ref-type="bibr">12</xref>] found that gradually ramped vibrotactile stimuli produced stronger and smoother motion percepts than abrupt onsets, consistent with the use of continuous amplitude modulated vibrations in the present study to simulate naturalistic motion cues. Experiment 2 established that the upper frequency limit for reliable tactile motion discrimination lies below 1.5 Hz, a nearly ten-fold lower upper limit than those reported in earlier studies using similar stimuli but for asynchrony detection [<xref rid="B35-sensors-25-05918" ref-type="bibr">35</xref>]. Experiment 3 revealed systematic changes in confidence and reaction time with phase difference, with ambiguous conditions (0&#176; and 180&#176;) producing slower responses and lower confidence ratings. Importantly, the 180&#176; condition, despite producing the largest moment-by-moment amplitude differences between fingers, did not yield a consistent percept of direction, suggesting that motion perception depends on phase differences, not amplitude disparity.</p><p>Together, these results provide new insight into the computational basis of tactile motion perception. They support a mechanism in which tactile motion perception arises from the relative phase differences between temporally structured signals across skin locations, rather than from instantaneous amplitude differences or energy shifts. Unlike prior studies of tactile synchrony detection, the present paradigm required spatial trajectory inference across inputs, revealing that &#8220;phase-based&#8221; temporal integration, rather than amplitude contrast, underpins tactile motion perception. While Kuroki et al. [<xref rid="B35-sensors-25-05918" ref-type="bibr">35</xref>] demonstrated that humans can detect temporal asynchrony in AM tactile stimuli at higher modulation frequencies (up to 20 Hz) indicative of sensitivity to temporal structure, their task probed asynchrony detection, not motion inference. Drawing parallels to the visual system, they proposed that tactile perception may rely on both &#8220;phase-shift&#8221; and &#8220;energy-shift&#8221; mechanisms, analogous to first- and second-order motion processing in vision.</p><p>Notably, Kuroki et al. [<xref rid="B35-sensors-25-05918" ref-type="bibr">35</xref>] reported peak detection at 180&#176; phase difference. Yet in the current study, the same phase difference produced ambiguous motion percepts, reflected in lower confidence, slower responses, and inconsistent choices. This discrepancy likely reflects task-specific neural computations for synchrony detection and motion perception. Synchrony detection may rely on local temporal contrast or energy cues at single skin locations, whereas tactile motion perception requires spatial comparison and temporal integration across fingertips. The present results suggest that phase-based readout, rather than local amplitude difference, is central to tactile motion perception.</p><p>This dissociation highlights that motion perception depends on the integration of temporal phase relationships across space and time. As in the visual system, where distinct pathways support multiple forms of motion processing, the tactile system may also engage parallel mechanisms for temporal analysis. Phase-based computations appear specifically tuned for inferring motion trajectories, distinguishing them from those supporting synchrony detection. These findings reveal how the tactile system transforms temporally structured input into spatial motion percepts and how the brain selectively engages distinct temporal codes based on perceptual goals.</p><p>Here, I proposed two complementary models of tactile motion perception; one based on global cross-correlation of vibration envelopes and another relying on local temporal comparisons between salient features such as envelope peaks. While the cross-correlation model captures overall waveform similarity, the feature-based model formalises direction perception as a probabilistic judgement derived from uncertain detection of temporal landmarks within amplitude-defined windows. Notably, both models are applicable to conventional apparent motion paradigms, where discrete or pulsed stimuli with staggered onsets simulate movement. Although the inter-peak intervals in the present study (e.g., 167 ms for 30&#176; and 500 ms for 90&#176; at 0.5 Hz) exceed classical tactile temporal order judgement thresholds [<xref rid="B61-sensors-25-05918" ref-type="bibr">61</xref>], participants nonetheless exhibited robust directional performance and systematic confidence patterns. Notably, performance at a 30&#176; phase lag aligns with previously reported temporal order judgement thresholds (&#8764;100 ms; [<xref rid="B61-sensors-25-05918" ref-type="bibr">61</xref>]), despite differences in stimulus type and parameters, suggesting that reliable direction perception can emerge without discrete onsets or overt spatial displacement. While supramodal attentional tracking could, in principle, support such judgements&#8212;e.g., by tracking salient events across time and space irrespective of sensory modality&#8212;the proposed model provides a tactile-specific alternative. It attributes direction perception to probabilistic comparisons between uncertain temporal landmarks (e.g., envelope peaks), detected within amplitude-defined integration windows. This framework captures the non-linearity in psychometric curves, including both the reliable direction perception at shorter phase lags and the ambiguity at 180&#176;, without invoking higher-level amodal mechanisms or cross-modal attentional strategies. Instead, it reflects constraints intrinsic to tactile processing, where perceptual uncertainty in temporal feature extraction shapes directional judgements.</p><p>Central to the perception of the vibration-induced motion studied here is the brain&#8217;s ability to track dynamic changes in the envelopes of tactile signals and extract directional information from their relative timing. This sensory strategy has analogues across species: arachnids, for example, detect prey using complex vibration patterns transmitted through webs or substrates, relying on finely tuned mechanosensory systems that evolved independently from vertebrate touch [<xref rid="B34-sensors-25-05918" ref-type="bibr">34</xref>]. In mammalian glabrous skin, Meissner&#8217;s and Pacinian corpuscles are specialised for detecting vibration [<xref rid="B62-sensors-25-05918" ref-type="bibr">62</xref>,<xref rid="B63-sensors-25-05918" ref-type="bibr">63</xref>,<xref rid="B64-sensors-25-05918" ref-type="bibr">64</xref>,<xref rid="B65-sensors-25-05918" ref-type="bibr">65</xref>,<xref rid="B66-sensors-25-05918" ref-type="bibr">66</xref>], with Pacinian corpuscles implicated in encoding vibrotactile pitch in both mice and humans [<xref rid="B67-sensors-25-05918" ref-type="bibr">67</xref>,<xref rid="B68-sensors-25-05918" ref-type="bibr">68</xref>,<xref rid="B69-sensors-25-05918" ref-type="bibr">69</xref>,<xref rid="B70-sensors-25-05918" ref-type="bibr">70</xref>]. My previous work demonstrated that rodents can discriminate vibrations based on both amplitude and frequency using their whiskers [<xref rid="B57-sensors-25-05918" ref-type="bibr">57</xref>,<xref rid="B71-sensors-25-05918" ref-type="bibr">71</xref>,<xref rid="B72-sensors-25-05918" ref-type="bibr">72</xref>]. Neurons in primary somatosensory cortex integrate these features in a way that supports vibrotactile perception. The present study builds on these principles, showing that temporal features&#8212;specifically phase relationships&#8212;can be exploited to generate robust perceptions of tactile motion across fingertips. This supports the idea that tactile systems, across species and sensor types, flexibly encode both spectral and temporal properties of mechanical stimuli to extract high-level perceptual content.</p><p>In natural touch, a variety of cues, such as localised skin stretch in the direction of motion, texture changes, and temporal shear patterns by engaging multiple mechanoreceptor types (e.g., SA1, SA2, RA1, and RA2) [<xref rid="B3-sensors-25-05918" ref-type="bibr">3</xref>,<xref rid="B73-sensors-25-05918" ref-type="bibr">73</xref>], jointly contribute to tactile motion perception. In contrast, the present study demonstrates that even a single channel of information&#8212;vibrotactile input delivered to just two skin sites&#8212;is sufficient to elicit robust and directionally specific motion percepts. While contact force, finger posture, and transducer&#8211;skin coupling were not directly measured, participants maintained passive, stable contact with the actuators, in line with established psychophysical methods [<xref rid="B74-sensors-25-05918" ref-type="bibr">74</xref>]. These controlled conditions yielded consistent directional reports, indicating that the observed effects are robust to minor naturalistic variability in contact conditions. Future studies may incorporate force sensing or posture tracking to further refine the paradigm; however, such additions are not necessary to support the current findings.</p><p>A major challenge in somatosensory research is delivering tactile stimuli with high precision and consistency, particularly in freely moving animal preparations or in humans, where skin mechanics, posture, and contact variability can alter mechanoreceptor engagement. To mitigate these issues, the present paradigm derives motion perception from the phase relationships between temporally structured vibrations delivered at fixed spatial locations without requiring physical displacement. This approach decouples directional cues from low-level variables such as pressure, tension, amplitude, or frequency fluctuations, offering a robust and reproducible method. Moreover, it provides a powerful framework for probing tactile decision-making and perceptual inference under structured temporal stimulation, analogous to the random-dot motion in vision science. By dissociating low-level vibration features from high-level motion percepts, the paradigm links somatosensory encoding with computational decision models across both human and animal studies. Future extensions, particularly when combined with physiological or imaging techniques, may help test and refine the proposed computational mechanisms and further illuminate the neural basis of tactile motion perception, laying the scientific groundwork for applications in touch-based interfaces, neuroprosthetics, and tactile cognition.</p><p>Finally, given the increasing demand for motion-capable haptic feedback in wearable systems, neuroprosthetic interfaces, and immersive VR/AR environments [<xref rid="B40-sensors-25-05918" ref-type="bibr">40</xref>,<xref rid="B41-sensors-25-05918" ref-type="bibr">41</xref>,<xref rid="B42-sensors-25-05918" ref-type="bibr">42</xref>], this approach can be integrated with current wearable vibrotactile devices such as [<xref rid="B37-sensors-25-05918" ref-type="bibr">37</xref>,<xref rid="B38-sensors-25-05918" ref-type="bibr">38</xref>,<xref rid="B39-sensors-25-05918" ref-type="bibr">39</xref>] providing an efficient, scalable, lightweight, and cost-effective method for conveying directional tactile motion information without physical displacement&#8212;even in settings with limited actuator count or power budget such as mobile platforms. Further research is required to evaluate the paradigm with larger and more diverse participant groups, under a wider range of contact conditions and stimulation parameters, and across other body regions to better understand its generalisability and limitations.</p></sec></body><back><ack><title>Acknowledgments</title><p>The author thanks Mohammad Razmjoo and Erfan Rezaei for their assistance with data collection in Experiment 1.</p></ack><fn-group><fn><p><bold>Disclaimer/Publisher&#8217;s Note:</bold> The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.</p></fn></fn-group><notes><title>Institutional Review Board Statement</title><p>This study was conducted in accordance with the Declaration of Helsinki and approved by the Monash University Human Research Ethics Committee (MUHREC) (Project ID 27649; date of approval: 2 August 2021).</p></notes><notes><title>Informed Consent Statement</title><p>Informed consent was obtained from all subjects involved in this study.</p></notes><notes notes-type="data-availability"><title>Data Availability Statement</title><p>The data presented in this study are available on request from the author.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The author declares no conflicts of interest.</p></notes><glossary><title>Abbreviations</title><p>The following abbreviations are used in this manuscript:
<array orientation="portrait"><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">2-AFC</td><td align="left" valign="middle" rowspan="1" colspan="1">Two-Alternative Forced-Choice</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">2D</td><td align="left" valign="middle" rowspan="1" colspan="1">Two Dimensional</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">3D</td><td align="left" valign="middle" rowspan="1" colspan="1">Three Dimensional</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">AIC</td><td align="left" valign="middle" rowspan="1" colspan="1">Akaike Information Criterion</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">AM</td><td align="left" valign="middle" rowspan="1" colspan="1">Amplitude Modulation/Modulated</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">AR</td><td align="left" valign="middle" rowspan="1" colspan="1">Augmented Reality</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">ARC</td><td align="left" valign="middle" rowspan="1" colspan="1">Australian Research Council</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">BIC</td><td align="left" valign="middle" rowspan="1" colspan="1">Bayesian Information Criterion</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CI</td><td align="left" valign="middle" rowspan="1" colspan="1">Confidence Interval</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">GLMM</td><td align="left" valign="middle" rowspan="1" colspan="1">Generalised Linear Mixed-Effects Model</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">LME</td><td align="left" valign="middle" rowspan="1" colspan="1">Linear Mixed-Effects</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">RA1</td><td align="left" valign="middle" rowspan="1" colspan="1">Rapidly Adapting type I</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">RA2</td><td align="left" valign="middle" rowspan="1" colspan="1">Rapidly Adapting type II</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">RMSE</td><td align="left" valign="middle" rowspan="1" colspan="1">Root Mean Squared Error</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">RT</td><td align="left" valign="middle" rowspan="1" colspan="1">Response Time</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">S1</td><td align="left" valign="middle" rowspan="1" colspan="1">Primary Somatosensory Cortex</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">S2</td><td align="left" valign="middle" rowspan="1" colspan="1">Secondary Somatosensory Cortex</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">SA1</td><td align="left" valign="middle" rowspan="1" colspan="1">Slowly Adapting type I</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">SA2</td><td align="left" valign="middle" rowspan="1" colspan="1">Slowly Adapting type II</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">SE</td><td align="left" valign="middle" rowspan="1" colspan="1">Standard Error</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">SEM</td><td align="left" valign="middle" rowspan="1" colspan="1">Standard Error of the Mean</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">VR</td><td align="left" valign="middle" rowspan="1" colspan="1">Virtual Reality</td></tr></tbody></array></p></glossary><ref-list><title>References</title><ref id="B1-sensors-25-05918"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Clifford</surname><given-names>C.W.G.</given-names></name><name name-style="western"><surname>Ibbotson</surname><given-names>M.R.</given-names></name><name name-style="western"><surname>Langley</surname><given-names>K.</given-names></name></person-group><article-title>An adaptive Reichardt detector model of motion adaptation in insects and mammals</article-title><source>Vis. Neurosci.</source><year>1997</year><volume>14</volume><fpage>741</fpage><lpage>749</lpage><pub-id pub-id-type="doi">10.1017/S0952523800012694</pub-id><pub-id pub-id-type="pmid">9279002</pub-id></element-citation></ref><ref id="B2-sensors-25-05918"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Adibi</surname><given-names>M.</given-names></name><name name-style="western"><surname>Zoccolan</surname><given-names>D.</given-names></name><name name-style="western"><surname>Clifford</surname><given-names>C.W.G.</given-names></name></person-group><article-title>Editorial: Sensory Adaptation</article-title><source>Front. Syst. Neurosci.</source><year>2021</year><volume>15</volume><elocation-id>809000</elocation-id><pub-id pub-id-type="doi">10.3389/fnsys.2021.809000</pub-id><pub-id pub-id-type="pmid">34955772</pub-id><pub-id pub-id-type="pmcid">PMC8692977</pub-id></element-citation></ref><ref id="B3-sensors-25-05918"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Johansson</surname><given-names>R.S.</given-names></name><name name-style="western"><surname>Flanagan</surname><given-names>J.R.</given-names></name></person-group><article-title>Coding and use of tactile signals from the fingertips in object manipulation tasks</article-title><source>Nat. Rev. Neurosci.</source><year>2009</year><volume>10</volume><fpage>345</fpage><lpage>359</lpage><pub-id pub-id-type="doi">10.1038/nrn2621</pub-id><pub-id pub-id-type="pmid">19352402</pub-id></element-citation></ref><ref id="B4-sensors-25-05918"><label>4.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Johnson</surname><given-names>K.O.</given-names></name></person-group><article-title>Neural Basis of Haptic Perception</article-title><source>Stevens&#8217; Handbook of Experimental Psychology</source><edition>3rd ed.</edition><person-group person-group-type="editor"><name name-style="western"><surname>Yantis</surname><given-names>S.</given-names></name></person-group><publisher-name>Wiley</publisher-name><publisher-loc>Hoboken, NJ, USA</publisher-loc><year>2002</year><volume>Volume 1</volume><fpage>537</fpage><lpage>580</lpage><pub-id pub-id-type="doi">10.1002/0471214426.pas0113</pub-id></element-citation></ref><ref id="B5-sensors-25-05918"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pei</surname><given-names>Y.C.</given-names></name><name name-style="western"><surname>Bensmaia</surname><given-names>S.J.</given-names></name></person-group><article-title>The neural basis of tactile motion perception</article-title><source>J. Neurophysiol.</source><year>2014</year><volume>112</volume><fpage>3023</fpage><lpage>3032</lpage><pub-id pub-id-type="doi">10.1152/jn.00391.2014</pub-id><pub-id pub-id-type="pmid">25253479</pub-id><pub-id pub-id-type="pmcid">PMC4269710</pub-id></element-citation></ref><ref id="B6-sensors-25-05918"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Olausson</surname><given-names>H.</given-names></name><name name-style="western"><surname>Norrsell</surname><given-names>U.</given-names></name></person-group><article-title>Observations on human tactile directional sensibility</article-title><source>J. Physiol.</source><year>1993</year><volume>464</volume><fpage>545</fpage><lpage>559</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1993.sp019650</pub-id><pub-id pub-id-type="pmid">8229817</pub-id><pub-id pub-id-type="pmcid">PMC1175401</pub-id></element-citation></ref><ref id="B7-sensors-25-05918"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sherrick</surname><given-names>C.E.</given-names></name><name name-style="western"><surname>Rogers</surname><given-names>R.</given-names></name></person-group><article-title>Apparent haptic movement</article-title><source>Percept. Psychophys.</source><year>1966</year><volume>1</volume><fpage>175</fpage><lpage>180</lpage><pub-id pub-id-type="doi">10.3758/BF03210054</pub-id></element-citation></ref><ref id="B8-sensors-25-05918"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kirman</surname><given-names>J.H.</given-names></name></person-group><article-title>Tactile apparent movement: The effects of interstimulus onset interval and stimulus duration</article-title><source>Percept. Psychophys.</source><year>1974</year><volume>15</volume><fpage>1</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.3758/BF03205819</pub-id></element-citation></ref><ref id="B9-sensors-25-05918"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gardner</surname><given-names>E.P.</given-names></name><name name-style="western"><surname>Palmer</surname><given-names>C.I.</given-names></name></person-group><article-title>Simulation of motion on the skin. I. Receptive fields and temporal frequency coding by cutaneous mechanoreceptors of OPTACON pulses delivered to the hand</article-title><source>J. Neurophysiol.</source><year>1989</year><volume>62</volume><fpage>1410</fpage><lpage>1436</lpage><pub-id pub-id-type="doi">10.1152/jn.1989.62.6.1410</pub-id><pub-id pub-id-type="pmid">2600632</pub-id></element-citation></ref><ref id="B10-sensors-25-05918"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gardner</surname><given-names>E.P.</given-names></name><name name-style="western"><surname>Palmer</surname><given-names>C.I.</given-names></name></person-group><article-title>Simulation of motion on the skin. II. Cutaneous mechanoreceptor coding of the width and texture of bar patterns displaced across the OPTACON</article-title><source>J. Neurophysiol.</source><year>1989</year><volume>62</volume><fpage>1437</fpage><lpage>1460</lpage><pub-id pub-id-type="doi">10.1152/jn.1989.62.6.1437</pub-id><pub-id pub-id-type="pmid">2600633</pub-id></element-citation></ref><ref id="B11-sensors-25-05918"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Killebrew</surname><given-names>J.H.</given-names></name><name name-style="western"><surname>Bensmaia</surname><given-names>S.J.</given-names></name><name name-style="western"><surname>Dammann</surname><given-names>J.F.</given-names></name><name name-style="western"><surname>Denchev</surname><given-names>P.</given-names></name><name name-style="western"><surname>Hsiao</surname><given-names>S.S.</given-names></name><name name-style="western"><surname>Craig</surname><given-names>J.C.</given-names></name><name name-style="western"><surname>Johnson</surname><given-names>K.O.</given-names></name></person-group><article-title>A dense array stimulator to generate arbitrary spatio-temporal tactile stimuli</article-title><source>J. Neurosci. Methods</source><year>2007</year><volume>161</volume><fpage>62</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2006.10.012</pub-id><pub-id pub-id-type="pmid">17134760</pub-id><pub-id pub-id-type="pmcid">PMC1851669</pub-id></element-citation></ref><ref id="B12-sensors-25-05918"><label>12.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Zhao</surname><given-names>S.</given-names></name><name name-style="western"><surname>Israr</surname><given-names>A.</given-names></name><name name-style="western"><surname>Klatzky</surname><given-names>R.</given-names></name></person-group><article-title>Intermanual apparent tactile motion on handheld tablets</article-title><source>Proceedings of the 2015 IEEE World Haptics Conference (WHC)</source><conf-loc>Chicago, IL, USA</conf-loc><conf-date>22&#8211;25 June 2015</conf-date><fpage>241</fpage><lpage>247</lpage><pub-id pub-id-type="doi">10.1109/WHC.2015.7177720</pub-id></element-citation></ref><ref id="B13-sensors-25-05918"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Seizova-Cajic</surname><given-names>T.</given-names></name><name name-style="western"><surname>Ludvigsson</surname><given-names>S.</given-names></name><name name-style="western"><surname>Sourander</surname><given-names>B.</given-names></name><name name-style="western"><surname>Popov</surname><given-names>M.</given-names></name><name name-style="western"><surname>Taylor</surname><given-names>J.L.</given-names></name></person-group><article-title>Scrambling the skin: A psychophysical study of adaptation to scrambled tactile apparent motion</article-title><source>PLoS ONE</source><year>2020</year><volume>15</volume><elocation-id>e0227462</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0227462</pub-id><pub-id pub-id-type="pmid">33382701</pub-id><pub-id pub-id-type="pmcid">PMC7775071</pub-id></element-citation></ref><ref id="B14-sensors-25-05918"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kuroki</surname><given-names>S.</given-names></name><name name-style="western"><surname>Nishida</surname><given-names>S.</given-names></name></person-group><article-title>Motion direction discrimination with tactile random-dot kinematograms</article-title><source>Iperception</source><year>2021</year><volume>12</volume><fpage>20416695211004620</fpage><pub-id pub-id-type="doi">10.1177/20416695211004620</pub-id><pub-id pub-id-type="pmid">33854748</pub-id><pub-id pub-id-type="pmcid">PMC8010832</pub-id></element-citation></ref><ref id="B15-sensors-25-05918"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Abdouni</surname><given-names>A.</given-names></name><name name-style="western"><surname>Vargiolu</surname><given-names>R.</given-names></name><name name-style="western"><surname>Zahouani</surname><given-names>H.</given-names></name></person-group><article-title>Impact of finger biophysical properties on touch gestures and tactile perception: Aging and gender effects</article-title><source>Sci. Rep.</source><year>2018</year><volume>8</volume><elocation-id>12605</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-018-30677-2</pub-id><pub-id pub-id-type="pmid">30135602</pub-id><pub-id pub-id-type="pmcid">PMC6105722</pub-id></element-citation></ref><ref id="B16-sensors-25-05918"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Olausson</surname><given-names>H.</given-names></name><name name-style="western"><surname>Wessberg</surname><given-names>J.</given-names></name><name name-style="western"><surname>Kakuda</surname><given-names>N.</given-names></name></person-group><article-title>Tactile directional sensibility: Peripheral neural mechanisms in man</article-title><source>Brain Res.</source><year>2000</year><volume>866</volume><fpage>178</fpage><lpage>187</lpage><pub-id pub-id-type="doi">10.1016/S0006-8993(00)02278-2</pub-id><pub-id pub-id-type="pmid">10825493</pub-id></element-citation></ref><ref id="B17-sensors-25-05918"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Phillips</surname><given-names>J.R.</given-names></name><name name-style="western"><surname>Johnson</surname><given-names>K.O.</given-names></name></person-group><article-title>Tactile spatial resolution. II. Neural representation of bars, edges, and gratings in monkey primary afferents</article-title><source>J. Neurophysiol.</source><year>1981</year><volume>46</volume><fpage>1192</fpage><lpage>1203</lpage><pub-id pub-id-type="doi">10.1152/jn.1981.46.6.1192</pub-id><pub-id pub-id-type="pmid">6275041</pub-id></element-citation></ref><ref id="B18-sensors-25-05918"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Friedman</surname><given-names>R.M.</given-names></name><name name-style="western"><surname>Khalsa</surname><given-names>P.S.</given-names></name><name name-style="western"><surname>Greenquist</surname><given-names>K.W.</given-names></name><name name-style="western"><surname>LaMotte</surname><given-names>R.H.</given-names></name></person-group><article-title>Neural coding of the location and direction of a moving object by a spatially distributed population of mechanoreceptors</article-title><source>J. Neurosci.</source><year>2002</year><volume>22</volume><fpage>9556</fpage><lpage>9566</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.22-21-09556.2002</pub-id><pub-id pub-id-type="pmid">12417680</pub-id><pub-id pub-id-type="pmcid">PMC6758035</pub-id></element-citation></ref><ref id="B19-sensors-25-05918"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kwon</surname><given-names>J.</given-names></name><name name-style="western"><surname>Park</surname><given-names>S.W.</given-names></name><name name-style="western"><surname>Sakamoto</surname><given-names>M.</given-names></name><name name-style="western"><surname>Mito</surname><given-names>K.</given-names></name></person-group><article-title>The effects of vibratory frequency and temporal interval on tactile apparent motion</article-title><source>IEEE Trans. Haptics</source><year>2021</year><volume>14</volume><fpage>675</fpage><lpage>679</lpage><pub-id pub-id-type="doi">10.1109/TOH.2021.3051388</pub-id><pub-id pub-id-type="pmid">33439848</pub-id></element-citation></ref><ref id="B20-sensors-25-05918"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bliss</surname><given-names>J.C.</given-names></name><name name-style="western"><surname>Katcher</surname><given-names>M.H.</given-names></name><name name-style="western"><surname>Rogers</surname><given-names>C.H.</given-names></name><name name-style="western"><surname>Shepard</surname><given-names>R.P.</given-names></name></person-group><article-title>Optical-to-Tactile Image Conversion for the Blind</article-title><source>IEEE Trans.-Man-Mach. Syst.</source><year>1970</year><volume>11</volume><fpage>58</fpage><lpage>65</lpage><pub-id pub-id-type="doi">10.1109/TMMS.1970.299963</pub-id></element-citation></ref><ref id="B21-sensors-25-05918"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gardner</surname><given-names>E.P.</given-names></name><name name-style="western"><surname>Palmer</surname><given-names>C.I.</given-names></name><name name-style="western"><surname>Hamalainen</surname><given-names>H.A.</given-names></name><name name-style="western"><surname>Warren</surname><given-names>S.</given-names></name></person-group><article-title>Simulation of motion on the skin. V. Effect of stimulus temporal frequency on the representation of moving bar patterns in primary somatosensory cortex of monkeys</article-title><source>J. Neurophysiol.</source><year>1992</year><volume>67</volume><fpage>37</fpage><lpage>63</lpage><pub-id pub-id-type="doi">10.1152/jn.1992.67.1.37</pub-id><pub-id pub-id-type="pmid">1552322</pub-id></element-citation></ref><ref id="B22-sensors-25-05918"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gardner</surname><given-names>E.P.</given-names></name><name name-style="western"><surname>Sklar</surname><given-names>B.F.</given-names></name></person-group><article-title>Discrimination of the direction of motion on the human hand: A psychophysical study of stimulation parameters</article-title><source>J. Neurophysiol.</source><year>1994</year><volume>71</volume><fpage>2414</fpage><lpage>2429</lpage><pub-id pub-id-type="doi">10.1152/jn.1994.71.6.2414</pub-id><pub-id pub-id-type="pmid">7931525</pub-id></element-citation></ref><ref id="B23-sensors-25-05918"><label>23.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>McIntyre</surname><given-names>S.</given-names></name><name name-style="western"><surname>Seizova-Cajic</surname><given-names>T.</given-names></name><name name-style="western"><surname>Birznieks</surname><given-names>I.</given-names></name><name name-style="western"><surname>Holcombe</surname><given-names>A.O.</given-names></name><name name-style="western"><surname>Vickery</surname><given-names>R.M.</given-names></name></person-group><article-title>Adaptation to Motion Presented with a Tactile Array</article-title><source>Proceedings of the Haptics: Neuroscience, Devices, Modeling, and Applications</source><conf-loc>Versailles, France</conf-loc><conf-date>24&#8211;26 June 2014</conf-date><fpage>351</fpage><lpage>359</lpage></element-citation></ref><ref id="B24-sensors-25-05918"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Srinivasan</surname><given-names>M.A.</given-names></name><name name-style="western"><surname>Whitehouse</surname><given-names>J.M.</given-names></name><name name-style="western"><surname>LaMotte</surname><given-names>R.H.</given-names></name></person-group><article-title>Tactile detection of slip: Surface microgeometry and peripheral neural codes</article-title><source>J. Neurophysiol.</source><year>1990</year><volume>63</volume><fpage>1323</fpage><lpage>1332</lpage><pub-id pub-id-type="doi">10.1152/jn.1990.63.6.1323</pub-id><pub-id pub-id-type="pmid">2358880</pub-id></element-citation></ref><ref id="B25-sensors-25-05918"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Keyson</surname><given-names>D.V.</given-names></name><name name-style="western"><surname>Houtsma</surname><given-names>A.J.M.</given-names></name></person-group><article-title>Directional sensitivity to a tactile point stimulus moving across the fingerpad</article-title><source>Percept. Psychophys.</source><year>1995</year><volume>57</volume><fpage>738</fpage><lpage>744</lpage><pub-id pub-id-type="doi">10.3758/BF03213278</pub-id><pub-id pub-id-type="pmid">7644332</pub-id></element-citation></ref><ref id="B26-sensors-25-05918"><label>26.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Essick</surname><given-names>G.K.</given-names></name></person-group><article-title>Factors affecting direction discrimination of moving tactile stimuli</article-title><source>Neural Aspects in Tactile Sensation</source><comment>Advances in Psychology</comment><person-group person-group-type="editor"><name name-style="western"><surname>Morley</surname><given-names>J.</given-names></name></person-group><publisher-name>North-Holland</publisher-name><publisher-loc>Amsterdam, The Netherlands</publisher-loc><year>1998</year><volume>Volume 127</volume><fpage>1</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1016/S0166-4115(98)80063-0</pub-id></element-citation></ref><ref id="B27-sensors-25-05918"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pei</surname><given-names>Y.C.</given-names></name><name name-style="western"><surname>Lee</surname><given-names>T.C.</given-names></name><name name-style="western"><surname>Chang</surname><given-names>T.Y.</given-names></name><name name-style="western"><surname>Ruffatto</surname><given-names>D.</given-names></name><name name-style="western"><surname>Spenko</surname><given-names>M.</given-names></name><name name-style="western"><surname>Bensmaia</surname><given-names>S.</given-names></name></person-group><article-title>A multi-digit tactile motion stimulator</article-title><source>J. Neurosci. Methods</source><year>2014</year><volume>226</volume><fpage>80</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2014.01.021</pub-id><pub-id pub-id-type="pmid">24485869</pub-id></element-citation></ref><ref id="B28-sensors-25-05918"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Arslanova</surname><given-names>I.</given-names></name><name name-style="western"><surname>Takamuku</surname><given-names>S.</given-names></name><name name-style="western"><surname>Gomi</surname><given-names>H.</given-names></name><name name-style="western"><surname>Haggard</surname><given-names>P.</given-names></name></person-group><article-title>Multidigit tactile perception I: Motion integration benefits for tactile trajectories presented bimanually</article-title><source>J. Neurophysiol.</source><year>2022</year><volume>128</volume><fpage>418</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1152/jn.00022.2022</pub-id><pub-id pub-id-type="pmid">35822710</pub-id><pub-id pub-id-type="pmcid">PMC9359661</pub-id></element-citation></ref><ref id="B29-sensors-25-05918"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kuroki</surname><given-names>S.</given-names></name><name name-style="western"><surname>Nishida</surname><given-names>S.</given-names></name></person-group><article-title>Human tactile detection of within- and inter-finger spatiotemporal phase shifts of low-frequency vibrations</article-title><source>Sci. Rep.</source><year>2018</year><volume>8</volume><elocation-id>4288</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-018-22774-z</pub-id><pub-id pub-id-type="pmid">29523834</pub-id><pub-id pub-id-type="pmcid">PMC5844903</pub-id></element-citation></ref><ref id="B30-sensors-25-05918"><label>30.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Gardner</surname><given-names>E.P.</given-names></name><name name-style="western"><surname>Martin</surname><given-names>J.H.</given-names></name></person-group><article-title>Coding of sensory information</article-title><source>Principles of Neural Science</source><publisher-name>McGraw-Hill</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>2000</year><fpage>411</fpage><lpage>429</lpage></element-citation></ref><ref id="B31-sensors-25-05918"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mountcastle</surname><given-names>V.B.</given-names></name><name name-style="western"><surname>Talbot</surname><given-names>W.H.</given-names></name><name name-style="western"><surname>Darian-Smith</surname><given-names>I.</given-names></name><name name-style="western"><surname>Kornhuber</surname><given-names>H.H.</given-names></name></person-group><article-title>Neural basis of the sense of flutter-vibration</article-title><source>Science</source><year>1967</year><volume>155</volume><fpage>597</fpage><lpage>600</lpage><pub-id pub-id-type="doi">10.1126/science.155.3762.597</pub-id><pub-id pub-id-type="pmid">4959494</pub-id></element-citation></ref><ref id="B32-sensors-25-05918"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Talbot</surname><given-names>W.H.</given-names></name><name name-style="western"><surname>Darian-Smith</surname><given-names>I.</given-names></name><name name-style="western"><surname>Kornhuber</surname><given-names>H.H.</given-names></name><name name-style="western"><surname>Mountcastle</surname><given-names>V.B.</given-names></name></person-group><article-title>The sense of flutter-vibration: Comparison of the human capacity with response patterns of mechanoreceptive afferents from the monkey hand</article-title><source>J. Neurophysiol.</source><year>1968</year><volume>31</volume><fpage>301</fpage><pub-id pub-id-type="doi">10.1152/jn.1968.31.2.301</pub-id><pub-id pub-id-type="pmid">4972033</pub-id></element-citation></ref><ref id="B33-sensors-25-05918"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Johansson</surname><given-names>R.S.</given-names></name><name name-style="western"><surname>Vallbo</surname><given-names>A.B.</given-names></name></person-group><article-title>Detection of tactile stimuli. Thresholds of afferent units related to psychophysical thresholds in the human hand</article-title><source>J. Physiol.</source><year>1979</year><volume>297</volume><fpage>405</fpage><pub-id pub-id-type="doi">10.1113/jphysiol.1979.sp013048</pub-id><pub-id pub-id-type="pmid">536918</pub-id><pub-id pub-id-type="pmcid">PMC1458728</pub-id></element-citation></ref><ref id="B34-sensors-25-05918"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Strau&#223;</surname><given-names>J.</given-names></name><name name-style="western"><surname>Stritih-Peljhan</surname><given-names>N.</given-names></name></person-group><article-title>Vibration detection in arthropods: Signal transfer, biomechanics and sensory adaptations</article-title><source>Arthropod Struct. Dev.</source><year>2022</year><volume>68</volume><fpage>101167</fpage><pub-id pub-id-type="doi">10.1016/j.asd.2022.101167</pub-id><pub-id pub-id-type="pmid">35576788</pub-id></element-citation></ref><ref id="B35-sensors-25-05918"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kuroki</surname><given-names>S.</given-names></name><name name-style="western"><surname>Watanabe</surname><given-names>J.</given-names></name><name name-style="western"><surname>Nishida</surname><given-names>S.</given-names></name></person-group><article-title>Neural timing signal for precise tactile timing judgments</article-title><source>J. Neurophysiol.</source><year>2016</year><volume>115</volume><fpage>1620</fpage><lpage>1629</lpage><pub-id pub-id-type="doi">10.1152/jn.00790.2015</pub-id><pub-id pub-id-type="pmid">26843600</pub-id><pub-id pub-id-type="pmcid">PMC4808138</pub-id></element-citation></ref><ref id="B36-sensors-25-05918"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ujitoko</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Kuroki</surname><given-names>S.</given-names></name></person-group><article-title>Sinusoidal Vibration Source Localization in Two-Dimensional Space Around the Hand</article-title><source>Front. Psychol.</source><year>2022</year><volume>13</volume><elocation-id>878397</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2022.878397</pub-id><pub-id pub-id-type="pmid">35756225</pub-id><pub-id pub-id-type="pmcid">PMC9232185</pub-id></element-citation></ref><ref id="B37-sensors-25-05918"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Seim</surname><given-names>C.E.</given-names></name><name name-style="western"><surname>Ritter</surname><given-names>B.</given-names></name><name name-style="western"><surname>Starner</surname><given-names>T.E.</given-names></name><name name-style="western"><surname>Flavin</surname><given-names>K.</given-names></name><name name-style="western"><surname>Lansberg</surname><given-names>M.G.</given-names></name><name name-style="western"><surname>Okamura</surname><given-names>A.M.</given-names></name></person-group><article-title>Design of a Wearable Vibrotactile Stimulation Device for Individuals With Upper-Limb Hemiparesis and Spasticity</article-title><source>IEEE Trans. Neural Syst. Rehabil. Eng.</source><year>2022</year><volume>30</volume><fpage>1277</fpage><lpage>1287</lpage><pub-id pub-id-type="doi">10.1109/TNSRE.2022.3174808</pub-id><pub-id pub-id-type="pmid">35552152</pub-id><pub-id pub-id-type="pmcid">PMC10139869</pub-id></element-citation></ref><ref id="B38-sensors-25-05918"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>de Vlam</surname><given-names>V.</given-names></name><name name-style="western"><surname>Wiertlewski</surname><given-names>M.</given-names></name><name name-style="western"><surname>Vardar</surname><given-names>Y.</given-names></name></person-group><article-title>Focused Vibrotactile Stimuli from a Wearable Sparse Array of Actuators</article-title><source>IEEE Trans. Haptics</source><year>2023</year><volume>16</volume><fpage>511</fpage><lpage>517</lpage><pub-id pub-id-type="doi">10.1109/TOH.2023.3270362</pub-id><pub-id pub-id-type="pmid">37097798</pub-id></element-citation></ref><ref id="B39-sensors-25-05918"><label>39.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Huang</surname><given-names>J.</given-names></name><name name-style="western"><surname>Fang</surname><given-names>Y.</given-names></name><name name-style="western"><surname>Guo</surname><given-names>W.</given-names></name><name name-style="western"><surname>Qiao</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Sheng</surname><given-names>X.</given-names></name></person-group><article-title>Optimized Design of a Haptic Unit for Vibrotactile Amplitude Modulation</article-title><source>Proceedings of the 2024 IEEE International Conference on Robotics and Biomimetics (ROBIO)</source><conf-loc>Bangkok, Thailand</conf-loc><conf-date>10&#8211;14 December 2024</conf-date><fpage>123</fpage><lpage>128</lpage><pub-id pub-id-type="doi">10.1109/ROBIO64047.2024.10907599</pub-id></element-citation></ref><ref id="B40-sensors-25-05918"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>van Wegen</surname><given-names>M.</given-names></name><name name-style="western"><surname>Herder</surname><given-names>J.L.</given-names></name><name name-style="western"><surname>Adelsberger</surname><given-names>R.</given-names></name><name name-style="western"><surname>Pastore-Wapp</surname><given-names>M.</given-names></name><name name-style="western"><surname>van Wegen</surname><given-names>E.E.H.</given-names></name><name name-style="western"><surname>Bohlhalter</surname><given-names>S.</given-names></name><name name-style="western"><surname>Nef</surname><given-names>T.</given-names></name><name name-style="western"><surname>Krack</surname><given-names>P.</given-names></name><name name-style="western"><surname>Vanbellingen</surname><given-names>T.</given-names></name></person-group><article-title>An Overview of Wearable Haptic Technologies and Their Performance in Virtual Object Exploration</article-title><source>Sensors</source><year>2023</year><volume>23</volume><elocation-id>1563</elocation-id><pub-id pub-id-type="doi">10.3390/s23031563</pub-id><pub-id pub-id-type="pmid">36772603</pub-id><pub-id pub-id-type="pmcid">PMC9919508</pub-id></element-citation></ref><ref id="B41-sensors-25-05918"><label>41.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Frisoli</surname><given-names>A.</given-names></name><name name-style="western"><surname>Leonardis</surname><given-names>D.</given-names></name></person-group><article-title>Wearable haptics for virtual reality and beyond</article-title><source>Nat. Rev. Electr. Eng.</source><year>2024</year><volume>1</volume><fpage>666</fpage><lpage>679</lpage><pub-id pub-id-type="doi">10.1038/s44287-024-00089-8</pub-id></element-citation></ref><ref id="B42-sensors-25-05918"><label>42.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jung</surname><given-names>K.</given-names></name><name name-style="western"><surname>Kim</surname><given-names>S.</given-names></name><name name-style="western"><surname>Oh</surname><given-names>S.</given-names></name><name name-style="western"><surname>Yoon</surname><given-names>S.H.</given-names></name></person-group><article-title>HapMotion: Motion-to-tactile framework with wearable haptic devices for immersive VR performance experience</article-title><source>Virtual Real.</source><year>2024</year><volume>28</volume><fpage>13</fpage><pub-id pub-id-type="doi">10.1007/s10055-023-00910-z</pub-id></element-citation></ref><ref id="B43-sensors-25-05918"><label>43.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fleck</surname><given-names>J.J.</given-names></name><name name-style="western"><surname>Zook</surname><given-names>Z.A.</given-names></name><name name-style="western"><surname>Clark</surname><given-names>J.P.</given-names></name><name name-style="western"><surname>Preston</surname><given-names>D.J.</given-names></name><name name-style="western"><surname>Lipomi</surname><given-names>D.J.</given-names></name><name name-style="western"><surname>Pacchierotti</surname><given-names>C.</given-names></name><name name-style="western"><surname>O&#8217;Malley</surname><given-names>M.K.</given-names></name></person-group><article-title>Wearable multi-sensory haptic devices</article-title><source>Nat. Rev. Bioeng.</source><year>2025</year><volume>3</volume><fpage>288</fpage><lpage>302</lpage><pub-id pub-id-type="doi">10.1038/s44222-025-00274-w</pub-id></element-citation></ref><ref id="B44-sensors-25-05918"><label>44.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jones</surname><given-names>L.A.</given-names></name></person-group><article-title>Tactile communication systems: Optimizing the display of information</article-title><source>Prog. Brain Res.</source><year>2011</year><volume>192</volume><fpage>113</fpage><lpage>128</lpage><pub-id pub-id-type="pmid">21763522</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/B978-0-444-53355-5.00008-7</pub-id></element-citation></ref><ref id="B45-sensors-25-05918"><label>45.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Severgnini</surname><given-names>F.M.</given-names></name><name name-style="western"><surname>Martinez</surname><given-names>J.S.</given-names></name><name name-style="western"><surname>Tan</surname><given-names>H.Z.</given-names></name><name name-style="western"><surname>Reed</surname><given-names>C.M.</given-names></name></person-group><article-title>Snake Effect: A Novel Haptic Illusion</article-title><source>IEEE Trans. Haptics</source><year>2021</year><volume>14</volume><fpage>907</fpage><lpage>913</lpage><pub-id pub-id-type="doi">10.1109/TOH.2021.3070277</pub-id><pub-id pub-id-type="pmid">33788692</pub-id></element-citation></ref><ref id="B46-sensors-25-05918"><label>46.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Young</surname><given-names>E.M.</given-names></name><name name-style="western"><surname>Gueorguiev</surname><given-names>D.</given-names></name><name name-style="western"><surname>Kuchenbecker</surname><given-names>K.J.</given-names></name><name name-style="western"><surname>Pacchierotti</surname><given-names>C.</given-names></name></person-group><article-title>Compensating for fingertip size to render tactile cues more accurately</article-title><source>IEEE Trans. Haptics</source><year>2020</year><volume>13</volume><fpage>144</fpage><lpage>151</lpage><pub-id pub-id-type="doi">10.1109/TOH.2020.2966993</pub-id><pub-id pub-id-type="pmid">31944996</pub-id></element-citation></ref><ref id="B47-sensors-25-05918"><label>47.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Treutwein</surname><given-names>B.</given-names></name></person-group><article-title>Adaptive psychophysical procedures</article-title><source>Vis. Res.</source><year>1995</year><volume>35</volume><fpage>2503</fpage><lpage>2522</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(95)00016-X</pub-id><pub-id pub-id-type="pmid">8594817</pub-id></element-citation></ref><ref id="B48-sensors-25-05918"><label>48.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cousineau</surname><given-names>D.</given-names></name></person-group><article-title>Confidence intervals in within-subject designs: A simpler solution to Loftus and Masson&#8217;s method</article-title><source>Tutor. Quant. Methods Psychol.</source><year>2005</year><volume>1</volume><fpage>42</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.20982/tqmp.01.1.p042</pub-id></element-citation></ref><ref id="B49-sensors-25-05918"><label>49.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Morey</surname><given-names>R.D.</given-names></name></person-group><article-title>Confidence intervals from normalized data: A correction to Cousineau (2005)</article-title><source>Tutor. Quant. Methods Psychol.</source><year>2008</year><volume>4</volume><fpage>61</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.20982/tqmp.04.2.p061</pub-id></element-citation></ref><ref id="B50-sensors-25-05918"><label>50.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cousineau</surname><given-names>D.</given-names></name></person-group><article-title>Varieties of confidence intervals</article-title><source>Adv. Cogn. Psychol.</source><year>2017</year><volume>13</volume><fpage>140</fpage><lpage>155</lpage><pub-id pub-id-type="doi">10.5709/acp-0214-z</pub-id><pub-id pub-id-type="pmid">28729890</pub-id><pub-id pub-id-type="pmcid">PMC5511611</pub-id></element-citation></ref><ref id="B51-sensors-25-05918"><label>51.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Duan</surname><given-names>N.</given-names></name></person-group><article-title>Smearing estimate: A nonparametric retransformation method</article-title><source>J. Am. Stat. Assoc.</source><year>1983</year><volume>78</volume><fpage>605</fpage><lpage>610</lpage><pub-id pub-id-type="doi">10.1080/01621459.1983.10478017</pub-id></element-citation></ref><ref id="B52-sensors-25-05918"><label>52.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pack</surname><given-names>C.C.</given-names></name><name name-style="western"><surname>Bensmaia</surname><given-names>S.J.</given-names></name></person-group><article-title>Seeing and feeling motion: Canonical computations in vision and touch</article-title><source>Plos Biol.</source><year>2015</year><volume>13</volume><elocation-id>e1002271</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002271</pub-id><pub-id pub-id-type="pmid">26418156</pub-id><pub-id pub-id-type="pmcid">PMC4587910</pub-id></element-citation></ref><ref id="B53-sensors-25-05918"><label>53.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Reichardt</surname><given-names>W.</given-names></name></person-group><article-title>Autocorrelation, a principle for the evaluation of sensory information by the central nervous system</article-title><source>Sensory Communication</source><person-group person-group-type="editor"><name name-style="western"><surname>Rosenblith</surname><given-names>W.</given-names></name></person-group><publisher-name>M.I.T. Press</publisher-name><publisher-loc>Cambridge, UK</publisher-loc><year>1961</year><comment>Chapter 17</comment><fpage>303</fpage><lpage>317</lpage></element-citation></ref><ref id="B54-sensors-25-05918"><label>54.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Franken</surname><given-names>T.P.</given-names></name><name name-style="western"><surname>Bremen</surname><given-names>P.</given-names></name><name name-style="western"><surname>Joris</surname><given-names>P.X.</given-names></name></person-group><article-title>Coincidence detection in the medial superior olive: Mechanistic implications of an analysis of input spiking patterns</article-title><source>Front. Neural Circuits</source><year>2014</year><volume>8</volume><elocation-id>42</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2014.00042</pub-id><pub-id pub-id-type="pmid">24822037</pub-id><pub-id pub-id-type="pmcid">PMC4013490</pub-id></element-citation></ref><ref id="B55-sensors-25-05918"><label>55.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rose</surname><given-names>G.</given-names></name><name name-style="western"><surname>Heiligenberg</surname><given-names>W.</given-names></name></person-group><article-title>Structure and function of electrosensory neurons in the torus semicircularis of Eigenmannia: Morphological correlates of phase and amplitude sensitivity</article-title><source>J. Neurosci.</source><year>1985</year><volume>5</volume><fpage>2269</fpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.05-08-02269.1985</pub-id><pub-id pub-id-type="pmid">4020437</pub-id><pub-id pub-id-type="pmcid">PMC6565276</pub-id></element-citation></ref><ref id="B56-sensors-25-05918"><label>56.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Harvey</surname><given-names>M.A.</given-names></name><name name-style="western"><surname>Saal</surname><given-names>H.P.</given-names></name><name name-style="western"><surname>Dammann III</surname><given-names>J.F.</given-names></name><name name-style="western"><surname>Bensmaia</surname><given-names>S.J.</given-names></name></person-group><article-title>Multiplexing stimulus information through rate and temporal codes in primate somatosensory cortex</article-title><source>PLoS Biol.</source><year>2013</year><volume>11</volume><elocation-id>e1001558</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1001558</pub-id><pub-id pub-id-type="pmid">23667327</pub-id><pub-id pub-id-type="pmcid">PMC3646728</pub-id></element-citation></ref><ref id="B57-sensors-25-05918"><label>57.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Adibi</surname><given-names>M.</given-names></name></person-group><article-title>Whisker-mediated touch system in rodents: From neuron to behavior</article-title><source>Front. Syst. Neurosci.</source><year>2019</year><volume>13</volume><elocation-id>40</elocation-id><pub-id pub-id-type="doi">10.3389/fnsys.2019.00040</pub-id><pub-id pub-id-type="pmid">31496942</pub-id><pub-id pub-id-type="pmcid">PMC6712080</pub-id></element-citation></ref><ref id="B58-sensors-25-05918"><label>58.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Reed</surname><given-names>J.L.</given-names></name><name name-style="western"><surname>Qi</surname><given-names>H.X.</given-names></name><name name-style="western"><surname>Zhou</surname><given-names>Z.</given-names></name><name name-style="western"><surname>Bernard</surname><given-names>M.R.</given-names></name><name name-style="western"><surname>Burish</surname><given-names>M.J.</given-names></name><name name-style="western"><surname>Bonds</surname><given-names>A.</given-names></name><name name-style="western"><surname>Kaas</surname><given-names>J.H.</given-names></name></person-group><article-title>Response properties of neurons in primary somatosensory cortex of owl monkeys reflect widespread spatiotemporal integration</article-title><source>J. Neurophysiol.</source><year>2010</year><volume>103</volume><fpage>2139</fpage><lpage>2157</lpage><pub-id pub-id-type="doi">10.1152/jn.00709.2009</pub-id><pub-id pub-id-type="pmid">20164400</pub-id><pub-id pub-id-type="pmcid">PMC2853283</pub-id></element-citation></ref><ref id="B59-sensors-25-05918"><label>59.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Thakur</surname><given-names>P.H.</given-names></name><name name-style="western"><surname>Fitzgerald</surname><given-names>P.J.</given-names></name><name name-style="western"><surname>Lane</surname><given-names>J.W.</given-names></name><name name-style="western"><surname>Hsiao</surname><given-names>S.S.</given-names></name></person-group><article-title>Receptive field properties of the macaque second somatosensory cortex: Nonlinear mechanisms underlying the representation of orientation within a finger pad</article-title><source>J. Neurosci.</source><year>2006</year><volume>26</volume><fpage>13567</fpage><lpage>13575</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3990-06.2006</pub-id><pub-id pub-id-type="pmid">17192440</pub-id><pub-id pub-id-type="pmcid">PMC1994909</pub-id></element-citation></ref><ref id="B60-sensors-25-05918"><label>60.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Ljung</surname><given-names>L.</given-names></name></person-group><article-title>System Identification</article-title><source>Signal Analysis and Prediction</source><person-group person-group-type="editor"><name name-style="western"><surname>Proch&#225;zka</surname><given-names>A.</given-names></name><name name-style="western"><surname>Uhl&#237;&#345;</surname><given-names>J.</given-names></name><name name-style="western"><surname>Rayner</surname><given-names>P.W.J.</given-names></name><name name-style="western"><surname>Kingsbury</surname><given-names>N.G.</given-names></name></person-group><publisher-name>Birkh&#228;user Boston</publisher-name><publisher-loc>Boston, MA, USA</publisher-loc><year>1998</year><fpage>163</fpage><lpage>173</lpage><pub-id pub-id-type="doi">10.1007/978-1-4612-1768-8_11</pub-id></element-citation></ref><ref id="B61-sensors-25-05918"><label>61.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Craig</surname><given-names>J.C.</given-names></name><name name-style="western"><surname>Baihua</surname><given-names>X.</given-names></name></person-group><article-title>Temporal order and tactile patterns</article-title><source>Percept. Psychophys.</source><year>1990</year><volume>47</volume><fpage>22</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.3758/BF03208161</pub-id><pub-id pub-id-type="pmid">2300421</pub-id></element-citation></ref><ref id="B62-sensors-25-05918"><label>62.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mountcastle</surname><given-names>V.</given-names></name><name name-style="western"><surname>LaMotte</surname><given-names>R.</given-names></name><name name-style="western"><surname>Carli</surname><given-names>G.</given-names></name></person-group><article-title>Detection thresholds for stimuli in humans and monkeys: Comparison with threshold events in mechanoreceptive afferent nerve fibers innervating the monkey hand</article-title><source>J. Neurophysiol.</source><year>1972</year><volume>35</volume><fpage>122</fpage><lpage>136</lpage><pub-id pub-id-type="doi">10.1152/jn.1972.35.1.122</pub-id><pub-id pub-id-type="pmid">4621505</pub-id></element-citation></ref><ref id="B63-sensors-25-05918"><label>63.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Freeman</surname><given-names>A.W.</given-names></name><name name-style="western"><surname>Johnson</surname><given-names>K.O.</given-names></name></person-group><article-title>Cutaneous mechanoreceptors in macaque monkey: Temporal discharge patterns evoked by vibration, and a receptor model</article-title><source>J. Physiol.</source><year>1982</year><volume>323</volume><fpage>21</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1982.sp014059</pub-id><pub-id pub-id-type="pmid">7097573</pub-id><pub-id pub-id-type="pmcid">PMC1250343</pub-id></element-citation></ref><ref id="B64-sensors-25-05918"><label>64.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Johansson</surname><given-names>R.S.</given-names></name><name name-style="western"><surname>Landstro</surname><given-names>U.</given-names></name><name name-style="western"><surname>Lundstro</surname><given-names>R.</given-names></name></person-group><article-title>Responses of mechanoreceptive afferent units in the glabrous skin of the human hand to sinusoidal skin displacements</article-title><source>Brain Res.</source><year>1982</year><volume>244</volume><fpage>17</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(82)90899-X</pub-id><pub-id pub-id-type="pmid">6288178</pub-id></element-citation></ref><ref id="B65-sensors-25-05918"><label>65.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bell</surname><given-names>J.</given-names></name><name name-style="western"><surname>Bolanowski</surname><given-names>S.</given-names></name><name name-style="western"><surname>Holmes</surname><given-names>M.H.</given-names></name></person-group><article-title>The structure and function of Pacinian corpuscles: A review</article-title><source>Prog. Neurobiol.</source><year>1994</year><volume>42</volume><fpage>79</fpage><lpage>128</lpage><pub-id pub-id-type="doi">10.1016/0301-0082(94)90022-1</pub-id><pub-id pub-id-type="pmid">7480788</pub-id></element-citation></ref><ref id="B66-sensors-25-05918"><label>66.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zimmerman</surname><given-names>A.</given-names></name><name name-style="western"><surname>Bai</surname><given-names>L.</given-names></name><name name-style="western"><surname>Ginty</surname><given-names>D.D.</given-names></name></person-group><article-title>The gentle touch receptors of mammalian skin</article-title><source>Science</source><year>2014</year><volume>346</volume><fpage>950</fpage><lpage>954</lpage><pub-id pub-id-type="doi">10.1126/science.1254229</pub-id><pub-id pub-id-type="pmid">25414303</pub-id><pub-id pub-id-type="pmcid">PMC4450345</pub-id></element-citation></ref><ref id="B67-sensors-25-05918"><label>67.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hollins</surname><given-names>E.A.R.M.</given-names></name></person-group><article-title>A ratio code for vibrotactile pitch</article-title><source>Somatosens. Mot. Res.</source><year>1998</year><volume>15</volume><fpage>134</fpage><lpage>145</lpage><pub-id pub-id-type="doi">10.1080/08990229870862</pub-id><pub-id pub-id-type="pmid">9730114</pub-id></element-citation></ref><ref id="B68-sensors-25-05918"><label>68.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tranchant</surname><given-names>P.</given-names></name><name name-style="western"><surname>Shiell</surname><given-names>M.M.</given-names></name><name name-style="western"><surname>Giordano</surname><given-names>M.</given-names></name><name name-style="western"><surname>Nadeau</surname><given-names>A.</given-names></name><name name-style="western"><surname>Peretz</surname><given-names>I.</given-names></name><name name-style="western"><surname>Zatorre</surname><given-names>R.J.</given-names></name></person-group><article-title>Feeling the beat: Bouncing synchronization to vibrotactile music in hearing and early deaf people</article-title><source>Front. Neurosci.</source><year>2017</year><volume>11</volume><elocation-id>507</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2017.00507</pub-id><pub-id pub-id-type="pmid">28955193</pub-id><pub-id pub-id-type="pmcid">PMC5601036</pub-id></element-citation></ref><ref id="B69-sensors-25-05918"><label>69.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Prsa</surname><given-names>M.</given-names></name><name name-style="western"><surname>Morandell</surname><given-names>K.</given-names></name><name name-style="western"><surname>Cuenu</surname><given-names>G.</given-names></name><name name-style="western"><surname>Huber</surname><given-names>D.</given-names></name></person-group><article-title>Feature-selective encoding of substrate vibrations in the forelimb somatosensory cortex</article-title><source>Nature</source><year>2019</year><volume>567</volume><fpage>384</fpage><lpage>388</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1015-8</pub-id><pub-id pub-id-type="pmid">30867600</pub-id></element-citation></ref><ref id="B70-sensors-25-05918"><label>70.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Prsa</surname><given-names>M.</given-names></name><name name-style="western"><surname>Kilicel</surname><given-names>D.</given-names></name><name name-style="western"><surname>Nourizonoz</surname><given-names>A.</given-names></name><name name-style="western"><surname>Lee</surname><given-names>K.S.</given-names></name><name name-style="western"><surname>Huber</surname><given-names>D.</given-names></name></person-group><article-title>A common computational principle for vibrotactile pitch perception in mouse and human</article-title><source>Nat. Commun.</source><year>2021</year><volume>12</volume><fpage>5336</fpage><pub-id pub-id-type="doi">10.1038/s41467-021-25476-9</pub-id><pub-id pub-id-type="pmid">34504074</pub-id><pub-id pub-id-type="pmcid">PMC8429766</pub-id></element-citation></ref><ref id="B71-sensors-25-05918"><label>71.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Adibi</surname><given-names>M.</given-names></name><name name-style="western"><surname>Arabzadeh</surname><given-names>E.</given-names></name></person-group><article-title>A comparison of neuronal and behavioral detection and discrimination performances in rat whisker system</article-title><source>J. Neurophysiol.</source><year>2011</year><volume>105</volume><fpage>356</fpage><pub-id pub-id-type="doi">10.1152/jn.00794.2010</pub-id><pub-id pub-id-type="pmid">21068262</pub-id></element-citation></ref><ref id="B72-sensors-25-05918"><label>72.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Adibi</surname><given-names>M.</given-names></name><name name-style="western"><surname>Diamond</surname><given-names>M.</given-names></name><name name-style="western"><surname>Arabzadeh</surname><given-names>E.</given-names></name></person-group><article-title>Behavioral study of whisker-mediated vibration sensation in rats</article-title><source>Proc. Natl. Acad. Sci. USA</source><year>2012</year><volume>109</volume><fpage>971</fpage><lpage>976</lpage><pub-id pub-id-type="doi">10.1073/pnas.1116726109</pub-id><pub-id pub-id-type="pmid">22219358</pub-id><pub-id pub-id-type="pmcid">PMC3271871</pub-id></element-citation></ref><ref id="B73-sensors-25-05918"><label>73.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Abraira</surname><given-names>V.E.</given-names></name><name name-style="western"><surname>Ginty</surname><given-names>D.D.</given-names></name></person-group><article-title>The sensory neurons of touch</article-title><source>Neuron</source><year>2013</year><volume>79</volume><fpage>618</fpage><lpage>639</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.07.051</pub-id><pub-id pub-id-type="pmid">23972592</pub-id><pub-id pub-id-type="pmcid">PMC3811145</pub-id></element-citation></ref><ref id="B74-sensors-25-05918"><label>74.</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Holmes</surname><given-names>N.P.</given-names></name><name name-style="western"><surname>Tam&#232;</surname><given-names>L.</given-names></name></person-group><article-title>Detection, Discrimination &amp; Localization: The Psychophysics of Touch</article-title><source>Somatosensory Research Methods</source><person-group person-group-type="editor"><name name-style="western"><surname>Holmes</surname><given-names>N.P.</given-names></name></person-group><publisher-name>Springer</publisher-name><publisher-loc>New York, NY, USA</publisher-loc><year>2023</year><fpage>3</fpage><lpage>33</lpage><pub-id pub-id-type="doi">10.1007/978-1-0716-3068-6_1</pub-id></element-citation></ref></ref-list></back><floats-group><fig position="float" id="sensors-25-05918-f001" orientation="portrait"><label>Figure 1</label><caption><p>Detecting the motion of a remote vibrating source through patterns of vibrations sensed at two touch points. (<bold>A</bold>) <inline-formula><mml:math id="mm224" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm225" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> denote the two touch points. The trajectory on plane <inline-formula><mml:math id="mm226" overflow="scroll"><mml:mrow><mml:msup><mml:mi>P</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> is the rotation of trajectory on plane <italic toggle="yes">P</italic> around the touch axis <inline-formula><mml:math id="mm227" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. The grey closed curve shows the mirror of the trajectory with respect to the touch axis <inline-formula><mml:math id="mm228" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. (<bold>B</bold>) For any arbitrary trajectory on the plane <italic toggle="yes">P</italic>, when the touch axis <inline-formula><mml:math id="mm229" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is orthogonal to <italic toggle="yes">P</italic>, the vibrations from source <italic toggle="yes">S</italic> received at <inline-formula><mml:math id="mm230" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm231" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> are in-phase. <inline-formula><mml:math id="mm232" overflow="scroll"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm233" overflow="scroll"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> represent the distances of <inline-formula><mml:math id="mm234" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm235" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> from <italic toggle="yes">P</italic>, respectively. <inline-formula><mml:math id="mm236" overflow="scroll"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm237" overflow="scroll"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> denote the distances from the source <italic toggle="yes">S</italic> to <inline-formula><mml:math id="mm238" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm239" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, respectively, and vary as <italic toggle="yes">S</italic> moves along the trajectory. (<bold>C</bold>) A circular trajectory with radius <inline-formula><mml:math id="mm240" overflow="scroll"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, centred at <italic toggle="yes">O</italic>. <inline-formula><mml:math id="mm241" overflow="scroll"><mml:mrow><mml:msup><mml:mi>T</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> denotes the projection of touch point <italic toggle="yes">T</italic> onto plane <italic toggle="yes">P</italic>. <italic toggle="yes">h</italic>, <italic toggle="yes">r</italic>, and <italic toggle="yes">d</italic> denote the distances from <italic toggle="yes">T</italic> to <italic toggle="yes">P</italic>, <italic toggle="yes">O</italic>, and <italic toggle="yes">S</italic>, respectively. <inline-formula><mml:math id="mm242" overflow="scroll"><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow></mml:math></inline-formula> is the angle between <inline-formula><mml:math id="mm243" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm244" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:msup><mml:mi>T</mml:mi><mml:mo>&#8242;</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. (<bold>D</bold>) <inline-formula><mml:math id="mm245" overflow="scroll"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm246" overflow="scroll"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> denote the distances from the source <italic toggle="yes">S</italic> to <inline-formula><mml:math id="mm247" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm248" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, respectively, and vary as <italic toggle="yes">S</italic> moves along the trajectory. <inline-formula><mml:math id="mm249" overflow="scroll"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm250" overflow="scroll"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> are the distances from <italic toggle="yes">O</italic> to <inline-formula><mml:math id="mm251" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm252" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, respectively. (<bold>E</bold>) An example of anti-phase vibrations, when the projection of the axis <inline-formula><mml:math id="mm253" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> (dashed line) onto the trajectory plane <italic toggle="yes">P</italic> passes through <italic toggle="yes">O</italic>. (<bold>F</bold>) The two-dimensional geometry. All conversions as in (<bold>D</bold>).</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05918-g001.jpg"/></fig><fig position="float" id="sensors-25-05918-f002" orientation="portrait"><label>Figure 2</label><caption><p>Motion direction discrimination task. (<bold>A</bold>) The index and middle fingers of the right hand were stimulated using a pair of solenoid transducers (upper panel, (<bold>B</bold>)), which delivered amplitude-modulated vibrations (lower panel, (<bold>B</bold>)). (<bold>C</bold>) On each trial, the envelopes of the two vibrations had a phase difference <inline-formula><mml:math id="mm254" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>&#916;</mml:mo><mml:mi>&#966;</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. The vibrations began at one of two points (marked in blue and red) where their envelope amplitudes were equal, as indicated by vertical dashed lines.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05918-g002.jpg"/></fig><fig position="float" id="sensors-25-05918-f003" orientation="portrait"><label>Figure 3</label><caption><p>Experiment 1: Naturalistic vs. sinusoidal vibration envelopes. (<bold>A</bold>) Schematic representation of naturalistic (exponential) and sinusoidal vibrations, along with their envelopes (thick curves). For illustration purposes, a 20 Hz carrier frequency is shown; the actual carrier frequency used in the experiments was 100 Hz. (<bold>B</bold>) Motion direction discrimination accuracy, shown as the proportion of correct trials for exponential and sinusoidal vibrations. Bars represent the average across subjects, with error bars indicating the standard error of the mean (SEM). Data points represent individual participants (<inline-formula><mml:math id="mm255" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>).</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05918-g003.jpg"/></fig><fig position="float" id="sensors-25-05918-f004" orientation="portrait"><label>Figure 4</label><caption><p>Experiment 2: Effect of envelope frequency on tactile motion perception. (<bold>A</bold>) Motion direction discrimination performance as a function of phase difference, shown separately for each envelope frequency (indicated by colour). Data points represent cross-subject averages, with error bars indicating SEM across subjects. Curves represent psychometric fits for each frequency condition. (<bold>B</bold>) The same data points from (<bold>A</bold>) (cross-subject averages) are replotted with error bars showing Cousineau&#8211;Morey within-subject SEM [<xref rid="B48-sensors-25-05918" ref-type="bibr">48</xref>,<xref rid="B49-sensors-25-05918" ref-type="bibr">49</xref>,<xref rid="B50-sensors-25-05918" ref-type="bibr">50</xref>] across phase differences and frequencies. Curves represent predictions from the GLMM (population-average fits), obtained with subject-level conditional predictions averaged across participants. For clarity, standard errors are plotted instead of confidence intervals (CIs); CIs at any desired level can be obtained by scaling the standard errors with the corresponding <italic toggle="yes">t</italic>-statistic.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05918-g004.jpg"/></fig><fig position="float" id="sensors-25-05918-f005" orientation="portrait"><label>Figure 5</label><caption><p>Experiment 3: Cognitive and metacognitive measures of tactile motion. (<bold>A</bold>) Discrimination accuracy (proportion correct), averaged across subjects (<inline-formula><mml:math id="mm256" overflow="scroll"><mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>12</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). The solid curve shows the average of subject-specific predictions from the mixed-effects model. The shaded area indicates the 95% confidence interval of the population-level fit. Data points are participant means per phase difference and error bars are within-subject 95% confidence intervals (Cousineau&#8211;Morey method) [<xref rid="B48-sensors-25-05918" ref-type="bibr">48</xref>,<xref rid="B49-sensors-25-05918" ref-type="bibr">49</xref>,<xref rid="B50-sensors-25-05918" ref-type="bibr">50</xref>]. The inset compares model predictions with empirical values, with each marker representing a participant&#8211;phase difference pair. (<bold>B</bold>) Psychometric curves (choice likelihood) showing the proportion of &#8220;left&#8221; responses as a function of phase difference, averaged across subjects. Error bars represent SEM across participants. (<bold>C</bold>) Reaction times normalised by each participant&#8217;s geometric mean and back-transformed to the arithmetic scale [<xref rid="B51-sensors-25-05918" ref-type="bibr">51</xref>]. The solid curve and shaded region indicate population-level predictions from the linear mixed-effects model with corresponding 95% confidence intervals. Data points show participant means, and error bars indicate SEM across participants. The inset compares predictions from a model fitted without normalisation (in seconds) with empirical values. Each marker represents a participant&#8211;phase difference pair. (<bold>D</bold>) Confidence ratings as a function of phase difference. The solid curve and shaded region show population-level mixed-effects model predictions with 95% confidence intervals. Data points are participant means, and error bars represent within-subject SEM (Cousineau&#8211;Morey). The inset plots predicted against empirical values, with each marker corresponding to a participant&#8211;phase difference pair.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05918-g005.jpg"/></fig><fig position="float" id="sensors-25-05918-f006" orientation="portrait"><label>Figure 6</label><caption><p>Predicted direction discrimination performance from the probabilistic feature-based model. (<bold>A</bold>) Model-predicted proportion of correct motion direction discrimination as a function of phase difference. Each trace corresponds to a different amplitude detection threshold (indicated by colour), expressed as a proportion of the peak envelope amplitude (ranging from 0.1 to 0.9 in increments of 0.1). (<bold>B</bold>) Model fit to the behavioural data from <xref rid="sensors-25-05918-f004" ref-type="fig">Figure 4</xref>. Curves represent model predictions, and markers indicate average performance across participants. Error bars represent SEM. Group-level fits yielded RMSE values of 0.029, 0.011, and 0.017 for the 0.5, 1, and 1.5 Hz conditions, respectively.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="sensors-25-05918-g006.jpg"/></fig></floats-group></article></pmc-articleset>