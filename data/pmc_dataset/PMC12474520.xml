<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xml:lang="en" article-type="research-article" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">J Med Ethics Hist Med</journal-id><journal-id journal-id-type="iso-abbrev">J Med Ethics Hist Med</journal-id><journal-id journal-id-type="pmc-domain-id">2152</journal-id><journal-id journal-id-type="pmc-domain">jmehm</journal-id><journal-id journal-id-type="publisher-id">JMEHM</journal-id><journal-title-group><journal-title>Journal of Medical Ethics and History of Medicine</journal-title></journal-title-group><issn pub-type="epub">2008-0387</issn><publisher><publisher-name>Tehran University of Medical Sciences</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12474520</article-id><article-id pub-id-type="pmcid-ver">PMC12474520.1</article-id><article-id pub-id-type="pmcaid">12474520</article-id><article-id pub-id-type="pmcaiid">12474520</article-id><article-id pub-id-type="doi">10.18502/jmehm.v18i1.18814</article-id><article-id pub-id-type="publisher-id">JMEHM-18-1</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Original Article</subject></subj-group></article-categories><title-group><article-title>Why is the idea of AI completely replacing physicians a pseudo-problem? a philosophical analysis</article-title></title-group><contrib-group><contrib contrib-type="author"><name name-style="western"><surname>Monajemi</surname><given-names initials="A">Alireza</given-names></name></contrib></contrib-group><aff id="aff">
<italic toggle="yes">Associate Professor, Philosophy of Science and Technology Department, History and Philosophy of Science Faculty, Institute for 
Humanities and Cultural Studies, Tehran, Iran.</italic>
</aff><author-notes><corresp id="cor">Corresponding Author: Alireza Monajemi. Address: No 4, Institute for Humanities and Cultural Studies, Iranshenasi St., Kurdestan Highway, Tehran, Iran. Zip Code: 1437774681. PO Box : 14155. Tel: (+98) 21 88 49 02 09. <email>Email: monajemi@ihcs.ac.ir</email></corresp></author-notes><pub-date pub-type="collection"><year>2025</year></pub-date><pub-date pub-type="epub"><day>25</day><month>5</month><year>2025</year></pub-date><volume>18</volume><issue-id pub-id-type="pmc-issue-id">497681</issue-id><elocation-id>1</elocation-id><history><date date-type="received"><day>24</day><month>12</month><year>2024</year></date><date date-type="accepted"><day>6</day><month>5</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>25</day><month>05</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>28</day><month>09</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-09-28 13:25:37.627"><day>28</day><month>09</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>Copyright &#169; 2025 Tehran University of Medical Sciences.</copyright-statement><license><ali:license_ref specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref><license-p>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International license (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">https://creativecommons.org/licenses/by-nc/4.0/</ext-link>). Non-commercial uses of the work are permitted, provided the original work is properly cited.</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="JMEHM-18-1.pdf"/><abstract><p>Artificial intelligence (AI) has the potential to revolutionize healthcare, but is unlikely to fully replace human doctors. This paper explores the limitations of AI in healthcare, focusing on three key areas: lack of embodiment, limited understanding of meaning in everyday language, and the inability to exercise judgment and clinical reasoning. Recognizing these limitations enables us to use AI to enhance our capabilities rather than allowing it to substitute humans. Following this philosophical examination of AI's limitations, I will argue that the question of whether AI will replace doctors is a misleading one. Instead, this framework advocates for synergistic human-AI collaboration in health-care settings. It necessitates the development of hybrid entities: a physician-AI partnership and a patient-AI interface. The overarching objective is to effectively address the core mission of medicine, which is providing optimal treatment and compassionate care for all patients. This hybrid model must proactively mitigate the risks of AI integration, such as exacerbation of existing health-care challenges and potential dehumanization of patient care. Within this framework, key objectives include: reducing medical errors, fostering humane doctor-patient relationships, mitigating the trend of medicalization, and ultimately improving overall public health outcomes.</p></abstract><kwd-group><title>Key Words</title><kwd><italic toggle="yes">AI in medicine</italic></kwd><kwd><italic toggle="yes">Embodiment</italic></kwd><kwd><italic toggle="yes">Clinical judgment</italic></kwd><kwd><italic toggle="yes">Philosophy of medicine</italic></kwd><kwd><italic toggle="yes">Philosophy of technology</italic>.</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro"><title>Introduction</title><p>Medical technology broadly refers to a collection of tools that empower health-care professionals to improve patient outcomes and societal health. Historically, these technologies were predominantly physical devices, but the integration of smartphones, wearables, and AI has ushered in a new era of medical innovation. AI-powered applications embedded in these devices facilitate early diagnosis, minimize complications, optimize treatment regimens, and shorten hospitalizations. AI, a subfield of computer science adept at processing complex problems with extensive datasets, has emerged as a transformative force in medical technology (<xref rid="B1" ref-type="bibr">1</xref>).</p><p>As AIs facilitate a 4P model of medicine (predictive, preventive, personalized, and participatory), they empower patients by promoting autonomy and self-management. Intelligent medical technologies, driven by artificial intelligence, have garnered significant enthusiasm from the general public. Smartphones, for example, have become ubiquitous tools for maintaining electronic health records, monitoring vital signs, and optimizing treatment adherence. These advancements elevate patients to the role of active participants in their own care pathways (<xref rid="B2" ref-type="bibr">2</xref> - <xref rid="B4" ref-type="bibr">4</xref>).</p><p>While artificial intelligence has made substantial strides in healthcare, concerns persist about its potential impact on the role of human physicians. One of the most prominent concerns is the possibility of AI replacing human doctors. While this claim often lacks rigorous scientific support and tends to be more sensationalized than evidence-based, its significance warrants serious academic investigation. This paper offers a philosophical exploration of why AI, despite its advancements, cannot replace human doctors. Nevertheless, recognizing AI's limitations helps us pinpoint its strengths and direct future research toward more promising avenues in healthcare.</p><p>This paper will commence with a philosophical analysis of the inherent limitations of artificial intelligence (AI) within the medical domain. Building upon these insights, I will demonstrate that the idea of AI entirely replacing human physicians constitutes a false dichotomy. The central challenge lies in understanding the true nature of the human-AI relationship within healthcare, which necessitates the development of a hybrid model that effectively integrates both human expertise and the capabilities of AI. </p><p>This hybrid model encompasses two key components: AI as a powerful tool to assist physicians in their clinical practice, serving as a sophisticated medical assistant, and AI as a valuable resource for patients, acting as a personalized health companion. To fully comprehend the potentials and limitations of this hybrid model, it is crucial to examine the strengths of AI in light of the previously discussed limitations, while simultaneously acknowledging and mitigating the potential risks associated with the integration of AI within the health-care system. </p><p>Here, a few important points need to be highlighted. This article focuses on whether AI can replace doctors in clinical medicine, excluding the role of AI in biomedical research or public health. It is also important to note that the AI referred to in this article embodies the typical features of contemporary AI systems. However, the claims I make are not definitive, as future AI may overcome the existing limitations.</p><p>This article undertakes a philosophical analysis by drawing upon a synthesis of frameworks and theses from both the philosophy of medicine and the philosophy of technology. Given that the central inquiry revolves around the potential replacement of physicians with artificial intelligence, I will focus on the philosophy of clinical medicine, with a particular emphasis on praxeology (<xref rid="B5" ref-type="bibr">5</xref>). Consequently, the clinical encounter, the intricate doctor-patient relationship, and the nuanced process of clinical reasoning will constitute the core elements of this analysis. Among prominent medical philosophers, Sadeghzadeh, emerges as a particularly valuable resource for investigating this issue (<xref rid="B5" ref-type="bibr">5</xref>). Conversely, within the philosophy of technology, the insightful critiques of renowned thinkers such as Gadamer and Dreyfus concerning artificial intelligence will prove highly instrumental (<xref rid="B6" ref-type="bibr">6</xref> - <xref rid="B7" ref-type="bibr">7</xref>).</p><p>
<italic toggle="yes">1.&#160;&#160;&#160;Fundamental limitations of AI in replacing physicians</italic>
</p><p>
<italic toggle="yes">1.1. &#160;Lack of embodiment </italic>
</p><p>One of the fundamental limitations of AI is its lack of physical embodiment (<xref rid="B8" ref-type="bibr">8</xref>). The inherent lack of a physical body within artificial intelligence precludes the establishment of a genuine clinical encounter, a cornerstone of sound medical practice. During a clinical examination, the physician cultivates an initial understanding of the patient's condition by astutely observing the context and discerning subtle non-verbal cues such as body language, facial expressions, and tone of voice, which can provide valuable insights into a patient's condition. Determining a patient's state of well-being, while seemingly straightforward, necessitates a complex analytical process on the part of the physician, one that demands a profound bodily connection between the doctor and the patient. Many of the limitations encountered by artificial intelligence can be aptly compared to the challenges faced by an on-call physician who is compelled to offer medical consultation via telephone without the benefit of prior physical interaction with the patient.</p><p>From the standpoint of the doctor-patient relationship, the absence of a physical presence significantly diminishes the potential for genuine empathy with the patient, inadvertently signaling a novel form of dehumanization. Medical philosophers have long equated dehumanization in the health-care context with the erosion of the patient's agency and the subsequent reduction of the patient to a mere embodiment of their illness (<xref rid="B5" ref-type="bibr">5</xref> - <xref rid="B6" ref-type="bibr">6</xref>). Within this framework, the removal of the physician as a compassionate human agent constitutes yet another facet of this concerning trend of dehumanization in medical practice.</p><p>From the perspective of clinical reasoning, the accurate perception of numerous signs and symptoms necessitates a close physical engagement with the patient, a capability that remains inherently elusive for artificial intelligence. Doctors possess the ability to physically examine patients, and this continues to remain a crucial aspect of diagnosis and treatment. Through touch, they can assess factors like temperature, texture, and muscle tone, which are essential for accurate diagnosis. In cases such as acute abdominal pain, a careful physical examination assumes paramount importance, surpassing the significance of even the most comprehensive medical history or advanced para-clinical data, such as sophisticated imaging or laboratory tests.&#160;</p><p>
<italic toggle="yes">1.2.&#160;Limited understanding of everyday language </italic>
</p><p>A second significant limitation of artificial intelligence resides in its inability to comprehend the nuances of everyday human language (<xref rid="B7" ref-type="bibr">7</xref> - <xref rid="B8" ref-type="bibr">8</xref>). Barring instances where a patient is unconscious or otherwise unable to communicate, a clinical encounter typically commences with the patient articulating their health concerns. It is crucial to recognize that a patient's expressed complaints do not always directly translate into precise medical signs or symptoms. The physician plays a pivotal role in this process, skillfully translating these everyday language expressions into the formalized language of medical semiology. This inherent limitation poses a considerable challenge for AI when interacting directly with patients. Patients often present their medical concerns in a way that reflects their individual understanding of their condition, sometimes using medical terminology they may have acquired. However, it is imperative to acknowledge that these everyday conversations necessitate the discerning filter of a qualified physician before they can be subjected to meaningful interpretation and subsequent analysis. The root of this limitation lies in the very foundation of current artificial intelligence, which primarily relies on large language models (<xref rid="B9" ref-type="bibr">9</xref>). These models are inherently built upon a framework of explicit linguistic propositions. However, a closer examination reveals two significant domains within everyday human language that defy such explicit representation or facile translation into propositional form:</p><p>Firstly, the realm of tacit knowledge presents a considerable challenge. This encompasses the knowledge acquired through extensive practice, such as the skills involved in swimming or driving, where &#8220;knowing&#8221; is inextricably intertwined with &#8220;doing&#8221;. The profound implications of this become evident when we encounter individuals with dementia who struggle to perform seemingly simple tasks like eating with a spoon or fork. This observation underscores the presence of an underlying, often unarticulated, knowledge base that is essential for the execution of these seemingly basic actions (<xref rid="B10" ref-type="bibr">10</xref>).</p><p>Secondly, the domain of embodied cognition poses a significant obstacle. A substantial portion of our everyday language is deeply intertwined with our bodily experiences, often defying direct verbalization. Consider, for instance, the effortless human capacity to discern the relative weight of two objects held simultaneously in each hand. This type of embodied inference, despite its apparent simplicity, proves remarkably resistant to translation into a purely propositional format. Consequently, this crucial aspect of human cognition falls largely outside the purview of current large language models.</p><p>While AI can process vast amounts of data, it struggles to understand the nuances of human language and context. Medical situations often involve complex social, emotional and psychological factors that AI may not fully grasp. For example, a patient's medical history, family history, and cultural background can significantly impact their health and treatment needs. Human doctors, on the other hand, can draw on their own experiences and empathy to understand and respond to these complexities. &#160; </p><p>Moreover, a patient's complaints or descriptions of their illness should not always be strictly interpreted through a medical lens. A substantial part of what they express is their personal experience of being unwell, including their worries and anxieties. It is essential to acknowledge and empathize with these subjective experiences without reducing them solely to medical terms. AI currently struggles to replicate this level of human empathy (<xref rid="B6" ref-type="bibr">6</xref>).</p><p>
<italic toggle="yes">1.3.&#160;Inability to exercise clinical judgment</italic>
</p><p>A significant limitation of current artificial intelligence systems lies in their inherent inability to exercise sound judgment (<xref rid="B7" ref-type="bibr">7</xref>). The act of judgment necessitates a profound understanding of context. Consider a physician faced with the critical task of making a real-time decision for a patient. Such a decision cannot be solely predicated upon a rigid adherence to pre-established rules. Rather, it demands a nuanced appreciation of the patient's unique condition at that specific juncture. One of the primary impediments to AI's successful navigation of this complex terrain is its inherent insensitivity to the subtleties of context.</p><p>Even if one were to posit that the paradigm of deep learning could potentially mitigate this shortcoming within existing AI models, it is crucial to acknowledge the fundamental nature of clinical reasoning. Clinical reasoning constitutes a form of tacit knowledge, deeply ingrained within the practitioner's experience, and proving exceptionally resistant to translation into a set of explicit propositions. Moreover, while a significant component of a physician's cognitive processes is non-conscious, the verbalizable fraction is frequently too limited to provide meaningful training data for large language models.</p><p>A contributing factor to this limitation is our incomplete understanding of the underlying mechanisms of clinical reasoning and judgment. Although cognitive psychology has made substantial strides in this area, many questions still persist. As the distinguished medical philosopher Sadeghzadeh has pointed out, despite the rapid advances in biomedical sciences over the last century and a half, our knowledge of medical practice remains surprisingly limited (<xref rid="B11" ref-type="bibr">11</xref>).</p><p>Many studies comparing AI to clinicians suffer from methodological limitations, such as inadequate replication and biases in the training data. While open science principles offer a potential solution by promoting data sharing and transparency, their widespread adoption may face resistance from companies seeking to maintain a competitive advantage in the AI-powered medical software market. Furthermore, limitations in study design, such as reliance on retrospective data and small sample sizes, can lead to overfitting, where AI models perform well on the training data but poorly on new, unseen patients. This necessitates continuous monitoring and recalibration of AI models to ensure their continued effectiveness across diverse patient populations. Direct comparisons often reveal limitations in AI performance, particularly in terms of diagnostic accuracy, when compared to human specialists. However, framing the AI-clinician relationship as a competitive struggle may be counterproductive. Emerging research suggests that a collaborative approach, where AI augments human expertise, holds the most promise for improving patient care (<xref rid="B1" ref-type="bibr">1</xref>).</p><fig position="float" id="F1" orientation="portrait"><label>Figure 1</label><caption><p>AI's limitations in physician replacement</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="JMEHM-18-1-g001.jpg"/></fig><p>
<italic toggle="yes">2.&#160;&#160;&#160;Replacement of physicians by AI is a pseudo-problem</italic>
</p><p>If we consider medicine as a practice whose ultimate goal is to treat and care for sick patients, we recognize that it is deeply intertwined with the unique relationship between doctor and patient. This dynamic necessitates open dialogue, mutual understanding, and application of sound clinical judgment and decision-making. Thus, the proposition of replacing doctors entirely with artificial intelligence presents a significant oversimplification. Not only does AI currently lack the capacity to fully fulfill the multifaceted goals of medical practice, but as previously demonstrated, inherent limitations restrict AI's ability to comprehensively address the complex needs of patients.</p><p>The notion of AI substituting doctors appears to be more of a hypothetical construct, driven by the imaginations of AI companies and science fiction authors, rather than a practical concern within the health-care field. Consequently, replacement of physicians by AI is a false dichotomy. AI presents an incredible opportunity to revolutionize healthcare by enhancing the capabilities of physicians and improving patient care. By embracing this technology responsibly and focusing on human-AI collaboration, we can create a future where both humans and AI contribute to a more effective and equitable health-care system. </p><p>Contemporary medicine has not been entirely successful in achieving its goals, as evidenced by the so-called 'medical crisis'. Therefore, instead of asking whether AI will replace doctors, we should ask how AI can help medicine overcome its own crises. One significant contributor to medical crisis is the overemphasis on technological advancements, leading to a potential dehumanization of patient care. This excessive reliance on technology can inadvertently create a distance between doctors and patients, shifting the focus from holistic care to disease management. In such instances, physicians may prioritize technological interventions over the empathetic and compassionate care that is fundamental to the doctor-patient relationship. </p><p>The future of healthcare lies in effective human-AI collaboration. Combining physician and AI strengths leads to synergistic outcomes. Instead of fearing AI replacing physicians, we should focus on developing AI systems that are reliable, safe, and ethically sound, ensuring equitable access to AI-powered healthcare for all, and preparing health-care workforce for AI integration.&#160; </p><p>
<italic toggle="yes">3.&#160;&#160;&#160;The hybrid model</italic>
</p><p>This framework proposes a hybrid model that recognizes the need for a synergistic interaction between humans and AI within the health-care domain. This model necessitates the development of a hybrid entity comprising the physician and AI, as well as a complementary hybrid entity encompassing the patient and AI. The overarching objective of this integrated approach is to effectively address the core mission of medicine: to provide optimal treatment and compassionate care for all patients.</p><p>Furthermore, this hybrid model should actively contribute to mitigating and managing the current medical crisis. It is crucial to acknowledge that the indiscriminate integration of AI into health-care systems could inadvertently exacerbate existing challenges and potentially even contribute to a further deterioration of patient care. Within this framework, hybrid entities should strive to achieve several key objectives: reducing medical errors, fostering more humane and compassionate doctor-patient relationships, mitigating the trend of medicalization, and ultimately contributing to a significant improvement in overall public health outcomes.</p><p>
<italic toggle="yes">&#160;&#160;&#160;3.1.&#160;&#160;&#160;Fields where AI is more efficient</italic>
</p><p>Having identified the limitations of AI in clinical medicine, we can now explore areas where AI can be a valuable tool. Due to its lack of embodiment, AI excels in tasks that do not require physical interaction with patients, such as analyzing medical images and laboratory data. AI can process these data more efficiently and accurately than humans, identifying patterns that may be missed by the human eye. AI algorithms can analyze medical images like X-rays, MRIs, and CT scans with high accuracy, often outperforming human radiologists (<xref rid="B12" ref-type="bibr">12</xref>). In addition, AI-powered devices (wearable devices) can monitor patients remotely, collecting and analyzing data to identify potential health issues early on (<xref rid="B2" ref-type="bibr">2</xref>, <xref rid="B4" ref-type="bibr">4</xref>).</p><p>We must remember, however, that given AI's inherent limitations in comprehending the nuances of natural human language, it is crucial to avoid consulting AI directly for medical advice without the oversight of a qualified medical professional. Symptom-checking applications, for instance, frequently generate inaccurate or misleading recommendations due to this inherent limitation. Consequently, the most effective application of AI within the medical domain lies in areas that necessitate the utilization of explicit and formally structured knowledge. This includes cases where physicians require access to precise and up-to-date evidence to inform their clinical decision-making. In these specific contexts, AI can serve as a valuable adjunct to human expertise, providing physicians with seamless access to vast repositories of medical information and facilitating efficient and comprehensive searches. By leveraging these capabilities, AI has the potential to significantly mitigate medical errors that may arise from lack of medical knowledge.</p><p>AI can prove invaluable when physicians require a rapid and comprehensive assessment of diagnostic hypotheses, necessitating the retrieval and analysis of prior medical knowledge. For example, if a physician diagnoses a patient with chronic heart failure while simultaneously noting the patient's complaint of indigestion, AI can efficiently query relevant medical databases to determine the frequency and significance of indigestion as a potential comorbidity in patients with heart failure.</p><p>AI can play a crucial role in mitigating medical errors that may arise from complex rule-based scenarios, such as potential drug interactions. By meticulously analyzing vast repositories of medical data, AI can effectively identify and alert physicians to potential adverse drug reactions. For instance, AI can serve as a valuable safeguard by warning the physician that administering drug Y to a patient already receiving drug X may pose a significant risk of adverse health outcomes.</p><p>While it is commonly asserted that artificial intelligence lacks the capacity for empathy, research findings suggest that human physicians may also exhibit limitations in this crucial area. Studies have demonstrated that physicians, on average, interrupt patient narratives within a remarkably short timeframe, often within just 18 seconds (<xref rid="B13" ref-type="bibr">13</xref>). This observation raises the intriguing possibility that AI, despite its inherent limitations, could potentially serve as a valuable adjunct to enhance physician-patient communication.</p><p>Research consistently indicates that patients tend to exhibit a greater degree of receptivity when interacting with AI systems, primarily due to a perceived increase in autonomy in the process (<xref rid="B1" ref-type="bibr">1</xref>). The absence of interruptions from an AI system fosters an environment where patients feel more comfortable and empowered to freely express their concerns and experiences without feeling rushed or judged. This enhanced patient-AI interaction can, in turn, create a more conducive environment for physicians to cultivate genuine empathy. By initially engaging with AI, patients can freely articulate their concerns, allowing the AI system to generate a concise summary of their concerns and experiences for subsequent review by the physician. This approach has the potential to facilitate more empathetic and informed physician-patient interactions.</p><p>
<italic toggle="yes">&#160;&#160;&#160;3.2.&#160;&#160;&#160;Threads of AI</italic>
</p><p>When analyzing the role of artificial intelligence in clinical medicine, it's crucial to consider both sides of the clinical encounter. Research indicates that patients generally have a more favorable view of AI, while physicians often exhibit greater resistance (<xref rid="B1" ref-type="bibr">1</xref>). This resistance can be attributed to professional concerns, as well as anxieties about the time-consuming nature and novelty of this technology (<xref rid="B14" ref-type="bibr">14</xref>). Some of these concerns can be addressed through modifications to medical school curricula and professional regulations (<xref rid="B15" ref-type="bibr">15</xref>). However, some concerns are more profound and may compromise the authenticity of the patient-physician relationship.</p><p>One such concern is the proliferation of medical knowledge among the general public through AI interactions. Patients may use AI-generated information to second-guess their physicians and become more involved in clinical decision-making. Ironically, this increased involvement can undermine trust between patients and physicians and ultimately harm patients because of provoking health anxiety (<xref rid="B16" ref-type="bibr">16</xref> - <xref rid="B17" ref-type="bibr">17</xref>).</p><p>Another risk is the over-medicalization of human problems. Research suggests that society, rather than the medical profession, often drives the desire for medical solutions. The cultural inclination toward quick fixes can lead people to seek medical interventions for social issues that require broader societal changes. AI can exacerbate this trend by offering seemingly easy solutions to complex problems (<xref rid="B18" ref-type="bibr">18</xref>).</p><p>Finally, data ownership is a significant concern in this regard. As AI is often developed and controlled by private companies, the ownership of patient data becomes a critical issue (<xref rid="B19" ref-type="bibr">19</xref> - <xref rid="B22" ref-type="bibr">22</xref>). While AI has the potential to improve the patient-physician relationship, its introduction into healthcare can be harmful if the associated risks are not carefully managed.</p><p>
<italic toggle="yes">&#160;&#160;&#160;3.3.&#160;&#160;&#160;Hybrid model: patient companion or physician assistant</italic>
</p><p>Artificial intelligence is poised to revolutionize healthcare, but its precise role remains a subject of debate. Will AI primarily function as a patient companion, empowering individuals with personalized health management tools, or will it primarily serve as a physician assistant, augmenting the capabilities of health-care professionals? </p><p>
<italic toggle="yes">3.3.1.&#160;AI as a physician assistant</italic>
</p><p>AI is poised to revolutionize healthcare across multiple fronts (<xref rid="B23" ref-type="bibr">23</xref> - <xref rid="B24" ref-type="bibr">24</xref>). AI algorithms can analyze vast amounts of medical data, including medical images, lab results, and patient records, to assist physicians in diagnosing diseases with greater accuracy. AI-powered diagnostic tools can help identify subtle patterns and anomalies that may be missed by the human eye. Furthermore, AI can streamline workflows and increase efficiency by automating many time-consuming tasks for health-care professionals, such as scheduling appointments, managing patient records, and generating reports. This frees up physicians' time to focus on providing more direct patient care. Additionally, AI can personalize treatment plans by analyzing patient data to develop treatment strategies tailored to individual needs and medical histories. AI algorithms can consider a wide range of factors, including genetic information, lifestyle habits, and environmental factors, to recommend the most effective treatment options. Moreover, AI is playing an increasingly important role in drug discovery and development. AI algorithms can analyze vast amounts of data to identify potential drug targets, design new medications, and predict the effectiveness and safety of new therapies. Finally, AI-powered surgical robots and other AI-assisted surgical tools can enhance the accuracy and precision of surgical procedures, leading to improved patient outcomes and reduced complications.</p><p>Several significant challenges must be addressed to ensure the safe and ethical integration of AI within the health-care domain. The accuracy and reliability of AI-powered diagnostic tools heavily depend on the quality and integrity of the data used to train them. Inaccurate or biased data can lead to erroneous diagnoses and potentially harmful treatment recommendations. Furthermore, many AI algorithms are complex and difficult to understand, making it challenging to explain their decision-making processes to physicians and patients. This lack of transparency can hinder trust and impede the widespread adoption of AI-powered tools (<xref rid="B25" ref-type="bibr">25</xref>). The increasing automation of tasks by AI also raises concerns about potential job displacement for health-care professionals, such as medical assistants and radiologists (<xref rid="B26" ref-type="bibr">26</xref>). Finally, the ethical implications of AI-powered decision-making in healthcare require careful consideration and ongoing ethical discussions. These implications encompass a wide range of concerns, including the potential for algorithmic bias and the crucial role of human oversight in ensuring safe and responsible use of AI in health-care settings (<xref rid="B27" ref-type="bibr">27</xref> - <xref rid="B28" ref-type="bibr">28</xref>). </p><p>In sum, artificial intelligence, when employed as a physician's assistant, should be designed to collaborate in reducing medical errors, providing more accurate interpretations of patient data, and fostering a deeper level of empathy between the physician and the patient.</p><p>
<italic toggle="yes">3.3.2.&#160;AI as a patient companion</italic>
</p><p>AI has the potential to revolutionize how individuals manage their own health. As a patient companion, AI can act as a 24/7 health coach, providing personalized guidance on diet, exercise, and lifestyle choices. AI-powered apps can track individual health data, identify potential risks, and offer tailored recommendations to improve overall well-being. For example, an AI companion could analyze a user's activity levels, sleep patterns, and dietary habits to suggest personalized fitness plans and nutrition advice. AI can also significantly improve medication adherence rates. AI-powered reminders and personalized support systems can send timely alerts, track medication intake, and even identify potential drug interactions. Furthermore, AI-powered chatbots can provide emotional support and cognitive behavioral therapy techniques to individuals struggling with mental health issues. These AI companions can offer a safe and accessible platform for individuals to express their concerns, receive emotional support, and engage in self-guided therapeutic exercises. AI can also play a crucial role in early disease detection. By analyzing patient data from various sources, such as wearable devices and electronic health records, AI can identify early signs of potential health problems. This proactive approach can enable early intervention and improve health outcomes. For example, an AI companion could analyze a user's heart rate data to detect potential arrhythmias and alert them to seek medical attention. Finally, AI-powered telemedicine platforms can increase access to health-care services, particularly for individuals in remote or underserved areas. AI companions can facilitate virtual consultations with health-care professionals, provide remote monitoring of patient health, and even assist with basic triage (<xref rid="B29" ref-type="bibr">29</xref> - <xref rid="B30" ref-type="bibr">30</xref>).</p><p>However, the successful integration of AI as a patient companion necessitates careful consideration of several issues (<xref rid="B21" ref-type="bibr">21</xref> - <xref rid="B32" ref-type="bibr">32</xref>). The precision and dependability of health tools powered by AI are greatly influenced by the quality and integrity of the data used for their training process. Using incorrect or biased data will result in wrong diagnoses and potentially harmful treatments. Another issue is the complexity of AI algorithms and the fact that their decision-making processes are hard to explain to users, who may therefore hesitate to trust AI-powered health companions and refrain from adopting them. In addition, depending on AI for personal health management may lead to over-reliance and a decline in self-reliance and self-care abilities. It is crucial to strike a balance between AI-powered support and individual responsibility for health. Last but not least is concern over the ethical implications of using AI-powered companions, for instance the potential for data privacy breaches, the risk of algorithmic bias, the possibility of manipulation, and the impact on the doctor-patient relationship.</p><p>In summary, rather than encouraging patients&#8217; curiosity about their diagnosis and treatment, AI should facilitate the patients&#8217; ability to provide the most accurate and relevant information to their physician, thereby strengthening the doctor-patient relationship.</p></sec><sec sec-type="conclusions"><title>Conclusion</title><p>The preceding philosophical analysis reveals that the notion of AI entirely replacing human physicians is not a genuine problem that needs to be solved, but rather a conceptual misdirection. The inherent limitations of current and near-future AI systems, particularly their lack of embodied experience, their constrained understanding of the nuanced complexities of everyday language, and their fundamental inability to exercise true clinical judgment, underscore the irreplaceable role of human doctors in healthcare. Medicine, at its core, is a practice deeply rooted in the interpersonal dynamics of the doctor-patient relationship, demanding empathy, contextual awareness, and the application of tacit knowledge in clinical reasoning &#8211; qualities that continue to remain beyond the grasp of artificial intelligence. </p><p>Building upon these insights, I will argue that the notion of AI completely replacing human physicians is a flawed premise. Instead, the central challenge lies in fostering a synergistic collaboration between human expertise and the capabilities of AI within the health-care domain. This hybrid model must be carefully implemented to avoid unintentional exacerbation of the current medical crisis. While AI offers significant potential, its indiscriminate integration into health-care systems could have unintended consequences. Within this framework, the hybrid entities should prioritize the following key objectives: reducing medical errors, fostering more humane and compassionate doctor-patient relationships, mitigating the trend of over-medicalization, and ultimately contributing to a significant improvement in overall public health outcomes.</p><p>Furthermore, this paper emphasizes the importance of addressing ethical and societal concerns surrounding AI in healthcare. These include the potential for data privacy violations, algorithmic bias, and the over-medicalization of social issues. It also highlights the need for ongoing critical evaluation and public discourse to ensure the responsible and ethical development and implementation of AI in healthcare.</p><p>The current discourse surrounding artificial intelligence is often characterized by extreme positions, ranging from unbridled optimism to apocalyptic dread. However, it is likely that these initial reactions will gradually give way to more nuanced and balanced perspectives. Historical precedents suggest that technologies tend to evolve organically through a process of iterative development and refinement, shaped by both widespread use and critical evaluation. The ideas of Andrew Feenberg, a renowned philosopher of technology, can provide significant insights for future research into artificial intelligence in medicine. In his critical theory of technology, he suggests that technology is not simply a tool, but rather a dynamic and inherently uncertain process (<xref rid="B33" ref-type="bibr">33</xref> - <xref rid="B34" ref-type="bibr">34</xref>). Applying Feenberg's ideas to artificial intelligence in medicine can help us better understand the dynamic interplay between technology and health-care practices. Rather than viewing AI as a neutral tool with a singular path of development, we must recognize that its design and application are deeply intertwined with societal values and priorities. Consequently, the extent to which AI transforms medical practice &#8211; whether it primarily serves to augment human capabilities or potentially leads to more disruptive changes &#8211; will be affected by ongoing social discussions, ethical considerations, and the choices we collectively make regarding its implementation. This perspective reframes the integration of AI in medicine as a dynamic arena where different visions of the future of healthcare will inevitably contend. It is evident that addressing these questions and expanding upon these ideas will require significant future research efforts.</p></sec><sec><title>Funding</title><p>The author(s) received no financial support for the research, authorship, and/or publication of this article.</p></sec></body><back><sec><title>Notes:</title><p>
<bold>
<italic toggle="yes">Citation to this article:</italic>
</bold>
</p><p>
<italic toggle="yes">Monajemi A.</italic>
<italic toggle="yes">Why is the idea of AI completely replacing physicians a pseudo-problem? A philosophical analysis. J Med Ethics Hist Med. 2025; 18: 1.</italic></p><p>
<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://doi.org/10.18502/jmehm.v18i1.18814" ext-link-type="uri">https://doi.org/10.18502/jmehm.v18i1.18814 </ext-link>
</p></sec><sec sec-type="COI-statement"><title>Conflict of Interests</title><p>The author(s) declare no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p></sec><ref-list><title>References</title><ref id="B1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Briganti</surname><given-names>G</given-names></name><name name-style="western"><surname>Le</surname><given-names>Moine O</given-names></name></person-group><article-title>Artificial intelligence in medicine: today and tomorrow</article-title><source>Front Med (Lausanne).</source><year>2020</year><volume>5</volume><issue>7</issue><fpage>27</fpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.3389/fmed.2020.00027</pub-id><pub-id pub-id-type="pmcid">PMC7012990</pub-id><pub-id pub-id-type="pmid">32118012</pub-id></element-citation></ref><ref id="B2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Abdulnabi</surname><given-names>M</given-names></name><name name-style="western"><surname>Al-Haiqi</surname><given-names>A</given-names></name><name name-style="western"><surname>Kiah</surname><given-names>MLM</given-names></name><name name-style="western"><surname>Zaidan</surname><given-names>AA</given-names></name><name name-style="western"><surname>Zaidan</surname><given-names>BB</given-names></name><name name-style="western"><surname>Hussain</surname><given-names>M</given-names></name></person-group><article-title>A distributed framework for health information exchange using smartphone technologies</article-title><source> J Biomed Inform</source><year>2017</year><volume>69</volume><fpage>230</fpage><lpage>50</lpage><pub-id pub-id-type="pmid">28433825</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.jbi.2017.04.013</pub-id></element-citation></ref><ref id="B3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Topol</surname><given-names>EJ</given-names></name></person-group><article-title>A decade of digital medicine innovation</article-title><source> Sci Transl Med</source><year>2019</year><volume>11</volume><fpage>eaaw7610</fpage><pub-id pub-id-type="pmid">31243153</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1126/scitranslmed.aaw7610</pub-id></element-citation></ref><ref id="B4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Morawski</surname><given-names>K</given-names></name><name name-style="western"><surname>Ghazinouri</surname><given-names>R</given-names></name><name name-style="western"><surname>Krumme</surname><given-names>A</given-names></name><name name-style="western"><surname>Lauffenburger</surname><given-names>JC</given-names></name><name name-style="western"><surname>Lu</surname><given-names>Z</given-names></name><name name-style="western"><surname>Durfee</surname><given-names>E</given-names></name><etal/></person-group><article-title>Association of a smartphone application with medication adherence and blood pressure control: the MedISAFE-BP randomized clinical trial</article-title><source> JAMA Intern Med</source><year>2018</year><volume>178</volume><fpage>802</fpage><lpage>9</lpage><pub-id pub-id-type="pmid">29710289</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1001/jamainternmed.2018.0447</pub-id><pub-id pub-id-type="pmcid">PMC6145760</pub-id></element-citation></ref><ref id="B5"><label>5</label><element-citation publication-type="book"><person-group person-group-type="editor"><name name-style="western"><surname>Sadegh-Zadeh</surname><given-names>K</given-names></name></person-group><source>Handbook of analytic philosophy of medicine</source><year>2013</year><publisher-loc> Dordrecht</publisher-loc><publisher-name>Springer</publisher-name><fpage>121</fpage><lpage>398</lpage></element-citation></ref><ref id="B6"><label>6</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Gadamer</surname><given-names>HG</given-names></name></person-group><person-group person-group-type="translator"><name name-style="western"><surname>Gaiger</surname><given-names>J</given-names></name><name name-style="western"><surname>Walker</surname><given-names>N</given-names></name></person-group><source>The enigma of health</source><year>1996</year><publisher-loc>Stanford (CT)</publisher-loc><publisher-name>Stanford University Press</publisher-name><fpage>45</fpage><lpage>61</lpage></element-citation></ref><ref id="B7"><label>7</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Hubert</surname><given-names>L</given-names></name></person-group><source>Dreyfus: On the Internet (Thinking in Action)</source><year>2001</year><publisher-name>Routledge</publisher-name></element-citation></ref><ref id="B8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Fjelland</surname><given-names>R</given-names></name></person-group><article-title>Why general artificial intelligence will not be realized</article-title><source>Humanit Soc Sci Commun</source><year>2020</year><volume>7</volume><fpage>10</fpage></element-citation></ref><ref id="B9"><label>9</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Goodfellow</surname><given-names>I</given-names></name><name name-style="western"><surname>Bengio</surname><given-names>Y</given-names></name><name name-style="western"><surname>Courville</surname><given-names>A I</given-names></name></person-group><source>Deep Learning</source><year>2016</year><publisher-loc>Cambridge</publisher-loc><publisher-name>MIT Press</publisher-name><fpage>11</fpage><lpage>29</lpage></element-citation></ref><ref id="B10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Litman</surname><given-names>L</given-names></name><name name-style="western"><surname>Reber</surname><given-names>AS</given-names></name></person-group><source>Implicit cognition and thought. The Cambridge handbook of thinking and reasoning</source><year>2005</year><volume>858</volume><fpage>431</fpage><lpage>53</lpage></element-citation></ref><ref id="B11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sadegh-Zadeh</surname><given-names>K</given-names></name></person-group><article-title>Toward metamedicine</article-title><source> Metamedicine.</source><year>1980</year><volume>1</volume><fpage>3</fpage><lpage>10</lpage></element-citation></ref><ref id="B12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>X</given-names></name><name name-style="western"><surname>Faes</surname><given-names>L</given-names></name><name name-style="western"><surname>Kale</surname><given-names>AU</given-names></name><name name-style="western"><surname>Wagner</surname><given-names>SK</given-names></name><name name-style="western"><surname>Fu</surname><given-names>DJ</given-names></name><name name-style="western"><surname>Bruynseels</surname><given-names>A</given-names></name><etal/></person-group><article-title>A comparison of deep learning performance against health-care professionals in detecting diseases from medical imaging: a systematic review and meta-analysis</article-title><source> Lancet Digit Health.</source><year>2019</year><volume>1</volume><fpage>e271</fpage><lpage>97</lpage><pub-id pub-id-type="pmid">33323251</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/S2589-7500(19)30123-2</pub-id></element-citation></ref><ref id="B13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Schwartz</surname><given-names>B</given-names></name><name name-style="western"><surname>Sharpe</surname><given-names>K</given-names></name></person-group><article-title>Practical wisdom: The right way to do the right thing</article-title><source> Penguin</source><year>2011</year></element-citation></ref><ref id="B14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>West</surname><given-names>CP</given-names></name><name name-style="western"><surname>Dyrbye</surname><given-names>LN</given-names></name><name name-style="western"><surname>Shanafelt</surname><given-names>TD</given-names></name></person-group><article-title>Physician burnout: contributors, consequences and solutions</article-title><source> J Intern Med</source><year>2018</year><volume>283</volume><fpage>516</fpage><lpage>29</lpage><pub-id pub-id-type="pmid">29505159</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1111/joim.12752</pub-id></element-citation></ref><ref id="B15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Brouillette</surname><given-names>M</given-names></name></person-group><article-title>AI added to the curriculum for doctors-to-be</article-title><source> Nat Med.</source><year>2019</year><volume>25</volume><fpage>1808</fpage><lpage>9</lpage><pub-id pub-id-type="pmid">31806886</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41591-019-0648-3</pub-id></element-citation></ref><ref id="B16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Brown</surname><given-names>RJ</given-names></name><name name-style="western"><surname>Skelly</surname><given-names>N</given-names></name><name name-style="western"><surname>Chew&#8208;Graham</surname><given-names>CA</given-names></name></person-group><article-title>Online health research and health anxiety: A systematic review and conceptual integration</article-title><source> Clinical psychology: Science and practice</source><year>2020</year><volume>27</volume><issue>2</issue><fpage>e12299</fpage></element-citation></ref><ref id="B17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jungmann</surname><given-names>SM</given-names></name><name name-style="western"><surname>Brand</surname><given-names>S</given-names></name><name name-style="western"><surname>Kolb</surname><given-names>J</given-names></name><name name-style="western"><surname>Witth&#246;ft</surname><given-names>M</given-names></name><name name-style="western"><surname>Do</surname><given-names>Dr</given-names></name></person-group><article-title>Google and health apps have (comparable) side effects? An experimental study</article-title><source> Clinical Psychological Science</source><year>2020</year><volume>8</volume><issue>2</issue><fpage>306</fpage><lpage>17</lpage></element-citation></ref><ref id="B18"><label>18</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Goli</surname><given-names>F</given-names></name><name name-style="western"><surname>Monajemi</surname><given-names>A</given-names></name><name name-style="western"><surname>Ahmadzadeh,</surname><given-names>G.H</given-names></name><name name-style="western"><surname>Malekian,</surname><given-names>A</given-names></name></person-group><person-group person-group-type="editor"><name name-style="western"><surname>Goli,</surname><given-names>F</given-names></name></person-group><article-title>How to Prescribe Information: Health Education Without Health Anxiety and Nocebo Effects</article-title><source>Biosemiotic Medicine. Studies in Neuroscience, Consciousness and Spirituality</source><year>2016</year><volume>vol 5</volume><publisher-loc>Cham</publisher-loc><publisher-name>Springer</publisher-name><pub-id pub-id-type="doi">10.1007/978-3-319-35092-9_7.</pub-id></element-citation></ref><ref id="B19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Williamson</surname><given-names>JB</given-names></name></person-group><article-title>Preserving confidentiality and security of patient health care information</article-title><source> Top Health Inf Manage</source><year>1996</year><volume>16</volume><fpage>56</fpage><lpage>60</lpage><pub-id pub-id-type="pmid">10157662</pub-id></element-citation></ref><ref id="B20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Montgomery</surname><given-names>J</given-names></name></person-group><article-title>Data sharing and the idea of ownership</article-title><source> New Bioeth </source><year>2017</year><volume>23</volume><fpage>81</fpage><lpage>6</lpage><pub-id pub-id-type="pmid">28517982</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1080/20502877.2017.1314893</pub-id></element-citation></ref><ref id="B21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rodwin</surname><given-names>MA</given-names></name></person-group><article-title>The case for public ownership of patient data</article-title><source> JAMA.</source><year>2009</year><volume>302</volume><fpage>86</fpage><lpage>8</lpage><pub-id pub-id-type="pmid">19567445</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1001/jama.2009.965</pub-id></element-citation></ref><ref id="B22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mikk</surname><given-names>KA</given-names></name><name name-style="western"><surname>Sleeper</surname><given-names>HA</given-names></name><name name-style="western"><surname>Topol</surname><given-names>EJ</given-names></name></person-group><article-title>The pathway to patient data ownership and better health</article-title><source> JAMA.</source><year>2017</year><volume>318</volume><fpage>1433</fpage><lpage>4</lpage><pub-id pub-id-type="pmid">28973063</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1001/jama.2017.12145</pub-id></element-citation></ref><ref id="B23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Panch</surname><given-names>T</given-names></name><name name-style="western"><surname>Mattie</surname><given-names>H</given-names></name><name name-style="western"><surname>Celi</surname><given-names>LA</given-names></name></person-group><article-title>The &#8220;inconvenient truth&#8221; about AI in healthcare</article-title><source> NPJ digital medicine</source><year>2019</year><day>16</day><volume>2</volume><issue>1</issue><fpage>1</fpage><lpage>3</lpage><pub-id pub-id-type="pmid">31453372</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41746-019-0155-4</pub-id><pub-id pub-id-type="pmcid">PMC6697674</pub-id></element-citation></ref><ref id="B24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kelly</surname><given-names>CJ</given-names></name><name name-style="western"><surname>Karthikesalingam</surname><given-names>A</given-names></name><name name-style="western"><surname>Suleyman</surname><given-names>M</given-names></name><name name-style="western"><surname>Corrado</surname><given-names>G</given-names></name><name name-style="western"><surname>King</surname><given-names>D</given-names></name></person-group><article-title>Key challenges for delivering clinical impact with artificial intelligence</article-title><source> BMC Med.</source><year>2019</year><volume>17</volume><fpage>195</fpage><pub-id pub-id-type="pmid">31665002</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1186/s12916-019-1426-2</pub-id><pub-id pub-id-type="pmcid">PMC6821018</pub-id></element-citation></ref><ref id="B25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Al-Antari</surname><given-names>MA</given-names></name></person-group><article-title>Artificial intelligence for medical diagnostics&#8212;existing and future aI technology!</article-title><source> Diagnostics</source><year>2023</year><volume>13</volume><issue>4</issue><fpage>688</fpage><pub-id pub-id-type="pmid">36832175</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3390/diagnostics13040688</pub-id><pub-id pub-id-type="pmcid">PMC9955430</pub-id></element-citation></ref><ref id="B26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Topol</surname><given-names>EJ</given-names></name></person-group><article-title>High-performance medicine: the convergence of human and artificial intelligence</article-title><source> Nat Med.</source><year>2019</year><volume>25</volume><fpage>44</fpage><lpage>56</lpage><pub-id pub-id-type="pmid">30617339</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41591-018-0300-7</pub-id></element-citation></ref><ref id="B27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Verghese</surname><given-names>A</given-names></name><name name-style="western"><surname>Shah</surname><given-names>NH</given-names></name><name name-style="western"><surname>Harrington</surname><given-names>RA</given-names></name></person-group><article-title>What this computer needs is a physician: humanism and artificial intelligence</article-title><source> JAMA.</source><year>2018</year><volume>319</volume><fpage>19</fpage><lpage>20</lpage><pub-id pub-id-type="pmid">29261830</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1001/jama.2017.19198</pub-id></element-citation></ref><ref id="B28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Varlamov</surname><given-names>OO</given-names></name><name name-style="western"><surname>Chuvikov</surname><given-names>DA</given-names></name><name name-style="western"><surname>Adamova</surname><given-names>LE</given-names></name><name name-style="western"><surname>Petrov</surname><given-names>MA</given-names></name><name name-style="western"><surname>Zabolotskaya</surname><given-names>IK</given-names></name><name name-style="western"><surname>Zhilina</surname><given-names>TN</given-names></name></person-group><article-title>Logical, philosophical and ethical aspects of AI in medicine</article-title><source> Int J Mach Learn Comput</source><year>2019</year><volume>9</volume><issue>6</issue><fpage>868</fpage></element-citation></ref><ref id="B29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Acampora</surname><given-names>G</given-names></name><name name-style="western"><surname>Cook</surname><given-names>DJ</given-names></name><name name-style="western"><surname>Rashidi</surname><given-names>P</given-names></name><name name-style="western"><surname>Vasilakos</surname><given-names>AV</given-names></name></person-group><article-title>A survey on ambient intelligence in health care</article-title><source> Proc IEEE Inst Electr Electron Eng</source><year>2013</year><volume>101</volume><fpage>2470</fpage><lpage>94</lpage><pub-id pub-id-type="pmid">24431472</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/JPROC.2013.2262913</pub-id><pub-id pub-id-type="pmcid">PMC3890262</pub-id></element-citation></ref><ref id="B30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Orth</surname><given-names>M</given-names></name><name name-style="western"><surname>Averina</surname><given-names>M</given-names></name><name name-style="western"><surname>Chatzipanagiotou</surname><given-names>S</given-names></name><name name-style="western"><surname>Faure</surname><given-names>G</given-names></name><name name-style="western"><surname>Haushofer</surname><given-names>A</given-names></name><name name-style="western"><surname>Kusec</surname><given-names>V</given-names></name><etal/></person-group><article-title>Opinion: redefining the role of the physician in laboratory medicine in the context of emerging technologies, personalised medicine and patient autonomy ('4P medicine')</article-title><source> J Clin Pathol.</source><year>2019</year><volume>72</volume><fpage>191</fpage><lpage>7</lpage><pub-id pub-id-type="pmid">29273576</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1136/jclinpath-2017-204734</pub-id><pub-id pub-id-type="pmcid">PMC6580792</pub-id></element-citation></ref><ref id="B31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mittelstadt</surname><given-names>B</given-names></name></person-group><article-title>Ethics of the health-related internet of things: a narrative review</article-title><source> Ethics Informat Technol.</source><year>2017</year><volume>19</volume><fpage>157</fpage><lpage>75</lpage></element-citation></ref><ref id="B32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bennett</surname><given-names>MT</given-names></name><name name-style="western"><surname>Maruyama</surname><given-names>Y</given-names></name></person-group><article-title>Philosophical specification of empathetic ethical artificial intelligence</article-title><source> IEEE Trans Cogn Dev Syst.</source><year>2021</year><day>26</day><volume>14</volume><issue>2</issue><fpage>292</fpage><lpage>300</lpage></element-citation></ref><ref id="B33"><label>33</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Feenberg</surname><given-names>A</given-names></name></person-group><source>Questioning technology</source><year>2012</year><publisher-name>Routledge</publisher-name><fpage>177</fpage><lpage>180</lpage></element-citation></ref><ref id="B34"><label>34</label><element-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Feenberg</surname><given-names>A</given-names></name></person-group><source>Transforming technology: A critical theory revisited</source><publisher-name>Oxford University Press</publisher-name><fpage>162</fpage><lpage>191</lpage></element-citation></ref></ref-list></back></article></pmc-articleset>